

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Core Features &mdash; Transformers4Rec  documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Examples" href="examples/index.html" />
    <link rel="prev" title="Transformers4Rec" href="getting_started.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> Transformers4Rec
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="getting_started.html">Getting Started</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Core features</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#the-relationship-between-nlp-and-recsys">The relationship between NLP and RecSys</a></li>
<li class="toctree-l2"><a class="reference internal" href="#integration-with-huggingface-transformers">Integration with HuggingFace Transformers</a></li>
<li class="toctree-l2"><a class="reference internal" href="#flexibility-in-model-architecture">Flexibility in Model Architecture</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#features-processing">Features Processing</a></li>
<li class="toctree-l3"><a class="reference internal" href="#sequence-masking">Sequence Masking</a></li>
<li class="toctree-l3"><a class="reference internal" href="#sequence-processing">Sequence Processing</a></li>
<li class="toctree-l3"><a class="reference internal" href="#prediction-head">Prediction head</a></li>
<li class="toctree-l3"><a class="reference internal" href="#tying-embeddings">Tying embeddings</a></li>
<li class="toctree-l3"><a class="reference internal" href="#regularization">Regularization</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#training-and-evaluation">Training and evaluation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#data-loading">Data loading</a></li>
<li class="toctree-l3"><a class="reference internal" href="#pytorch-training">PyTorch Training</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#tensorflow-training">Tensorflow Training</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#evaluation">Evaluation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#incremental-evaluation">Incremental Evaluation</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#end-to-end-pipeline-with-merlin">End-to-end pipeline with Merlin</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#integration-with-nvtabular">Integration with NVTabular</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#outputs">Outputs</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#integration-with-triton-inference-server">Integration with Triton Inference Server</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="examples/index.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="api/modules.html">API Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="resources.html">Additional Resources</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Transformers4Rec</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Core Features</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/core_features.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="core-features">
<h1>Core Features<a class="headerlink" href="#core-features" title="Permalink to this headline">¶</a></h1>
<div class="section" id="the-relationship-between-nlp-and-recsys">
<h2>The relationship between NLP and RecSys<a class="headerlink" href="#the-relationship-between-nlp-and-recsys" title="Permalink to this headline">¶</a></h2>
<p>Over the past decade there has been a trend toward leveraging and adapting approaches proposed by Natural Language Processing (NLP) research like Word2Vec, GRU, and Attention for recommender systems (RecSys). The phenomena is especially noticeable for sequential and session-based recommendation where the sequential processing of users interactions is analogous to the language modeling (LM) task and many key RecSys architectures have been adapted from NLP, like GRU4Rec – the seminal Recurrent Neural Network (RNN)-based architecture for session-based recommendation.</p>
<p>More recently, Transformer architectures have become the dominant technique over convolutional and recurrent neural networks for language modeling tasks. Because of their efficient parallel training, these architectures scale well with training data and model size, and are effective at modeling long-range sequences.</p>
<p>Transformers have similarly been applied to sequential recommendation in architectures like <a class="reference external" href="https://arxiv.org/abs/1808.09781">SASRec</a>, <a class="reference external" href="https://arxiv.org/abs/1904.06690">BERT4Rec</a> and <a class="reference external" href="https://arxiv.org/pdf/1905.06874.pdf%C2%A0">BST</a>, providing higher accuracy than architectures based on CNN and RNNs, as can be seen in their reported experiments and also in our <a class="reference external" href="https://github.com/NVIDIA-Merlin/publications/blob/main/2021_acm_recsys_transformers4rec/recsys21_transformers4rec_paper.pdf">ACM RecSys’21 paper</a>.</p>
<p>You can read more about this relationship between NLP and RecSys and the evolution of the architectures for sequential and session-based recommendation towards Transformers in our <a class="reference external" href="https://github.com/NVIDIA-Merlin/publications/blob/main/2021_acm_recsys_transformers4rec/recsys21_transformers4rec_paper.pdf">paper</a> too.</p>
<div style="text-align: center; margin: 20pt"><img src="_images/nlp_x_recsys.png" alt="A timeline illustrating the influence of NLP research in Recommender Systems" style="width:800px;"/><br><figcaption style="font-style: italic;">Fig. 1 - A timeline illustrating the influence of NLP research in Recommender Systems, from the <a href="https://github.com/NVIDIA-Merlin/publications/blob/main/2021_acm_recsys_transformers4rec/recsys21_transformers4rec_paper.pdf)">Transformers4Rec paper</a></figcaption></div></div>
<div class="section" id="integration-with-huggingface-transformers">
<h2>Integration with HuggingFace Transformers<a class="headerlink" href="#integration-with-huggingface-transformers" title="Permalink to this headline">¶</a></h2>
<p>Transformers4Rec integrates with the <a class="reference external" href="https://github.com/huggingface/transformers">HuggingFace (HF) Transformers</a> library, allowing RecSys researchers and practitioners to easily experiment with the latest and state-of-the-art NLP Transformer architectures for sequential and session-based recommendation tasks and deploy those models into production.</p>
<p>The HF Transformers was <em>“established with the goal of opening up advancements in NLP to the wider machine learning community”</em>. It has become very popular among NLP researchers and practitioners (more than 900 contributors), providing standardized implementations of the state-of-the-art Transformer architectures (more than 68 and counting) produced by the research community, often within days or weeks of their publication.</p>
<p>HF Transformers is designed for both research and production. Models are composed of three building blocks: (a) a tokenizer, which converts raw text to sparse index encodings; (b) a transformer architecture; and (c) a head for NLP tasks, like Text Classification, Generation, Sentiment Analysis, Translation, Summarization, among others.</p>
<p>In Transformers4Rec we leverage from HF Transformers only the transformer architectures building block (b) and their configuration classes. Transformers4Rec provides additional blocks necessary for recommendation, e.g., input features normalization and aggregation, and heads for recommendation and sequence classification/prediction. We also extend their <code class="docutils literal notranslate"><span class="pre">Trainer</span></code> class to allow for the evaluation with RecSys metrics.</p>
</div>
<div class="section" id="flexibility-in-model-architecture">
<h2>Flexibility in Model Architecture<a class="headerlink" href="#flexibility-in-model-architecture" title="Permalink to this headline">¶</a></h2>
<p>Transformers4Rec provides modularized building blocks that can be combined with plain PyTorch modules and Keras layers. This provides a great flexibility in the model definition, as you can use the blocks to build custom architectures, e.g., with multiple towers, multiple heads and losses (multi-task).</p>
<p>In Fig. 2, we provide a reference architecture for next-item prediction with Transformers, that can be used for both sequential and session-based recommendation. We can divide that reference architecture in four conceptual layers, described next.</p>
<div style="text-align: center; margin: 20pt"><img src="_images/transformers4rec_metaarchitecture.png" alt="Transformers4Rec meta-architecture" style="width:600px;"/><br><figcaption style="font-style: italic;">Fig. 2 - Transformers4Rec meta-architecture</figcaption></div><div class="section" id="features-processing">
<h3>Features Processing<a class="headerlink" href="#features-processing" title="Permalink to this headline">¶</a></h3>
<p>Here the input features are processed. Categorical features are represented by embeddings. Numerical features can be represented as a scalar, projected by a fully-connected (FC) layer to multiple dimensions, or represented as a weighted average of embeddings by the technique Soft One-Hot embeddings (more info in our <a class="reference external" href="https://github.com/NVIDIA-Merlin/publications/blob/main/2021_acm_recsys_transformers4rec/Appendices/Appendix_A-Techniques_used_in_Transformers4Rec_Meta-Architecture.md">paper online appendix</a>).</p>
<p>The features are optionally normalized (with layer normalization) and then aggregated. The current feature aggregation options are:</p>
<ul class="simple">
<li><p><strong>Concat</strong> - Concatenation of the features</p></li>
<li><p><strong>Element-wise sum</strong> - Features are summed. For that, all features must have the same dimension, i.e. categorical embeddings must have the same dim and continuous features are projected to that dim.</p></li>
<li><p><strong>Element-wise sum &amp; item multiplication</strong> - Similar to <em>Element-wise sum</em>, as all features are summed. except for the item id embedding, which is multiplied by the other features sum. The aggregation formula is available in our <a class="reference external" href="https://github.com/NVIDIA-Merlin/publications/blob/main/2021_acm_recsys_transformers4rec/recsys21_transformers4rec_paper.pdf">paper</a>.</p></li>
</ul>
<p>The core class of this module is the <code class="docutils literal notranslate"><span class="pre">TabularSequenceFeatures</span></code>, which is responsible to process and aggregate all features and outputs <em>interaction embeddings</em>. It can be instantiated from a dataset schema (<code class="docutils literal notranslate"><span class="pre">from_schema()</span></code>), which directly creates all the necessary layers to represent categorical and continuous features. In addition, it has options to aggregate the sequential features, to prepare masked labels, depending on the chosen sequence masking approach (see next section)).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">transformers4rec.torch</span> <span class="kn">import</span> <span class="n">TabularSequenceFeatures</span>
<span class="n">tabular_inputs</span> <span class="o">=</span> <span class="n">TabularSequenceFeatures</span><span class="o">.</span><span class="n">from_schema</span><span class="p">(</span>
        <span class="n">schema</span><span class="p">,</span>
        <span class="n">max_sequence_length</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
        <span class="n">d_output</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
        <span class="n">aggregation</span><span class="o">=</span><span class="s2">&quot;concat&quot;</span><span class="p">,</span>
        <span class="n">masking</span><span class="o">=</span><span class="s2">&quot;clm&quot;</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="sequence-masking">
<h3>Sequence Masking<a class="headerlink" href="#sequence-masking" title="Permalink to this headline">¶</a></h3>
<p>Transformer architectures can be trained in different ways. Depending of the training method, there is a specific masking schema. The masking schema sets the items to be predicted (labels) and mask (hide) some positions of the sequence that cannot be used by the Transformer layers for prediction. Currently supports the following training approaches, inspired by NLP:</p>
<ul class="simple">
<li><p><strong>Causal LM (<code class="docutils literal notranslate"><span class="pre">masking=&quot;clm&quot;</span></code>)</strong> - Predicts the next item based on past positions of the sequence. Future positions are masked.</p></li>
<li><p><strong>Masked LM (<code class="docutils literal notranslate"><span class="pre">masking=&quot;mlm&quot;</span></code>)</strong> - Randomly select some positions of the sequence to be predicted, which are masked. The Transformer layer is allowed to use positions on the right (future information) during training. During inference, all past items are visible for the Transformer layer, which tries to predict the next item.</p></li>
<li><p><strong>Permutation LM (<code class="docutils literal notranslate"><span class="pre">masking=&quot;plm&quot;</span></code>)</strong> - Uses a permutation factorization at the level of the self-attention layer to define the accessible bidirectional context</p></li>
<li><p><strong>Replacement Token Detection (<code class="docutils literal notranslate"><span class="pre">masking=&quot;rtd&quot;</span></code>)</strong> - Uses MLM to randomly select some items, but replaces them by random tokens. Then, a discriminator model (that can share the weights with the generator or not), is asked to classify whether the item at each position belongs or not to the original sequence. The generator-discriminator architecture was jointly trained using Masked LM and RTD tasks.</p></li>
</ul>
</div>
<div class="section" id="sequence-processing">
<h3>Sequence Processing<a class="headerlink" href="#sequence-processing" title="Permalink to this headline">¶</a></h3>
<p>Processes the input sequences of interaction vectors. It can the <code class="docutils literal notranslate"><span class="pre">RNNBlock</span></code> for RNN architectures (e.g. LSTM or GRU) or the <code class="docutils literal notranslate"><span class="pre">TransformerBlock</span></code> for supported Transformer architectures.</p>
<p>In the following example, a <code class="docutils literal notranslate"><span class="pre">SequentialBlock</span></code> module is defined connecting the output of the <code class="docutils literal notranslate"><span class="pre">TabularSequenceFeatures</span></code> (inputs), with a MLP projection to 64 dim (to match the Transformer <code class="docutils literal notranslate"><span class="pre">d_model</span></code>) with an XLNet transformer block with 2 layers (4 heads each).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">transformers4rec.config</span> <span class="kn">import</span> <span class="n">transformer</span>
<span class="kn">from</span> <span class="nn">transformers4rec.torch</span> <span class="kn">import</span> <span class="n">MLPBlock</span><span class="p">,</span> <span class="n">SequentialBlock</span><span class="p">,</span> <span class="n">TransformerBlock</span>

<span class="c1"># Configures the XLNet Transformer architecture</span>
<span class="n">transformer_config</span> <span class="o">=</span> <span class="n">transformer</span><span class="o">.</span><span class="n">XLNetConfig</span><span class="o">.</span><span class="n">build</span><span class="p">(</span>
    <span class="n">d_model</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">n_head</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">n_layer</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">total_seq_length</span><span class="o">=</span><span class="mi">20</span>
<span class="p">)</span>

<span class="c1"># Defines the model body including: inputs, masking, projection and transformer block.</span>
<span class="n">model_body</span> <span class="o">=</span> <span class="n">SequentialBlock</span><span class="p">(</span>
    <span class="n">tabular_inputs</span><span class="p">,</span> 
    <span class="n">torch4rec</span><span class="o">.</span><span class="n">MLPBlock</span><span class="p">([</span><span class="mi">64</span><span class="p">]),</span> 
    <span class="n">torch4rec</span><span class="o">.</span><span class="n">TransformerBlock</span><span class="p">(</span><span class="n">transformer_config</span><span class="p">,</span> <span class="n">masking</span><span class="o">=</span><span class="n">inputs</span><span class="o">.</span><span class="n">masking</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="prediction-head">
<h3>Prediction head<a class="headerlink" href="#prediction-head" title="Permalink to this headline">¶</a></h3>
<p>The library supports the following prediction heads. They can have multiple losses, that can be combined for multi-task learning and multiple metrics.</p>
<ul class="simple">
<li><p><strong>Item Prediction</strong> - Predicts items for a given sequence of interactions. During training it can be the next item or randomly selected items, depending on the masking scheme. For inference it is meant to always predict the next interacted item. Currently cross-entropy and some pairwise losses are supported.</p></li>
<li><p><strong>Classification</strong> - Predicts a categorical feature using the whole sequence. In the context of recommendation, it can be used to predict for example if the user is going to abandon a product added to cart or proceed to its purchase.</p></li>
<li><p><strong>Regression</strong> - Predicts a continuous feature using the whole sequence. The label could be for example the elapsed time until the user returns to a service.</p></li>
</ul>
<p>In the following example, it is instantiated a head with the pre-defined <code class="docutils literal notranslate"><span class="pre">model_body</span></code> for the <code class="docutils literal notranslate"><span class="pre">NextItemPredictionTask</span></code>. That head enables the <code class="docutils literal notranslate"><span class="pre">weight_tying</span></code> option, which is described in the next section.<br />Decoupling model bodies and heads allow for a flexible model architecture definition, as it allows for multiple towers and/or heads. Finally, the <code class="docutils literal notranslate"><span class="pre">Model</span></code> class combines the heads and wraps the whole model.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">transformers4rec.torch</span> <span class="kn">import</span> <span class="n">Head</span><span class="p">,</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="nn">transformers4rec.torch.model.head</span> <span class="kn">import</span> <span class="n">NextItemPredictionTask</span>

<span class="c1"># Defines the head related to next item prediction task </span>
<span class="n">head</span> <span class="o">=</span> <span class="n">Head</span><span class="p">(</span>
    <span class="n">model_body</span><span class="p">,</span>
    <span class="n">NextItemPredictionTask</span><span class="p">(</span><span class="n">weight_tying</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">hf_format</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
    <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Get the end-to-end Model class </span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">head</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="tying-embeddings">
<h3>Tying embeddings<a class="headerlink" href="#tying-embeddings" title="Permalink to this headline">¶</a></h3>
<p>For <code class="docutils literal notranslate"><span class="pre">NextItemPredictionTask</span></code>, it is available an option called <strong>Tying Embeddings</strong>, proposed originally by the NLP community to tie the weights of the input (item id) embedding matrix with the output projection layer. <strong>Tying Embeddings</strong> showed to be a very effective technique in extensive experimentation for competitions and empirical analysis (more details in our <a class="reference external" href="https://github.com/NVIDIA-Merlin/publications/blob/main/2021_acm_recsys_transformers4rec/recsys21_transformers4rec_paper.pdf">paper</a> and its <a class="reference external" href="https://github.com/NVIDIA-Merlin/publications/blob/main/2021_acm_recsys_transformers4rec/Appendices/Appendix_A-Techniques_used_in_Transformers4Rec_Meta-Architecture.md">online appendix</a>). You can enable this option as follows.</p>
</div>
<div class="section" id="regularization">
<h3>Regularization<a class="headerlink" href="#regularization" title="Permalink to this headline">¶</a></h3>
<p>The library supports a number of regularization techniques like Dropout, Weight Decay, Softmax Temperature Scaling, Stochastic Shared Embeddings, and Label Smoothing. In our extensive experimentation hypertuning all regularization techniques for different dataset we found that the Label Smoothing was particularly useful at improving both train and validation accuracy and better calibrating the predictions.</p>
<p>More details of the options available for each building block can be found in our <strong>API Documentation</strong>.</p>
</div>
</div>
<div class="section" id="training-and-evaluation">
<h2>Training and evaluation<a class="headerlink" href="#training-and-evaluation" title="Permalink to this headline">¶</a></h2>
<div class="section" id="data-loading">
<h3>Data loading<a class="headerlink" href="#data-loading" title="Permalink to this headline">¶</a></h3>
<p>Transformers4Rec leverages by default the NVTabular dataloader for GPU-accelerated loading of preprocessed data stored in Parquet format, which is a suitable format for being structured and queryable.
The data in Parquet files are directly loaded to GPU memory as feature tensors. CPUs are also supported when GPUs are not available.</p>
<p>The following example uses the NVTabular data loader, wrapped by the <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code> that automatically sets some options from the dataset schema. Optionally the <code class="docutils literal notranslate"><span class="pre">PyarrowDataLoader</span></code> can also be used as a basic option, but it is slower and works only for small datasets, as the full data is loaded to CPU memory.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">train_loader</span> <span class="o">=</span> <span class="n">transformers4rec</span><span class="o">.</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data_utils</span><span class="o">.</span><span class="n">DataLoader</span><span class="o">.</span><span class="n">from_schema</span><span class="p">(</span>
        <span class="n">schema</span><span class="p">,</span>
        <span class="n">paths_or_dataset</span><span class="o">=</span><span class="n">train_path</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">TrainingArguments</span><span class="o">.</span><span class="n">train_batch_size</span><span class="p">,</span>
        <span class="n">drop_last</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="pytorch-training">
<h3>PyTorch Training<a class="headerlink" href="#pytorch-training" title="Permalink to this headline">¶</a></h3>
<p>For PyTorch we extend the HF Transformers <code class="docutils literal notranslate"><span class="pre">Trainer</span></code> class, but keep its <code class="docutils literal notranslate"><span class="pre">train()</span></code> method. That means that we leverage the efficient training implementation from that library, which manages for example half-precision (FP16) and multi-GPU training.</p>
<p>Two <a class="reference external" href="https://pytorch.org/tutorials/intermediate/ddp_tutorial.html">approaches</a> are available for PyTorch multi-GPU training: <code class="docutils literal notranslate"><span class="pre">DataParallel</span></code> and <code class="docutils literal notranslate"><span class="pre">DistributedDataParallel</span></code>. <code class="docutils literal notranslate"><span class="pre">DataParallel</span></code> uses a single process and multiple threads on a single machine. <code class="docutils literal notranslate"><span class="pre">DistributedDataParallel</span></code> is more efficient for assigning separate processes for each GPU. Transformers4Rec supports both training approaches when using the NVTabular Dataloader.</p>
<p><strong>TODO: Update the previous statement if we cannot have <code class="docutils literal notranslate"><span class="pre">DistributedDataParallel</span></code> working completely with our Data loader.</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">transformers4rec.config.trainer</span> <span class="kn">import</span> <span class="n">T4RecTrainingArguments</span>
<span class="kn">from</span> <span class="nn">transformers4rec.torch</span> <span class="kn">import</span> <span class="n">Trainer</span>

<span class="n">training_args</span> <span class="o">=</span> <span class="n">T4RecTrainingArguments</span><span class="p">(</span>
            <span class="n">output_dir</span><span class="o">=</span><span class="s2">&quot;./tmp&quot;</span><span class="p">,</span>
            <span class="n">avg_session_length</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
            <span class="n">num_train_epochs</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>            
            <span class="n">fp16</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>

<span class="n">recsys_trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
    <span class="n">args</span><span class="o">=</span><span class="n">training_args</span><span class="p">,</span>
    <span class="n">train_dataloader</span><span class="o">=</span><span class="n">train_loader</span><span class="p">,</span>
    <span class="n">eval_dataloader</span><span class="o">=</span><span class="n">eval_loader</span><span class="p">,</span>
<span class="p">)</span>     

<span class="n">recsys_trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</pre></div>
</div>
<p>You can optionally get the data loaders instantiated by the <code class="docutils literal notranslate"><span class="pre">Trainer</span></code> when the following arguments are provided.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">training_args</span> <span class="o">=</span> <span class="n">T4RecTrainingArguments</span><span class="p">(</span>
            <span class="o">...</span><span class="p">,</span>
            <span class="n">data_loader_engine</span><span class="o">=</span><span class="s2">&quot;nvtabular&quot;</span><span class="p">,</span>
            <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
            <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>            
        <span class="p">)</span>

<span class="c1"># Instantiates the train and eval dataloader</span>
<span class="n">Trainer</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
    <span class="n">args</span><span class="o">=</span><span class="n">training_args</span><span class="p">,</span>
    <span class="n">train_dataset_or_path</span><span class="o">=</span><span class="n">train_path</span><span class="p">,</span>
    <span class="n">eval_dataset_or_path</span><span class="o">=</span><span class="n">eval_path</span><span class="p">,</span>   
<span class="p">)</span>     
</pre></div>
</div>
</div>
</div>
<div class="section" id="tensorflow-training">
<h2>Tensorflow Training<a class="headerlink" href="#tensorflow-training" title="Permalink to this headline">¶</a></h2>
<p><strong>TODO: Describe the training options for TF</strong></p>
<p><strong>TODO: Include code snippets for training with TF</strong></p>
<div class="section" id="evaluation">
<h3>Evaluation<a class="headerlink" href="#evaluation" title="Permalink to this headline">¶</a></h3>
<p>For the Item Prediction head, top-N metrics comonly used in <a class="reference external" href="https://en.wikipedia.org/wiki/Evaluation_measures_(information_retrieval)">Information Retrieval</a> and RecSys are supported for evaluation:</p>
<p>Top-N metrics</p>
<ul class="simple">
<li><p><strong>Precision&#64;n</strong> - Computes the percentage of the top-N recommended items which are relevant (labels)</p></li>
<li><p><strong>Recall&#64;n</strong> - Computes the percentage of elevant items (labels) are present among the top-N recommended items</p></li>
</ul>
<p>Ranking metrics</p>
<ul class="simple">
<li><p><strong>NDCG&#64;n</strong> - Normalized Discounted Cumulative Gain at cut-off N of the recommendation list</p></li>
<li><p><strong>MAP&#64;n</strong> - Mean Average Precision at cut-off N of the recommendation list</p></li>
</ul>
<p>During training, the metrics are computed each N steps for both training and evaluation sets. During evaluation, the metrics are computed for all evaluation batches and averaged.</p>
<div class="section" id="incremental-evaluation">
<h4>Incremental Evaluation<a class="headerlink" href="#incremental-evaluation" title="Permalink to this headline">¶</a></h4>
<p>You can implement incremental evaluation by splitting your data into time windows (e.g. week, day or hour). Then you can have a loop that trains (or fine-tune a pre-trained model) with session of time window T and evaluates on sessions of time window T+1.</p>
<p>Here is an example which assumes daily data is split in folders. There is a loop that iterates over the days, trains the model (or fine-tunes the model pre-trained in the previous day) and evaluates with data of the next day.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Iterates over parquet files with daily data</span>
<span class="k">for</span> <span class="n">time_index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">7</span><span class="p">):</span>    
    <span class="n">train_paths</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;./data/day-</span><span class="si">{</span><span class="n">time_index</span><span class="si">}</span><span class="s2">/data.parquet&quot;</span><span class="p">)</span>
    <span class="n">eval_paths</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;./data/day-</span><span class="si">{</span><span class="n">time_index</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/data.parquet&quot;</span><span class="p">)</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Training with day </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">time_index</span><span class="p">))</span>
    <span class="n">trainer</span><span class="o">.</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">train_paths</span>
    <span class="n">trainer</span><span class="o">.</span><span class="n">reset_lr_scheduler</span><span class="p">()</span>
    <span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Evaluating with day </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">time_index</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">trainer</span><span class="o">.</span><span class="n">eval_dataset</span> <span class="o">=</span> <span class="n">eval_paths</span>
    <span class="n">train_metrics</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">metric_key_prefix</span><span class="o">=</span><span class="s1">&#39;eval&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">train_metrics</span><span class="p">)</span>
    <span class="n">trainer</span><span class="o">.</span><span class="n">wipe_memory</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="end-to-end-pipeline-with-merlin">
<h2>End-to-end pipeline with Merlin<a class="headerlink" href="#end-to-end-pipeline-with-merlin" title="Permalink to this headline">¶</a></h2>
<p>Transformers4Rec has a first-class integration with NVIDIA Merlin components, to build end-to-end GPU accelerated pipelines for sequential and session-based recommendation.</p>
<div style="text-align: center; margin: 20pt"><img src="_images/pipeline.png" alt="Pipeline for Sequential and Session-based recommendation using NVIDIA Merlin components" style="width:600px;"/><br><figcaption style="font-style: italic;">Fig.3 -cPipeline for Sequential and Session-based recommendation using NVIDIA Merlin components</figcaption></div><div class="section" id="integration-with-nvtabular">
<h3>Integration with NVTabular<a class="headerlink" href="#integration-with-nvtabular" title="Permalink to this headline">¶</a></h3>
<p><a class="reference external" href="https://github.com/NVIDIA/NVTabular/">NVTabular</a> is a feature engineering and preprocessing library for tabular data that is designed to easily manipulate terabyte scale datasets and train deep learning (DL) based recommender systems.</p>
<p>It has some popular <a class="reference external" href="https://nvidia.github.io/NVTabular/main/api/index.html">techniques</a> to deal with categorical and numerical features like <code class="docutils literal notranslate"><span class="pre">Categorify</span></code>, <code class="docutils literal notranslate"><span class="pre">Normalize</span></code>, <code class="docutils literal notranslate"><span class="pre">Bucketize</span></code>, <code class="docutils literal notranslate"><span class="pre">TargetEncoding</span></code>, <code class="docutils literal notranslate"><span class="pre">DifferenceLag</span></code>, to name a few supported, and also allow for the definition of custom transformations (<code class="docutils literal notranslate"><span class="pre">LambdaOp</span></code>) using cuDF data frame operations.</p>
<p>Usually the input RecSys datasets contains one example per user interaction. For sequential recommendation, the training example is a sequence of user interactions, and for session-based recommendation it is a sequence of session interactions. In practice, each interaction-level feature needs to be converted to a sequence grouped by user/session and their sequence length must match, as each position of the sequence correspond to one interaction. You can see in Fig. 4 how the preprocessed parquet should look like.</p>
<div style="text-align: center; margin: 20pt"><img src="_images/preproc_data_example.png" alt="Example of preprocessed parquet file" style="width:800px;"/><br><figcaption style="font-style: italic;">Example of preprocessed parquet file</figcaption></div><p>NVTabular can easily prepare such data with the <a class="reference external" href="https://nvidia.github.io/NVTabular/main/api/ops/groupby.html">Groupby</a> op, which allows grouping by a categorical column (e.g. user id, session id), sorting by another column (e.g. timestamp) and aggregating other columns as sequences (<code class="docutils literal notranslate"><span class="pre">list</span></code>) or by taking the <code class="docutils literal notranslate"><span class="pre">first</span></code> or <code class="docutils literal notranslate"><span class="pre">last</span></code> element of the sequence, as exemplified below.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">groupby_features</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s1">&#39;user_id&#39;</span><span class="p">,</span> <span class="s1">&#39;session_id&#39;</span><span class="p">,</span> <span class="s1">&#39;product_id&#39;</span><span class="p">,</span> <span class="s1">&#39;category_id&#39;</span><span class="p">,</span> <span class="s1">&#39;timestamp&#39;</span>
<span class="p">]</span> <span class="o">&gt;&gt;</span> <span class="n">ops</span><span class="o">.</span><span class="n">Groupby</span><span class="p">(</span>
    <span class="n">groupby_cols</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;session_id&#39;</span><span class="p">],</span>
    <span class="n">sort_cols</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;timestamp&#39;</span><span class="p">],</span>
    <span class="n">aggs</span><span class="o">=</span><span class="p">{</span>
        <span class="s1">&#39;product_id&#39;</span><span class="p">:</span> <span class="s1">&#39;list&#39;</span><span class="p">,</span>
        <span class="s1">&#39;category_id&#39;</span><span class="p">:</span> <span class="s1">&#39;list&#39;</span><span class="p">,</span>
        <span class="s1">&#39;timestamp&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;first&#39;</span><span class="p">,</span> <span class="s1">&#39;last&#39;</span><span class="p">],</span>
    <span class="p">},</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="section" id="outputs">
<h4>Outputs<a class="headerlink" href="#outputs" title="Permalink to this headline">¶</a></h4>
<p>NVTabular outputs parquet files with the preprocessed data. The parquet files can be (Hive) partitioned by a categorical column (e.g. day, company), as in the following example.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">nvt_output_path</span> <span class="o">=</span><span class="s1">&#39;./output&#39;</span>
<span class="n">partition_col</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;day&#39;</span><span class="p">]</span>
<span class="n">nvt</span><span class="o">.</span><span class="n">Dataset</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span><span class="o">.</span><span class="n">to_parquet</span><span class="p">(</span><span class="n">nvt_output_path</span><span class="p">,</span> <span class="n">partition_on</span><span class="o">=</span><span class="p">[</span><span class="n">partition_col</span><span class="p">])</span>
</pre></div>
</div>
<p>NVTabular also outputs a schema of the parquet columns in Profobuf Text format, e.g. including the cardinality of categorical features, the max squence length for sequential features and tags that can be associated to features (e.g. to indicate what is the item id, what are item and user features, what are categorical or continuous features). You can see <a class="reference external" href="../../tests/assets/data_schema/schema.pbtxt">here</a> an example of such schema in Protobuf Text format.
P.s. If you don’t use NVTabular to preprocess your data, you can generate the Schema via code.</p>
<p><strong>TODO: Include code snippet of how to define the Schema manualy using code</strong></p>
<p>The NVTabular workflow can be saved after <code class="docutils literal notranslate"><span class="pre">workflow.fit()</span></code> is called, so that the same preproc workflow can be applied to new input data, either in batch or online (via integration with Triton Inference Server), described in the next section.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Instantiates an NVTabular dataset</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">nvt</span><span class="o">.</span><span class="n">Dataset</span><span class="p">([</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">INPUT_PATH</span><span class="p">,</span> <span class="s2">&quot;*.parquet&quot;</span><span class="p">)],</span> <span class="n">part_size</span><span class="o">=</span><span class="s2">&quot;100MB&quot;</span><span class="p">)</span>
<span class="c1"># Perform a single pass over the dataset to collect columns statistics</span>
<span class="n">workflow</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
<span class="c1"># Applies the transform ops to the dataset</span>
<span class="n">new_dataset</span> <span class="o">=</span> <span class="n">workflow</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
<span class="c1"># Saves the &quot;fitted&quot; preprocessing workflow</span>
<span class="n">workflow</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">OUTPUT_PATH</span><span class="p">,</span> <span class="s2">&quot;workflow&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="integration-with-triton-inference-server">
<h3>Integration with Triton Inference Server<a class="headerlink" href="#integration-with-triton-inference-server" title="Permalink to this headline">¶</a></h3>
<p><strong>TODO: Describe the integration with Triton</strong></p>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="examples/index.html" class="btn btn-neutral float-right" title="Examples" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="getting_started.html" class="btn btn-neutral float-left" title="Transformers4Rec" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, NVIDIA.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>