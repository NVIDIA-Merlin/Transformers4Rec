

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Session-based Recommendation with XLNET &mdash; Transformers4Rec  documentation</title>
  

  
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "tex2jax_ignore|mathjax_ignore|document", "processClass": "tex2jax_process|mathjax_process|math|output_area"}})</script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="End-to-end session-based recommendation" href="../end-to-end-session-based/index.html" />
    <link rel="prev" title="ETL with NVTabular" href="01-ETL-with-NVTabular.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html" class="icon icon-home"> Transformers4Rec
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../getting_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../why_transformers4rec.html">Why Transformers4Rec?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_definition.html">Model Architectures</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../training_eval.html">Training and Evaluation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../pipeline.html">End-to-end pipeline with NVIDIA Merlin</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">Examples</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="index.html">Getting started session-based with Synthetic Data</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="01-ETL-with-NVTabular.html">ETL with NVTabular</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">Session based XLNet with PyTorch</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#Build-a-DL-model-with-Transformers4Rec-library">Build a DL model with Transformers4Rec library</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Daily-Fine-Tuning:-Training-over-a-time-window">Daily Fine-Tuning: Training over a time window</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../end-to-end-session-based/index.html">End-to-end session-based with Yoochoose dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorial/index.html">Tutorial: End-to-end session-based recommendation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../api/modules.html">API Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../resources.html">Additional Resources</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Transformers4Rec</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../index.html">Transformers4Rec Example Notebooks</a> &raquo;</li>
        
          <li><a href="index.html">Getting started - Session-based recommendation with Synthetic Data</a> &raquo;</li>
        
      <li>Session-based Recommendation with XLNET</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../../_sources/examples/getting-started-session-based/02-session-based-XLNet-with-PyT.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Copyright 2021 NVIDIA Corporation. All Rights Reserved.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="c1"># ==============================================================================</span>
</pre></div>
</div>
</div>
<div class="section" id="Session-based-Recommendation-with-XLNET">
<h1>Session-based Recommendation with XLNET<a class="headerlink" href="#Session-based-Recommendation-with-XLNET" title="Permalink to this headline">¶</a></h1>
<p>In this notebook we introduce the <a class="reference external" href="https://github.com/NVIDIA-Merlin/Transformers4Rec">Transformers4Rec</a> library for sequential and session-based recommendation. This notebook uses the PyTorch API, but a TensorFlow API is also available. Transformers4Rec integrates with the popular <a class="reference external" href="https://github.com/huggingface/transformers">HuggingFace’s Transformers</a> and make it possible to experiment with cutting-edge implementation of the latest NLP Transformer architectures.</p>
<p>We demonstrate how to build a session-based recommendation model with the <a class="reference external" href="https://arxiv.org/abs/1906.08237">XLNET</a> Transformer architecture. The XLNet architecture was designed to leverage the best of both auto-regressive language modeling and auto-encoding with its Permutation Language Modeling training method. In this example we will use XLNET with masked language modeling (MLM) training method, which showed very promising results in the experiments conducted in our <a class="reference external" href="https://github.com/NVIDIA-Merlin/publications/blob/main/2021_acm_recsys_transformers4rec/recsys21_transformers4rec_paper.pdf">ACM RecSys’21
paper</a>.</p>
<p>In the previous notebook we went through our ETL pipeline with NVTabular library, and created sequential features to be used in training a session-based recommendation model. In this notebook we will learn:</p>
<ul class="simple">
<li><p>Accelerating data loading of parquet files with multiple features on PyTorch using NVTabular library</p></li>
<li><p>Training and evaluating a Transformer-based (XLNET-MLM) session-based recommendation model with multiple features</p></li>
</ul>
<div class="section" id="Build-a-DL-model-with-Transformers4Rec-library">
<h2>Build a DL model with Transformers4Rec library<a class="headerlink" href="#Build-a-DL-model-with-Transformers4Rec-library" title="Permalink to this headline">¶</a></h2>
<p>Transformers4Rec supports multiple input features and provides configurable building blocks that can be easily combined for custom architectures:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/NVIDIA-Merlin/Transformers4Rec/blob/main/transformers4rec/torch/features/sequence.py#L74">TabularSequenceFeatures</a> class that reads from schema and creates an input block. This input module combines different types of features (continuous, categorical &amp; text) to a sequence.</p></li>
<li><p><a class="reference external" href="https://github.com/NVIDIA-Merlin/Transformers4Rec/blob/main/transformers4rec/torch/masking.py#L28">MaskSequence</a> to define masking schema and prepare the masked inputs and labels for the selected LM task.</p></li>
<li><p><a class="reference external" href="https://github.com/NVIDIA-Merlin/Transformers4Rec/blob/main/transformers4rec/torch/block/transformer.py#L38">TransformerBlock</a> class that supports HuggingFace Transformers for session-based and sequential-based recommendation models.</p></li>
<li><p><a class="reference external" href="https://github.com/NVIDIA-Merlin/Transformers4Rec/blob/main/transformers4rec/torch/block/base.py#L61">SequentialBlock</a> that creates the body by mimicking <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html">torch.nn.sequential</a> class. It is designed to define our model as a sequence of layers.</p></li>
<li><p><a class="reference external" href="https://github.com/NVIDIA-Merlin/Transformers4Rec/blob/main/transformers4rec/torch/model/head.py">Head</a> where we define the prediction task of the model.</p></li>
<li><p><a class="reference external" href="https://github.com/NVIDIA-Merlin/Transformers4Rec/blob/main/transformers4rec/torch/model/head.py#L236">NextItemPredictionTask</a> that is the class to support next item prediction task.</p></li>
<li><p><a class="reference external" href="https://github.com/NVIDIA-Merlin/Transformers4Rec/blob/main/transformers4rec/torch/trainer.py#L34">Trainer</a> manages the model training and evaluation.</p></li>
</ul>
<p>Figure 1 illustrates Transformers4Rec meta-architecture and how each module/block interacts with each other.</p>
<p><a href="#id1"><span class="problematic" id="id2">|tf4rec\_meta|</span></a></p>
<div class="section" id="Imports-required-libraries">
<h3>Imports required libraries<a class="headerlink" href="#Imports-required-libraries" title="Permalink to this headline">¶</a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">glob</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="kn">from</span> <span class="nn">transformers4rec</span> <span class="kn">import</span> <span class="n">torch</span> <span class="k">as</span> <span class="n">tr</span>
<span class="kn">from</span> <span class="nn">transformers4rec.torch.ranking_metric</span> <span class="kn">import</span> <span class="n">NDCGAt</span><span class="p">,</span> <span class="n">AvgPrecisionAt</span><span class="p">,</span> <span class="n">RecallAt</span>
</pre></div>
</div>
</div>
<p>Transformers4Rec library relies on a schema object to automatically build all necessary layers to represent, normalize and aggregate input features. As you can see below, <code class="docutils literal notranslate"><span class="pre">schema.pb</span></code> is a protobuf file that contains metadata including statistics about features such as cardinality, min and max values and also tags features based on their characteristics and dtypes (e.g., categorical, continuous, list, integer).</p>
</div>
<div class="section" id="Manually-set-the-schema">
<h3>Manually set the schema<a class="headerlink" href="#Manually-set-the-schema" title="Permalink to this headline">¶</a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">merlin_standard_lib</span> <span class="kn">import</span> <span class="n">Schema</span>
<span class="n">SCHEMA_PATH</span> <span class="o">=</span> <span class="s2">&quot;schema.pb&quot;</span>
<span class="n">schema</span> <span class="o">=</span> <span class="n">Schema</span><span class="p">()</span><span class="o">.</span><span class="n">from_proto_text</span><span class="p">(</span><span class="n">SCHEMA_PATH</span><span class="p">)</span>
<span class="o">!</span>cat <span class="nv">$SCHEMA_PATH</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
feature {
  name: &#34;session_id&#34;
  type: INT
  int_domain {
    name: &#34;session_id&#34;
    min: 1
    max: 100001
    is_categorical: false
  }
  annotation {
    tag: &#34;groupby_col&#34;
  }
}
feature {
  name: &#34;category-list_trim&#34;
  value_count {
    min: 2
    max: 20
  }
  type: INT
  int_domain {
    name: &#34;category-list_trim&#34;
    min: 1
    max: 400
    is_categorical: true
  }
  annotation {
    tag: &#34;list&#34;
    tag: &#34;categorical&#34;
    tag: &#34;item&#34;
  }
}
feature {
  name: &#34;item_id-list_trim&#34;
  value_count {
    min: 2
    max: 20
  }
  type: INT
  int_domain {
    name: &#34;item_id/list&#34;
    min: 1
    max: 50005
    is_categorical: true
  }
  annotation {
    tag: &#34;item_id&#34;
    tag: &#34;list&#34;
    tag: &#34;categorical&#34;
    tag: &#34;item&#34;
  }
}
feature {
  name: &#34;timestamp/age_days-list_trim&#34;
  value_count {
    min: 2
    max: 20
  }
  type: FLOAT
  float_domain {
    name: &#34;timestamp/age_days-list_trim&#34;
    min: 0.0000003
    max: 0.9999999
  }
  annotation {
    tag: &#34;continuous&#34;
    tag: &#34;list&#34;
  }
}
feature {
  name: &#34;timestamp/weekday/sin-list_trim&#34;
  value_count {
    min: 2
    max: 20
  }
  type: FLOAT
  float_domain {
    name: &#34;timestamp/weekday-sin_trim&#34;
    min: 0.0000003
    max: 0.9999999
  }
  annotation {
    tag: &#34;time&#34;
    tag: &#34;list&#34;
  }
}
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># You can select a subset of features for training</span>
<span class="n">schema</span> <span class="o">=</span> <span class="n">schema</span><span class="o">.</span><span class="n">select_by_name</span><span class="p">([</span><span class="s1">&#39;item_id-list_trim&#39;</span><span class="p">,</span>
                                <span class="s1">&#39;category-list_trim&#39;</span><span class="p">,</span>
                                <span class="s1">&#39;timestamp/weekday/sin-list_trim&#39;</span><span class="p">,</span>
                                <span class="s1">&#39;timestamp/age_days-list_trim&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Define-the-sequential-input-module">
<h3>Define the sequential input module<a class="headerlink" href="#Define-the-sequential-input-module" title="Permalink to this headline">¶</a></h3>
<p>Below we define our <code class="docutils literal notranslate"><span class="pre">input</span></code> block using the <code class="docutils literal notranslate"><span class="pre">TabularSequenceFeatures</span></code> <a class="reference external" href="https://github.com/NVIDIA-Merlin/Transformers4Rec/blob/main/transformers4rec/torch/features/sequence.py#L91">class</a>. The <code class="docutils literal notranslate"><span class="pre">from_schema()</span></code> method processes the schema and creates the necessary layers to represent features and aggregate them. It keeps only features tagged as <code class="docutils literal notranslate"><span class="pre">categorical</span></code> and <code class="docutils literal notranslate"><span class="pre">continuous</span></code> and supports data aggregation methods like <code class="docutils literal notranslate"><span class="pre">concat</span></code> and <code class="docutils literal notranslate"><span class="pre">elementwise-sum</span></code> techniques. It also support data
augmentation techniques like stochastic swap noise. It outputs an interaction representation after combining all features and also the input mask according to the training task (more on this later).</p>
<p>The <code class="docutils literal notranslate"><span class="pre">max_sequence_length</span></code> argument defines the maximum sequence length of our sequential input, and if <code class="docutils literal notranslate"><span class="pre">continuous_projection</span></code> argument is set, all numerical features are concatenated and projected by an MLP block so that continuous features are represented by a vector of size defined by user, which is <code class="docutils literal notranslate"><span class="pre">64</span></code> in this example.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">inputs</span> <span class="o">=</span> <span class="n">tr</span><span class="o">.</span><span class="n">TabularSequenceFeatures</span><span class="o">.</span><span class="n">from_schema</span><span class="p">(</span>
        <span class="n">schema</span><span class="p">,</span>
        <span class="n">max_sequence_length</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
        <span class="n">continuous_projection</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
        <span class="n">d_output</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
        <span class="n">masking</span><span class="o">=</span><span class="s2">&quot;mlm&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="line-block">
<div class="line">The output of the <code class="docutils literal notranslate"><span class="pre">TabularSequenceFeatures</span></code> module is the sequence of interactions embeddings vectors defined in the following steps: - 1. Create sequence inputs: If the schema contains non sequential features, expand each feature to a sequence by repeating the value as many as the <code class="docutils literal notranslate"><span class="pre">max_sequence_length</span></code> value.</div>
<div class="line">- 2. Get a representation vector of categorical features: Project each sequential categorical feature using the related embedding table. The resulting tensor is of shape (bs, max_sequence_length, embed_dim). - 3. Project scalar values if <code class="docutils literal notranslate"><span class="pre">continuous_projection</span></code> is set : Apply an MLP layer with hidden size equal to <code class="docutils literal notranslate"><span class="pre">continuous_projection</span></code> vector size value. The resulting tensor is of shape (batch_size, max_sequence_length, continuous_projection). - 4. Aggregate the list of features
vectors to represent each interaction in the sequence with one vector: For example, <code class="docutils literal notranslate"><span class="pre">concat</span></code> will concat all vectors based on the last dimension <code class="docutils literal notranslate"><span class="pre">-1</span></code> and the resulting tensor will be of shape (batch_size, max_sequence_length, D) where D is the sum over all embedding dimensions and the value of continuous_projection. - 5. If masking schema is set (needed only for the NextItemPredictionTask training), the masked labels are derived from the sequence of raw item-ids and the sequence of
interactions embeddings are processed to mask information about the masked positions.</div>
</div>
</div>
<div class="section" id="Define-the-Transformer-Block">
<h3>Define the Transformer Block<a class="headerlink" href="#Define-the-Transformer-Block" title="Permalink to this headline">¶</a></h3>
<div class="line-block">
<div class="line">In the next cell, the whole model is build with a few lines of code. Here is a brief explanation of the main classes:</div>
<div class="line">- <a class="reference external" href="https://github.com/NVIDIA-Merlin/Transformers4Rec/blob/main/transformers4rec/config/transformer.py#L261">XLNetConfig</a> - We have injected in the HF transformers config classes like <code class="docutils literal notranslate"><span class="pre">XLNetConfig</span></code>the <code class="docutils literal notranslate"><span class="pre">build()</span></code> method, that provides default configuration to Transformer architectures for session-based recommendation. Here we use it to instantiate and configure an XLNET architecture.</div>
<div class="line">- <a class="reference external" href="https://github.com/NVIDIA-Merlin/Transformers4Rec/blob/main/transformers4rec/torch/block/transformer.py#L37">TransformerBlock</a> class integrates with HF Transformers, which are made available as a sequence processing module for session-based and sequential-based recommendation models.</div>
<div class="line">- <a class="reference external" href="https://github.com/NVIDIA-Merlin/Transformers4Rec/blob/main/transformers4rec/torch/model/head.py#L238">NextItemPredictionTask</a> supports the next-item prediction task. We also support other predictions <a class="reference external" href="https://github.com/NVIDIA-Merlin/Transformers4Rec/blob/main/transformers4rec/torch/model/head.py">tasks</a>, like classification and regression for the whole sequence.</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Define XLNetConfig class and set default parameters for HF XLNet config</span>
<span class="n">transformer_config</span> <span class="o">=</span> <span class="n">tr</span><span class="o">.</span><span class="n">XLNetConfig</span><span class="o">.</span><span class="n">build</span><span class="p">(</span>
    <span class="n">d_model</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">n_head</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">n_layer</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">total_seq_length</span><span class="o">=</span><span class="mi">20</span>
<span class="p">)</span>
<span class="c1"># Define the model block including: inputs, masking, projection and transformer block.</span>
<span class="n">body</span> <span class="o">=</span> <span class="n">tr</span><span class="o">.</span><span class="n">SequentialBlock</span><span class="p">(</span>
    <span class="n">inputs</span><span class="p">,</span> <span class="n">tr</span><span class="o">.</span><span class="n">MLPBlock</span><span class="p">([</span><span class="mi">64</span><span class="p">]),</span> <span class="n">tr</span><span class="o">.</span><span class="n">TransformerBlock</span><span class="p">(</span><span class="n">transformer_config</span><span class="p">,</span> <span class="n">masking</span><span class="o">=</span><span class="n">inputs</span><span class="o">.</span><span class="n">masking</span><span class="p">)</span>
<span class="p">)</span>

<span class="c1"># Defines the evaluation top-N metrics and the cut-offs</span>
<span class="n">metrics</span> <span class="o">=</span> <span class="p">[</span><span class="n">NDCGAt</span><span class="p">(</span><span class="n">top_ks</span><span class="o">=</span><span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">40</span><span class="p">],</span> <span class="n">labels_onehot</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
           <span class="n">RecallAt</span><span class="p">(</span><span class="n">top_ks</span><span class="o">=</span><span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">40</span><span class="p">],</span> <span class="n">labels_onehot</span><span class="o">=</span><span class="kc">True</span><span class="p">)]</span>

<span class="c1"># Define a head related to next item prediction task</span>
<span class="n">head</span> <span class="o">=</span> <span class="n">tr</span><span class="o">.</span><span class="n">Head</span><span class="p">(</span>
    <span class="n">body</span><span class="p">,</span>
    <span class="n">tr</span><span class="o">.</span><span class="n">NextItemPredictionTask</span><span class="p">(</span><span class="n">weight_tying</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">hf_format</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                              <span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span><span class="p">),</span>
    <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Get the end-to-end Model class</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">tr</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">head</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Note that we can easily define an RNN-based model inside the <code class="docutils literal notranslate"><span class="pre">SequentialBlock</span></code> instead of a Transformer-based model. You can explore this <a class="reference external" href="https://github.com/NVIDIA-Merlin/Transformers4Rec/tree/main/examples/tutorial">tutorial</a> for a GRU-based model example.</p>
</div>
<div class="section" id="Train-the-model">
<h3>Train the model<a class="headerlink" href="#Train-the-model" title="Permalink to this headline">¶</a></h3>
<p>We use the NVTabular PyTorch Dataloader for optimized loading of multiple features from input parquet files. You can learn more about this data loader <a class="reference external" href="https://nvidia.github.io/NVTabular/main/training/pytorch.html">here</a>.</p>
</div>
<div class="section" id="Set-Training-arguments">
<h3><strong>Set Training arguments</strong><a class="headerlink" href="#Set-Training-arguments" title="Permalink to this headline">¶</a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">transformers4rec.config.trainer</span> <span class="kn">import</span> <span class="n">T4RecTrainingArguments</span>
<span class="kn">from</span> <span class="nn">transformers4rec.torch</span> <span class="kn">import</span> <span class="n">Trainer</span>
<span class="c1"># Set hyperparameters for training</span>
<span class="n">train_args</span> <span class="o">=</span> <span class="n">T4RecTrainingArguments</span><span class="p">(</span><span class="n">data_loader_engine</span><span class="o">=</span><span class="s1">&#39;nvtabular&#39;</span><span class="p">,</span>
                                    <span class="n">dataloader_drop_last</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
                                    <span class="n">report_to</span> <span class="o">=</span> <span class="p">[],</span>
                                    <span class="n">gradient_accumulation_steps</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
                                    <span class="n">per_device_train_batch_size</span> <span class="o">=</span> <span class="mi">256</span><span class="p">,</span>
                                    <span class="n">per_device_eval_batch_size</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span>
                                    <span class="n">output_dir</span> <span class="o">=</span> <span class="s2">&quot;./tmp&quot;</span><span class="p">,</span>
                                    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.0005</span><span class="p">,</span>
                                    <span class="n">lr_scheduler_type</span><span class="o">=</span><span class="s1">&#39;cosine&#39;</span><span class="p">,</span>
                                    <span class="n">learning_rate_num_cosine_cycles_by_epoch</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span>
                                    <span class="n">num_train_epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                                    <span class="n">max_sequence_length</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
                                    <span class="n">no_cuda</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Note that we add an argument <code class="docutils literal notranslate"><span class="pre">data_loader_engine='nvtabular'</span></code> to automatically load the features needed for training using the schema. The default value is nvtabular for optimized GPU-based data-loading. Optionally a PyarrowDataLoader (pyarrow) can also be used as a basic option, but it is slower and works only for small datasets, as the full data is loaded to CPU memory.</p>
</div>
</div>
<div class="section" id="Daily-Fine-Tuning:-Training-over-a-time-window">
<h2>Daily Fine-Tuning: Training over a time window<a class="headerlink" href="#Daily-Fine-Tuning:-Training-over-a-time-window" title="Permalink to this headline">¶</a></h2>
<p>Here we do daily fine-tuning meaning that we use the first day to train and second day to evaluate, then we use the second day data to train the model by resuming from the first step, and evaluate on the third day, so on so forth.</p>
<p>We have extended the HuggingFace transformers <code class="docutils literal notranslate"><span class="pre">Trainer</span></code> class (PyTorch only) to support evaluation of RecSys metrics. In this example, the evaluation of the session-based recommendation model is performed using traditional Top-N ranking metrics such as Normalized Discounted Cumulative Gain (<a class="reference external" href="mailto:NDCG&#37;&#52;&#48;20">NDCG<span>&#64;</span>20</a>) and Hit Rate (<a class="reference external" href="mailto:HR&#37;&#52;&#48;20">HR<span>&#64;</span>20</a>). NDCG accounts for rank of the relevant item in the recommendation list and is a more fine-grained metric than HR, which only verifies whether the relevant item is among the
top-n items. HR&#64;n is equivalent to Recall&#64;n when there is only one relevant item in the recommendation list.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Instantiate the T4Rec Trainer, which manages training and evaluation for the PyTorch API</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
    <span class="n">args</span><span class="o">=</span><span class="n">train_args</span><span class="p">,</span>
    <span class="n">schema</span><span class="o">=</span><span class="n">schema</span><span class="p">,</span>
    <span class="n">compute_metrics</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<ul class="simple">
<li><p>Define the output folder of the processed parquet files</p></li>
</ul>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">OUTPUT_DIR</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;OUTPUT_DIR&quot;</span><span class="p">,</span> <span class="s2">&quot;/workspace/data/sessions_by_day&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">start_time_window_index</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">final_time_window_index</span> <span class="o">=</span> <span class="mi">7</span>
<span class="c1">#Iterating over days of one week</span>
<span class="k">for</span> <span class="n">time_index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">start_time_window_index</span><span class="p">,</span> <span class="n">final_time_window_index</span><span class="p">):</span>
    <span class="c1"># Set data</span>
    <span class="n">time_index_train</span> <span class="o">=</span> <span class="n">time_index</span>
    <span class="n">time_index_eval</span> <span class="o">=</span> <span class="n">time_index</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">train_paths</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">OUTPUT_DIR</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">time_index_train</span><span class="si">}</span><span class="s2">/train.parquet&quot;</span><span class="p">))</span>
    <span class="n">eval_paths</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">OUTPUT_DIR</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">time_index_eval</span><span class="si">}</span><span class="s2">/valid.parquet&quot;</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">train_paths</span><span class="p">)</span>

    <span class="c1"># Train on day related to time_index</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;*&#39;</span><span class="o">*</span><span class="mi">20</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Launch training for day </span><span class="si">%s</span><span class="s2"> are:&quot;</span> <span class="o">%</span><span class="k">time_index</span>)
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;*&#39;</span><span class="o">*</span><span class="mi">20</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">trainer</span><span class="o">.</span><span class="n">train_dataset_or_path</span> <span class="o">=</span> <span class="n">train_paths</span>
    <span class="n">trainer</span><span class="o">.</span><span class="n">reset_lr_scheduler</span><span class="p">()</span>
    <span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">trainer</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">global_step</span> <span class="o">+=</span><span class="mi">1</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;finished&#39;</span><span class="p">)</span>

    <span class="c1"># Evaluate on the following day</span>
    <span class="n">trainer</span><span class="o">.</span><span class="n">eval_dataset_or_path</span> <span class="o">=</span> <span class="n">eval_paths</span>
    <span class="n">train_metrics</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">metric_key_prefix</span><span class="o">=</span><span class="s1">&#39;eval&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;*&#39;</span><span class="o">*</span><span class="mi">20</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Eval results for day </span><span class="si">%s</span><span class="s2"> are:</span><span class="se">\t</span><span class="s2">&quot;</span> <span class="o">%</span><span class="k">time_index_eval</span>)
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> <span class="s1">&#39;*&#39;</span><span class="o">*</span><span class="mi">20</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">train_metrics</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot; </span><span class="si">%s</span><span class="s2"> = </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">train_metrics</span><span class="p">[</span><span class="n">key</span><span class="p">])))</span>
    <span class="n">trainer</span><span class="o">.</span><span class="n">wipe_memory</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[&#39;/workspace/data/sessions_by_day/1/train.parquet&#39;]
********************
Launch training for day 1 are:
********************

</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
***** Running training *****
  Num examples = 768
  Num Epochs = 5
  Instantaneous batch size per device = 256
  Total train batch size (w. parallel, distributed &amp; accumulation) = 1024
  Gradient Accumulation steps = 1
  Total optimization steps = 15
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
    <div>

      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>
      [15/15 00:00, Epoch 5/5]
    </div>
    <table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>Step</th>
      <th>Training Loss</th>
    </tr>
  </thead>
  <tbody>
  </tbody>
</table><p></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>


Training completed. Do not forget to share your model on huggingface.co/models =)


</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
finished
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<div>

  <progress value='21' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>
  [3/3 00:05]
</div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
********************
Eval results for day 2 are:

********************

 epoch = 5.0
 eval/loss = 10.33902645111084
 eval/next-item/ndcg_at_20 = 0.0209574606269598
 eval/next-item/ndcg_at_40 = 0.02929079346358776
 eval/next-item/recall_at_20 = 0.0520833358168602
 eval/next-item/recall_at_40 = 0.09375
 eval_runtime = 0.0882
 eval_samples_per_second = 1088.723
 eval_steps_per_second = 11.341
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
***** Running training *****
  Num examples = 768
  Num Epochs = 5
  Instantaneous batch size per device = 256
  Total train batch size (w. parallel, distributed &amp; accumulation) = 1024
  Gradient Accumulation steps = 1
  Total optimization steps = 15
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[&#39;/workspace/data/sessions_by_day/2/train.parquet&#39;]
********************
Launch training for day 2 are:
********************

</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
    <div>

      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>
      [15/15 00:00, Epoch 5/5]
    </div>
    <table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>Step</th>
      <th>Training Loss</th>
    </tr>
  </thead>
  <tbody>
  </tbody>
</table><p></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>


Training completed. Do not forget to share your model on huggingface.co/models =)


</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
finished
********************
Eval results for day 3 are:

********************

 epoch = 5.0
 eval/loss = 9.9208345413208
 eval/next-item/ndcg_at_20 = 0.053623538464307785
 eval/next-item/ndcg_at_40 = 0.08480535447597504
 eval/next-item/recall_at_20 = 0.1354166716337204
 eval/next-item/recall_at_40 = 0.28125
 eval_runtime = 0.0886
 eval_samples_per_second = 1083.283
 eval_steps_per_second = 11.284
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
***** Running training *****
  Num examples = 768
  Num Epochs = 5
  Instantaneous batch size per device = 256
  Total train batch size (w. parallel, distributed &amp; accumulation) = 1024
  Gradient Accumulation steps = 1
  Total optimization steps = 15
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[&#39;/workspace/data/sessions_by_day/3/train.parquet&#39;]
********************
Launch training for day 3 are:
********************

</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
    <div>

      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>
      [15/15 00:00, Epoch 5/5]
    </div>
    <table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>Step</th>
      <th>Training Loss</th>
    </tr>
  </thead>
  <tbody>
  </tbody>
</table><p></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>


Training completed. Do not forget to share your model on huggingface.co/models =)


</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
finished
********************
Eval results for day 4 are:

********************

 epoch = 5.0
 eval/loss = 9.478459358215332
 eval/next-item/ndcg_at_20 = 0.08707290887832642
 eval/next-item/ndcg_at_40 = 0.11134807765483856
 eval/next-item/recall_at_20 = 0.2291666716337204
 eval/next-item/recall_at_40 = 0.34375
 eval_runtime = 0.0888
 eval_samples_per_second = 1080.702
 eval_steps_per_second = 11.257
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
***** Running training *****
  Num examples = 768
  Num Epochs = 5
  Instantaneous batch size per device = 256
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[&#39;/workspace/data/sessions_by_day/4/train.parquet&#39;]
********************
Launch training for day 4 are:
********************

</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
  Total train batch size (w. parallel, distributed &amp; accumulation) = 1024
  Gradient Accumulation steps = 1
  Total optimization steps = 15
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
    <div>

      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>
      [15/15 00:00, Epoch 5/5]
    </div>
    <table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>Step</th>
      <th>Training Loss</th>
    </tr>
  </thead>
  <tbody>
  </tbody>
</table><p></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>


Training completed. Do not forget to share your model on huggingface.co/models =)


</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
finished
********************
Eval results for day 5 are:

********************

 epoch = 5.0
 eval/loss = 8.747222900390625
 eval/next-item/ndcg_at_20 = 0.13623034954071045
 eval/next-item/ndcg_at_40 = 0.179062157869339
 eval/next-item/recall_at_20 = 0.34375
 eval/next-item/recall_at_40 = 0.5520833730697632
 eval_runtime = 0.0947
 eval_samples_per_second = 1013.663
 eval_steps_per_second = 10.559
[&#39;/workspace/data/sessions_by_day/5/train.parquet&#39;]
********************
Launch training for day 5 are:
********************

</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
***** Running training *****
  Num examples = 768
  Num Epochs = 5
  Instantaneous batch size per device = 256
  Total train batch size (w. parallel, distributed &amp; accumulation) = 1024
  Gradient Accumulation steps = 1
  Total optimization steps = 15
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
    <div>

      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>
      [15/15 00:00, Epoch 5/5]
    </div>
    <table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>Step</th>
      <th>Training Loss</th>
    </tr>
  </thead>
  <tbody>
  </tbody>
</table><p></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>


Training completed. Do not forget to share your model on huggingface.co/models =)


</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
finished
********************
Eval results for day 6 are:

********************

 epoch = 5.0
 eval/loss = 8.153544425964355
 eval/next-item/ndcg_at_20 = 0.13773086667060852
 eval/next-item/ndcg_at_40 = 0.18069738149642944
 eval/next-item/recall_at_20 = 0.3541666865348816
 eval/next-item/recall_at_40 = 0.5625
 eval_runtime = 0.0944
 eval_samples_per_second = 1017.132
 eval_steps_per_second = 10.595
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
***** Running training *****
  Num examples = 768
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[&#39;/workspace/data/sessions_by_day/6/train.parquet&#39;]
********************
Launch training for day 6 are:
********************

</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
  Num Epochs = 5
  Instantaneous batch size per device = 256
  Total train batch size (w. parallel, distributed &amp; accumulation) = 1024
  Gradient Accumulation steps = 1
  Total optimization steps = 15
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
    <div>

      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>
      [15/15 00:00, Epoch 5/5]
    </div>
    <table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>Step</th>
      <th>Training Loss</th>
    </tr>
  </thead>
  <tbody>
  </tbody>
</table><p></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>


Training completed. Do not forget to share your model on huggingface.co/models =)


</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
finished
********************
Eval results for day 7 are:

********************

 epoch = 5.0
 eval/loss = 7.682921886444092
 eval/next-item/ndcg_at_20 = 0.16451486945152283
 eval/next-item/ndcg_at_40 = 0.19865691661834717
 eval/next-item/recall_at_20 = 0.3958333432674408
 eval/next-item/recall_at_40 = 0.5625
 eval_runtime = 0.091
 eval_samples_per_second = 1055.176
 eval_steps_per_second = 10.991
</pre></div></div>
</div>
<div class="section" id="Saves-the-model">
<h3>Saves the model<a class="headerlink" href="#Saves-the-model" title="Permalink to this headline">¶</a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">_save_model_and_checkpoint</span><span class="p">(</span><span class="n">save_model_class</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Saving model checkpoint to ./tmp/checkpoint-16
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
</pre></div></div>
</div>
</div>
<div class="section" id="Reloads-the-model">
<h3>Reloads the model<a class="headerlink" href="#Reloads-the-model" title="Permalink to this headline">¶</a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">trainer</span><span class="o">.</span><span class="n">load_model_trainer_states_from_checkpoint</span><span class="p">(</span><span class="s1">&#39;./tmp/checkpoint-</span><span class="si">%s</span><span class="s1">&#39;</span><span class="o">%</span><span class="k">trainer</span>.state.global_step)
</pre></div>
</div>
</div>
</div>
<div class="section" id="Re-compute-eval-metrics-of-validation-data">
<h3>Re-compute eval metrics of validation data<a class="headerlink" href="#Re-compute-eval-metrics-of-validation-data" title="Permalink to this headline">¶</a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">eval_data_paths</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">OUTPUT_DIR</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">time_index_eval</span><span class="si">}</span><span class="s2">/valid.parquet&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># set new data from day 7</span>
<span class="n">eval_metrics</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">eval_dataset</span><span class="o">=</span><span class="n">eval_data_paths</span><span class="p">,</span> <span class="n">metric_key_prefix</span><span class="o">=</span><span class="s1">&#39;eval&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">eval_metrics</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  </span><span class="si">%s</span><span class="s2"> = </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">eval_metrics</span><span class="p">[</span><span class="n">key</span><span class="p">])))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
  epoch = 5.0
  eval/loss = 7.682921886444092
  eval/next-item/ndcg_at_20 = 0.16451486945152283
  eval/next-item/ndcg_at_40 = 0.19865691661834717
  eval/next-item/recall_at_20 = 0.3958333432674408
  eval/next-item/recall_at_40 = 0.5625
  eval_runtime = 0.1
  eval_samples_per_second = 960.363
  eval_steps_per_second = 10.004
</pre></div></div>
</div>
<div class="line-block">
<div class="line">That’s it!</div>
<div class="line">You have just trained your session-based recommendation model using Transformers4Rec.</div>
</div>
<p>Tip: We can easily log and visualize model training and evaluation on <a class="reference external" href="https://wandb.ai/home">Weights &amp; Biases (W&amp;B)</a>, <a class="reference external" href="https://www.tensorflow.org/tensorboard">Tensorboard</a> and <a class="reference external" href="https://github.com/NVIDIA/dllogger">NVIDIA DLLogger</a>. By default, the HuggingFace transformers <code class="docutils literal notranslate"><span class="pre">Trainer</span></code> (which we extend) uses Weights &amp; Biases (W&amp;B) to log training and evaluation metrics, which provides nice results visualization and comparison between different runs.</p>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="../end-to-end-session-based/index.html" class="btn btn-neutral float-right" title="End-to-end session-based recommendation" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="01-ETL-with-NVTabular.html" class="btn btn-neutral float-left" title="ETL with NVTabular" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, NVIDIA.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>