<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>End-to-end session-based recommendation with Transformers4Rec &mdash; Transformers4Rec  documentation</title><link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "tex2jax_ignore|mathjax_ignore|document", "processClass": "tex2jax_process|mathjax_process|math|output_area"}})</script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Tutorial: End-to-end Session-based recommendation" href="../tutorial/index.html" />
    <link rel="prev" title="End-to-end session-based recommendation" href="index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html" class="icon icon-home"> Transformers4Rec
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../getting_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../why_transformers4rec.html">Why Transformers4Rec?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_definition.html">Model Architectures</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../training_eval.html">Training and Evaluation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../pipeline.html">End-to-end pipeline with NVIDIA Merlin</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">Examples</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../getting-started-session-based/index.html">Getting started session-based with Synthetic Data</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="index.html">End-to-end session-based with Yoochoose dataset</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="#">End-to-end session-based with Yoochoose</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#1.-Setup">1. Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="#2.-Define-a-preprocessing-workflow-with-NVTabular">2. Define a preprocessing workflow with NVTabular</a></li>
<li class="toctree-l4"><a class="reference internal" href="#3.-Model-definition-using-Transformers4Rec">3. Model definition using Transformers4Rec</a></li>
<li class="toctree-l4"><a class="reference internal" href="#4.-Serving-Ensemble-Model-to-the-Triton-Inference-Server">4. Serving Ensemble Model to the Triton Inference Server</a></li>
<li class="toctree-l4"><a class="reference internal" href="#References">References</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../tutorial/index.html">Tutorial: End-to-end session-based recommendation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../api/modules.html">API Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../resources.html">Additional Resources</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Transformers4Rec</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../index.html">Transformers4Rec Example Notebooks</a> &raquo;</li>
          <li><a href="index.html">End-to-end session-based recommendation</a> &raquo;</li>
      <li>End-to-end session-based recommendation with Transformers4Rec</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt .copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Copyright 2021 NVIDIA Corporation. All Rights Reserved.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="c1"># ==============================================================================</span>
</pre></div>
</div>
</div>
<div class="section" id="End-to-end-session-based-recommendation-with-Transformers4Rec">
<h1>End-to-end session-based recommendation with Transformers4Rec<a class="headerlink" href="#End-to-end-session-based-recommendation-with-Transformers4Rec" title="Permalink to this headline"></a></h1>
<p>In recent years, several deep learning-based algorithms have been proposed for recommendation systems while its adoption in industry deployments have been steeply growing. In particular, NLP inspired approaches have been successfully adapted for sequential and session-based recommendation problems, which are important for many domains like e-commerce, news and streaming media. Session-Based Recommender Systems (SBRS) have been proposed to model the sequence of interactions within the current
user session, where a session is a short sequence of user interactions typically bounded by user inactivity. They have recently gained popularity due to their ability to capture short-term or contextual user preferences towards items.</p>
<p>The field of NLP has evolved significantly within the last decade, particularly due to the increased usage of deep learning. As a result, state of the art NLP approaches have inspired RecSys practitioners and researchers to adapt those architectures, especially for sequential and session-based recommendation problems. Here, we leverage one of the state-of-the-art Transformer-based architecture, <a class="reference external" href="https://arxiv.org/abs/1906.08237">XLNet</a> with Masked Language Modeling (MLM) training technique
(see our <a class="reference external" href="https://github.com/NVIDIA-Merlin/Transformers4Rec/tree/main/examples/tutorial">tutorial</a> for details) for training a session-based model.</p>
<p>In this end-to-end-session-based recommnender model example, we use <code class="docutils literal notranslate"><span class="pre">Transformers4Rec</span></code> library, which leverages the popular <a class="reference external" href="https://github.com/huggingface/transformers">HuggingFace’s Transformers</a> NLP library and make it possible to experiment with cutting-edge implementation of such architectures for sequential and session-based recommendation problems. For detailed explanations of the building blocks of Transformers4Rec meta-architecture visit
<a class="reference external" href="https://github.com/NVIDIA-Merlin/Transformers4Rec/tree/main/examples/getting-started-session-based">getting-started-session-based</a> and <a class="reference external" href="https://github.com/NVIDIA-Merlin/Transformers4Rec/tree/main/examples/tutorial">tutorial</a> example notebooks.</p>
<div class="section" id="1.-Setup">
<h2>1. Setup<a class="headerlink" href="#1.-Setup" title="Permalink to this headline"></a></h2>
<div class="section" id="1.1.-Import-Libraries-and-Define-Data-Input-and-Output-Paths">
<h3>1.1. Import Libraries and Define Data Input and Output Paths<a class="headerlink" href="#1.1.-Import-Libraries-and-Define-Data-Input-and-Output-Paths" title="Permalink to this headline"></a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">glob</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">gc</span>

<span class="kn">import</span> <span class="nn">cudf</span>
<span class="kn">import</span> <span class="nn">cupy</span>
<span class="kn">import</span> <span class="nn">nvtabular</span> <span class="k">as</span> <span class="nn">nvt</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">DATA_FOLDER</span> <span class="o">=</span> <span class="s2">&quot;/workspace/data/&quot;</span>
<span class="n">FILENAME_PATTERN</span> <span class="o">=</span> <span class="s1">&#39;yoochoose-clicks.dat&#39;</span>
<span class="n">DATA_PATH</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">DATA_FOLDER</span><span class="p">,</span> <span class="n">FILENAME_PATTERN</span><span class="p">)</span>

<span class="n">OUTPUT_FOLDER</span> <span class="o">=</span> <span class="s2">&quot;./yoochoose_transformed&quot;</span>
<span class="n">OVERWRITE</span> <span class="o">=</span> <span class="kc">False</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="1.2.-Download-the-data">
<h3>1.2. Download the data<a class="headerlink" href="#1.2.-Download-the-data" title="Permalink to this headline"></a></h3>
<p>In this notebook we are using the <code class="docutils literal notranslate"><span class="pre">YOOCHOOSE</span></code> dataset which contains a collection of sessions from a retailer. Each session encapsulates the click events that the user performed in that session.</p>
<p>The dataset is available on <a class="reference external" href="https://www.kaggle.com/chadgostopp/recsys-challenge-2015">Kaggle</a>. You need to download it and copy to the <code class="docutils literal notranslate"><span class="pre">DATA_FOLDER</span></code> path. Note that we are only using the <code class="docutils literal notranslate"><span class="pre">yoochoose-clicks.dat</span></code> file.</p>
</div>
<div class="section" id="1.3.-Load-and-clean-raw-data">
<h3>1.3. Load and clean raw data<a class="headerlink" href="#1.3.-Load-and-clean-raw-data" title="Permalink to this headline"></a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">interactions_df</span> <span class="o">=</span> <span class="n">cudf</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">DATA_PATH</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">,</span>
                                <span class="n">names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;session_id&#39;</span><span class="p">,</span><span class="s1">&#39;timestamp&#39;</span><span class="p">,</span> <span class="s1">&#39;item_id&#39;</span><span class="p">,</span> <span class="s1">&#39;category&#39;</span><span class="p">],</span>
                                <span class="n">dtype</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;int&#39;</span><span class="p">,</span> <span class="s1">&#39;datetime64[s]&#39;</span><span class="p">,</span> <span class="s1">&#39;int&#39;</span><span class="p">,</span> <span class="s1">&#39;int&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="section" id="Remove-repeated-interactions-within-the-same-session">
<h4>Remove repeated interactions within the same session<a class="headerlink" href="#Remove-repeated-interactions-within-the-same-session" title="Permalink to this headline"></a></h4>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Count with in-session repeated interactions: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">interactions_df</span><span class="p">)))</span>
<span class="c1"># Sorts the dataframe by session and timestamp, to remove consecutive repetitions</span>
<span class="n">interactions_df</span><span class="o">.</span><span class="n">timestamp</span> <span class="o">=</span> <span class="n">interactions_df</span><span class="o">.</span><span class="n">timestamp</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="n">interactions_df</span> <span class="o">=</span> <span class="n">interactions_df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">([</span><span class="s1">&#39;session_id&#39;</span><span class="p">,</span> <span class="s1">&#39;timestamp&#39;</span><span class="p">])</span>
<span class="n">past_ids</span> <span class="o">=</span> <span class="n">interactions_df</span><span class="p">[</span><span class="s1">&#39;item_id&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shift</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">fillna</span><span class="p">()</span>
<span class="n">session_past_ids</span> <span class="o">=</span> <span class="n">interactions_df</span><span class="p">[</span><span class="s1">&#39;session_id&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shift</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">fillna</span><span class="p">()</span>
<span class="c1"># Keeping only no consectutive repeated in session interactions</span>
<span class="n">interactions_df</span> <span class="o">=</span> <span class="n">interactions_df</span><span class="p">[</span><span class="o">~</span><span class="p">((</span><span class="n">interactions_df</span><span class="p">[</span><span class="s1">&#39;session_id&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">session_past_ids</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">interactions_df</span><span class="p">[</span><span class="s1">&#39;item_id&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">past_ids</span><span class="p">))]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Count after removed in-session repeated interactions: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">interactions_df</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Count with in-session repeated interactions: 33003944
Count after removed in-session repeated interactions: 28971543
</pre></div></div>
</div>
</div>
<div class="section" id="Creates-new-feature-with-the-timestamp-when-the-item-was-first-seen">
<h4>Creates new feature with the timestamp when the item was first seen<a class="headerlink" href="#Creates-new-feature-with-the-timestamp-when-the-item-was-first-seen" title="Permalink to this headline"></a></h4>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">items_first_ts_df</span> <span class="o">=</span> <span class="n">interactions_df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;item_id&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">agg</span><span class="p">({</span><span class="s1">&#39;timestamp&#39;</span><span class="p">:</span> <span class="s1">&#39;min&#39;</span><span class="p">})</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;timestamp&#39;</span><span class="p">:</span> <span class="s1">&#39;itemid_ts_first&#39;</span><span class="p">})</span>
<span class="n">interactions_merged_df</span> <span class="o">=</span> <span class="n">interactions_df</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">items_first_ts_df</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;item_id&#39;</span><span class="p">],</span> <span class="n">how</span><span class="o">=</span><span class="s1">&#39;left&#39;</span><span class="p">)</span>
<span class="n">interactions_merged_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>session_id</th>
      <th>timestamp</th>
      <th>item_id</th>
      <th>category</th>
      <th>itemid_ts_first</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>549</td>
      <td>1396774534</td>
      <td>214714927</td>
      <td>0</td>
      <td>1396334996</td>
    </tr>
    <tr>
      <th>1</th>
      <td>549</td>
      <td>1396774556</td>
      <td>214517450</td>
      <td>0</td>
      <td>1396329825</td>
    </tr>
    <tr>
      <th>2</th>
      <td>549</td>
      <td>1396774617</td>
      <td>214714929</td>
      <td>0</td>
      <td>1396341783</td>
    </tr>
    <tr>
      <th>3</th>
      <td>549</td>
      <td>1396774647</td>
      <td>214518555</td>
      <td>0</td>
      <td>1396327272</td>
    </tr>
    <tr>
      <th>4</th>
      <td>549</td>
      <td>1396774664</td>
      <td>214639297</td>
      <td>0</td>
      <td>1396353119</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># free gpu memory</span>
<span class="k">del</span> <span class="n">interactions_df</span><span class="p">,</span> <span class="n">session_past_ids</span><span class="p">,</span> <span class="n">items_first_ts_df</span>
<span class="n">gc</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
0
</pre></div></div>
</div>
</div>
</div>
</div>
<div class="section" id="2.-Define-a-preprocessing-workflow-with-NVTabular">
<h2>2. Define a preprocessing workflow with NVTabular<a class="headerlink" href="#2.-Define-a-preprocessing-workflow-with-NVTabular" title="Permalink to this headline"></a></h2>
<p>NVTabular is a feature engineering and preprocessing library for tabular data designed to quickly and easily manipulate terabyte scale datasets used to train deep learning based recommender systems. It provides a high level abstraction to simplify code and accelerates computation on the GPU using the RAPIDS cuDF library.</p>
<p>NVTabular supports different feature engineering transformations required by deep learning (DL) models such as Categorical encoding and numerical feature normalization. It also supports feature engineering and generating sequential features.</p>
<p>More information about the supported features can be found here.</p>
<div class="section" id="2.1-Feature-engineering:-Create-and-Transform-items-features">
<h3>2.1 Feature engineering: Create and Transform items features<a class="headerlink" href="#2.1-Feature-engineering:-Create-and-Transform-items-features" title="Permalink to this headline"></a></h3>
<p>In this cell, we are defining three transformations ops:</p>
<ul class="simple">
<li><ol class="arabic simple">
<li><p>Encoding categorical variables using <code class="docutils literal notranslate"><span class="pre">Categorify()</span></code> op. We set <code class="docutils literal notranslate"><span class="pre">start_index</span></code> to 1, so that encoded null values start from <code class="docutils literal notranslate"><span class="pre">1</span></code> instead of <code class="docutils literal notranslate"><span class="pre">0</span></code> because we reserve <code class="docutils literal notranslate"><span class="pre">0</span></code> for padding the sequence features.</p></li>
</ol>
</li>
<li><ol class="arabic simple" start="2">
<li><p>Deriving temporal features from timestamp and computing their cyclical representation using a custom lambda function.</p></li>
</ol>
</li>
<li><ol class="arabic simple" start="3">
<li><p>Computing the item recency in days using a custom Op. Note that item recency is defined as the difference between the first occurence of the item in dataset and the actual date of item interaction.</p></li>
</ol>
</li>
</ul>
<p>For more ETL workflow examples, visit NVTabular <a class="reference external" href="https://github.com/NVIDIA/NVTabular/tree/main/examples">example notebooks</a>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Encodes categorical features as contiguous integers</span>
<span class="n">cat_feats</span> <span class="o">=</span> <span class="n">nvt</span><span class="o">.</span><span class="n">ColumnSelector</span><span class="p">([</span><span class="s1">&#39;session_id&#39;</span><span class="p">,</span> <span class="s1">&#39;category&#39;</span><span class="p">,</span> <span class="s1">&#39;item_id&#39;</span><span class="p">])</span> <span class="o">&gt;&gt;</span> <span class="n">nvt</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Categorify</span><span class="p">(</span><span class="n">start_index</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># create time features</span>
<span class="n">session_ts</span> <span class="o">=</span> <span class="n">nvt</span><span class="o">.</span><span class="n">ColumnSelector</span><span class="p">([</span><span class="s1">&#39;timestamp&#39;</span><span class="p">])</span>
<span class="n">session_time</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">session_ts</span> <span class="o">&gt;&gt;</span>
    <span class="n">nvt</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">LambdaOp</span><span class="p">(</span><span class="k">lambda</span> <span class="n">col</span><span class="p">:</span> <span class="n">cudf</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">col</span><span class="p">,</span> <span class="n">unit</span><span class="o">=</span><span class="s1">&#39;s&#39;</span><span class="p">))</span> <span class="o">&gt;&gt;</span>
    <span class="n">nvt</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Rename</span><span class="p">(</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;event_time_dt&#39;</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">sessiontime_weekday</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">session_time</span> <span class="o">&gt;&gt;</span>
    <span class="n">nvt</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">LambdaOp</span><span class="p">(</span><span class="k">lambda</span> <span class="n">col</span><span class="p">:</span> <span class="n">col</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">weekday</span><span class="p">)</span> <span class="o">&gt;&gt;</span>
    <span class="n">nvt</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Rename</span><span class="p">(</span><span class="n">name</span> <span class="o">=</span><span class="s1">&#39;et_dayofweek&#39;</span><span class="p">)</span>
<span class="p">)</span>

<span class="c1"># Derive cyclical features: Defines a custom lambda function</span>
<span class="k">def</span> <span class="nf">get_cycled_feature_value_sin</span><span class="p">(</span><span class="n">col</span><span class="p">,</span> <span class="n">max_value</span><span class="p">):</span>
    <span class="n">value_scaled</span> <span class="o">=</span> <span class="p">(</span><span class="n">col</span> <span class="o">+</span> <span class="mf">0.000001</span><span class="p">)</span> <span class="o">/</span> <span class="n">max_value</span>
    <span class="n">value_sin</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">*</span><span class="n">value_scaled</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">value_sin</span>

<span class="n">weekday_sin</span> <span class="o">=</span> <span class="n">sessiontime_weekday</span> <span class="o">&gt;&gt;</span> <span class="p">(</span><span class="k">lambda</span> <span class="n">col</span><span class="p">:</span> <span class="n">get_cycled_feature_value_sin</span><span class="p">(</span><span class="n">col</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span> <span class="o">&gt;&gt;</span> <span class="n">nvt</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Rename</span><span class="p">(</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;et_dayofweek_sin&#39;</span><span class="p">)</span>

<span class="c1"># Compute Item recency: Define a custom Op</span>
<span class="k">class</span> <span class="nc">ItemRecency</span><span class="p">(</span><span class="n">nvt</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Operator</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">columns</span><span class="p">,</span> <span class="n">gdf</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">columns</span><span class="o">.</span><span class="n">names</span><span class="p">:</span>
            <span class="n">col</span> <span class="o">=</span> <span class="n">gdf</span><span class="p">[</span><span class="n">column</span><span class="p">]</span>
            <span class="n">item_first_timestamp</span> <span class="o">=</span> <span class="n">gdf</span><span class="p">[</span><span class="s1">&#39;itemid_ts_first&#39;</span><span class="p">]</span>
            <span class="n">delta_days</span> <span class="o">=</span> <span class="p">(</span><span class="n">col</span> <span class="o">-</span> <span class="n">item_first_timestamp</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">60</span><span class="o">*</span><span class="mi">60</span><span class="o">*</span><span class="mi">24</span><span class="p">)</span>
            <span class="n">gdf</span><span class="p">[</span><span class="n">column</span> <span class="o">+</span> <span class="s2">&quot;_age_days&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">delta_days</span> <span class="o">*</span> <span class="p">(</span><span class="n">delta_days</span> <span class="o">&gt;=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">gdf</span>

    <span class="k">def</span> <span class="nf">output_column_names</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">columns</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">nvt</span><span class="o">.</span><span class="n">ColumnSelector</span><span class="p">([</span><span class="n">column</span> <span class="o">+</span> <span class="s2">&quot;_age_days&quot;</span> <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">columns</span><span class="o">.</span><span class="n">names</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">dependencies</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">[</span><span class="s2">&quot;itemid_ts_first&quot;</span><span class="p">]</span>

<span class="n">recency_features</span> <span class="o">=</span> <span class="n">session_ts</span> <span class="o">&gt;&gt;</span> <span class="n">ItemRecency</span><span class="p">()</span>
<span class="c1"># Apply standardization to this continuous feature</span>
<span class="n">recency_features_norm</span> <span class="o">=</span> <span class="n">recency_features</span> <span class="o">&gt;&gt;</span> <span class="n">nvt</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">LogOp</span><span class="p">()</span> <span class="o">&gt;&gt;</span> <span class="n">nvt</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Normalize</span><span class="p">()</span> <span class="o">&gt;&gt;</span> <span class="n">nvt</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Rename</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;product_recency_days_log_norm&#39;</span><span class="p">)</span>

<span class="n">time_features</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">session_time</span> <span class="o">+</span>
    <span class="n">sessiontime_weekday</span> <span class="o">+</span>
    <span class="n">weekday_sin</span> <span class="o">+</span>
    <span class="n">recency_features_norm</span>
<span class="p">)</span>

<span class="n">features</span> <span class="o">=</span> <span class="n">nvt</span><span class="o">.</span><span class="n">ColumnSelector</span><span class="p">([</span><span class="s1">&#39;timestamp&#39;</span><span class="p">,</span> <span class="s1">&#39;session_id&#39;</span><span class="p">])</span> <span class="o">+</span> <span class="n">cat_feats</span> <span class="o">+</span> <span class="n">time_features</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="2.2-Defines-the-preprocessing-of-sequential-features">
<h3>2.2 Defines the preprocessing of sequential features<a class="headerlink" href="#2.2-Defines-the-preprocessing-of-sequential-features" title="Permalink to this headline"></a></h3>
<p>Once the item features are generated, the objective of this cell is grouping interactions at the session level, sorting the interactions by time. We additionally truncate all sessions to first 20 interactions and filter out sessions with less than 2 interactions.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define Groupby Operator</span>
<span class="n">groupby_features</span> <span class="o">=</span> <span class="n">features</span> <span class="o">&gt;&gt;</span> <span class="n">nvt</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Groupby</span><span class="p">(</span>
    <span class="n">groupby_cols</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;session_id&quot;</span><span class="p">],</span>
    <span class="n">sort_cols</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;timestamp&quot;</span><span class="p">],</span>
    <span class="n">aggs</span><span class="o">=</span><span class="p">{</span>
        <span class="s1">&#39;item_id&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;list&quot;</span><span class="p">,</span> <span class="s2">&quot;count&quot;</span><span class="p">],</span>
        <span class="s1">&#39;category&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;list&quot;</span><span class="p">],</span>
        <span class="s1">&#39;timestamp&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;first&quot;</span><span class="p">],</span>
        <span class="s1">&#39;event_time_dt&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;first&quot;</span><span class="p">],</span>
        <span class="s1">&#39;et_dayofweek_sin&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;list&quot;</span><span class="p">],</span>
        <span class="s1">&#39;product_recency_days_log_norm&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;list&quot;</span><span class="p">]</span>
        <span class="p">},</span>
    <span class="n">name_sep</span><span class="o">=</span><span class="s2">&quot;-&quot;</span><span class="p">)</span>


<span class="c1"># Truncate sequence features to first interacted 20 items</span>
<span class="n">SESSIONS_MAX_LENGTH</span> <span class="o">=</span> <span class="mi">20</span>

<span class="n">groupby_features_list</span> <span class="o">=</span> <span class="n">groupby_features</span><span class="p">[</span><span class="s1">&#39;item_id-list&#39;</span><span class="p">,</span> <span class="s1">&#39;category-list&#39;</span><span class="p">,</span> <span class="s1">&#39;et_dayofweek_sin-list&#39;</span><span class="p">,</span> <span class="s1">&#39;product_recency_days_log_norm-list&#39;</span><span class="p">]</span>
<span class="n">groupby_features_truncated</span> <span class="o">=</span> <span class="n">groupby_features_list</span> <span class="o">&gt;&gt;</span> <span class="n">nvt</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">ListSlice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">SESSIONS_MAX_LENGTH</span><span class="p">)</span> <span class="o">&gt;&gt;</span> <span class="n">nvt</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Rename</span><span class="p">(</span><span class="n">postfix</span> <span class="o">=</span> <span class="s1">&#39;_seq&#39;</span><span class="p">)</span>

<span class="c1"># Calculate session day index based on &#39;event_time_dt-first&#39; column</span>
<span class="n">day_index</span> <span class="o">=</span> <span class="p">((</span><span class="n">groupby_features</span><span class="p">[</span><span class="s1">&#39;event_time_dt-first&#39;</span><span class="p">])</span>  <span class="o">&gt;&gt;</span>
    <span class="n">nvt</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">LambdaOp</span><span class="p">(</span><span class="k">lambda</span> <span class="n">col</span><span class="p">:</span> <span class="p">(</span><span class="n">col</span> <span class="o">-</span> <span class="n">col</span><span class="o">.</span><span class="n">min</span><span class="p">())</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">days</span> <span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">&gt;&gt;</span>
    <span class="n">nvt</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Rename</span><span class="p">(</span><span class="n">f</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">col</span><span class="p">:</span> <span class="s2">&quot;day_index&quot;</span><span class="p">)</span>
<span class="p">)</span>

<span class="c1"># Select features for training</span>
<span class="n">selected_features</span> <span class="o">=</span> <span class="n">groupby_features</span><span class="p">[</span><span class="s1">&#39;session_id&#39;</span><span class="p">,</span> <span class="s1">&#39;item_id-count&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">groupby_features_truncated</span> <span class="o">+</span> <span class="n">day_index</span>

<span class="c1"># Filter out sessions with less than 2 interactions</span>
<span class="n">MINIMUM_SESSION_LENGTH</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">filtered_sessions</span> <span class="o">=</span> <span class="n">selected_features</span> <span class="o">&gt;&gt;</span> <span class="n">nvt</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Filter</span><span class="p">(</span><span class="n">f</span><span class="o">=</span><span class="k">lambda</span> <span class="n">df</span><span class="p">:</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;item_id-count&quot;</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">MINIMUM_SESSION_LENGTH</span><span class="p">)</span>
</pre></div>
</div>
</div>
<ul class="simple">
<li><p>Avoid Numba low occupancy warnings</p></li>
</ul>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">numba</span> <span class="kn">import</span> <span class="n">config</span>
<span class="n">config</span><span class="o">.</span><span class="n">CUDA_LOW_OCCUPANCY_WARNINGS</span> <span class="o">=</span> <span class="mi">0</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="2.3-Execute-NVTabular-workflow">
<h3>2.3 Execute NVTabular workflow<a class="headerlink" href="#2.3-Execute-NVTabular-workflow" title="Permalink to this headline"></a></h3>
<p>Once we have defined the general workflow (<code class="docutils literal notranslate"><span class="pre">filtered_sessions</span></code>), we provide our cudf dataset to nvt.Dataset class which is optimized to split data into chunks that can fit in device memory and to handle the calculation of complex global statistics. Then, we execute the pipeline that fits and transforms data to get the desired output features.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">nvt</span><span class="o">.</span><span class="n">Dataset</span><span class="p">(</span><span class="n">interactions_merged_df</span><span class="p">)</span>
<span class="n">workflow</span> <span class="o">=</span> <span class="n">nvt</span><span class="o">.</span><span class="n">Workflow</span><span class="p">(</span><span class="n">filtered_sessions</span><span class="p">)</span>
<span class="c1"># Learns features statistics necessary of the preprocessing workflow</span>
<span class="n">workflow</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
<span class="c1"># Apply the preprocessing workflow in the dataset and converts the resulting Dask cudf dataframe to a cudf dataframe</span>
<span class="n">sessions_gdf</span> <span class="o">=</span> <span class="n">workflow</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
</pre></div>
</div>
</div>
<p>Let’s print the head of our preprocessed dataset. You can notice that now each example (row) is a session and the sequential features with respect to user interactions were converted to lists with matching length.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sessions_gdf</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>session_id</th>
      <th>item_id-count</th>
      <th>item_id-list_seq</th>
      <th>category-list_seq</th>
      <th>et_dayofweek_sin-list_seq</th>
      <th>product_recency_days_log_norm-list_seq</th>
      <th>day_index</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2</td>
      <td>200</td>
      <td>[2223, 2125, 1800, 123, 3030, 1861, 1076, 1285...</td>
      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>
      <td>[1.1285199e-06, 1.1285199e-06, 1.1285199e-06, ...</td>
      <td>[-1.1126341, -0.9665389, -0.1350116, -0.127809...</td>
      <td>27</td>
    </tr>
    <tr>
      <th>1</th>
      <td>3</td>
      <td>200</td>
      <td>[26562, 35137, 19260, 46449, 29027, 39096, 272...</td>
      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>
      <td>[0.43388295, 0.43388295, 0.43388295, 0.4338829...</td>
      <td>[0.40848607, 0.39331725, 0.5418466, -3.0278225...</td>
      <td>58</td>
    </tr>
    <tr>
      <th>2</th>
      <td>4</td>
      <td>200</td>
      <td>[23212, 30448, 16468, 2052, 22490, 31097, 6243...</td>
      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>
      <td>[0.9749277, 0.9749277, 0.9749277, 0.9749277, 0...</td>
      <td>[0.6801631, 0.7174695, 0.7185285, 0.7204116, 0...</td>
      <td>71</td>
    </tr>
    <tr>
      <th>3</th>
      <td>5</td>
      <td>200</td>
      <td>[230, 451, 732, 1268, 2014, 567, 497, 439, 338...</td>
      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, ...</td>
      <td>[0.43388295, 0.43388295, 0.43388295, 0.4338829...</td>
      <td>[1.3680888, -0.6530481, -0.69314253, -0.590593...</td>
      <td>149</td>
    </tr>
    <tr>
      <th>4</th>
      <td>6</td>
      <td>200</td>
      <td>[23, 70, 160, 70, 90, 742, 851, 359, 734, 878,...</td>
      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>
      <td>[0.43388295, 0.43388295, 0.43388295, 0.4338829...</td>
      <td>[1.3714824, 1.3715883, 1.3715737, 1.3715955, 1...</td>
      <td>149</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<div class="section" id="Saves-the-preprocesing-workflow">
<h4>Saves the preprocesing workflow<a class="headerlink" href="#Saves-the-preprocesing-workflow" title="Permalink to this headline"></a></h4>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">workflow</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;workflow_etl&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="2.4-Export-pre-processed-data-by-day">
<h3>2.4 Export pre-processed data by day<a class="headerlink" href="#2.4-Export-pre-processed-data-by-day" title="Permalink to this headline"></a></h3>
<p>In this example we are going to split the preprocessed parquet files by days, to allow for temporal training and evaluation. There will be a folder for each day and three parquet files within each day: <code class="docutils literal notranslate"><span class="pre">train.parquet</span></code>, <code class="docutils literal notranslate"><span class="pre">validation.parquet</span></code> and <code class="docutils literal notranslate"><span class="pre">test.parquet</span></code></p>
<p>P.s. It is worthwhile a note that the dataset have a single categorical feature (category), but it is inconsistent over time in the dataset. All interactions before day 84 (2014-06-23) have the same value for that feature, whereas many other categories are introduced afterwards. Thus for the demo we save only the last five days.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sessions_gdf</span> <span class="o">=</span> <span class="n">sessions_gdf</span><span class="p">[</span><span class="n">sessions_gdf</span><span class="o">.</span><span class="n">day_index</span><span class="o">&gt;=</span><span class="mi">178</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">transformers4rec.data.preprocessing</span> <span class="kn">import</span> <span class="n">save_time_based_splits</span>
<span class="n">save_time_based_splits</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">nvt</span><span class="o">.</span><span class="n">Dataset</span><span class="p">(</span><span class="n">sessions_gdf</span><span class="p">),</span>
                       <span class="n">output_dir</span><span class="o">=</span> <span class="s2">&quot;./preproc_sessions_by_day&quot;</span><span class="p">,</span>
                       <span class="n">partition_col</span><span class="o">=</span><span class="s1">&#39;day_index&#39;</span><span class="p">,</span>
                       <span class="n">timestamp_col</span><span class="o">=</span><span class="s1">&#39;session_id&#39;</span><span class="p">,</span>
                      <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Creating time-based splits: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00&lt;00:00,  5.64it/s]
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">transformers4rec.torch.utils.examples_utils</span> <span class="kn">import</span> <span class="n">list_files</span>
<span class="n">list_files</span><span class="p">(</span><span class="s1">&#39;./preproc_sessions_by_day&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
preproc_sessions_by_day/
    180/
        test.parquet
        valid.parquet
        train.parquet
    181/
        test.parquet
        valid.parquet
        train.parquet
    179/
        test.parquet
        valid.parquet
        train.parquet
    182/
        test.parquet
        valid.parquet
        train.parquet
    178/
        test.parquet
        valid.parquet
        train.parquet
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># free gpu memory</span>
<span class="k">del</span>  <span class="n">sessions_gdf</span>
<span class="n">gc</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
0
</pre></div></div>
</div>
</div>
</div>
<div class="section" id="3.-Model-definition-using-Transformers4Rec">
<h2>3. Model definition using Transformers4Rec<a class="headerlink" href="#3.-Model-definition-using-Transformers4Rec" title="Permalink to this headline"></a></h2>
<div class="section" id="3.1-Get-the-schema">
<h3>3.1 Get the schema<a class="headerlink" href="#3.1-Get-the-schema" title="Permalink to this headline"></a></h3>
<p>The library uses a schema format to configure the input features and automatically creates the necessary layers. This <em>protobuf</em> text file contains the description of each input feature by defining: the name, the type, the number of elements of a list column, the cardinality of a categorical feature and the min and max values of each feature. In addition, the annotation field contains the tags such as specifying <code class="docutils literal notranslate"><span class="pre">continuous</span></code> and <code class="docutils literal notranslate"><span class="pre">categorical</span></code> features, the <code class="docutils literal notranslate"><span class="pre">target</span></code> column or the
<code class="docutils literal notranslate"><span class="pre">item_id</span></code> feature, among others.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">merlin_standard_lib</span> <span class="kn">import</span> <span class="n">Schema</span>
<span class="n">SCHEMA_PATH</span> <span class="o">=</span> <span class="s2">&quot;schema_demo.pb&quot;</span>
<span class="n">schema</span> <span class="o">=</span> <span class="n">Schema</span><span class="p">()</span><span class="o">.</span><span class="n">from_proto_text</span><span class="p">(</span><span class="n">SCHEMA_PATH</span><span class="p">)</span>
<span class="o">!</span>cat <span class="nv">$SCHEMA_PATH</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
feature {
  name: &#34;item_id-list_seq&#34;
  value_count {
    min: 2
    max: 185
  }
  type: INT
  int_domain {
    name: &#34;item_id/list&#34;
    min: 1
    max: 52742
    is_categorical: true
  }
  annotation {
    tag: &#34;item_id&#34;
    tag: &#34;list&#34;
    tag: &#34;categorical&#34;
    tag: &#34;item&#34;
  }
}
feature {
  name: &#34;session_id&#34;
  type: INT
  int_domain {
    name: &#34;session_id&#34;
    min: 1
    max: 9249733
    is_categorical: false
  }
  annotation {
    tag: &#34;groupby_col&#34;
  }
}
feature {
  name: &#34;category-list_seq&#34;
  value_count {
    min: 2
    max: 185
  }
  type: INT
  int_domain {
    name: &#34;category-list_seq&#34;
    min: 1
    max: 337
    is_categorical: true
  }
  annotation {
    tag: &#34;list&#34;
    tag: &#34;categorical&#34;
    tag: &#34;item&#34;
  }
}
feature {
  name: &#34;product_recency_days_log_norm-list_seq&#34;
  value_count {
    min: 2
    max: 185
  }
  type: FLOAT
  float_domain {
    name: &#34;product_recency_days_log_norm-list_seq&#34;
    min: -2.9177291
    max: 1.5231701
  }
  annotation {
    tag: &#34;continuous&#34;
    tag: &#34;list&#34;
  }
}
feature {
  name: &#34;et_dayofweek_sin-list_seq&#34;
  value_count {
    min: 2
    max: 185
  }
  type: FLOAT
  float_domain {
    name: &#34;et_dayofweek_sin-list_seq&#34;
    min: 0.7421683
    max: 0.9995285
  }
  annotation {
    tag: &#34;time&#34;
    tag: &#34;list&#34;
  }
}
</pre></div></div>
</div>
<p>We can select the subset of features we want to use for training the model by their tags or their names.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">schema</span> <span class="o">=</span> <span class="n">schema</span><span class="o">.</span><span class="n">select_by_name</span><span class="p">(</span>
   <span class="p">[</span><span class="s1">&#39;item_id-list_seq&#39;</span><span class="p">,</span> <span class="s1">&#39;category-list_seq&#39;</span><span class="p">,</span> <span class="s1">&#39;product_recency_days_log_norm-list_seq&#39;</span><span class="p">,</span> <span class="s1">&#39;et_dayofweek_sin-list_seq&#39;</span><span class="p">]</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="3.2-Define-the-end-to-end-Session-based-Transformer-based-recommendation-model">
<h3>3.2 Define the end-to-end Session-based Transformer-based recommendation model<a class="headerlink" href="#3.2-Define-the-end-to-end-Session-based-Transformer-based-recommendation-model" title="Permalink to this headline"></a></h3>
<p>For session-based recommendation model definition, the end-to-end model definition requires four steps:</p>
<ol class="arabic simple">
<li><p>Instantiate <a class="reference external" href="https://nvidia-merlin.github.io/Transformers4Rec/main/api/transformers4rec.tf.features.html?highlight=tabularsequence#transformers4rec.tf.features.sequence.TabularSequenceFeatures">TabularSequenceFeatures</a> input-module from schema to prepare the embedding tables of categorical variables and project continuous features, if specified. In addition, the module provides different aggregation methods (e.g. ‘concat’, ‘elementwise-sum’) to merge input features and generate the
sequence of interactions embeddings. The module also supports language modeling tasks to prepare masked labels for training and evaluation (e.g: ‘mlm’ for masked language modeling)</p></li>
<li><p>Next, we need to define one or multiple prediction tasks. For this demo, we are going to use <a class="reference external" href="https://nvidia-merlin.github.io/Transformers4Rec/main/api/transformers4rec.tf.model.html?highlight=nextitem#transformers4rec.tf.model.prediction_task.NextItemPredictionTask">NextItemPredictionTask</a> with <code class="docutils literal notranslate"><span class="pre">Masked</span> <span class="pre">Language</span> <span class="pre">modeling</span></code>: during training randomly selected items are masked and predicted using the unmasked sequence items. For inference it is meant to always predict the next item to be
interacted with.</p></li>
<li><p>Then we construct a <code class="docutils literal notranslate"><span class="pre">transformer_config</span></code> based on the architectures provided by <a class="reference external" href="https://github.com/huggingface/transformers">Hugging Face Transformers</a> framework.</p></li>
<li><p>Finally we link the transformer-body to the inputs and the prediction tasks to get the final pytorch <code class="docutils literal notranslate"><span class="pre">Model</span></code> class.</p></li>
</ol>
<p>For more details about the features supported by each sub-module, please check out the library <a class="reference external" href="https://nvidia-merlin.github.io/Transformers4Rec/main/index.html">documentation</a> page.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">transformers4rec</span> <span class="kn">import</span> <span class="n">torch</span> <span class="k">as</span> <span class="n">tr</span>

<span class="n">max_sequence_length</span><span class="p">,</span> <span class="n">d_model</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">320</span>
<span class="c1"># Define input module to process tabular input-features and to prepare masked inputs</span>
<span class="n">input_module</span> <span class="o">=</span> <span class="n">tr</span><span class="o">.</span><span class="n">TabularSequenceFeatures</span><span class="o">.</span><span class="n">from_schema</span><span class="p">(</span>
    <span class="n">schema</span><span class="p">,</span>
    <span class="n">max_sequence_length</span><span class="o">=</span><span class="n">max_sequence_length</span><span class="p">,</span>
    <span class="n">continuous_projection</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
    <span class="n">aggregation</span><span class="o">=</span><span class="s2">&quot;concat&quot;</span><span class="p">,</span>
    <span class="n">d_output</span><span class="o">=</span><span class="n">d_model</span><span class="p">,</span>
    <span class="n">masking</span><span class="o">=</span><span class="s2">&quot;mlm&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Define Next item prediction-task</span>
<span class="n">prediction_task</span> <span class="o">=</span> <span class="n">tr</span><span class="o">.</span><span class="n">NextItemPredictionTask</span><span class="p">(</span><span class="n">hf_format</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">weight_tying</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Define the config of the XLNet Transformer architecture</span>
<span class="n">transformer_config</span> <span class="o">=</span> <span class="n">tr</span><span class="o">.</span><span class="n">XLNetConfig</span><span class="o">.</span><span class="n">build</span><span class="p">(</span>
    <span class="n">d_model</span><span class="o">=</span><span class="n">d_model</span><span class="p">,</span> <span class="n">n_head</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">n_layer</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">total_seq_length</span><span class="o">=</span><span class="n">max_sequence_length</span>
<span class="p">)</span>

<span class="c1">#Get the end-to-end model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">transformer_config</span><span class="o">.</span><span class="n">to_torch_model</span><span class="p">(</span><span class="n">input_module</span><span class="p">,</span> <span class="n">prediction_task</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Projecting inputs of NextItemPredictionTask to&#39;64&#39; As weight tying requires the input dimension &#39;320&#39; to be equal to the item-id embedding dimension &#39;64&#39;
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Model(
  (heads): ModuleList(
    (0): Head(
      (body): SequentialBlock(
        (0): TabularSequenceFeatures(
          (_aggregation): ConcatFeatures()
          (to_merge): ModuleDict(
            (continuous_module): SequentialBlock(
              (0): ContinuousFeatures(
                (filter_features): FilterFeatures()
                (_aggregation): ConcatFeatures()
              )
              (1): SequentialBlock(
                (0): DenseBlock(
                  (0): Linear(in_features=1, out_features=64, bias=True)
                  (1): ReLU(inplace=True)
                )
              )
              (2): AsTabular()
            )
            (categorical_module): SequenceEmbeddingFeatures(
              (filter_features): FilterFeatures()
              (embedding_tables): ModuleDict(
                (item_id-list_seq): Embedding(52743, 64, padding_idx=0)
                (category-list_seq): Embedding(338, 64, padding_idx=0)
              )
            )
          )
          (projection_module): SequentialBlock(
            (0): DenseBlock(
              (0): Linear(in_features=192, out_features=320, bias=True)
              (1): ReLU(inplace=True)
            )
          )
          (_masking): MaskedLanguageModeling()
        )
        (1): TansformerBlock(
          (transformer): XLNetModel(
            (word_embedding): Embedding(1, 320)
            (layer): ModuleList(
              (0): XLNetLayer(
                (rel_attn): XLNetRelativeAttention(
                  (layer_norm): LayerNorm((320,), eps=0.03, elementwise_affine=True)
                  (dropout): Dropout(p=0.3, inplace=False)
                )
                (ff): XLNetFeedForward(
                  (layer_norm): LayerNorm((320,), eps=0.03, elementwise_affine=True)
                  (layer_1): Linear(in_features=320, out_features=1280, bias=True)
                  (layer_2): Linear(in_features=1280, out_features=320, bias=True)
                  (dropout): Dropout(p=0.3, inplace=False)
                )
                (dropout): Dropout(p=0.3, inplace=False)
              )
              (1): XLNetLayer(
                (rel_attn): XLNetRelativeAttention(
                  (layer_norm): LayerNorm((320,), eps=0.03, elementwise_affine=True)
                  (dropout): Dropout(p=0.3, inplace=False)
                )
                (ff): XLNetFeedForward(
                  (layer_norm): LayerNorm((320,), eps=0.03, elementwise_affine=True)
                  (layer_1): Linear(in_features=320, out_features=1280, bias=True)
                  (layer_2): Linear(in_features=1280, out_features=320, bias=True)
                  (dropout): Dropout(p=0.3, inplace=False)
                )
                (dropout): Dropout(p=0.3, inplace=False)
              )
            )
            (dropout): Dropout(p=0.3, inplace=False)
          )
          (masking): MaskedLanguageModeling()
        )
      )
      (prediction_task_dict): ModuleDict(
        (next-item): NextItemPredictionTask(
          (sequence_summary): SequenceSummary(
            (summary): Identity()
            (activation): Identity()
            (first_dropout): Identity()
            (last_dropout): Identity()
          )
          (metrics): ModuleList(
            (0): NDCGAt()
            (1): AvgPrecisionAt()
            (2): RecallAt()
          )
          (loss): NLLLoss()
          (embeddings): SequenceEmbeddingFeatures(
            (filter_features): FilterFeatures()
            (embedding_tables): ModuleDict(
              (item_id-list_seq): Embedding(52743, 64, padding_idx=0)
              (category-list_seq): Embedding(338, 64, padding_idx=0)
            )
          )
          (item_embedding_table): Embedding(52743, 64, padding_idx=0)
          (masking): MaskedLanguageModeling()
          (task_block): SequentialBlock(
            (0): DenseBlock(
              (0): Linear(in_features=320, out_features=64, bias=True)
              (1): ReLU(inplace=True)
            )
          )
          (pre): Block(
            (module): NextItemPredictionTask(
              (item_embedding_table): Embedding(52743, 64, padding_idx=0)
              (log_softmax): LogSoftmax(dim=-1)
            )
          )
        )
      )
    )
  )
)
</pre></div></div>
</div>
</div>
<div class="section" id="3.3.-Daily-Fine-Tuning:-Training-over-a-time-window¶">
<h3>3.3. Daily Fine-Tuning: Training over a time window¶<a class="headerlink" href="#3.3.-Daily-Fine-Tuning:-Training-over-a-time-window¶" title="Permalink to this headline"></a></h3>
<p>Now that the model is defined, we are going to launch training. For that, Transfromers4rec extends HF Transformers Trainer class to adapt the evaluation loop for session-based recommendation task and the calculation of ranking metrics. The original <code class="docutils literal notranslate"><span class="pre">train()</span></code> method is not modified meaning that we leverage the efficient training implementation from that library, which manages for example half-precision (FP16) training.</p>
<div class="section" id="Sets-Training-arguments">
<h4>Sets Training arguments<a class="headerlink" href="#Sets-Training-arguments" title="Permalink to this headline"></a></h4>
<p>An additional argument <code class="docutils literal notranslate"><span class="pre">data_loader_engine</span></code> is defined to automatically load the features needed for training using the schema. The default value is <code class="docutils literal notranslate"><span class="pre">nvtabular</span></code> for optimized GPU-based data-loading. Optionally a <code class="docutils literal notranslate"><span class="pre">PyarrowDataLoader</span></code> (<code class="docutils literal notranslate"><span class="pre">pyarrow</span></code>) can also be used as a basic option, but it is slower and works only for small datasets, as the full data is loaded to CPU memory.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">training_args</span> <span class="o">=</span> <span class="n">tr</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">T4RecTrainingArguments</span><span class="p">(</span>
            <span class="n">output_dir</span><span class="o">=</span><span class="s2">&quot;./tmp&quot;</span><span class="p">,</span>
            <span class="n">max_sequence_length</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
            <span class="n">data_loader_engine</span><span class="o">=</span><span class="s1">&#39;nvtabular&#39;</span><span class="p">,</span>
            <span class="n">num_train_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
            <span class="n">dataloader_drop_last</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">per_device_train_batch_size</span> <span class="o">=</span> <span class="mi">384</span><span class="p">,</span>
            <span class="n">per_device_eval_batch_size</span> <span class="o">=</span> <span class="mi">512</span><span class="p">,</span>
            <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.0005</span><span class="p">,</span>
            <span class="n">fp16</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">report_to</span> <span class="o">=</span> <span class="p">[],</span>
            <span class="n">logging_steps</span><span class="o">=</span><span class="mi">200</span>
        <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Instantiate-the-trainer">
<h4>Instantiate the trainer<a class="headerlink" href="#Instantiate-the-trainer" title="Permalink to this headline"></a></h4>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[22]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">recsys_trainer</span> <span class="o">=</span> <span class="n">tr</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
    <span class="n">args</span><span class="o">=</span><span class="n">training_args</span><span class="p">,</span>
    <span class="n">schema</span><span class="o">=</span><span class="n">schema</span><span class="p">,</span>
    <span class="n">compute_metrics</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Using amp fp16 backend
</pre></div></div>
</div>
</div>
<div class="section" id="Launches-daily-Training-and-Evaluation">
<h4>Launches daily Training and Evaluation<a class="headerlink" href="#Launches-daily-Training-and-Evaluation" title="Permalink to this headline"></a></h4>
<p>In this demo, we will use the <code class="docutils literal notranslate"><span class="pre">fit_and_evaluate</span></code> method that allows us to conduct a time-based finetuning by iteratively training and evaluating using a sliding time window: At each iteration, we use training data of a specific time index <span class="math notranslate nohighlight">\(t\)</span> to train the model then we evaluate on the validation data of next index <span class="math notranslate nohighlight">\(t + 1\)</span>. Particularly, the start time is set to 178 and end time to 180.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">transformers4rec.torch.utils.examples_utils</span> <span class="kn">import</span> <span class="n">fit_and_evaluate</span>
<span class="n">aot_results</span> <span class="o">=</span> <span class="n">fit_and_evaluate</span><span class="p">(</span><span class="n">recsys_trainer</span><span class="p">,</span> <span class="n">start_time_index</span><span class="o">=</span><span class="mi">178</span><span class="p">,</span> <span class="n">end_time_index</span><span class="o">=</span><span class="mi">178</span><span class="p">,</span> <span class="n">input_dir</span><span class="o">=</span><span class="s1">&#39;./preproc_sessions_by_day&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
***** Running training *****
  Num examples = 28800
  Num Epochs = 10
  Instantaneous batch size per device = 384
  Total train batch size (w. parallel, distributed &amp; accumulation) = 1536
  Gradient Accumulation steps = 1
  Total optimization steps = 750
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

***** Launch training for day 178: *****
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
    <div>

      <progress value='750' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>
      [750/750 00:31, Epoch 10/10]
    </div>
    <table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>Step</th>
      <th>Training Loss</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>200</td>
      <td>7.807600</td>
    </tr>
    <tr>
      <td>400</td>
      <td>6.737500</td>
    </tr>
    <tr>
      <td>600</td>
      <td>6.462300</td>
    </tr>
  </tbody>
</table><p></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Saving model checkpoint to ./tmp/checkpoint-500
Trainer.model is not a `PreTrainedModel`, only saving its state dict.


Training completed. Do not forget to share your model on huggingface.co/models =)


</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<div>

  <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>
  [6/6 00:00]
</div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

***** Evaluation results for day 179:*****

 eval/next-item/avg_precision_@10 = 0.06432348489761353
 eval/next-item/avg_precision_@20 = 0.06879562139511108
 eval/next-item/ndcg_@10 = 0.09142451733350754
 eval/next-item/ndcg_@20 = 0.10751541703939438
 eval/next-item/recall_@10 = 0.17764931917190552
 eval/next-item/recall_@20 = 0.24123314023017883
</pre></div></div>
</div>
</div>
<div class="section" id="Visualize-the-average-over-time-metrics">
<h4>Visualize the average over time metrics<a class="headerlink" href="#Visualize-the-average-over-time-metrics" title="Permalink to this headline"></a></h4>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mean_results</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="n">aot_results</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
<span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">mean_results</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot; </span><span class="si">%s</span><span class="s2"> = </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">mean_results</span><span class="p">[</span><span class="n">key</span><span class="p">])))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
 AOT_eval/next-item/avg_precision@10 = 0.06432348489761353
 AOT_eval/next-item/avg_precision@20 = 0.06879562139511108
 AOT_eval/next-item/ndcg@10 = 0.09142451733350754
 AOT_eval/next-item/ndcg@20 = 0.10751541703939438
 AOT_eval/next-item/recall@10 = 0.17764931917190552
 AOT_eval/next-item/recall@20 = 0.24123314023017883
</pre></div></div>
</div>
</div>
<div class="section" id="Saves-the-model">
<h4>Saves the model<a class="headerlink" href="#Saves-the-model" title="Permalink to this headline"></a></h4>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[25]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">recsys_trainer</span><span class="o">.</span><span class="n">_save_model_and_checkpoint</span><span class="p">(</span><span class="n">save_model_class</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Saving model checkpoint to ./tmp/checkpoint-750
Trainer.model is not a `PreTrainedModel`, only saving its state dict.
</pre></div></div>
</div>
</div>
<div class="section" id="Exports-the-preprocessing-workflow-and-model-in-the-format-required-by-Triton-server:**">
<h4>Exports the preprocessing workflow and model in the format required by Triton server:<a href="#id1"><span class="problematic" id="id2">*</span></a>*<a class="headerlink" href="#Exports-the-preprocessing-workflow-and-model-in-the-format-required-by-Triton-server:**" title="Permalink to this headline"></a></h4>
<p>NVTabular’s <code class="docutils literal notranslate"><span class="pre">export_pytorch_ensemble()</span></code> function enables us to create model files and config files to be served to Triton Inference Server.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[26]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nvtabular.inference.triton</span> <span class="kn">import</span> <span class="n">export_pytorch_ensemble</span>
<span class="n">export_pytorch_ensemble</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">workflow</span><span class="p">,</span>
    <span class="n">sparse_max</span><span class="o">=</span><span class="n">recsys_trainer</span><span class="o">.</span><span class="n">get_train_dataloader</span><span class="p">()</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">sparse_max</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span> <span class="s2">&quot;t4r_pytorch&quot;</span><span class="p">,</span>
    <span class="n">model_path</span><span class="o">=</span> <span class="s2">&quot;/workspace/TF4Rec/models/&quot;</span><span class="p">,</span>
    <span class="n">label_columns</span> <span class="o">=</span><span class="p">[],</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="4.-Serving-Ensemble-Model-to-the-Triton-Inference-Server">
<h2>4. Serving Ensemble Model to the Triton Inference Server<a class="headerlink" href="#4.-Serving-Ensemble-Model-to-the-Triton-Inference-Server" title="Permalink to this headline"></a></h2>
<p>NVIDIA <a class="reference external" href="https://github.com/triton-inference-server/server">Triton Inference Server (TIS)</a> simplifies the deployment of AI models at scale in production. TIS provides a cloud and edge inferencing solution optimized for both CPUs and GPUs. It supports a number of different machine learning frameworks such as TensorFlow and PyTorch.</p>
<p>The last step of machine learning (ML)/deep learning (DL) pipeline is to deploy the ETL workflow and saved model to production. In the production setting, we want to transform the input data as done during training (ETL). We need to apply the same mean/std for continuous features and use the same categorical mapping to convert the categories to continuous integer before we use the DL model for a prediction. Therefore, we deploy the NVTabular workflow with the PyTorch model as an ensemble model
to Triton Inference. The ensemble model guarantees that the same transformation is applied to the raw inputs.</p>
<p>In this section, you will learn how to - to deploy saved NVTabular and PyTorch models to Triton Inference Server - send requests for predictions and get responses.</p>
<div class="section" id="4.1.-Pull-and-Start-Inference-Container">
<h3>4.1. Pull and Start Inference Container<a class="headerlink" href="#4.1.-Pull-and-Start-Inference-Container" title="Permalink to this headline"></a></h3>
<p>At this point, before connecing to the Triton Server, we launch the inference docker container and then load the ensemble <code class="docutils literal notranslate"><span class="pre">t4r_pytorch</span></code> to the inference server. This is done with the scripts below:</p>
<p><strong>Launch the docker container</strong></p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>docker run -it --gpus device=0 -p 8000:8000 -p 8001:8001 -p 8002:8002 -v &lt;path_to_saved_models&gt;:/workspace/models/ nvcr.io/nvidia/merlin/merlin-inference:21.09
</pre></div>
</div>
<p>This script will mount your local model-repository folder that includes your saved models from the previous cell to <code class="docutils literal notranslate"><span class="pre">/workspace/models</span></code> directory in the merlin-inference docker container.</p>
<p><strong>Start triton server</strong> After you started the merlin-inference container, you can start triton server with the command below. You need to provide correct path of the models folder.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>tritonserver --model-repository=&lt;path_to_models&gt; --model-control-mode=explicit
</pre></div>
</div>
<p>Note: The model-repository path for our example is <code class="docutils literal notranslate"><span class="pre">/workspace/models</span></code>. The models haven’t been loaded, yet. Below, we will request the Triton server to load the saved ensemble model below.</p>
</div>
<div class="section" id="Connect-to-the-Triton-Inference-Server-and-check-if-the-server-is-alive">
<h3>Connect to the Triton Inference Server and check if the server is alive<a class="headerlink" href="#Connect-to-the-Triton-Inference-Server-and-check-if-the-server-is-alive" title="Permalink to this headline"></a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tritonhttpclient</span>
<span class="k">try</span><span class="p">:</span>
    <span class="n">triton_client</span> <span class="o">=</span> <span class="n">tritonhttpclient</span><span class="o">.</span><span class="n">InferenceServerClient</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="s2">&quot;localhost:8000&quot;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;client created.&quot;</span><span class="p">)</span>
<span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;channel creation failed: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">))</span>
<span class="n">triton_client</span><span class="o">.</span><span class="n">is_server_live</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
client created.
GET /v2/health/live, headers None
&lt;HTTPSocketPoolResponse status=200 headers={&#39;content-length&#39;: &#39;0&#39;, &#39;content-type&#39;: &#39;text/plain&#39;}&gt;
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
True
</pre></div></div>
</div>
</div>
<div class="section" id="Load-raw-data-for-inference">
<h3>Load raw data for inference<a class="headerlink" href="#Load-raw-data-for-inference" title="Permalink to this headline"></a></h3>
<p>We select the last 50 interactions and filter out sessions with less than 2 interactions.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">interactions_merged_df</span><span class="o">=</span><span class="n">interactions_merged_df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;timestamp&#39;</span><span class="p">)</span>
<span class="n">batch</span> <span class="o">=</span> <span class="n">interactions_merged_df</span><span class="p">[</span><span class="o">-</span><span class="mi">50</span><span class="p">:]</span>
<span class="n">sessions_to_use</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">session_id</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
<span class="n">filtered_batch</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="n">batch</span><span class="o">.</span><span class="n">session_id</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">sessions_to_use</span><span class="p">[</span><span class="n">sessions_to_use</span><span class="o">.</span><span class="n">values</span><span class="o">&gt;</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">values</span><span class="p">)]</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Send-the-request-to-triton-server">
<h3>Send the request to triton server<a class="headerlink" href="#Send-the-request-to-triton-server" title="Permalink to this headline"></a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">triton_client</span><span class="o">.</span><span class="n">get_model_repository_index</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
POST /v2/repository/index, headers None

&lt;HTTPSocketPoolResponse status=200 headers={&#39;content-type&#39;: &#39;application/json&#39;, &#39;content-length&#39;: &#39;77&#39;}&gt;
bytearray(b&#39;[{&#34;name&#34;:&#34;t4r_pytorch&#34;},{&#34;name&#34;:&#34;t4r_pytorch_nvt&#34;},{&#34;name&#34;:&#34;t4r_pytorch_pt&#34;}]&#39;)
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[{&#39;name&#39;: &#39;t4r_pytorch&#39;},
 {&#39;name&#39;: &#39;t4r_pytorch_nvt&#39;},
 {&#39;name&#39;: &#39;t4r_pytorch_pt&#39;}]
</pre></div></div>
</div>
</div>
<div class="section" id="Load-the-ensemble-model-to-triton">
<h3>Load the ensemble model to triton<a class="headerlink" href="#Load-the-ensemble-model-to-triton" title="Permalink to this headline"></a></h3>
<p>If all models are loaded succesfully, you should be seeing <code class="docutils literal notranslate"><span class="pre">successfully</span> <span class="pre">loaded</span></code> status next to each model name on your terminal.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">triton_client</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;t4r_pytorch&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
POST /v2/repository/models/t4r_pytorch/load, headers None

&lt;HTTPSocketPoolResponse status=200 headers={&#39;content-type&#39;: &#39;application/json&#39;, &#39;content-length&#39;: &#39;0&#39;}&gt;
Loaded model &#39;t4r_pytorch&#39;
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[22]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">nvtabular.inference.triton</span> <span class="k">as</span> <span class="nn">nvt_triton</span>
<span class="kn">import</span> <span class="nn">tritonclient.grpc</span> <span class="k">as</span> <span class="nn">grpcclient</span>

<span class="n">inputs</span> <span class="o">=</span> <span class="n">nvt_triton</span><span class="o">.</span><span class="n">convert_df_to_triton_input</span><span class="p">(</span><span class="n">filtered_batch</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">filtered_batch</span><span class="p">,</span> <span class="n">grpcclient</span><span class="o">.</span><span class="n">InferInput</span><span class="p">)</span>

<span class="n">output_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;output&quot;</span><span class="p">]</span>

<span class="n">outputs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">output_names</span><span class="p">:</span>
    <span class="n">outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">grpcclient</span><span class="o">.</span><span class="n">InferRequestedOutput</span><span class="p">(</span><span class="n">col</span><span class="p">))</span>

<span class="n">MODEL_NAME_NVT</span> <span class="o">=</span> <span class="s2">&quot;t4r_pytorch&quot;</span>

<span class="k">with</span> <span class="n">grpcclient</span><span class="o">.</span><span class="n">InferenceServerClient</span><span class="p">(</span><span class="s2">&quot;localhost:8001&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">client</span><span class="p">:</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">infer</span><span class="p">(</span><span class="n">MODEL_NAME_NVT</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">col</span><span class="p">,</span> <span class="s1">&#39;:</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">response</span><span class="o">.</span><span class="n">as_numpy</span><span class="p">(</span><span class="n">col</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
output :
 [[-13.53608   -14.02154    -8.15927   ... -13.912806  -14.316951
  -13.758053 ]
 [-15.546847  -16.178349   -7.881463  ... -16.058243  -17.085182
  -15.761725 ]
 [-12.496786  -13.111265   -8.736879  ... -13.031836  -13.436075
  -12.741135 ]
 ...
 [-14.425283  -14.728777   -7.756508  ... -14.73007   -15.161329
  -14.437494 ]
 [-15.366516  -15.427296   -7.3262033 ... -15.448423  -15.94982
  -15.064197 ]
 [-11.908236  -12.42782    -8.78612   ... -12.316145  -12.594669
  -12.181059 ]]
</pre></div></div>
</div>
<ul class="simple">
<li><p>Visualise top-k predictions</p></li>
</ul>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">transformers4rec.torch.utils.examples_utils</span> <span class="kn">import</span> <span class="n">visualize_response</span>
<span class="n">visualize_response</span><span class="p">(</span><span class="n">filtered_batch</span><span class="p">,</span> <span class="n">response</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">session_col</span><span class="o">=</span><span class="s1">&#39;session_id&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
- Top-5 predictions for session `11257991`: 2365 || 260 || 196 || 33 || 1169

- Top-5 predictions for session `11270119`: 898 || 2214 || 1169 || 958 || 2814

- Top-5 predictions for session `11311424`: 898 || 2214 || 1987 || 958 || 1169

- Top-5 predictions for session `11336059`: 260 || 196 || 1169 || 2365 || 33

- Top-5 predictions for session `11394056`: 863 || 2365 || 196 || 33 || 1169

- Top-5 predictions for session `11399751`: 1987 || 2214 || 958 || 2814 || 1169

- Top-5 predictions for session `11401481`: 898 || 157 || 2214 || 620 || 2814

- Top-5 predictions for session `11421333`: 1126 || 196 || 127 || 1169 || 1987

- Top-5 predictions for session `11425751`: 196 || 33 || 958 || 1169 || 1987

- Top-5 predictions for session `11445777`: 33 || 196 || 1987 || 1126 || 1169

- Top-5 predictions for session `11457123`: 184 || 1169 || 313 || 33 || 863

- Top-5 predictions for session `11467406`: 898 || 958 || 2214 || 1169 || 1987

- Top-5 predictions for session `11493827`: 863 || 2365 || 196 || 33 || 1169

- Top-5 predictions for session `11528554`: 1061 || 33 || 863 || 1020 || 1169

- Top-5 predictions for session `11561822`: 127 || 1126 || 196 || 1169 || 1987

</pre></div></div>
</div>
<p>As you noticed, we first got prediction results (logits) from the trained model head, and then by using a handy util function <code class="docutils literal notranslate"><span class="pre">visualize_response</span></code> we extracted top-k encoded item-ids from logits. Basically, we generated recommended items for a given session.</p>
<p>This is the end of the tutorial. You successfully</p>
<ul class="simple">
<li><p>performed feature engineering with NVTabular</p></li>
<li><p>trained transformer architecture based session-based recommendation models with Transformers4Rec</p></li>
<li><p>deployed a trained model to Triton Inference Server, sent request and got responses from the server.</p></li>
</ul>
<p><strong>Unload models</strong></p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">triton_client</span><span class="o">.</span><span class="n">unload_model</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;t4r_pytorch&quot;</span><span class="p">)</span>
<span class="n">triton_client</span><span class="o">.</span><span class="n">unload_model</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;t4r_pytorch_nvt&quot;</span><span class="p">)</span>
<span class="n">triton_client</span><span class="o">.</span><span class="n">unload_model</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;t4r_pytorch_pt&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="References">
<h2>References<a class="headerlink" href="#References" title="Permalink to this headline"></a></h2>
<ul class="simple">
<li><p>Merlin Transformers4rec: <a class="reference external" href="https://github.com/NVIDIA-Merlin/Transformers4Rec">https://github.com/NVIDIA-Merlin/Transformers4Rec</a></p></li>
<li><p>Merlin NVTabular: <a class="reference external" href="https://github.com/NVIDIA/NVTabular/tree/main/nvtabular">https://github.com/NVIDIA/NVTabular/tree/main/nvtabular</a></p></li>
<li><p>Triton inference server: <a class="reference external" href="https://github.com/triton-inference-server">https://github.com/triton-inference-server</a></p></li>
</ul>
</div>
</div>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="index.html" class="btn btn-neutral float-left" title="End-to-end session-based recommendation" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../tutorial/index.html" class="btn btn-neutral float-right" title="Tutorial: End-to-end Session-based recommendation" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, NVIDIA.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  
<div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    <span class="fa fa-book"> Other Versions</span>
    v: v0.1.1
    <span class="fa fa-caret-down"></span>
  </span>
  <div class="rst-other-versions">
    <dl>
      <dt>Tags</dt>
      <dd><a href="end-to-end-session-based-with-Yoochoose.html">v0.1.1</a></dd>
      <dd><a href="../../../v0.1.2/index.html">v0.1.2</a></dd>
      <dd><a href="../../../v0.1.3/index.html">v0.1.3</a></dd>
      <dd><a href="../../../v0.1.4/index.html">v0.1.4</a></dd>
      <dd><a href="../../../v0.1.5/index.html">v0.1.5</a></dd>
      <dd><a href="../../../v0.1.6/index.html">v0.1.6</a></dd>
    </dl>
    <dl>
      <dt>Branches</dt>
      <dd><a href="../../../main/index.html">main</a></dd>
    </dl>
  </div>
</div><script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>