<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>transformers4rec.torch.model.prediction_task &mdash; Transformers4Rec  documentation</title><link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/togglebutton.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/mystnb.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/css/custom.css" type="text/css" />
    <link rel="canonical" href="https://nvidia-merlin.github.io/Transformers4Rec/stable/_modules/transformers4rec/torch/model/prediction_task.html" />
  <!--[if lt IE 9]>
    <script src="../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
        <script src="../../../../_static/jquery.js"></script>
        <script src="../../../../_static/underscore.js"></script>
        <script src="../../../../_static/doctools.js"></script>
        <script >let toggleHintShow = 'Click to show';</script>
        <script >let toggleHintHide = 'Click to hide';</script>
        <script >let toggleOpenOnPrint = 'true';</script>
        <script src="../../../../_static/togglebutton.js"></script>
        <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../../index.html" class="icon icon-home"> Transformers4Rec
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption"><span class="caption-text">Contents</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../README.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../why_transformers4rec.html">Why Transformers4Rec?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../model_definition.html">Model Architectures</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../training_eval.html">Training and Evaluation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../pipeline.html">End-to-End Pipeline with Hugging Face Transformers and NVIDIA Merlin</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../multi_gpu_train.html">Multi-GPU data-parallel training using the <code class="docutils literal notranslate"><span class="pre">Trainer</span></code> class</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../examples/index.html">Example Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api/modules.html">API Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../resources.html">Additional Resources</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">Transformers4Rec</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../../../index.html">Module code</a> &raquo;</li>
      <li>transformers4rec.torch.model.prediction_task</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for transformers4rec.torch.model.prediction_task</h1><div class="highlight"><pre>
<span></span><span class="c1">#</span>
<span class="c1"># Copyright (c) 2021, NVIDIA CORPORATION.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="c1">#</span>


<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="n">sqrt</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Iterable</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">,</span> <span class="n">Tuple</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torchmetrics</span> <span class="k">as</span> <span class="nn">tm</span>

<span class="kn">from</span> <span class="nn">..block.base</span> <span class="kn">import</span> <span class="n">Block</span><span class="p">,</span> <span class="n">BuildableBlock</span><span class="p">,</span> <span class="n">SequentialBlock</span>
<span class="kn">from</span> <span class="nn">..block.mlp</span> <span class="kn">import</span> <span class="n">MLPBlock</span>
<span class="kn">from</span> <span class="nn">..masking</span> <span class="kn">import</span> <span class="n">MaskedLanguageModeling</span>
<span class="kn">from</span> <span class="nn">..ranking_metric</span> <span class="kn">import</span> <span class="n">AvgPrecisionAt</span><span class="p">,</span> <span class="n">NDCGAt</span><span class="p">,</span> <span class="n">RecallAt</span>
<span class="kn">from</span> <span class="nn">..utils.torch_utils</span> <span class="kn">import</span> <span class="n">LambdaModule</span>
<span class="kn">from</span> <span class="nn">.base</span> <span class="kn">import</span> <span class="n">BlockType</span><span class="p">,</span> <span class="n">PredictionTask</span>

<span class="n">LOG</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="s2">&quot;transformers4rec&quot;</span><span class="p">)</span>


<div class="viewcode-block" id="BinaryClassificationPrepareBlock"><a class="viewcode-back" href="../../../../api/transformers4rec.torch.model.html#transformers4rec.torch.BinaryClassificationPrepareBlock">[docs]</a><span class="k">class</span> <span class="nc">BinaryClassificationPrepareBlock</span><span class="p">(</span><span class="n">BuildableBlock</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Prepares the output layer of the binary classification prediction task.</span>
<span class="sd">    The output layer is a SequentialBlock of a torch linear</span>
<span class="sd">    layer followed by a sigmoid activation and a squeeze operation.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="BinaryClassificationPrepareBlock.build"><a class="viewcode-back" href="../../../../api/transformers4rec.torch.model.html#transformers4rec.torch.BinaryClassificationPrepareBlock.build">[docs]</a>    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">SequentialBlock</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Builds the output layer of binary classification based on the input_size.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        input_size: Tuple[int]</span>
<span class="sd">            The size of the input tensor, specifically the last dimension is</span>
<span class="sd">            used for setting the input dimension of the linear layer.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        SequentialBlock</span>
<span class="sd">            A SequentialBlock consisting of a linear layer (with input dimension equal to the last</span>
<span class="sd">            dimension of input_size), a sigmoid activation, and a squeeze operation.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">SequentialBlock</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">(),</span>
            <span class="n">LambdaModule</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)),</span>
            <span class="n">output_size</span><span class="o">=</span><span class="p">[</span>
                <span class="kc">None</span><span class="p">,</span>
            <span class="p">],</span>
        <span class="p">)</span></div></div>


<div class="viewcode-block" id="BinaryClassificationTask"><a class="viewcode-back" href="../../../../api/transformers4rec.torch.model.html#transformers4rec.torch.BinaryClassificationTask">[docs]</a><span class="k">class</span> <span class="nc">BinaryClassificationTask</span><span class="p">(</span><span class="n">PredictionTask</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Returns a ``PredictionTask`` for binary classification.</span>

<span class="sd">    Example usage::</span>

<span class="sd">        # Define the input module to process the tabular input features.</span>
<span class="sd">        input_module = tr.TabularSequenceFeatures.from_schema(</span>
<span class="sd">            schema,</span>
<span class="sd">            max_sequence_length=max_sequence_length,</span>
<span class="sd">            continuous_projection=d_model,</span>
<span class="sd">            aggregation=&quot;concat&quot;,</span>
<span class="sd">            masking=None,</span>
<span class="sd">        )</span>

<span class="sd">        # Define XLNetConfig class and set default parameters for HF XLNet config.</span>
<span class="sd">        transformer_config = tr.XLNetConfig.build(</span>
<span class="sd">            d_model=d_model, n_head=4, n_layer=2, total_seq_length=max_sequence_length</span>
<span class="sd">        )</span>

<span class="sd">        # Define the model block including: inputs, masking, projection and transformer block.</span>
<span class="sd">        body = tr.SequentialBlock(</span>
<span class="sd">            input_module,</span>
<span class="sd">            tr.MLPBlock([64]),</span>
<span class="sd">            tr.TransformerBlock(</span>
<span class="sd">                transformer_config,</span>
<span class="sd">                masking=input_module.masking</span>
<span class="sd">            )</span>
<span class="sd">        )</span>

<span class="sd">        # Define a head with BinaryClassificationTask.</span>
<span class="sd">        head = tr.Head(</span>
<span class="sd">            body,</span>
<span class="sd">            tr.BinaryClassificationTask(</span>
<span class="sd">                &quot;click&quot;,</span>
<span class="sd">                summary_type=&quot;mean&quot;,</span>
<span class="sd">                metrics=[</span>
<span class="sd">                    tm.Precision(task=&#39;binary&#39;),</span>
<span class="sd">                    tm.Recall(task=&#39;binary&#39;),</span>
<span class="sd">                    tm.Accuracy(task=&#39;binary&#39;),</span>
<span class="sd">                    tm.F1Score(task=&#39;binary&#39;)</span>
<span class="sd">                ]</span>
<span class="sd">            ),</span>
<span class="sd">            inputs=input_module,</span>
<span class="sd">        )</span>

<span class="sd">        # Get the end-to-end Model class.</span>
<span class="sd">        model = tr.Model(head)</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    target_name: Optional[str] = None</span>
<span class="sd">        Specifies the variable name that represents the positive and negative values.</span>

<span class="sd">    task_name: Optional[str] = None</span>
<span class="sd">        Specifies the name of the prediction task. If this parameter is not specified,</span>
<span class="sd">        a name is automatically constructed based on ``target_name`` and the Python</span>
<span class="sd">        class name of the model.</span>

<span class="sd">    task_block: Optional[BlockType] = None</span>
<span class="sd">        Specifies a module to transform the input tensor before computing predictions.</span>

<span class="sd">    loss: torch.nn.Module</span>
<span class="sd">        Specifies the loss function for the task.</span>
<span class="sd">        The default class is ``torch.nn.BCELoss``.</span>

<span class="sd">    metrics: Tuple[torch.nn.Module, ...]</span>
<span class="sd">        Specifies the metrics to calculate during training and evaluation.</span>
<span class="sd">        The default metrics are ``Precision``, ``Recall``, and ``Accuracy``.</span>

<span class="sd">    summary_type: str</span>
<span class="sd">        Summarizes a sequence into a single tensor. Accepted values are:</span>

<span class="sd">            - ``last`` -- Take the last token hidden state (like XLNet)</span>
<span class="sd">            - ``first`` -- Take the first token hidden state (like Bert)</span>
<span class="sd">            - ``mean`` -- Take the mean of all tokens hidden states</span>
<span class="sd">            - ``cls_index`` -- Supply a Tensor of classification token position (GPT/GPT-2)</span>
<span class="sd">            - ``attn`` -- Not implemented now, use multi-head attention</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">DEFAULT_LOSS</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">BCELoss</span><span class="p">()</span>
    <span class="n">DEFAULT_METRICS</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">tm</span><span class="o">.</span><span class="n">Precision</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">task</span><span class="o">=</span><span class="s2">&quot;binary&quot;</span><span class="p">),</span>
        <span class="n">tm</span><span class="o">.</span><span class="n">Recall</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">task</span><span class="o">=</span><span class="s2">&quot;binary&quot;</span><span class="p">),</span>
        <span class="n">tm</span><span class="o">.</span><span class="n">Accuracy</span><span class="p">(</span><span class="n">task</span><span class="o">=</span><span class="s2">&quot;binary&quot;</span><span class="p">),</span>
        <span class="c1"># TODO: Fix this: tm.AUC()</span>
    <span class="p">)</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">target_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">task_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">task_block</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">BlockType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">loss</span><span class="o">=</span><span class="n">DEFAULT_LOSS</span><span class="p">,</span>
        <span class="n">metrics</span><span class="o">=</span><span class="n">DEFAULT_METRICS</span><span class="p">,</span>
        <span class="n">summary_type</span><span class="o">=</span><span class="s2">&quot;first&quot;</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_dim</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span>
            <span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span><span class="p">,</span>
            <span class="n">target_name</span><span class="o">=</span><span class="n">target_name</span><span class="p">,</span>
            <span class="n">task_name</span><span class="o">=</span><span class="n">task_name</span><span class="p">,</span>
            <span class="n">summary_type</span><span class="o">=</span><span class="n">summary_type</span><span class="p">,</span>
            <span class="n">task_block</span><span class="o">=</span><span class="n">task_block</span><span class="p">,</span>
            <span class="n">pre</span><span class="o">=</span><span class="n">BinaryClassificationPrepareBlock</span><span class="p">(),</span>
            <span class="n">forward_to_prediction_fn</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">int</span><span class="p">(),</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="RegressionPrepareBlock"><a class="viewcode-back" href="../../../../api/transformers4rec.torch.model.html#transformers4rec.torch.RegressionPrepareBlock">[docs]</a><span class="k">class</span> <span class="nc">RegressionPrepareBlock</span><span class="p">(</span><span class="n">BuildableBlock</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Prepares the output layer of the regression prediction task.</span>
<span class="sd">    The output layer is a SequentialBlock of a torch linear</span>
<span class="sd">    layer followed by a squeeze operation.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="RegressionPrepareBlock.build"><a class="viewcode-back" href="../../../../api/transformers4rec.torch.model.html#transformers4rec.torch.RegressionPrepareBlock.build">[docs]</a>    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">SequentialBlock</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Builds the output layer of regression based on the input_size.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        input_size: Tuple[int]</span>
<span class="sd">            The size of the input tensor, specifically the last dimension is</span>
<span class="sd">            used for setting the input dimension of the linear layer.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        SequentialBlock</span>
<span class="sd">            A SequentialBlock consisting of a linear layer (with input dimension equal to</span>
<span class="sd">            the last dimension of input_size), and a squeeze operation.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">SequentialBlock</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">),</span>
            <span class="n">LambdaModule</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)),</span>
            <span class="n">output_size</span><span class="o">=</span><span class="p">[</span>
                <span class="kc">None</span><span class="p">,</span>
            <span class="p">],</span>
        <span class="p">)</span></div></div>


<div class="viewcode-block" id="RegressionTask"><a class="viewcode-back" href="../../../../api/transformers4rec.torch.model.html#transformers4rec.torch.RegressionTask">[docs]</a><span class="k">class</span> <span class="nc">RegressionTask</span><span class="p">(</span><span class="n">PredictionTask</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Returns a ``PredictionTask`` for regression.</span>

<span class="sd">    Example usage::</span>

<span class="sd">        # Define the input module to process the tabular input features.</span>
<span class="sd">        input_module = tr.TabularSequenceFeatures.from_schema(</span>
<span class="sd">            schema,</span>
<span class="sd">            max_sequence_length=max_sequence_length,</span>
<span class="sd">            continuous_projection=d_model,</span>
<span class="sd">            aggregation=&quot;concat&quot;,</span>
<span class="sd">            masking=None,</span>
<span class="sd">        )</span>

<span class="sd">        # Define XLNetConfig class and set default parameters for HF XLNet config.</span>
<span class="sd">        transformer_config = tr.XLNetConfig.build(</span>
<span class="sd">            d_model=d_model, n_head=4, n_layer=2, total_seq_length=max_sequence_length</span>
<span class="sd">        )</span>

<span class="sd">        # Define the model block including: inputs, projection and transformer block.</span>
<span class="sd">        body = tr.SequentialBlock(</span>
<span class="sd">            input_module,</span>
<span class="sd">            tr.MLPBlock([64]),</span>
<span class="sd">            tr.TransformerBlock(</span>
<span class="sd">                transformer_config,</span>
<span class="sd">            )</span>
<span class="sd">        )</span>

<span class="sd">        # Define a head with BinaryClassificationTask.</span>
<span class="sd">        head = tr.Head(</span>
<span class="sd">            body,</span>
<span class="sd">            tr.RegressionTask(</span>
<span class="sd">                &quot;watch_time&quot;,</span>
<span class="sd">                summary_type=&quot;mean&quot;,</span>
<span class="sd">                metrics=[tm.regression.MeanSquaredError()]</span>
<span class="sd">            ),</span>
<span class="sd">            inputs=input_module,</span>
<span class="sd">        )</span>

<span class="sd">        # Get the end-to-end Model class.</span>
<span class="sd">        model = tr.Model(head)</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    target_name: Optional[str]</span>
<span class="sd">        Specifies the variable name that represents the continuous value to predict.</span>
<span class="sd">        By default None</span>

<span class="sd">    task_name: Optional[str]</span>
<span class="sd">        Specifies the name of the prediction task. If this parameter is not specified,</span>
<span class="sd">        a name is automatically constructed based on ``target_name`` and the Python</span>
<span class="sd">        class name of the model.</span>
<span class="sd">        By default None</span>

<span class="sd">    task_block: Optional[BlockType] = None</span>
<span class="sd">        Specifies a module to transform the input tensor before computing predictions.</span>

<span class="sd">    loss: torch.nn.Module</span>
<span class="sd">        Specifies the loss function for the task.</span>
<span class="sd">        The default class is ``torch.nn.MSELoss``.</span>

<span class="sd">    metrics: Tuple[torch.nn.Module, ...]</span>
<span class="sd">        Specifies the metrics to calculate during training and evaluation.</span>
<span class="sd">        The default metric is MeanSquaredError.</span>

<span class="sd">    summary_type: str</span>
<span class="sd">        Summarizes a sequence into a single tensor. Accepted values are:</span>

<span class="sd">            - ``last`` -- Take the last token hidden state (like XLNet)</span>
<span class="sd">            - ``first`` -- Take the first token hidden state (like Bert)</span>
<span class="sd">            - ``mean`` -- Take the mean of all tokens hidden states</span>
<span class="sd">            - ``cls_index`` -- Supply a Tensor of classification token position (GPT/GPT-2)</span>
<span class="sd">            - ``attn`` -- Not implemented now, use multi-head attention</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">DEFAULT_LOSS</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
    <span class="n">DEFAULT_METRICS</span> <span class="o">=</span> <span class="p">(</span><span class="n">tm</span><span class="o">.</span><span class="n">regression</span><span class="o">.</span><span class="n">MeanSquaredError</span><span class="p">(),)</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">target_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">task_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">task_block</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">BlockType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">loss</span><span class="o">=</span><span class="n">DEFAULT_LOSS</span><span class="p">,</span>
        <span class="n">metrics</span><span class="o">=</span><span class="n">DEFAULT_METRICS</span><span class="p">,</span>
        <span class="n">summary_type</span><span class="o">=</span><span class="s2">&quot;first&quot;</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_dim</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span>
            <span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span><span class="p">,</span>
            <span class="n">target_name</span><span class="o">=</span><span class="n">target_name</span><span class="p">,</span>
            <span class="n">task_name</span><span class="o">=</span><span class="n">task_name</span><span class="p">,</span>
            <span class="n">summary_type</span><span class="o">=</span><span class="n">summary_type</span><span class="p">,</span>
            <span class="n">task_block</span><span class="o">=</span><span class="n">task_block</span><span class="p">,</span>
            <span class="n">pre</span><span class="o">=</span><span class="n">RegressionPrepareBlock</span><span class="p">(),</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="NextItemPredictionTask"><a class="viewcode-back" href="../../../../api/transformers4rec.torch.model.html#transformers4rec.torch.NextItemPredictionTask">[docs]</a><span class="k">class</span> <span class="nc">NextItemPredictionTask</span><span class="p">(</span><span class="n">PredictionTask</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;This block performs item prediction task for session and sequential-based models.</span>
<span class="sd">    It requires a body containing a masking schema to use for training and target generation.</span>
<span class="sd">    For the supported masking schemes, please refers to:</span>
<span class="sd">    https://nvidia-merlin.github.io/Transformers4Rec/stable/model_definition.html#sequence-masking</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    loss: torch.nn.Module</span>
<span class="sd">        Loss function to use. Defaults to NLLLos.</span>
<span class="sd">    metrics: Iterable[torchmetrics.Metric]</span>
<span class="sd">        List of ranking metrics to use for evaluation.</span>
<span class="sd">    task_block:</span>
<span class="sd">        Module to transform input tensor before computing predictions.</span>
<span class="sd">    task_name: str, optional</span>
<span class="sd">        Name of the prediction task, if not provided a name will be automatically constructed based</span>
<span class="sd">        on the target-name &amp; class-name.</span>
<span class="sd">    weight_tying: bool</span>
<span class="sd">        The item id embedding table weights are shared with the prediction network layer.</span>
<span class="sd">    softmax_temperature: float</span>
<span class="sd">        Softmax temperature, used to reduce model overconfidence, so that softmax(logits / T).</span>
<span class="sd">        Value 1.0 reduces to regular softmax.</span>
<span class="sd">    padding_idx: int</span>
<span class="sd">        pad token id.</span>
<span class="sd">    target_dim: int</span>
<span class="sd">        vocabulary size of item ids</span>
<span class="sd">    sampled_softmax: Optional[bool]</span>
<span class="sd">        Enables sampled softmax. By default False</span>
<span class="sd">    max_n_samples: Optional[int]</span>
<span class="sd">        Number of samples for sampled softmax. By default 100</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">DEFAULT_METRICS</span> <span class="o">=</span> <span class="p">(</span>
        <span class="c1"># default metrics suppose labels are int encoded</span>
        <span class="n">NDCGAt</span><span class="p">(</span><span class="n">top_ks</span><span class="o">=</span><span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">],</span> <span class="n">labels_onehot</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
        <span class="n">AvgPrecisionAt</span><span class="p">(</span><span class="n">top_ks</span><span class="o">=</span><span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">],</span> <span class="n">labels_onehot</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
        <span class="n">RecallAt</span><span class="p">(</span><span class="n">top_ks</span><span class="o">=</span><span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">],</span> <span class="n">labels_onehot</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
    <span class="p">)</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">loss</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(),</span>
        <span class="n">metrics</span><span class="p">:</span> <span class="n">Iterable</span><span class="p">[</span><span class="n">tm</span><span class="o">.</span><span class="n">Metric</span><span class="p">]</span> <span class="o">=</span> <span class="n">DEFAULT_METRICS</span><span class="p">,</span>
        <span class="n">task_block</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">BlockType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">task_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;next-item&quot;</span><span class="p">,</span>
        <span class="n">weight_tying</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">softmax_temperature</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">padding_idx</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">target_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">sampled_softmax</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">max_n_samples</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span><span class="p">,</span> <span class="n">task_block</span><span class="o">=</span><span class="n">task_block</span><span class="p">,</span> <span class="n">task_name</span><span class="o">=</span><span class="n">task_name</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">softmax_temperature</span> <span class="o">=</span> <span class="n">softmax_temperature</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight_tying</span> <span class="o">=</span> <span class="n">weight_tying</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">padding_idx</span> <span class="o">=</span> <span class="n">padding_idx</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_dim</span> <span class="o">=</span> <span class="n">target_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sampled_softmax</span> <span class="o">=</span> <span class="n">sampled_softmax</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_n_samples</span> <span class="o">=</span> <span class="n">max_n_samples</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">item_embedding_table</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">masking</span> <span class="o">=</span> <span class="kc">None</span>

<div class="viewcode-block" id="NextItemPredictionTask.build"><a class="viewcode-back" href="../../../../api/transformers4rec.torch.model.html#transformers4rec.torch.NextItemPredictionTask.build">[docs]</a>    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">body</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">task_block</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">pre</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Build method, this is called by the `Head`.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_size</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;NextItemPredictionTask needs a 3-dim vector as input, found:&quot;</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">input_size</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="c1"># Retrieve the embedding module to get the name of itemid col and its related table</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">inputs</span><span class="p">:</span>
            <span class="n">inputs</span> <span class="o">=</span> <span class="n">body</span><span class="o">.</span><span class="n">inputs</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="s2">&quot;item_id&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;For Item Prediction task a categorical_module &quot;</span>
                <span class="s2">&quot;including an item_id column is required.&quot;</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">categorical_module</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_dim</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">target_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span><span class="o">.</span><span class="n">item_embedding_table</span><span class="o">.</span><span class="n">num_embeddings</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight_tying</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">item_embedding_table</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span><span class="o">.</span><span class="n">item_embedding_table</span>
            <span class="n">item_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">item_embedding_table</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">input_size</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="n">item_dim</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">task_block</span><span class="p">:</span>
                <span class="n">LOG</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Projecting inputs of NextItemPredictionTask to&#39;</span><span class="si">{</span><span class="n">item_dim</span><span class="si">}</span><span class="s2">&#39; &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;As weight tying requires the input dimension &#39;</span><span class="si">{</span><span class="n">input_size</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">&#39; &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;to be equal to the item-id embedding dimension &#39;</span><span class="si">{</span><span class="n">item_dim</span><span class="si">}</span><span class="s2">&#39;&quot;</span>
                <span class="p">)</span>
                <span class="c1"># project input tensors to same dimension as item-id embeddings</span>
                <span class="n">task_block</span> <span class="o">=</span> <span class="n">MLPBlock</span><span class="p">([</span><span class="n">item_dim</span><span class="p">],</span> <span class="n">activation</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

        <span class="c1"># Retrieve the masking from the input block</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">masking</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">masking</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">masking</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;The input block should contain a masking schema for training and evaluation&quot;</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">padding_idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">masking</span><span class="o">.</span><span class="n">padding_idx</span>
        <span class="n">pre</span> <span class="o">=</span> <span class="n">NextItemPredictionPrepareBlock</span><span class="p">(</span>
            <span class="n">target_dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">target_dim</span><span class="p">,</span>
            <span class="n">weight_tying</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">weight_tying</span><span class="p">,</span>
            <span class="n">item_embedding_table</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">item_embedding_table</span><span class="p">,</span>
            <span class="n">softmax_temperature</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">softmax_temperature</span><span class="p">,</span>
            <span class="n">sampled_softmax</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sampled_softmax</span><span class="p">,</span>
            <span class="n">max_n_samples</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_n_samples</span><span class="p">,</span>
            <span class="n">min_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">padding_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">build</span><span class="p">(</span>
            <span class="n">body</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">task_block</span><span class="o">=</span><span class="n">task_block</span><span class="p">,</span> <span class="n">pre</span><span class="o">=</span><span class="n">pre</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="NextItemPredictionTask.forward"><a class="viewcode-back" href="../../../../api/transformers4rec.torch.model.html#transformers4rec.torch.NextItemPredictionTask.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inputs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">targets</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">testing</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">top_k</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">)):</span>
            <span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_block</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">task_block</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># type: ignore</span>

        <span class="c1"># Retrieve labels from masking</span>
        <span class="k">if</span> <span class="n">training</span> <span class="ow">or</span> <span class="n">testing</span><span class="p">:</span>
            <span class="n">labels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">masking</span><span class="o">.</span><span class="n">masked_targets</span>  <span class="c1"># type: ignore</span>
            <span class="n">trg_flat</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
            <span class="n">non_pad_mask</span> <span class="o">=</span> <span class="n">trg_flat</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding_idx</span>
            <span class="n">labels_all</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">masked_select</span><span class="p">(</span><span class="n">trg_flat</span><span class="p">,</span> <span class="n">non_pad_mask</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
            <span class="c1"># remove padded items, keep only masked positions</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">remove_pad_3d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">non_pad_mask</span><span class="p">)</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">labels_all</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">targets</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">,</span> <span class="n">testing</span><span class="o">=</span><span class="n">testing</span><span class="p">)</span>  <span class="c1"># type: ignore</span>

            <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
            <span class="k">return</span> <span class="p">{</span>
                <span class="s2">&quot;loss&quot;</span><span class="p">:</span> <span class="n">loss</span><span class="p">,</span>
                <span class="s2">&quot;labels&quot;</span><span class="p">:</span> <span class="n">y</span><span class="p">,</span>
                <span class="s2">&quot;predictions&quot;</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span>
            <span class="p">}</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Get the hidden position to use for predicting the next item</span>
            <span class="n">labels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embeddings</span><span class="o">.</span><span class="n">item_seq</span>
            <span class="n">non_pad_mask</span> <span class="o">=</span> <span class="n">labels</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding_idx</span>
            <span class="n">rows_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">labels</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">masking</span><span class="p">,</span> <span class="n">MaskedLanguageModeling</span><span class="p">):</span>
                <span class="n">last_item_sessions</span> <span class="o">=</span> <span class="n">non_pad_mask</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">last_item_sessions</span> <span class="o">=</span> <span class="n">non_pad_mask</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">rows_ids</span><span class="p">,</span> <span class="n">last_item_sessions</span><span class="p">]</span>

            <span class="c1"># Compute predictions probs</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># type: ignore</span>

            <span class="k">if</span> <span class="n">top_k</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">x</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">preds_sorted_item_scores</span><span class="p">,</span> <span class="n">preds_sorted_item_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">top_k</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
                <span class="k">return</span> <span class="n">preds_sorted_item_scores</span><span class="p">,</span> <span class="n">preds_sorted_item_ids</span></div>

<div class="viewcode-block" id="NextItemPredictionTask.remove_pad_3d"><a class="viewcode-back" href="../../../../api/transformers4rec.torch.model.html#transformers4rec.torch.NextItemPredictionTask.remove_pad_3d">[docs]</a>    <span class="k">def</span> <span class="nf">remove_pad_3d</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inp_tensor</span><span class="p">,</span> <span class="n">non_pad_mask</span><span class="p">):</span>
        <span class="c1"># inp_tensor: (n_batch x seqlen x emb_dim)</span>
        <span class="n">inp_tensor</span> <span class="o">=</span> <span class="n">inp_tensor</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">end_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">inp_tensor_fl</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">masked_select</span><span class="p">(</span>
            <span class="n">inp_tensor</span><span class="p">,</span> <span class="n">non_pad_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand_as</span><span class="p">(</span><span class="n">inp_tensor</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">out_tensor</span> <span class="o">=</span> <span class="n">inp_tensor_fl</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">inp_tensor</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">out_tensor</span></div>

<div class="viewcode-block" id="NextItemPredictionTask.calculate_metrics"><a class="viewcode-back" href="../../../../api/transformers4rec.torch.model.html#transformers4rec.torch.NextItemPredictionTask.calculate_metrics">[docs]</a>    <span class="k">def</span> <span class="nf">calculate_metrics</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>  <span class="c1"># type: ignore</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">targets</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_name</span><span class="p">:</span>
            <span class="n">targets</span> <span class="o">=</span> <span class="n">targets</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">target_name</span><span class="p">]</span>

        <span class="n">outputs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward_to_prediction_fn</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">metric</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">metric</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
            <span class="n">outputs</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">metric_name</span><span class="p">(</span><span class="n">metric</span><span class="p">)]</span> <span class="o">=</span> <span class="n">result</span>

        <span class="k">return</span> <span class="n">outputs</span></div>

<div class="viewcode-block" id="NextItemPredictionTask.compute_metrics"><a class="viewcode-back" href="../../../../api/transformers4rec.torch.model.html#transformers4rec.torch.NextItemPredictionTask.compute_metrics">[docs]</a>    <span class="k">def</span> <span class="nf">compute_metrics</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">metrics</span> <span class="o">=</span> <span class="p">{</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">metric_name</span><span class="p">(</span><span class="n">metric</span><span class="p">):</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">metric</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span>
            <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">metric</span><span class="p">,</span> <span class="s2">&quot;top_ks&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="p">}</span>
        <span class="c1"># Explode metrics for each cut-off</span>
        <span class="c1"># TODO make result generic:</span>
        <span class="c1"># To accept a mix of ranking metrics and others not requiring top_ks ?</span>
        <span class="n">topks</span> <span class="o">=</span> <span class="p">{</span><span class="bp">self</span><span class="o">.</span><span class="n">metric_name</span><span class="p">(</span><span class="n">metric</span><span class="p">):</span> <span class="n">metric</span><span class="o">.</span><span class="n">top_ks</span> <span class="k">for</span> <span class="n">metric</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="p">}</span>
        <span class="n">results</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">metric</span> <span class="ow">in</span> <span class="n">metrics</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="c1"># Fix for when using a single cut-off, as torch metrics convert results to scalar</span>
            <span class="c1"># when a single element vector is returned</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">metric</span><span class="o">.</span><span class="n">size</span><span class="p">())</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">metric</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">measure</span><span class="p">,</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">metric</span><span class="p">,</span> <span class="n">topks</span><span class="p">[</span><span class="n">name</span><span class="p">]):</span>
                <span class="n">results</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">measure</span>
        <span class="k">return</span> <span class="n">results</span></div></div>


<div class="viewcode-block" id="NextItemPredictionPrepareBlock"><a class="viewcode-back" href="../../../../api/transformers4rec.torch.model.html#transformers4rec.torch.NextItemPredictionPrepareBlock">[docs]</a><span class="k">class</span> <span class="nc">NextItemPredictionPrepareBlock</span><span class="p">(</span><span class="n">BuildableBlock</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Prepares the output layer of the next item prediction task.</span>
<span class="sd">    The output layer is a an instance of `_NextItemPredictionTask` class.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    target_dim: int</span>
<span class="sd">        The output dimension for next-item predictions.</span>
<span class="sd">    weight_tying: bool, optional</span>
<span class="sd">        If true, ties the weights of the prediction layer and the item embedding layer.</span>
<span class="sd">        By default False.</span>
<span class="sd">    item_embedding_table: torch.nn.Module, optional</span>
<span class="sd">        The module containing the item embedding table.</span>
<span class="sd">        By default None.</span>
<span class="sd">    softmax_temperature: float, optional</span>
<span class="sd">        The temperature to be applied to the softmax function. Defaults to 0.</span>
<span class="sd">    sampled_softmax: bool, optional</span>
<span class="sd">        If true, sampled softmax is used for approximating the full softmax function.</span>
<span class="sd">        By default False.</span>
<span class="sd">    max_n_samples: int, optional</span>
<span class="sd">        The maximum number of samples when using sampled softmax.</span>
<span class="sd">        By default 100.</span>
<span class="sd">    min_id: int, optional</span>
<span class="sd">        The minimum value of the range for the log-uniform sampling.</span>
<span class="sd">        By default 0.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">target_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">weight_tying</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">item_embedding_table</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">softmax_temperature</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">sampled_softmax</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">max_n_samples</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
        <span class="n">min_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_dim</span> <span class="o">=</span> <span class="n">target_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight_tying</span> <span class="o">=</span> <span class="n">weight_tying</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">item_embedding_table</span> <span class="o">=</span> <span class="n">item_embedding_table</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">softmax_temperature</span> <span class="o">=</span> <span class="n">softmax_temperature</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sampled_softmax</span> <span class="o">=</span> <span class="n">sampled_softmax</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_n_samples</span> <span class="o">=</span> <span class="n">max_n_samples</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">min_id</span> <span class="o">=</span> <span class="n">min_id</span>

<div class="viewcode-block" id="NextItemPredictionPrepareBlock.build"><a class="viewcode-back" href="../../../../api/transformers4rec.torch.model.html#transformers4rec.torch.NextItemPredictionPrepareBlock.build">[docs]</a>    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Block</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Builds the output layer of next-item prediction based on the input_size.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        input_size : Tuple[int]</span>
<span class="sd">            The size of the input tensor, specifically the last dimension is</span>
<span class="sd">            used for setting the input dimension of the output layer.</span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Block[_NextItemPredictionTask]</span>
<span class="sd">            an instance of _NextItemPredictionTask</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">Block</span><span class="p">(</span>
            <span class="n">_NextItemPredictionTask</span><span class="p">(</span>
                <span class="n">input_size</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">target_dim</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">weight_tying</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">item_embedding_table</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">softmax_temperature</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">sampled_softmax</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">max_n_samples</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">min_id</span><span class="p">,</span>
            <span class="p">),</span>
            <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_dim</span><span class="p">],</span>
        <span class="p">)</span></div></div>


<span class="k">class</span> <span class="nc">_NextItemPredictionTask</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Predict the interacted item-id probabilities.</span>

<span class="sd">    - During inference, the task consists of predicting the next item.</span>
<span class="sd">    - During training, the class supports the following Language modeling tasks:</span>
<span class="sd">        Causal LM, Masked LM, Permutation LM and Replacement Token Detection</span>

<span class="sd">    Parameters:</span>
<span class="sd">    -----------</span>
<span class="sd">        input_size: int</span>
<span class="sd">            Input size of this module.</span>
<span class="sd">        target_dim: int</span>
<span class="sd">            Dimension of the target.</span>
<span class="sd">        weight_tying: bool</span>
<span class="sd">            The item id embedding table weights are shared with the prediction network layer.</span>
<span class="sd">        item_embedding_table: torch.nn.Module</span>
<span class="sd">            Module that&#39;s used to store the embedding table for the item.</span>
<span class="sd">        softmax_temperature: float</span>
<span class="sd">            Softmax temperature, used to reduce model overconfidence, so that softmax(logits / T).</span>
<span class="sd">            Value 1.0 reduces to regular softmax.</span>
<span class="sd">        sampled_softmax: Optional[bool]</span>
<span class="sd">            Enables sampled softmax. By default False</span>
<span class="sd">        max_n_samples: Optional[int]</span>
<span class="sd">            Number of samples for sampled softmax. By default 100</span>
<span class="sd">        min_id : Optional[int]</span>
<span class="sd">            The minimum value of the range for the log-uniform sampling. By default 0.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">input_size</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">,</span>
        <span class="n">target_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">weight_tying</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">item_embedding_table</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">softmax_temperature</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">sampled_softmax</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">max_n_samples</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
        <span class="n">min_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_size</span> <span class="o">=</span> <span class="n">input_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_dim</span> <span class="o">=</span> <span class="n">target_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight_tying</span> <span class="o">=</span> <span class="n">weight_tying</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">item_embedding_table</span> <span class="o">=</span> <span class="n">item_embedding_table</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">softmax_temperature</span> <span class="o">=</span> <span class="n">softmax_temperature</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sampled_softmax</span> <span class="o">=</span> <span class="n">sampled_softmax</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight_tying</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">output_layer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">target_dim</span><span class="p">,</span> <span class="n">input_size</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">kaiming_uniform_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_layer</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">5</span><span class="p">))</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">sampled_softmax</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sampler</span> <span class="o">=</span> <span class="n">LogUniformSampler</span><span class="p">(</span>
                <span class="n">max_n_samples</span><span class="o">=</span><span class="n">max_n_samples</span><span class="p">,</span>
                <span class="n">max_id</span><span class="o">=</span><span class="n">target_dim</span><span class="p">,</span>
                <span class="n">min_id</span><span class="o">=</span><span class="n">min_id</span><span class="p">,</span>
                <span class="n">unique_sampling</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inputs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">targets</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">testing</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight_tying</span><span class="p">:</span>
            <span class="n">output_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">item_embedding_table</span><span class="o">.</span><span class="n">weight</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">output_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_layer</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">sampled_softmax</span> <span class="ow">and</span> <span class="n">training</span><span class="p">:</span>
            <span class="n">logits</span><span class="p">,</span> <span class="n">targets</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sampled</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">output_weights</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">logits</span> <span class="o">=</span> <span class="n">inputs</span> <span class="o">@</span> <span class="n">output_weights</span><span class="o">.</span><span class="n">t</span><span class="p">()</span>  <span class="c1"># type: ignore</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">softmax_temperature</span><span class="p">:</span>
            <span class="c1"># Softmax temperature to reduce model overconfidence</span>
            <span class="c1"># and better calibrate probs and accuracy</span>
            <span class="n">logits</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">div</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">softmax_temperature</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">logits</span><span class="p">,</span> <span class="n">targets</span>

    <span class="k">def</span> <span class="nf">sampled</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">output_weights</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns logits using sampled softmax&quot;&quot;&quot;</span>
        <span class="n">neg_samples</span><span class="p">,</span> <span class="n">targets_probs</span><span class="p">,</span> <span class="n">samples_probs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sampler</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">targets</span><span class="p">)</span>

        <span class="n">positive_weights</span> <span class="o">=</span> <span class="n">output_weights</span><span class="p">[</span><span class="n">targets</span><span class="p">]</span>
        <span class="n">negative_weights</span> <span class="o">=</span> <span class="n">output_weights</span><span class="p">[</span><span class="n">neg_samples</span><span class="p">]</span>

        <span class="n">positive_scores</span> <span class="o">=</span> <span class="p">(</span><span class="n">inputs</span> <span class="o">*</span> <span class="n">positive_weights</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">negative_scores</span> <span class="o">=</span> <span class="n">inputs</span> <span class="o">@</span> <span class="n">negative_weights</span><span class="o">.</span><span class="n">t</span><span class="p">()</span>

        <span class="c1"># logQ correction, to not overpenalize popular items for being sampled</span>
        <span class="c1"># more often as negatives</span>
        <span class="n">epsilon</span> <span class="o">=</span> <span class="mf">1e-16</span>
        <span class="n">positive_scores</span> <span class="o">-=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">targets_probs</span> <span class="o">+</span> <span class="n">epsilon</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">negative_scores</span> <span class="o">-=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">samples_probs</span> <span class="o">+</span> <span class="n">epsilon</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="c1"># Remove accidental matches</span>
        <span class="n">accidental_hits</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">targets</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">neg_samples</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">negative_scores</span><span class="p">[</span><span class="n">accidental_hits</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">)</span><span class="o">.</span><span class="n">min</span> <span class="o">/</span> <span class="mf">100.0</span>

        <span class="n">logits</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">positive_scores</span><span class="p">,</span> <span class="n">negative_scores</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">new_targets</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">logits</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">targets</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">logits</span><span class="p">,</span> <span class="n">new_targets</span>

    <span class="k">def</span> <span class="nf">_get_name</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="s2">&quot;NextItemPredictionTask&quot;</span>


<div class="viewcode-block" id="LogUniformSampler"><a class="viewcode-back" href="../../../../api/transformers4rec.torch.model.html#transformers4rec.torch.LogUniformSampler">[docs]</a><span class="k">class</span> <span class="nc">LogUniformSampler</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">max_n_samples</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">max_id</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">min_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">unique_sampling</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">n_samples_multiplier_before_unique</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;LogUniformSampler samples negative samples based on a log-uniform distribution.</span>
<span class="sd">        `P(class) = (log(class + 2) - log(class + 1)) / log(max_id + 1)`</span>

<span class="sd">        This implementation is based on to:</span>
<span class="sd">        https://github.com/kimiyoung/transformer-xl/blob/master/pytorch/utils/log_uniform_sampler.py</span>
<span class="sd">        TensorFlow Reference:</span>
<span class="sd">        https://github.com/tensorflow/tensorflow/blob/r1.10/tensorflow/python/ops/candidate_sampling_ops.py</span>

<span class="sd">        LogUniformSampler assumes item ids are sorted decreasingly by their frequency.</span>

<span class="sd">        if `unique_sampling==True`, then only unique sampled items will be returned.</span>
<span class="sd">        The actual # samples will vary from run to run if `unique_sampling==True`,</span>
<span class="sd">        as sampling without replacement (`torch.multinomial(..., replacement=False)`) is slow,</span>
<span class="sd">        so we use `torch.multinomial(..., replacement=True).unique()` which doesn&#39;t guarantee</span>
<span class="sd">        the same number of unique sampled items. You can try to increase</span>
<span class="sd">        n_samples_multiplier_before_unique to increase the chances to have more</span>
<span class="sd">        unique samples in that case.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        max_n_samples : int</span>
<span class="sd">            The maximum desired number of negative samples. The number of samples might be</span>
<span class="sd">            smaller than that if `unique_sampling==True`, as explained above.</span>
<span class="sd">        max_id : int</span>
<span class="sd">            The maximum value of the range for the log-uniform distribution.</span>
<span class="sd">        min_id : Optional[int]</span>
<span class="sd">            The minimum value of the range for the log-uniform sampling. By default 0.</span>
<span class="sd">        unique_sampling : bool</span>
<span class="sd">            Whether to return unique samples. By default True</span>
<span class="sd">        n_samples_multiplier_before_unique : int</span>
<span class="sd">            If unique_sampling=True, it is not guaranteed that the number of returned</span>
<span class="sd">            samples will be equal to max_n_samples, as explained above.</span>
<span class="sd">            You can increase n_samples_multiplier_before_unique to maximize</span>
<span class="sd">            chances that a larger number of unique samples is returned.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">max_id</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;max_id must be a positive integer.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">max_n_samples</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;n_sample must be a positive integer.&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">max_id</span> <span class="o">=</span> <span class="n">max_id</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">unique_sampling</span> <span class="o">=</span> <span class="n">unique_sampling</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_n_samples</span> <span class="o">=</span> <span class="n">max_n_samples</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_sample</span> <span class="o">=</span> <span class="n">max_n_samples</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">unique_sampling</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_sample</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_sample</span> <span class="o">*</span> <span class="n">n_samples_multiplier_before_unique</span><span class="p">)</span>

        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">dist</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_log_uniform_distr</span><span class="p">(</span><span class="n">max_id</span><span class="p">,</span> <span class="n">min_id</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;dist&quot;</span><span class="p">,</span> <span class="n">dist</span><span class="p">)</span>
            <span class="n">unique_sampling_dist</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_unique_sampling_distr</span><span class="p">(</span><span class="n">dist</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_sample</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;unique_sampling_dist&quot;</span><span class="p">,</span> <span class="n">unique_sampling_dist</span><span class="p">)</span>

<div class="viewcode-block" id="LogUniformSampler.get_log_uniform_distr"><a class="viewcode-back" href="../../../../api/transformers4rec.torch.model.html#transformers4rec.torch.LogUniformSampler.get_log_uniform_distr">[docs]</a>    <span class="k">def</span> <span class="nf">get_log_uniform_distr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">max_id</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">min_id</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Approximates the items frequency distribution with log-uniform probability distribution</span>
<span class="sd">        with P(class) = (log(class + 2) - log(class + 1)) / log(max_id + 1).</span>
<span class="sd">        It assumes item ids are sorted decreasingly by their frequency.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        max_id : int</span>
<span class="sd">            Maximum discrete value for sampling (e.g. cardinality of the item id)</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.Tensor</span>
<span class="sd">            Returns the log uniform probability distribution</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">log_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">max_id</span> <span class="o">-</span> <span class="n">min_id</span> <span class="o">+</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span><span class="o">.</span><span class="n">log_</span><span class="p">()</span>
        <span class="n">probs</span> <span class="o">=</span> <span class="p">(</span><span class="n">log_indices</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">-</span> <span class="n">log_indices</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="o">/</span> <span class="n">log_indices</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">min_id</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">probs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
                <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">min_id</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">probs</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span> <span class="n">probs</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span>
            <span class="p">)</span>  <span class="c1"># type: ignore</span>
        <span class="k">return</span> <span class="n">probs</span></div>

<div class="viewcode-block" id="LogUniformSampler.get_unique_sampling_distr"><a class="viewcode-back" href="../../../../api/transformers4rec.torch.model.html#transformers4rec.torch.LogUniformSampler.get_unique_sampling_distr">[docs]</a>    <span class="k">def</span> <span class="nf">get_unique_sampling_distr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dist</span><span class="p">,</span> <span class="n">n_sample</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns the probability that each item is sampled at least once</span>
<span class="sd">        given the specified number of trials. This is meant to be used when</span>
<span class="sd">        self.unique_sampling == True.</span>
<span class="sd">        That probability can be approximated by by 1 - (1 - p)^n</span>
<span class="sd">        and we use a numerically stable version: -expm1(num_tries * log1p(-p))</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">(</span><span class="o">-</span><span class="p">(</span><span class="o">-</span><span class="n">dist</span><span class="o">.</span><span class="n">double</span><span class="p">()</span><span class="o">.</span><span class="n">log1p_</span><span class="p">()</span> <span class="o">*</span> <span class="n">n_sample</span><span class="p">)</span><span class="o">.</span><span class="n">expm1_</span><span class="p">())</span><span class="o">.</span><span class="n">float</span><span class="p">()</span></div>

<div class="viewcode-block" id="LogUniformSampler.sample"><a class="viewcode-back" href="../../../../api/transformers4rec.torch.model.html#transformers4rec.torch.LogUniformSampler.sample">[docs]</a>    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">labels</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Sample negative samples and calculate their probabilities.</span>

<span class="sd">        If `unique_sampling==True`, then only unique sampled items will be returned.</span>
<span class="sd">        The actual # samples will vary from run to run if `unique_sampling==True`,</span>
<span class="sd">        as sampling without replacement (`torch.multinomial(..., replacement=False)`) is slow,</span>
<span class="sd">        so we use `torch.multinomial(..., replacement=True).unique()`</span>
<span class="sd">        which doesn&#39;t guarantee the same number of unique sampled items.</span>
<span class="sd">        You can try to increase n_samples_multiplier_before_unique</span>
<span class="sd">        to increase the chances to have more unique samples in that case.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        labels : torch.Tensor, dtype=torch.long, shape=(batch_size,)</span>
<span class="sd">            The input labels for which negative samples should be generated.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        neg_samples : torch.Tensor, dtype=torch.long, shape=(n_samples,)</span>
<span class="sd">            The unique negative samples drawn from the log-uniform distribution.</span>
<span class="sd">        true_probs : torch.Tensor, dtype=torch.float32, shape=(batch_size,)</span>
<span class="sd">            The probabilities of the input labels according</span>
<span class="sd">            to the log-uniform distribution (depends on self.unique_sampling choice).</span>
<span class="sd">        samp_log_probs : torch.Tensor, dtype=torch.float32, shape=(n_samples,)</span>
<span class="sd">            The probabilities of the sampled negatives according</span>
<span class="sd">            to the log-uniform distribution (depends on self.unique_sampling choice).</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">labels</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Labels must be a torch.Tensor.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">labels</span><span class="o">.</span><span class="n">dtype</span> <span class="o">!=</span> <span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Labels must be a tensor of dtype long.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">labels</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">2</span> <span class="ow">or</span> <span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">and</span> <span class="nb">min</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Labels must be a 1-dimensional tensor or a 2-dimensional tensor&quot;</span>
                <span class="s2">&quot;with one of the dimensions equal to 1.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Labels must not be an empty tensor.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">labels</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">()</span> <span class="ow">or</span> <span class="p">(</span><span class="n">labels</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_id</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;All label values must be within the range [0, max_id].&quot;</span><span class="p">)</span>

        <span class="n">n_tries</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_sample</span>

        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">neg_samples</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">multinomial</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">dist</span><span class="p">,</span> <span class="n">n_tries</span><span class="p">,</span> <span class="n">replacement</span><span class="o">=</span><span class="kc">True</span>  <span class="c1"># type: ignore</span>
            <span class="p">)</span><span class="o">.</span><span class="n">unique</span><span class="p">()[:</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_n_samples</span><span class="p">]</span>

            <span class="n">device</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">device</span>
            <span class="n">neg_samples</span> <span class="o">=</span> <span class="n">neg_samples</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">unique_sampling</span><span class="p">:</span>
                <span class="n">dist</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">unique_sampling_dist</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">dist</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dist</span>

            <span class="n">true_probs</span> <span class="o">=</span> <span class="n">dist</span><span class="p">[</span><span class="n">labels</span><span class="p">]</span>  <span class="c1"># type: ignore</span>
            <span class="n">samples_probs</span> <span class="o">=</span> <span class="n">dist</span><span class="p">[</span><span class="n">neg_samples</span><span class="p">]</span>  <span class="c1"># type: ignore</span>

            <span class="k">return</span> <span class="n">neg_samples</span><span class="p">,</span> <span class="n">true_probs</span><span class="p">,</span> <span class="n">samples_probs</span></div>

<div class="viewcode-block" id="LogUniformSampler.forward"><a class="viewcode-back" href="../../../../api/transformers4rec.torch.model.html#transformers4rec.torch.LogUniformSampler.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span></div></div>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">

    <p>&#169; Copyright 2021–2024, NVIDIA.</p>
<p>
<a href="https://www.nvidia.com/en-us/about-nvidia/privacy-policy/" target="_blank">Privacy Policy</a> |
<a href="https://www.nvidia.com/en-us/about-nvidia/privacy-center/" target="_blank">Manage My Privacy</a> |
<a href="https://www.nvidia.com/en-us/preferences/start/" target="_blank">Do Not Sell or Share My Data</a> |
<a href="https://www.nvidia.com/en-us/about-nvidia/terms-of-service/" target="_blank">Terms of Service</a> |
<a href="https://www.nvidia.com/en-us/about-nvidia/accessibility/" target="_blank">Accessibility</a> |
<a href="https://www.nvidia.com/en-us/about-nvidia/company-policies/" target="_blank">Corporate Policies</a> |
<a href="https://www.nvidia.com/en-us/product-security/" target="_blank">Product Security</a> |
<a href="https://www.nvidia.com/en-us/contact/" target="_blank">Contact</a>
</p>

  </div>

   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
    <!-- Theme Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-NVJ1Y1YJHK"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-NVJ1Y1YJHK', {
          'anonymize_ip': false,
      });
    </script> 

</body>
</html>