<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Additional Resources &mdash; Transformers4Rec  documentation</title><link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/togglebutton.css" type="text/css" />
      <link rel="stylesheet" href="_static/mystnb.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/custom.css" type="text/css" />
    <link rel="canonical" href="https://nvidia-merlin.github.io/Transformers4Rec/main/resources.html" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script >let toggleHintShow = 'Click to show';</script>
        <script >let toggleHintHide = 'Click to hide';</script>
        <script >let toggleOpenOnPrint = 'true';</script>
        <script src="_static/togglebutton.js"></script>
        <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Contributing to Transformers4Rec" href="CONTRIBUTING.html" />
    <link rel="prev" title="merlin_standard_lib.utils package" href="api/merlin_standard_lib.utils.html" /> 
</head>

<body class="wy-body-for-nav">
  <div class="banner">
    <p class="banner">
      Beginning in January 2023, versions for all NVIDIA Merlin projects
      will change from semantic versioning like <code>4.0</code>
      to calendar versioning like <code>23.01</code>.</p>
  </div>

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> Transformers4Rec
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption"><span class="caption-text">Contents</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="README.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="why_transformers4rec.html">Why Transformers4Rec?</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_definition.html">Model Architectures</a></li>
<li class="toctree-l1"><a class="reference internal" href="training_eval.html">Training and Evaluation</a></li>
<li class="toctree-l1"><a class="reference internal" href="pipeline.html">End-to-End Pipeline with Hugging Face Transformers and NVIDIA Merlin</a></li>
<li class="toctree-l1"><a class="reference internal" href="multi_gpu_train.html">Multi-GPU data-parallel training using the <code class="docutils literal notranslate"><span class="pre">Trainer</span></code> class</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples/index.html">Example Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="api/modules.html">API Documentation</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Additional Resources</a><ul>
<li class="toctree-l2"><a class="reference internal" href="CONTRIBUTING.html">Contributing to Transformers4Rec</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Transformers4Rec</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Additional Resources</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="tex2jax_ignore mathjax_ignore section" id="additional-resources">
<h1>Additional Resources<a class="headerlink" href="#additional-resources" title="Permalink to this headline"></a></h1>
<div class="contents local topic" id="contents">
<ul class="simple">
<li><p><a class="reference internal" href="#transformers4rec-and-session-based-recommendation" id="id1">Transformers4Rec and Session-Based Recommendation</a></p></li>
<li><p><a class="reference internal" href="#competitions" id="id2">Competitions</a></p></li>
<li><p><a class="reference internal" href="#nvidia-merlin" id="id3">NVIDIA Merlin</a></p></li>
<li><p><a class="reference internal" href="#supported-hugging-face-architectures-and-pre-training-approaches" id="id4">Supported Hugging Face Architectures and Pre-Training Approaches</a></p></li>
<li><p><a class="reference internal" href="#other-resources" id="id5">Other Resources</a></p></li>
</ul>
</div>
<div class="section" id="transformers4rec-and-session-based-recommendation">
<h2>Transformers4Rec and Session-Based Recommendation<a class="headerlink" href="#transformers4rec-and-session-based-recommendation" title="Permalink to this headline"></a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://dl.acm.org/doi/10.1145/3460231.3474255">Transformers4Rec: Bridging the Gap between NLP and Sequential / Session-Based Recommendation</a> - Paper presented at the <a class="reference external" href="https://recsys.acm.org/recsys21/">ACM RecSys’21</a> where we discuss the relationship between NLP and RecSys and introduce Transformers4Rec along with its core features. We also provide a comprehensive empirical analysis comparing Transformer architectures with session-based recommendation algorithms. To obtain the <strong>Online Appendices of the Paper</strong> and <strong>Experiments Reproducibility</strong>, refer to this <a class="reference external" href="https://github.com/NVIDIA-Merlin/publications/blob/main/2021_acm_recsys_transformers4rec/README.md">README</a>.</p></li>
<li><p><a class="reference external" href="https://medium.com/nvidia-merlin/transformers4rec-4523cc7d8fa8">Blog post</a> - Briefly introduces Transformers4Rec.</p></li>
<li><p><a class="reference external" href="https://www.youtube.com/watch?v=ajegb0W-JbU">End-to-end session based recommendation demo</a> - Recorded demo presented at ACM RecSys’21 about end-to-end session-based recommendation using NVTabular, Transformers4Rec, and Triton.</p></li>
<li><p><a class="reference external" href="https://developer.nvidia.com/session-based-recommenders?ncid=so-medi-151539#cid=dl19_so-medi_en-us">Session-based recommenders</a> - Provides session-based recommendation resources.</p></li>
</ul>
</div>
<div class="section" id="competitions">
<h2>Competitions<a class="headerlink" href="#competitions" title="Permalink to this headline"></a></h2>
<ul class="simple">
<li><p><strong>SIGIR eCommerce Workshop Data Challenge 2021 (organized by Coveo)</strong> - The NVIDIA Merlin team won this competition by using Transformer architectures to predict the next interacted products for user sessions in an e-commerce. For more information about our solution, refer to our <a class="reference external" href="https://medium.com/nvidia-merlin/winning-the-sigir-ecommerce-challenge-on-session-based-recommendation-with-transformers-v2-793f6fac2994">blog post</a> and <a class="reference external" href="https://arxiv.org/abs/2107.05124">paper</a>.</p></li>
<li><p><strong>WSDM WebTour Challenge 2021 (organized by Booking. com)</strong> - The NVIDIA Merlin team won this competition by leveraging a Transformers4Rec model in the final ensemble. For more information about our solution, refer to our <a class="reference external" href="https://developer.nvidia.com/blog/how-to-build-a-winning-deep-learning-powered-recommender-system-part-3/">blog post</a> and <a class="reference external" href="http://ceur-ws.org/Vol-2855/challenge_short_2.pdf">paper</a>.</p></li>
</ul>
</div>
<div class="section" id="nvidia-merlin">
<h2>NVIDIA Merlin<a class="headerlink" href="#nvidia-merlin" title="Permalink to this headline"></a></h2>
<p>Transformers4Rec is part of the NVIDIA Merlin ecosystem for recommender systems, which includes the following components:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/NVIDIA-Merlin/NVTabular/">NVTabular</a> - NVTabular is a feature engineering and preprocessing library for tabular data that is designed to easily manipulate datasets at terabyte scale and train deep learning (DL) based recommender systems.</p></li>
<li><p><a class="reference external" href="https://github.com/triton-inference-server/server">Triton Inference Server</a> - Provides a cloud and edge inferencing solution that is optimized for both CPUs and GPUs. Transformers4Rec models can be exported and served with Triton.</p></li>
<li><p><a class="reference external" href="https://github.com/NVIDIA/HugeCTR">HugeCTR</a> - A GPU-accelerated recommender framework designed to distribute training across multiple GPUs and nodes and estimate Click-Through Rates (CTRs).</p></li>
</ul>
</div>
<div class="section" id="supported-hugging-face-architectures-and-pre-training-approaches">
<h2>Supported Hugging Face Architectures and Pre-Training Approaches<a class="headerlink" href="#supported-hugging-face-architectures-and-pre-training-approaches" title="Permalink to this headline"></a></h2>
<p>Transformers4Rec supports the following <a class="reference external" href="https://nvidia-merlin.github.io/Transformers4Rec/main/model_definition.html#sequence-masking">masking tasks</a>:</p>
<ul class="simple">
<li><p>Causal Language Modeling (CLM)</p></li>
<li><p>Masked Language Modeling (MLM)</p></li>
<li><p>Permutation Language Modeling (PLM)</p></li>
<li><p>Replacement Token Detection (RTD)</p></li>
</ul>
<p>In Transformers4Rec, we decouple the pre-training approaches from transformers architectures and provide a <code class="docutils literal notranslate"><span class="pre">TransformerBlock</span></code> module that links the config class of the transformer architecture to the masking task. Transformers4Rec also defines a <code class="docutils literal notranslate"><span class="pre">transformer_registry</span></code>, which includes pre-defined <a class="reference external" href="https://nvidia-merlin.github.io/Transformers4Rec/main/api/transformers4rec.config.html#transformers4rec.config.transformer.T4RecConfig"><code class="docutils literal notranslate"><span class="pre">T4RecConfig</span></code></a> constructors that automatically set the arguments of the related Hugging Face Transformers’ configuration classes.</p>
<p>The table below represents the architectures that are currently supported in Transformers4Rec and links them to the possible masking tasks. It also lists the pre-registered <code class="docutils literal notranslate"><span class="pre">T4RecConfig</span></code> classes in the <code class="docutils literal notranslate"><span class="pre">Registered</span></code> column.</p>
<p><strong>Tip</strong>: Consider registering HF Transformers config classes into Transformers4Rec as this can be a great first contribution.</p>
<table class="colwidths-auto docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Model</p></th>
<th class="head"><p>CLM</p></th>
<th class="head"><p>MLM</p></th>
<th class="head"><p>PLM</p></th>
<th class="head"><p>RTD</p></th>
<th class="head"><p>Registered</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><a class="reference external" href="https://huggingface.co/transformers/model_doc/albert.html#bertconfig">AlBERT</a></p></td>
<td><p>❌</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="https://huggingface.co/transformers/model_doc/bert.html#bertconfig">BERT</a></p></td>
<td><p>❌</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference external" href="https://huggingface.co/transformers/model_doc/convbert.html#convbertconfig">ConvBERT</a></p></td>
<td><p>❌</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="https://huggingface.co/transformers/model_doc/deberta.html#debertaconfig">DeBERTa</a></p></td>
<td><p>❌</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference external" href="https://huggingface.co/transformers/model_doc/distilbert.html#distilbertmodel">DistilBERT</a></p></td>
<td><p>❌</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="https://huggingface.co/transformers/model_doc/gpt2.html#gpt2config">GPT-2</a></p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
<td><p>✅</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference external" href="https://huggingface.co/transformers/model_doc/longformer.html#longformerconfig">Longformer</a></p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
<td><p>✅</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="https://huggingface.co/transformers/model_doc/megatron_bert.html#megatronbertconfig">MegatronBert</a></p></td>
<td><p>❌</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference external" href="https://huggingface.co/transformers/model_doc/mpnet.html#mpnetconfig">MPNet</a></p></td>
<td><p>❌</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="https://huggingface.co/transformers/model_doc/roberta.html#robertaconfig">RoBERTa</a></p></td>
<td><p>❌</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference external" href="https://huggingface.co/transformers/model_doc/roformer.html#roformerconfig">RoFormer</a></p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="https://huggingface.co/transformers/model_doc/transformerxl.html#transfoxlconfig">Transformer-XL</a></p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
<td><p>✅</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference external" href="https://huggingface.co/transformers/model_doc/xlnet.html#xlnetconfig">XLNet</a></p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
</tr>
</tbody>
</table>
<p><strong>Note</strong>: The following HF architectures will eventually be supported: <code class="docutils literal notranslate"><span class="pre">Reformer</span></code>, <code class="docutils literal notranslate"><span class="pre">Funnel</span> <span class="pre">Transformer</span></code>, and <code class="docutils literal notranslate"><span class="pre">ELECTRA</span></code>.</p>
</div>
<div class="section" id="other-resources">
<h2>Other Resources<a class="headerlink" href="#other-resources" title="Permalink to this headline"></a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://medium.com/nvidia-merlin">NVIDIA Merlin engineering blog</a></p></li>
<li><p>NVIDIA developer blogs:</p>
<ul>
<li><p><a class="reference external" href="https://developer.nvidia.com/blog/how-to-build-a-winning-recommendation-system-part-1/">Technical walkthrough on how to build a winning recommendation system</a></p></li>
<li><p><a class="reference external" href="https://developer.nvidia.com/blog/using-neural-networks-for-your-recommender-system/">Using Neural Networks for Your Recommender System</a></p></li>
</ul>
</li>
</ul>
</div>
<div class="toctree-wrapper compound">
</div>
</div>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="api/merlin_standard_lib.utils.html" class="btn btn-neutral float-left" title="merlin_standard_lib.utils package" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="CONTRIBUTING.html" class="btn btn-neutral float-right" title="Contributing to Transformers4Rec" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, NVIDIA.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
    <!-- Theme Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-NVJ1Y1YJHK"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-NVJ1Y1YJHK', {
          'anonymize_ip': false,
      });
    </script> 

</body>
</html>