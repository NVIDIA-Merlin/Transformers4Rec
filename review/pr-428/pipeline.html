<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>End-to-End Pipeline with Hugging Face Transformers and NVIDIA Merlin &mdash; Transformers4Rec  documentation</title><link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/togglebutton.css" type="text/css" />
      <link rel="stylesheet" href="_static/mystnb.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/custom.css" type="text/css" />
    <link rel="canonical" href="https://nvidia-merlin.github.io/Transformers4Rec/main/pipeline.html" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script >let toggleHintShow = 'Click to show';</script>
        <script >let toggleHintHide = 'Click to hide';</script>
        <script >let toggleOpenOnPrint = 'true';</script>
        <script src="_static/togglebutton.js"></script>
        <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Multi-GPU data-parallel training using the Trainer class" href="multi_gpu_train.html" />
    <link rel="prev" title="Training and Evaluation" href="training_eval.html" /> 
</head>

<body class="wy-body-for-nav">
  <div class="banner">
    <p class="banner">
      Beginning in January 2023, versions for all NVIDIA Merlin projects
      will change from semantic versioning like <code>4.0</code>
      to calendar versioning like <code>23.01</code>.</p>
  </div>

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> Transformers4Rec
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption"><span class="caption-text">Contents</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="README.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="why_transformers4rec.html">Why Transformers4Rec?</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_definition.html">Model Architectures</a></li>
<li class="toctree-l1"><a class="reference internal" href="training_eval.html">Training and Evaluation</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">End-to-End Pipeline with Hugging Face Transformers and NVIDIA Merlin</a></li>
<li class="toctree-l1"><a class="reference internal" href="multi_gpu_train.html">Multi-GPU data-parallel training using the <code class="docutils literal notranslate"><span class="pre">Trainer</span></code> class</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples/index.html">Example Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="api/modules.html">API Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="resources.html">Additional Resources</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Transformers4Rec</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>End-to-End Pipeline with Hugging Face Transformers and NVIDIA Merlin</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="tex2jax_ignore mathjax_ignore section" id="end-to-end-pipeline-with-hugging-face-transformers-and-nvidia-merlin">
<h1>End-to-End Pipeline with Hugging Face Transformers and NVIDIA Merlin<a class="headerlink" href="#end-to-end-pipeline-with-hugging-face-transformers-and-nvidia-merlin" title="Permalink to this headline"></a></h1>
<div class="contents local topic" id="contents">
<ul class="simple">
<li><p><a class="reference internal" href="#overview-of-the-pipeline" id="id1">Overview of the Pipeline</a></p></li>
<li><p><a class="reference internal" href="#integration-with-hugging-face-transformers" id="id2">Integration with Hugging Face Transformers</a></p></li>
<li><p><a class="reference internal" href="#integration-with-nvtabular" id="id3">Integration with NVTabular</a></p>
<ul>
<li><p><a class="reference internal" href="#outputs" id="id4">Outputs</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#integration-with-triton-inference-server" id="id5">Integration with Triton Inference Server</a></p></li>
</ul>
</div>
<div class="section" id="overview-of-the-pipeline">
<h2>Overview of the Pipeline<a class="headerlink" href="#overview-of-the-pipeline" title="Permalink to this headline"></a></h2>
<p>Transformers4Rec has a first-class integration with Hugging Face (HF) Transformers, NVTabular, and Triton Inference Server, making it easy to build end-to-end GPU accelerated pipelines for sequential and session-based recommendation.</p>
<p><img alt="Pipeline for Sequential and Session-based recommendation using NVIDIA Merlin components" src="_images/pipeline.png" /><br></p>
<div style="text-align: center; margin: 20pt">
<figcaption style="font-style: italic;">Pipeline for Sequential and Session-based recommendation using NVIDIA Merlin components</figcaption>
</div>
</div>
<div class="section" id="integration-with-hugging-face-transformers">
<h2>Integration with Hugging Face Transformers<a class="headerlink" href="#integration-with-hugging-face-transformers" title="Permalink to this headline"></a></h2>
<p>Transformers4Rec integrates with <a class="reference external" href="https://github.com/huggingface/transformers">Hugging Face Transformers</a>, allowing RecSys researchers and practitioners to easily experiment with the latest state-of-the-art NLP Transformer architectures for sequential and session-based recommendation tasks and deploy those models into production.</p>
<p>HF Transformers has become very popular among NLP researchers and practitioners (more than 900 contributors), providing standardized implementations of the state-of-the-art transformer architectures (more than 68 and counting) produced by the research community, often within days or weeks of their publication.</p>
<p>Models are composed of three building blocks:</p>
<ul class="simple">
<li><p>Tokenizer that converts raw text to sparse index encodings</p></li>
<li><p>Transformer architecture</p></li>
<li><p>Head for NLP tasks such as text classification, generation, sentiment analysis, translation, and summarization</p></li>
</ul>
<p><img alt="Example of preprocessed parquet file" src="_images/preproc_data_example.png" /><br></p>
<div style="text-align: center; margin: 20pt">
<figcaption style="font-style: italic;">Example of preprocessed parquet file</figcaption>
</div>
<p>Only the Transformer architecture building block and their configuration classes are leveraged from HF Transformers.
Transformers4Rec provides additional building blocks that are necessary for recommendation such as input features like normalization and aggregation as well as heads for recommendation and sequence classification and prediction.
These building blocks’ <code class="docutils literal notranslate"><span class="pre">Trainer</span></code> class are extended to enable evaluation with RecSys metrics.</p>
</div>
<div class="section" id="integration-with-nvtabular">
<h2>Integration with NVTabular<a class="headerlink" href="#integration-with-nvtabular" title="Permalink to this headline"></a></h2>
<p><a class="reference external" href="https://github.com/NVIDIA-Merlin/NVTabular/">NVTabular</a> is a feature engineering and preprocessing library for tabular data that is designed to easily manipulate datasets at terabyte scale and train deep learning (DL) based recommender systems.</p>
<p>Some popular <a class="reference external" href="https://nvidia-merlin.github.io/NVTabular/main/api/index.html">techniques</a> have been implemented within NVTabular to deal with categorical and numerical features, such as <code class="docutils literal notranslate"><span class="pre">Categorify</span></code>, <code class="docutils literal notranslate"><span class="pre">Normalize</span></code>, <code class="docutils literal notranslate"><span class="pre">Bucketize</span></code>, <code class="docutils literal notranslate"><span class="pre">TargetEncoding</span></code>, and <code class="docutils literal notranslate"><span class="pre">DifferenceLag</span></code>, and allow for custom transformations (<code class="docutils literal notranslate"><span class="pre">LambdaOp</span></code>) to be defined using cuDF data frame operations.</p>
<p>Typically, the input RecSys datasets contain one example per user interaction.
For sequential recommendation, the training example is a sequence of user interactions.
For session-based recommendation, the training example is a sequence of session interactions.
In practice, each interaction-level feature needs to be converted to a sequence that is grouped by user or session and their sequence length must match since each position of the sequence corresponds to one interaction.</p>
<p>The following figure provides a visualization of the preprocessed tabular data:</p>
<p><img alt="Example of a preprocessed parquet file" src="_images/preproc_data_example.png" /><br></p>
<div style="text-align:center;margin:20pt;">
<figcaption font-style: italic; align: center>Example of a Preprocessed Parquet File</figcaption>
</div>
<br/>
<p>NVTabular can easily prepare such data with the <a class="reference external" href="https://nvidia-merlin.github.io/NVTabular/main/api/ops/groupby.html">Groupby</a> operation.
This operation supports grouping by a categorical column such as user ID and session ID, sorting by another column such as timestamp and aggregating other columns as sequences (<code class="docutils literal notranslate"><span class="pre">list</span></code>), or by taking the <code class="docutils literal notranslate"><span class="pre">first</span></code> or <code class="docutils literal notranslate"><span class="pre">last</span></code> element of the sequence as shown in the following code block.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">groupby_features</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s1">&#39;user_id&#39;</span><span class="p">,</span> <span class="s1">&#39;session_id&#39;</span><span class="p">,</span> <span class="s1">&#39;product_id&#39;</span><span class="p">,</span> <span class="s1">&#39;category_id&#39;</span><span class="p">,</span> <span class="s1">&#39;timestamp&#39;</span>
<span class="p">]</span> <span class="o">&gt;&gt;</span> <span class="n">ops</span><span class="o">.</span><span class="n">Groupby</span><span class="p">(</span>
    <span class="n">groupby_cols</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;session_id&#39;</span><span class="p">],</span>
    <span class="n">sort_cols</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;timestamp&#39;</span><span class="p">],</span>
    <span class="n">aggs</span><span class="o">=</span><span class="p">{</span>
        <span class="s1">&#39;product_id&#39;</span><span class="p">:</span> <span class="s1">&#39;list&#39;</span><span class="p">,</span>
        <span class="s1">&#39;category_id&#39;</span><span class="p">:</span> <span class="s1">&#39;list&#39;</span><span class="p">,</span>
        <span class="s1">&#39;timestamp&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;first&#39;</span><span class="p">,</span> <span class="s1">&#39;last&#39;</span><span class="p">],</span>
    <span class="p">},</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="section" id="outputs">
<h3>Outputs<a class="headerlink" href="#outputs" title="Permalink to this headline"></a></h3>
<p>NVTabular can save preprocessed data in the Parquet file format.
You can partition the data by a categorical column, such as day and company, as shown in the following example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">nvt_output_path</span> <span class="o">=</span><span class="s1">&#39;./output&#39;</span>
<span class="n">partition_col</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;day&#39;</span><span class="p">]</span>
<span class="n">nvt</span><span class="o">.</span><span class="n">Dataset</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span><span class="o">.</span><span class="n">to_parquet</span><span class="p">(</span><span class="n">nvt_output_path</span><span class="p">,</span> <span class="n">partition_on</span><span class="o">=</span><span class="p">[</span><span class="n">partition_col</span><span class="p">])</span>
</pre></div>
</div>
<p>NVTabular also creates a schema file, <code class="docutils literal notranslate"><span class="pre">schema.pbtxt</span></code>, in the protobuf text format with the Parquet files.
The schema file contains statistics that are obtained during the preprocessing such as the cardinality of categorical features and the maximum sequence length for sequential features.
NVTabular also supports the association of tags for features.
You can use the tags to indicate the item ID, item and user features, and categorical or continuous features.
This example of a <a class="reference external" href="https://github.com/NVIDIA-Merlin/Transformers4Rec/blob/main/tests/assets/data_schema/data_seq_schema.pbtxt"><code class="docutils literal notranslate"><span class="pre">schema.pbtxt</span></code></a> file properly formats the schema in protobuf text.</p>
<p><strong>NOTE</strong>: If you don’t use NVTabular to preprocess your data, you can also instantiate a <code class="docutils literal notranslate"><span class="pre">Schema</span></code> in code manually as shown in this <a class="reference external" href="https://github.com/NVIDIA-Merlin/Transformers4Rec/blob/main/tests/merlin_standard_lib/schema/test_schema.py">schema example</a> Python program.</p>
<p>After you call <code class="docutils literal notranslate"><span class="pre">workflow.fit()</span></code>, you can save the workflow so that you can apply the same preprocessing workflow to new input data as a batch or online by using the Triton Inference Server integration.</p>
<p>The following code block shows how to save an NVTabular workflow:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Instantiates an NVTabular dataset</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">nvt</span><span class="o">.</span><span class="n">Dataset</span><span class="p">([</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">INPUT_PATH</span><span class="p">,</span> <span class="s2">&quot;*.parquet&quot;</span><span class="p">)],</span> <span class="n">part_size</span><span class="o">=</span><span class="s2">&quot;100MB&quot;</span><span class="p">)</span>

<span class="c1"># Perform a single pass over the dataset to collect columns statistics</span>
<span class="n">workflow</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>

<span class="c1"># Applies the transform ops to the dataset</span>
<span class="n">new_dataset</span> <span class="o">=</span> <span class="n">workflow</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>

<span class="c1"># Saves the preprocessed dataset in parquet files</span>
<span class="n">new_dataset</span><span class="o">.</span><span class="n">to_parquet</span><span class="p">(</span><span class="s2">&quot;/path&quot;</span><span class="p">)</span>

<span class="c1"># Saves the &quot;fitted&quot; preprocessing workflow</span>
<span class="n">workflow</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">OUTPUT_PATH</span><span class="p">,</span> <span class="s2">&quot;workflow&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="integration-with-triton-inference-server">
<h2>Integration with Triton Inference Server<a class="headerlink" href="#integration-with-triton-inference-server" title="Permalink to this headline"></a></h2>
<p>NVIDIA <a class="reference external" href="https://github.com/triton-inference-server/server">Triton Inference Server</a> (TIS) simplifies the deployment of AI models at scale to production.
TIS is a cloud and edge inferencing solution that is optimized to deploy machine learning models for GPUs and CPUs.
It supports a number of different deep learning frameworks such as TensorFlow and PyTorch.</p>
<p>An end-to-end ML/DL pipeline consists of preprocessing and feature engineering (ETL), model training, and model deployment for inference.
Model deployment to production is the critical step of this pipeline because it enables model inference for practical business decisions.
In the production setting, we want to apply the input data to the same data transformation operations that were completed during training (ETL).
Essentially, the preprocessing operations, such as standardizing continuous features and encoding categorical features, should be compatible with the statistics of the original data before feeding data to the deep learning model.
NVTabular supports the same scenario when you save the data processing workflow along with a trained PyTorch or Tensorflow model in a single ensemble pipeline to be served on TIS.</p>
<p>The TIS integration enables the deployment of deep learning recommender models at scale with GPU acceleration.
Transformers4Rec supports exporting a model trained with the PyTorch API to Triton Inference Server using the Python backend.</p>
<p>To learn about how to deploy a large and complex recommender workflow to production with only a few lines of code, refer to our <a class="reference internal" href="examples/end-to-end-session-based/index.html"><span class="xref myst">end-to-end-session-based recommendation notebook</span></a> and <a class="reference internal" href="examples/tutorial/index.html"><span class="xref myst">session-based recommendation on GPU with Transformers4Rec notebook</span></a>.</p>
</div>
</div>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="training_eval.html" class="btn btn-neutral float-left" title="Training and Evaluation" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="multi_gpu_train.html" class="btn btn-neutral float-right" title="Multi-GPU data-parallel training using the Trainer class" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, NVIDIA.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
    <!-- Theme Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-NVJ1Y1YJHK"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-NVJ1Y1YJHK', {
          'anonymize_ip': false,
      });
    </script> 

</body>
</html>