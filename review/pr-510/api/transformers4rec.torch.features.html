<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>transformers4rec.torch.features package &mdash; Transformers4Rec  documentation</title><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/togglebutton.css" type="text/css" />
      <link rel="stylesheet" href="../_static/mystnb.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />
    <link rel="canonical" href="https://nvidia-merlin.github.io/Transformers4Rec/main/api/transformers4rec.torch.features.html" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script >let toggleHintShow = 'Click to show';</script>
        <script >let toggleHintHide = 'Click to hide';</script>
        <script >let toggleOpenOnPrint = 'true';</script>
        <script src="../_static/togglebutton.js"></script>
        <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="transformers4rec.torch.model package" href="transformers4rec.torch.model.html" />
    <link rel="prev" title="transformers4rec.torch.block package" href="transformers4rec.torch.block.html" /> 
</head>

<body class="wy-body-for-nav">
  <div class="banner">
    <p class="banner">
      Beginning in January 2023, versions for all NVIDIA Merlin projects
      will change from semantic versioning like <code>4.0</code>
      to calendar versioning like <code>23.01</code>.</p>
  </div>

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> Transformers4Rec
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption"><span class="caption-text">Contents</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../README.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../why_transformers4rec.html">Why Transformers4Rec?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_definition.html">Model Architectures</a></li>
<li class="toctree-l1"><a class="reference internal" href="../training_eval.html">Training and Evaluation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pipeline.html">End-to-End Pipeline with Hugging Face Transformers and NVIDIA Merlin</a></li>
<li class="toctree-l1"><a class="reference internal" href="../multi_gpu_train.html">Multi-GPU data-parallel training using the <code class="docutils literal notranslate"><span class="pre">Trainer</span></code> class</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/index.html">Example Notebooks</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="modules.html">API Documentation</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="transformers4rec.html">transformers4rec package</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.config.html">transformers4rec.config package</a></li>
<li class="toctree-l3 current"><a class="reference internal" href="transformers4rec.torch.html">transformers4rec.torch package</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.block.html">transformers4rec.torch.block package</a></li>
<li class="toctree-l4 current"><a class="current reference internal" href="#">transformers4rec.torch.features package</a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.model.html">transformers4rec.torch.model package</a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.tabular.html">transformers4rec.torch.tabular package</a></li>
<li class="toctree-l4"><a class="reference internal" href="transformers4rec.torch.utils.html">transformers4rec.torch.utils package</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="transformers4rec.utils.html">transformers4rec.utils package</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="merlin_standard_lib.html">merlin_standard_lib package</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../resources.html">Additional Resources</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Transformers4Rec</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="modules.html">API Documentation</a> &raquo;</li>
          <li><a href="transformers4rec.html">transformers4rec package</a> &raquo;</li>
          <li><a href="transformers4rec.torch.html">transformers4rec.torch package</a> &raquo;</li>
      <li>transformers4rec.torch.features package</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="section" id="transformers4rec-torch-features-package">
<h1>transformers4rec.torch.features package<a class="headerlink" href="#transformers4rec-torch-features-package" title="Permalink to this headline"></a></h1>
<div class="section" id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline"></a></h2>
</div>
<div class="section" id="module-transformers4rec.torch.features.base">
<span id="transformers4rec-torch-features-base-module"></span><h2>transformers4rec.torch.features.base module<a class="headerlink" href="#module-transformers4rec.torch.features.base" title="Permalink to this headline"></a></h2>
<dl class="py class">
<dt id="transformers4rec.torch.features.base.InputBlock">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">transformers4rec.torch.features.base.</span></code><code class="sig-name descname"><span class="pre">InputBlock</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pre</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span> </span><span class="pre">transformers4rec.torch.tabular.base.TabularTransformation</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">post</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span> </span><span class="pre">transformers4rec.torch.tabular.base.TabularTransformation</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggregation</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span> </span><span class="pre">transformers4rec.torch.tabular.base.TabularAggregation</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">schema</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="merlin_standard_lib.schema.html#merlin_standard_lib.schema.schema.Schema" title="merlin_standard_lib.schema.schema.Schema"><span class="pre">merlin_standard_lib.schema.schema.Schema</span></a><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/features/base.html#InputBlock"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.features.base.InputBlock" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">transformers4rec.torch.tabular.base.TabularBlock</span></code>, <a class="reference external" href="https://docs.python.org/3/library/abc.html#abc.ABC" title="(in Python v3.11)"><code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code></a></p>
</dd></dl>

</div>
<div class="section" id="module-transformers4rec.torch.features.continuous">
<span id="transformers4rec-torch-features-continuous-module"></span><h2>transformers4rec.torch.features.continuous module<a class="headerlink" href="#module-transformers4rec.torch.features.continuous" title="Permalink to this headline"></a></h2>
<dl class="py class">
<dt id="transformers4rec.torch.features.continuous.ContinuousFeatures">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">transformers4rec.torch.features.continuous.</span></code><code class="sig-name descname"><span class="pre">ContinuousFeatures</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">features</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pre</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span> </span><span class="pre">transformers4rec.torch.tabular.base.TabularTransformation</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">post</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span> </span><span class="pre">transformers4rec.torch.tabular.base.TabularTransformation</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggregation</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span> </span><span class="pre">transformers4rec.torch.tabular.base.TabularAggregation</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">schema</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="merlin_standard_lib.schema.html#merlin_standard_lib.schema.schema.Schema" title="merlin_standard_lib.schema.schema.Schema"><span class="pre">merlin_standard_lib.schema.schema.Schema</span></a><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/features/continuous.html#ContinuousFeatures"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.features.continuous.ContinuousFeatures" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#transformers4rec.torch.features.base.InputBlock" title="transformers4rec.torch.features.base.InputBlock"><code class="xref py py-class docutils literal notranslate"><span class="pre">transformers4rec.torch.features.base.InputBlock</span></code></a></p>
<p>Input block for continuous features.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>features</strong> (<em>List</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><em>str</em></a><em>]</em>) – List of continuous features to include in this module.</p></li>
<li><p><strong>pre</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><em>str</em></a><em>, </em><a class="reference internal" href="transformers4rec.torch.html#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.TabularTransformation"><em>TabularTransformation</em></a><em>, </em><em>List</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><em>str</em></a><em>]</em><em>, </em><em>List</em><em>[</em><a class="reference internal" href="transformers4rec.torch.html#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.TabularTransformation"><em>TabularTransformation</em></a><em>]</em><em>]</em><em>, </em><em>optional</em>) – Transformations to apply on the inputs when the module is called (so <strong>before</strong> <cite>forward</cite>).</p></li>
<li><p><strong>post</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><em>str</em></a><em>, </em><a class="reference internal" href="transformers4rec.torch.html#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.TabularTransformation"><em>TabularTransformation</em></a><em>, </em><em>List</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><em>str</em></a><em>]</em><em>, </em><em>List</em><em>[</em><a class="reference internal" href="transformers4rec.torch.html#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.TabularTransformation"><em>TabularTransformation</em></a><em>]</em><em>]</em><em>, </em><em>optional</em>) – Transformations to apply on the inputs after the module is called (so <strong>after</strong> <cite>forward</cite>).</p></li>
<li><p><strong>aggregation</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><em>str</em></a><em>, </em><a class="reference internal" href="transformers4rec.torch.html#transformers4rec.torch.TabularAggregation" title="transformers4rec.torch.TabularAggregation"><em>TabularAggregation</em></a><em>]</em><em>, </em><em>optional</em>) – Aggregation to apply after processing the <cite>forward</cite>-method to output a single Tensor.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="transformers4rec.torch.features.continuous.ContinuousFeatures.from_features">
<em class="property"><span class="pre">classmethod</span> </em><code class="sig-name descname"><span class="pre">from_features</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">features</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/features/continuous.html#ContinuousFeatures.from_features"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.features.continuous.ContinuousFeatures.from_features" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="transformers4rec.torch.features.continuous.ContinuousFeatures.forward">
<code class="sig-name descname"><span class="pre">forward</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/features/continuous.html#ContinuousFeatures.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.features.continuous.ContinuousFeatures.forward" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="transformers4rec.torch.features.continuous.ContinuousFeatures.forward_output_size">
<code class="sig-name descname"><span class="pre">forward_output_size</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_sizes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/features/continuous.html#ContinuousFeatures.forward_output_size"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.features.continuous.ContinuousFeatures.forward_output_size" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-transformers4rec.torch.features.embedding">
<span id="transformers4rec-torch-features-embedding-module"></span><h2>transformers4rec.torch.features.embedding module<a class="headerlink" href="#module-transformers4rec.torch.features.embedding" title="Permalink to this headline"></a></h2>
<dl class="py class">
<dt id="transformers4rec.torch.features.embedding.EmbeddingFeatures">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">transformers4rec.torch.features.embedding.</span></code><code class="sig-name descname"><span class="pre">EmbeddingFeatures</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">feature_config</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span> </span><a class="reference internal" href="#transformers4rec.torch.features.embedding.FeatureConfig" title="transformers4rec.torch.features.embedding.FeatureConfig"><span class="pre">transformers4rec.torch.features.embedding.FeatureConfig</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">item_id</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pre</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span> </span><span class="pre">transformers4rec.torch.tabular.base.TabularTransformation</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">post</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span> </span><span class="pre">transformers4rec.torch.tabular.base.TabularTransformation</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggregation</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span> </span><span class="pre">transformers4rec.torch.tabular.base.TabularAggregation</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">schema</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="merlin_standard_lib.schema.html#merlin_standard_lib.schema.schema.Schema" title="merlin_standard_lib.schema.schema.Schema"><span class="pre">merlin_standard_lib.schema.schema.Schema</span></a><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/features/embedding.html#EmbeddingFeatures"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.features.embedding.EmbeddingFeatures" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#transformers4rec.torch.features.base.InputBlock" title="transformers4rec.torch.features.base.InputBlock"><code class="xref py py-class docutils literal notranslate"><span class="pre">transformers4rec.torch.features.base.InputBlock</span></code></a></p>
<p>Input block for embedding-lookups for categorical features.</p>
<p>For multi-hot features, the embeddings will be aggregated into a single tensor using the mean.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>feature_config</strong> (<em>Dict</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><em>str</em></a><em>, </em><a class="reference internal" href="#transformers4rec.torch.features.embedding.FeatureConfig" title="transformers4rec.torch.features.embedding.FeatureConfig"><em>FeatureConfig</em></a><em>]</em>) – This specifies what TableConfig to use for each feature. For shared embeddings, the same
TableConfig can be used for multiple features.</p></li>
<li><p><strong>item_id</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><em>str</em></a><em>, </em><em>optional</em>) – The name of the feature that’s used for the item_id.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>pre: Union[str, TabularTransformation, List[str], List[TabularTransformation]], optional</dt><dd><p>Transformations to apply on the inputs when the module is called (so <strong>before</strong> <cite>forward</cite>).</p>
</dd>
<dt>post: Union[str, TabularTransformation, List[str], List[TabularTransformation]], optional</dt><dd><p>Transformations to apply on the inputs after the module is called (so <strong>after</strong> <cite>forward</cite>).</p>
</dd>
<dt>aggregation: Union[str, TabularAggregation], optional</dt><dd><p>Aggregation to apply after processing the <cite>forward</cite>-method to output a single Tensor.</p>
</dd>
</dl>
<dl class="py method">
<dt id="transformers4rec.torch.features.embedding.EmbeddingFeatures.item_embedding_table">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">item_embedding_table</span></code><a class="headerlink" href="#transformers4rec.torch.features.embedding.EmbeddingFeatures.item_embedding_table" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="transformers4rec.torch.features.embedding.EmbeddingFeatures.table_to_embedding_module">
<code class="sig-name descname"><span class="pre">table_to_embedding_module</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">table</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#transformers4rec.torch.features.embedding.TableConfig" title="transformers4rec.torch.features.embedding.TableConfig"><span class="pre">transformers4rec.torch.features.embedding.TableConfig</span></a></span></em><span class="sig-paren">)</span> &#x2192; <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v1.13)"><span class="pre">torch.nn.modules.module.Module</span></a><a class="reference internal" href="../_modules/transformers4rec/torch/features/embedding.html#EmbeddingFeatures.table_to_embedding_module"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.features.embedding.EmbeddingFeatures.table_to_embedding_module" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="transformers4rec.torch.features.embedding.EmbeddingFeatures.from_schema">
<em class="property"><span class="pre">classmethod</span> </em><code class="sig-name descname"><span class="pre">from_schema</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">schema</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="merlin_standard_lib.schema.html#merlin_standard_lib.schema.schema.Schema" title="merlin_standard_lib.schema.schema.Schema"><span class="pre">merlin_standard_lib.schema.schema.Schema</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">embedding_dims</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><span class="pre">int</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embedding_dim_default</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><span class="pre">int</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">infer_embedding_sizes</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.11)"><span class="pre">bool</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">infer_embedding_sizes_multiplier</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.11)"><span class="pre">float</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">2.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embeddings_initializers</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span> </span><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.11)"><span class="pre">None</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">combiner</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><span class="pre">str</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tags</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="merlin_standard_lib.schema.html#merlin_standard_lib.schema.tag.Tag" title="merlin_standard_lib.schema.tag.Tag"><span class="pre">merlin_standard_lib.schema.tag.Tag</span></a><span class="p"><span class="pre">,</span> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.11)"><span class="pre">list</span></a><span class="p"><span class="pre">,</span> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">item_id</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">automatic_build</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.11)"><span class="pre">bool</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_sequence_length</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><span class="pre">int</span></a><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggregation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pre</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">post</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#transformers4rec.torch.features.embedding.EmbeddingFeatures" title="transformers4rec.torch.features.embedding.EmbeddingFeatures"><span class="pre">transformers4rec.torch.features.embedding.EmbeddingFeatures</span></a><span class="p"><span class="pre">]</span></span><a class="reference internal" href="../_modules/transformers4rec/torch/features/embedding.html#EmbeddingFeatures.from_schema"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.features.embedding.EmbeddingFeatures.from_schema" title="Permalink to this definition"></a></dt>
<dd><p>Instantitates <code class="docutils literal notranslate"><span class="pre">EmbeddingFeatures</span></code> from a <code class="docutils literal notranslate"><span class="pre">DatasetSchema</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>schema</strong> (<em>DatasetSchema</em>) – Dataset schema</p></li>
<li><p><strong>embedding_dims</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><em>int</em></a><em>]</em><em>]</em><em>, </em><em>optional</em>) – The dimension of the embedding table for each feature (key),
by default None by default None</p></li>
<li><p><strong>default_embedding_dim</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><em>int</em></a><em>]</em><em>, </em><em>optional</em>) – Default dimension of the embedding table, when the feature is not found
in <code class="docutils literal notranslate"><span class="pre">default_soft_embedding_dim</span></code>, by default 64</p></li>
<li><p><strong>infer_embedding_sizes</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.11)"><em>bool</em></a><em>, </em><em>optional</em>) – Automatically defines the embedding dimension from the
feature cardinality in the schema,
by default False</p></li>
<li><p><strong>infer_embedding_sizes_multiplier</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><em>int</em></a><em>]</em><em>, </em><em>by default 2.0</em>) – multiplier used by the heuristic to infer the embedding dimension from
its cardinality. Generally reasonable values range between 2.0 and 10.0</p></li>
<li><p><strong>embeddings_initializers</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><em>str</em></a><em>, </em><em>Callable</em><em>[</em><em>[</em><em>Any</em><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.11)"><em>None</em></a><em>]</em><em>]</em><em>]</em>) – Dict where keys are feature names and values are callable to initialize embedding tables</p></li>
<li><p><strong>combiner</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><em>str</em></a><em>]</em><em>, </em><em>optional</em>) – Feature aggregation option, by default “mean”</p></li>
<li><p><strong>tags</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>DefaultTags</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.11)"><em>list</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><em>str</em></a><em>]</em><em>]</em><em>, </em><em>optional</em>) – Tags to filter columns, by default None</p></li>
<li><p><strong>item_id</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><em>str</em></a><em>]</em><em>, </em><em>optional</em>) – Name of the item id column (feature), by default None</p></li>
<li><p><strong>automatic_build</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.11)"><em>bool</em></a><em>, </em><em>optional</em>) – Automatically infers input size from features, by default True</p></li>
<li><p><strong>max_sequence_length</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><em>int</em></a><em>]</em><em>, </em><em>optional</em>) – Maximum sequence length for list features,, by default None</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Returns the <code class="docutils literal notranslate"><span class="pre">EmbeddingFeatures</span></code> for the dataset schema</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Optional[<a class="reference internal" href="#transformers4rec.torch.features.embedding.EmbeddingFeatures" title="transformers4rec.torch.features.embedding.EmbeddingFeatures">EmbeddingFeatures</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="transformers4rec.torch.features.embedding.EmbeddingFeatures.item_ids">
<code class="sig-name descname"><span class="pre">item_ids</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span> &#x2192; <a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v1.13)"><span class="pre">torch.Tensor</span></a><a class="reference internal" href="../_modules/transformers4rec/torch/features/embedding.html#EmbeddingFeatures.item_ids"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.features.embedding.EmbeddingFeatures.item_ids" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="transformers4rec.torch.features.embedding.EmbeddingFeatures.forward">
<code class="sig-name descname"><span class="pre">forward</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/features/embedding.html#EmbeddingFeatures.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.features.embedding.EmbeddingFeatures.forward" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="transformers4rec.torch.features.embedding.EmbeddingFeatures.forward_output_size">
<code class="sig-name descname"><span class="pre">forward_output_size</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_sizes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/features/embedding.html#EmbeddingFeatures.forward_output_size"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.features.embedding.EmbeddingFeatures.forward_output_size" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="transformers4rec.torch.features.embedding.EmbeddingBagWrapper">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">transformers4rec.torch.features.embedding.</span></code><code class="sig-name descname"><span class="pre">EmbeddingBagWrapper</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_embeddings</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">embedding_dim</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_norm</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.11)"><span class="pre">float</span></a><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">norm_type</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.11)"><span class="pre">float</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">2.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale_grad_by_freq</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.11)"><span class="pre">bool</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><span class="pre">str</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sparse</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.11)"><span class="pre">bool</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">_weight</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v1.13)"><span class="pre">torch.Tensor</span></a><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include_last_offset</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.11)"><span class="pre">bool</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding_idx</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><span class="pre">int</span></a><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/features/embedding.html#EmbeddingBagWrapper"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.features.embedding.EmbeddingBagWrapper" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.EmbeddingBag.html#torch.nn.EmbeddingBag" title="(in PyTorch v1.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.sparse.EmbeddingBag</span></code></a></p>
<dl class="py method">
<dt id="transformers4rec.torch.features.embedding.EmbeddingBagWrapper.forward">
<code class="sig-name descname"><span class="pre">forward</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/features/embedding.html#EmbeddingBagWrapper.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.features.embedding.EmbeddingBagWrapper.forward" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="transformers4rec.torch.features.embedding.EmbeddingBagWrapper.num_embeddings">
<code class="sig-name descname"><span class="pre">num_embeddings</span></code><em class="property"><span class="pre">:</span> <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><span class="pre">int</span></a></em><a class="headerlink" href="#transformers4rec.torch.features.embedding.EmbeddingBagWrapper.num_embeddings" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="transformers4rec.torch.features.embedding.EmbeddingBagWrapper.embedding_dim">
<code class="sig-name descname"><span class="pre">embedding_dim</span></code><em class="property"><span class="pre">:</span> <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><span class="pre">int</span></a></em><a class="headerlink" href="#transformers4rec.torch.features.embedding.EmbeddingBagWrapper.embedding_dim" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="transformers4rec.torch.features.embedding.EmbeddingBagWrapper.max_norm">
<code class="sig-name descname"><span class="pre">max_norm</span></code><em class="property"><span class="pre">:</span> <span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.11)"><span class="pre">float</span></a><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#transformers4rec.torch.features.embedding.EmbeddingBagWrapper.max_norm" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="transformers4rec.torch.features.embedding.EmbeddingBagWrapper.norm_type">
<code class="sig-name descname"><span class="pre">norm_type</span></code><em class="property"><span class="pre">:</span> <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.11)"><span class="pre">float</span></a></em><a class="headerlink" href="#transformers4rec.torch.features.embedding.EmbeddingBagWrapper.norm_type" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="transformers4rec.torch.features.embedding.EmbeddingBagWrapper.scale_grad_by_freq">
<code class="sig-name descname"><span class="pre">scale_grad_by_freq</span></code><em class="property"><span class="pre">:</span> <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.11)"><span class="pre">bool</span></a></em><a class="headerlink" href="#transformers4rec.torch.features.embedding.EmbeddingBagWrapper.scale_grad_by_freq" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="transformers4rec.torch.features.embedding.EmbeddingBagWrapper.weight">
<code class="sig-name descname"><span class="pre">weight</span></code><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v1.13)"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#transformers4rec.torch.features.embedding.EmbeddingBagWrapper.weight" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="transformers4rec.torch.features.embedding.EmbeddingBagWrapper.mode">
<code class="sig-name descname"><span class="pre">mode</span></code><em class="property"><span class="pre">:</span> <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><span class="pre">str</span></a></em><a class="headerlink" href="#transformers4rec.torch.features.embedding.EmbeddingBagWrapper.mode" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="transformers4rec.torch.features.embedding.EmbeddingBagWrapper.sparse">
<code class="sig-name descname"><span class="pre">sparse</span></code><em class="property"><span class="pre">:</span> <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.11)"><span class="pre">bool</span></a></em><a class="headerlink" href="#transformers4rec.torch.features.embedding.EmbeddingBagWrapper.sparse" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="transformers4rec.torch.features.embedding.EmbeddingBagWrapper.include_last_offset">
<code class="sig-name descname"><span class="pre">include_last_offset</span></code><em class="property"><span class="pre">:</span> <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.11)"><span class="pre">bool</span></a></em><a class="headerlink" href="#transformers4rec.torch.features.embedding.EmbeddingBagWrapper.include_last_offset" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="transformers4rec.torch.features.embedding.EmbeddingBagWrapper.padding_idx">
<code class="sig-name descname"><span class="pre">padding_idx</span></code><em class="property"><span class="pre">:</span> <span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><span class="pre">int</span></a><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#transformers4rec.torch.features.embedding.EmbeddingBagWrapper.padding_idx" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="transformers4rec.torch.features.embedding.SoftEmbeddingFeatures">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">transformers4rec.torch.features.embedding.</span></code><code class="sig-name descname"><span class="pre">SoftEmbeddingFeatures</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">feature_config</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span> </span><a class="reference internal" href="#transformers4rec.torch.features.embedding.FeatureConfig" title="transformers4rec.torch.features.embedding.FeatureConfig"><span class="pre">transformers4rec.torch.features.embedding.FeatureConfig</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_norm</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.11)"><span class="pre">bool</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pre</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span> </span><span class="pre">transformers4rec.torch.tabular.base.TabularTransformation</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">post</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span> </span><span class="pre">transformers4rec.torch.tabular.base.TabularTransformation</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggregation</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span> </span><span class="pre">transformers4rec.torch.tabular.base.TabularAggregation</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwarg</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/features/embedding.html#SoftEmbeddingFeatures"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.features.embedding.SoftEmbeddingFeatures" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#transformers4rec.torch.features.embedding.EmbeddingFeatures" title="transformers4rec.torch.features.embedding.EmbeddingFeatures"><code class="xref py py-class docutils literal notranslate"><span class="pre">transformers4rec.torch.features.embedding.EmbeddingFeatures</span></code></a></p>
<p>Encapsulate continuous features encoded using the Soft-one hot encoding
embedding technique (SoftEmbedding),    from <a class="reference external" href="https://arxiv.org/pdf/1708.00065.pdf">https://arxiv.org/pdf/1708.00065.pdf</a>
In a nutshell, it keeps an embedding table for each continuous feature,
which is represented as a weighted average of embeddings.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>feature_config</strong> (<em>Dict</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><em>str</em></a><em>, </em><a class="reference internal" href="#transformers4rec.torch.features.embedding.FeatureConfig" title="transformers4rec.torch.features.embedding.FeatureConfig"><em>FeatureConfig</em></a><em>]</em>) – This specifies what TableConfig to use for each feature. For shared embeddings, the same
TableConfig can be used for multiple features.</p></li>
<li><p><strong>layer_norm</strong> (<em>boolean</em>) – When layer_norm is true, TabularLayerNorm will be used in post.</p></li>
<li><p><strong>pre</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><em>str</em></a><em>, </em><a class="reference internal" href="transformers4rec.torch.html#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.TabularTransformation"><em>TabularTransformation</em></a><em>, </em><em>List</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><em>str</em></a><em>]</em><em>, </em><em>List</em><em>[</em><a class="reference internal" href="transformers4rec.torch.html#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.TabularTransformation"><em>TabularTransformation</em></a><em>]</em><em>]</em><em>, </em><em>optional</em>) – Transformations to apply on the inputs when the module is called (so <strong>before</strong> <cite>forward</cite>).</p></li>
<li><p><strong>post</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><em>str</em></a><em>, </em><a class="reference internal" href="transformers4rec.torch.html#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.TabularTransformation"><em>TabularTransformation</em></a><em>, </em><em>List</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><em>str</em></a><em>]</em><em>, </em><em>List</em><em>[</em><a class="reference internal" href="transformers4rec.torch.html#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.TabularTransformation"><em>TabularTransformation</em></a><em>]</em><em>]</em><em>, </em><em>optional</em>) – Transformations to apply on the inputs after the module is called (so <strong>after</strong> <cite>forward</cite>).</p></li>
<li><p><strong>aggregation</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><em>str</em></a><em>, </em><a class="reference internal" href="transformers4rec.torch.html#transformers4rec.torch.TabularAggregation" title="transformers4rec.torch.TabularAggregation"><em>TabularAggregation</em></a><em>]</em><em>, </em><em>optional</em>) – Aggregation to apply after processing the <cite>forward</cite>-method to output a single Tensor.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="transformers4rec.torch.features.embedding.SoftEmbeddingFeatures.from_schema">
<em class="property"><span class="pre">classmethod</span> </em><code class="sig-name descname"><span class="pre">from_schema</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">schema</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="merlin_standard_lib.schema.html#merlin_standard_lib.schema.schema.Schema" title="merlin_standard_lib.schema.schema.Schema"><span class="pre">merlin_standard_lib.schema.schema.Schema</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">soft_embedding_cardinalities</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><span class="pre">int</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">soft_embedding_cardinality_default</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><span class="pre">int</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">soft_embedding_dims</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><span class="pre">int</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">soft_embedding_dim_default</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><span class="pre">int</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">8</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embeddings_initializers</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span> </span><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.11)"><span class="pre">None</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_norm</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.11)"><span class="pre">bool</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">combiner</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><span class="pre">str</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tags</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="merlin_standard_lib.schema.html#merlin_standard_lib.schema.tag.Tag" title="merlin_standard_lib.schema.tag.Tag"><span class="pre">merlin_standard_lib.schema.tag.Tag</span></a><span class="p"><span class="pre">,</span> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.11)"><span class="pre">list</span></a><span class="p"><span class="pre">,</span> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">automatic_build</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.11)"><span class="pre">bool</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_sequence_length</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><span class="pre">int</span></a><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#transformers4rec.torch.features.embedding.SoftEmbeddingFeatures" title="transformers4rec.torch.features.embedding.SoftEmbeddingFeatures"><span class="pre">transformers4rec.torch.features.embedding.SoftEmbeddingFeatures</span></a><span class="p"><span class="pre">]</span></span><a class="reference internal" href="../_modules/transformers4rec/torch/features/embedding.html#SoftEmbeddingFeatures.from_schema"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.features.embedding.SoftEmbeddingFeatures.from_schema" title="Permalink to this definition"></a></dt>
<dd><p>Instantitates <code class="docutils literal notranslate"><span class="pre">SoftEmbeddingFeatures</span></code> from a <code class="docutils literal notranslate"><span class="pre">DatasetSchema</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>schema</strong> (<em>DatasetSchema</em>) – Dataset schema</p></li>
<li><p><strong>soft_embedding_cardinalities</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><em>int</em></a><em>]</em><em>]</em><em>, </em><em>optional</em>) – The cardinality of the embedding table for each feature (key),
by default None</p></li>
<li><p><strong>soft_embedding_cardinality_default</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><em>int</em></a><em>]</em><em>, </em><em>optional</em>) – Default cardinality of the embedding table, when the feature
is not found in <code class="docutils literal notranslate"><span class="pre">soft_embedding_cardinalities</span></code>, by default 10</p></li>
<li><p><strong>soft_embedding_dims</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><em>int</em></a><em>]</em><em>]</em><em>, </em><em>optional</em>) – The dimension of the embedding table for each feature (key), by default None</p></li>
<li><p><strong>soft_embedding_dim_default</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><em>int</em></a><em>]</em><em>, </em><em>optional</em>) – Default dimension of the embedding table, when the feature
is not found in <code class="docutils literal notranslate"><span class="pre">soft_embedding_dim_default</span></code>, by default 8</p></li>
<li><p><strong>embeddings_initializers</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><em>str</em></a><em>, </em><em>Callable</em><em>[</em><em>[</em><em>Any</em><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.11)"><em>None</em></a><em>]</em><em>]</em><em>]</em>) – Dict where keys are feature names and values are callable to initialize embedding tables</p></li>
<li><p><strong>combiner</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><em>str</em></a><em>]</em><em>, </em><em>optional</em>) – Feature aggregation option, by default “mean”</p></li>
<li><p><strong>tags</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>DefaultTags</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.11)"><em>list</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><em>str</em></a><em>]</em><em>]</em><em>, </em><em>optional</em>) – Tags to filter columns, by default None</p></li>
<li><p><strong>automatic_build</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.11)"><em>bool</em></a><em>, </em><em>optional</em>) – Automatically infers input size from features, by default True</p></li>
<li><p><strong>max_sequence_length</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><em>int</em></a><em>]</em><em>, </em><em>optional</em>) – Maximum sequence length for list features, by default None</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Returns a <code class="docutils literal notranslate"><span class="pre">SoftEmbeddingFeatures</span></code> instance from the dataset schema</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Optional[<a class="reference internal" href="#transformers4rec.torch.features.embedding.SoftEmbeddingFeatures" title="transformers4rec.torch.features.embedding.SoftEmbeddingFeatures">SoftEmbeddingFeatures</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="transformers4rec.torch.features.embedding.SoftEmbeddingFeatures.table_to_embedding_module">
<code class="sig-name descname"><span class="pre">table_to_embedding_module</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">table</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#transformers4rec.torch.features.embedding.TableConfig" title="transformers4rec.torch.features.embedding.TableConfig"><span class="pre">transformers4rec.torch.features.embedding.TableConfig</span></a></span></em><span class="sig-paren">)</span> &#x2192; <a class="reference internal" href="#transformers4rec.torch.features.embedding.SoftEmbedding" title="transformers4rec.torch.features.embedding.SoftEmbedding"><span class="pre">transformers4rec.torch.features.embedding.SoftEmbedding</span></a><a class="reference internal" href="../_modules/transformers4rec/torch/features/embedding.html#SoftEmbeddingFeatures.table_to_embedding_module"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.features.embedding.SoftEmbeddingFeatures.table_to_embedding_module" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="transformers4rec.torch.features.embedding.TableConfig">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">transformers4rec.torch.features.embedding.</span></code><code class="sig-name descname"><span class="pre">TableConfig</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">vocabulary_size</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">initializer</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v1.13)"><span class="pre">torch.Tensor</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.11)"><span class="pre">None</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">combiner</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><span class="pre">str</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/features/embedding.html#TableConfig"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.features.embedding.TableConfig" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.11)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
</dd></dl>

<dl class="py class">
<dt id="transformers4rec.torch.features.embedding.FeatureConfig">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">transformers4rec.torch.features.embedding.</span></code><code class="sig-name descname"><span class="pre">FeatureConfig</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">table</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#transformers4rec.torch.features.embedding.TableConfig" title="transformers4rec.torch.features.embedding.TableConfig"><span class="pre">transformers4rec.torch.features.embedding.TableConfig</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_sequence_length</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><span class="pre">int</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/features/embedding.html#FeatureConfig"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.features.embedding.FeatureConfig" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.11)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
</dd></dl>

<dl class="py class">
<dt id="transformers4rec.torch.features.embedding.SoftEmbedding">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">transformers4rec.torch.features.embedding.</span></code><code class="sig-name descname"><span class="pre">SoftEmbedding</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_embeddings</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embeddings_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">emb_initializer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/features/embedding.html#SoftEmbedding"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.features.embedding.SoftEmbedding" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v1.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></a></p>
<p>Soft-one hot encoding embedding technique, from <a class="reference external" href="https://arxiv.org/pdf/1708.00065.pdf">https://arxiv.org/pdf/1708.00065.pdf</a>
In a nutshell, it represents a continuous feature as a weighted average of embeddings</p>
<dl class="py method">
<dt id="transformers4rec.torch.features.embedding.SoftEmbedding.forward">
<code class="sig-name descname"><span class="pre">forward</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_numeric</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/features/embedding.html#SoftEmbedding.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.features.embedding.SoftEmbedding.forward" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt id="transformers4rec.torch.features.embedding.SoftEmbedding.training">
<code class="sig-name descname"><span class="pre">training</span></code><em class="property"><span class="pre">:</span> <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.11)"><span class="pre">bool</span></a></em><a class="headerlink" href="#transformers4rec.torch.features.embedding.SoftEmbedding.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="transformers4rec.torch.features.embedding.PretrainedEmbeddingsInitializer">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">transformers4rec.torch.features.embedding.</span></code><code class="sig-name descname"><span class="pre">PretrainedEmbeddingsInitializer</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">weight_matrix</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v1.13)"><span class="pre">torch.Tensor</span></a><span class="p"><span class="pre">,</span> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.11)"><span class="pre">float</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trainable</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.11)"><span class="pre">bool</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/features/embedding.html#PretrainedEmbeddingsInitializer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.features.embedding.PretrainedEmbeddingsInitializer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v1.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></a></p>
<p>Initializer of embedding tables with pre-trained weights</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>weight_matrix</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v1.13)"><em>torch.Tensor</em></a><em>, </em><em>List</em><em>[</em><em>List</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.11)"><em>float</em></a><em>]</em><em>]</em><em>]</em>) – A 2D torch or numpy tensor or lists of lists with the pre-trained
weights for embeddings. The expect dims are
(embedding_cardinality, embedding_dim). The embedding_cardinality
can be inferred from the column schema, for example,
<cite>schema.select_by_name(“item_id”).feature[0].int_domain.max + 1</cite>.
The first position of the embedding table is reserved for padded
items (id=0).</p></li>
<li><p><strong>trainable</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.11)"><em>bool</em></a>) – Whether the embedding table should be trainable or not</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt id="transformers4rec.torch.features.embedding.PretrainedEmbeddingsInitializer.training">
<code class="sig-name descname"><span class="pre">training</span></code><em class="property"><span class="pre">:</span> <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.11)"><span class="pre">bool</span></a></em><a class="headerlink" href="#transformers4rec.torch.features.embedding.PretrainedEmbeddingsInitializer.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="transformers4rec.torch.features.embedding.PretrainedEmbeddingsInitializer.forward">
<code class="sig-name descname"><span class="pre">forward</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/features/embedding.html#PretrainedEmbeddingsInitializer.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.features.embedding.PretrainedEmbeddingsInitializer.forward" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-transformers4rec.torch.features.sequence">
<span id="transformers4rec-torch-features-sequence-module"></span><h2>transformers4rec.torch.features.sequence module<a class="headerlink" href="#module-transformers4rec.torch.features.sequence" title="Permalink to this headline"></a></h2>
<dl class="py class">
<dt id="transformers4rec.torch.features.sequence.SequenceEmbeddingFeatures">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">transformers4rec.torch.features.sequence.</span></code><code class="sig-name descname"><span class="pre">SequenceEmbeddingFeatures</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">feature_config</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span> </span><a class="reference internal" href="#transformers4rec.torch.features.embedding.FeatureConfig" title="transformers4rec.torch.features.embedding.FeatureConfig"><span class="pre">transformers4rec.torch.features.embedding.FeatureConfig</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">item_id</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding_idx</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><span class="pre">int</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pre</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span> </span><span class="pre">transformers4rec.torch.tabular.base.TabularTransformation</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">post</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span> </span><span class="pre">transformers4rec.torch.tabular.base.TabularTransformation</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggregation</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span> </span><span class="pre">transformers4rec.torch.tabular.base.TabularAggregation</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">schema</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="merlin_standard_lib.schema.html#merlin_standard_lib.schema.schema.Schema" title="merlin_standard_lib.schema.schema.Schema"><span class="pre">merlin_standard_lib.schema.schema.Schema</span></a><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/features/sequence.html#SequenceEmbeddingFeatures"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.features.sequence.SequenceEmbeddingFeatures" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#transformers4rec.torch.features.embedding.EmbeddingFeatures" title="transformers4rec.torch.features.embedding.EmbeddingFeatures"><code class="xref py py-class docutils literal notranslate"><span class="pre">transformers4rec.torch.features.embedding.EmbeddingFeatures</span></code></a></p>
<p>Input block for embedding-lookups for categorical features. This module produces 3-D tensors,
this is useful for sequential models like transformers.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>feature_config</strong> (<em>Dict</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><em>str</em></a><em>, </em><a class="reference internal" href="transformers4rec.torch.html#transformers4rec.torch.FeatureConfig" title="transformers4rec.torch.FeatureConfig"><em>FeatureConfig</em></a><em>]</em>) – This specifies what TableConfig to use for each feature. For shared embeddings, the same
TableConfig can be used for multiple features.</p></li>
<li><p><strong>item_id</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><em>str</em></a><em>, </em><em>optional</em>) – The name of the feature that’s used for the item_id.</p></li>
<li><p><strong>padding_idx</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><em>int</em></a>) – The symbol to use for padding.</p></li>
<li><p><strong>pre</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><em>str</em></a><em>, </em><a class="reference internal" href="transformers4rec.torch.html#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.TabularTransformation"><em>TabularTransformation</em></a><em>, </em><em>List</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><em>str</em></a><em>]</em><em>, </em><em>List</em><em>[</em><a class="reference internal" href="transformers4rec.torch.html#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.TabularTransformation"><em>TabularTransformation</em></a><em>]</em><em>]</em><em>, </em><em>optional</em>) – Transformations to apply on the inputs when the module is called (so <strong>before</strong> <cite>forward</cite>).</p></li>
<li><p><strong>post</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><em>str</em></a><em>, </em><a class="reference internal" href="transformers4rec.torch.html#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.TabularTransformation"><em>TabularTransformation</em></a><em>, </em><em>List</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><em>str</em></a><em>]</em><em>, </em><em>List</em><em>[</em><a class="reference internal" href="transformers4rec.torch.html#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.TabularTransformation"><em>TabularTransformation</em></a><em>]</em><em>]</em><em>, </em><em>optional</em>) – Transformations to apply on the inputs after the module is called (so <strong>after</strong> <cite>forward</cite>).</p></li>
<li><p><strong>aggregation</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><em>str</em></a><em>, </em><a class="reference internal" href="transformers4rec.torch.html#transformers4rec.torch.TabularAggregation" title="transformers4rec.torch.TabularAggregation"><em>TabularAggregation</em></a><em>]</em><em>, </em><em>optional</em>) – Aggregation to apply after processing the <cite>forward</cite>-method to output a single Tensor.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="transformers4rec.torch.features.sequence.SequenceEmbeddingFeatures.table_to_embedding_module">
<code class="sig-name descname"><span class="pre">table_to_embedding_module</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">table</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#transformers4rec.torch.features.embedding.TableConfig" title="transformers4rec.torch.features.embedding.TableConfig"><span class="pre">transformers4rec.torch.features.embedding.TableConfig</span></a></span></em><span class="sig-paren">)</span> &#x2192; <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html#torch.nn.Embedding" title="(in PyTorch v1.13)"><span class="pre">torch.nn.modules.sparse.Embedding</span></a><a class="reference internal" href="../_modules/transformers4rec/torch/features/sequence.html#SequenceEmbeddingFeatures.table_to_embedding_module"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.features.sequence.SequenceEmbeddingFeatures.table_to_embedding_module" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="transformers4rec.torch.features.sequence.SequenceEmbeddingFeatures.forward_output_size">
<code class="sig-name descname"><span class="pre">forward_output_size</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_sizes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/features/sequence.html#SequenceEmbeddingFeatures.forward_output_size"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.features.sequence.SequenceEmbeddingFeatures.forward_output_size" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="transformers4rec.torch.features.sequence.TabularSequenceFeatures">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">transformers4rec.torch.features.sequence.</span></code><code class="sig-name descname"><span class="pre">TabularSequenceFeatures</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">continuous_module</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">transformers4rec.torch.tabular.base.TabularModule</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">categorical_module</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">transformers4rec.torch.tabular.base.TabularModule</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">text_embedding_module</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">transformers4rec.torch.tabular.base.TabularModule</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">projection_module</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.base.BlockBase" title="transformers4rec.torch.block.base.BlockBase"><span class="pre">transformers4rec.torch.block.base.BlockBase</span></a><span class="p"><span class="pre">,</span> </span><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.base.BuildableBlock" title="transformers4rec.torch.block.base.BuildableBlock"><span class="pre">transformers4rec.torch.block.base.BuildableBlock</span></a><span class="p"><span class="pre">,</span> </span><a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v1.13)"><span class="pre">torch.nn.modules.module.Module</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">masking</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="transformers4rec.torch.html#transformers4rec.torch.masking.MaskSequence" title="transformers4rec.torch.masking.MaskSequence"><span class="pre">transformers4rec.torch.masking.MaskSequence</span></a><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pre</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span> </span><span class="pre">transformers4rec.torch.tabular.base.TabularTransformation</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">post</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span> </span><span class="pre">transformers4rec.torch.tabular.base.TabularTransformation</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggregation</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span> </span><span class="pre">transformers4rec.torch.tabular.base.TabularAggregation</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">schema</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="merlin_standard_lib.schema.html#merlin_standard_lib.schema.schema.Schema" title="merlin_standard_lib.schema.schema.Schema"><span class="pre">merlin_standard_lib.schema.schema.Schema</span></a><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/features/sequence.html#TabularSequenceFeatures"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.features.sequence.TabularSequenceFeatures" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#transformers4rec.torch.features.tabular.TabularFeatures" title="transformers4rec.torch.features.tabular.TabularFeatures"><code class="xref py py-class docutils literal notranslate"><span class="pre">transformers4rec.torch.features.tabular.TabularFeatures</span></code></a></p>
<p>Input module that combines different types of features to a sequence: continuous,
categorical &amp; text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>continuous_module</strong> (<a class="reference internal" href="transformers4rec.torch.html#transformers4rec.torch.TabularModule" title="transformers4rec.torch.TabularModule"><em>TabularModule</em></a><em>, </em><em>optional</em>) – Module used to process continuous features.</p></li>
<li><p><strong>categorical_module</strong> (<a class="reference internal" href="transformers4rec.torch.html#transformers4rec.torch.TabularModule" title="transformers4rec.torch.TabularModule"><em>TabularModule</em></a><em>, </em><em>optional</em>) – Module used to process categorical features.</p></li>
<li><p><strong>text_embedding_module</strong> (<a class="reference internal" href="transformers4rec.torch.html#transformers4rec.torch.TabularModule" title="transformers4rec.torch.TabularModule"><em>TabularModule</em></a><em>, </em><em>optional</em>) – Module used to process text features.</p></li>
<li><p><strong>projection_module</strong> (<em>BlockOrModule</em><em>, </em><em>optional</em>) – Module that’s used to project the output of this module, typically done by an MLPBlock.</p></li>
<li><p><strong>masking</strong> (<a class="reference internal" href="transformers4rec.torch.html#transformers4rec.torch.masking.MaskSequence" title="transformers4rec.torch.masking.MaskSequence"><em>MaskSequence</em></a><em>, </em><em>optional</em>) – Masking to apply to the inputs.</p></li>
<li><p><strong>pre</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><em>str</em></a><em>, </em><a class="reference internal" href="transformers4rec.torch.html#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.TabularTransformation"><em>TabularTransformation</em></a><em>, </em><em>List</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><em>str</em></a><em>]</em><em>, </em><em>List</em><em>[</em><a class="reference internal" href="transformers4rec.torch.html#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.TabularTransformation"><em>TabularTransformation</em></a><em>]</em><em>]</em><em>, </em><em>optional</em>) – Transformations to apply on the inputs when the module is called (so <strong>before</strong> <cite>forward</cite>).</p></li>
<li><p><strong>post</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><em>str</em></a><em>, </em><a class="reference internal" href="transformers4rec.torch.html#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.TabularTransformation"><em>TabularTransformation</em></a><em>, </em><em>List</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><em>str</em></a><em>]</em><em>, </em><em>List</em><em>[</em><a class="reference internal" href="transformers4rec.torch.html#transformers4rec.torch.TabularTransformation" title="transformers4rec.torch.TabularTransformation"><em>TabularTransformation</em></a><em>]</em><em>]</em><em>, </em><em>optional</em>) – Transformations to apply on the inputs after the module is called (so <strong>after</strong> <cite>forward</cite>).</p></li>
<li><p><strong>aggregation</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><em>str</em></a><em>, </em><a class="reference internal" href="transformers4rec.torch.html#transformers4rec.torch.TabularAggregation" title="transformers4rec.torch.TabularAggregation"><em>TabularAggregation</em></a><em>]</em><em>, </em><em>optional</em>) – Aggregation to apply after processing the <cite>forward</cite>-method to output a single Tensor.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt id="transformers4rec.torch.features.sequence.TabularSequenceFeatures.EMBEDDING_MODULE_CLASS">
<code class="sig-name descname"><span class="pre">EMBEDDING_MODULE_CLASS</span></code><a class="headerlink" href="#transformers4rec.torch.features.sequence.TabularSequenceFeatures.EMBEDDING_MODULE_CLASS" title="Permalink to this definition"></a></dt>
<dd><p>alias of <a class="reference internal" href="#transformers4rec.torch.features.sequence.SequenceEmbeddingFeatures" title="transformers4rec.torch.features.sequence.SequenceEmbeddingFeatures"><code class="xref py py-class docutils literal notranslate"><span class="pre">transformers4rec.torch.features.sequence.SequenceEmbeddingFeatures</span></code></a></p>
</dd></dl>

<dl class="py method">
<dt id="transformers4rec.torch.features.sequence.TabularSequenceFeatures.from_schema">
<em class="property"><span class="pre">classmethod</span> </em><code class="sig-name descname"><span class="pre">from_schema</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="pre">schema:</span> <span class="pre">merlin_standard_lib.schema.schema.Schema,</span> <span class="pre">continuous_tags:</span> <span class="pre">Optional[Union[List[str],</span> <span class="pre">List[merlin_standard_lib.schema.tag.Tag],</span> <span class="pre">List[Union[merlin_standard_lib.schema.tag.Tag,</span> <span class="pre">str]],</span> <span class="pre">Tuple[merlin_standard_lib.schema.tag.Tag]]]</span> <span class="pre">=</span> <span class="pre">(&lt;Tag.CONTINUOUS:</span> <span class="pre">'continuous'&gt;,),</span> <span class="pre">categorical_tags:</span> <span class="pre">Optional[Union[List[str],</span> <span class="pre">List[merlin_standard_lib.schema.tag.Tag],</span> <span class="pre">List[Union[merlin_standard_lib.schema.tag.Tag,</span> <span class="pre">str]],</span> <span class="pre">Tuple[merlin_standard_lib.schema.tag.Tag]]]</span> <span class="pre">=</span> <span class="pre">(&lt;Tag.CATEGORICAL:</span> <span class="pre">'categorical'&gt;,),</span> <span class="pre">aggregation:</span> <span class="pre">Optional[str]</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">automatic_build:</span> <span class="pre">bool</span> <span class="pre">=</span> <span class="pre">True,</span> <span class="pre">max_sequence_length:</span> <span class="pre">Optional[int]</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">continuous_projection:</span> <span class="pre">Optional[Union[List[int],</span> <span class="pre">int]]</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">continuous_soft_embeddings:</span> <span class="pre">bool</span> <span class="pre">=</span> <span class="pre">False,</span> <span class="pre">projection:</span> <span class="pre">Optional[Union[torch.nn.modules.module.Module,</span> <span class="pre">transformers4rec.torch.block.base.BuildableBlock]]</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">d_output:</span> <span class="pre">Optional[int]</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">masking:</span> <span class="pre">Optional[Union[str,</span> <span class="pre">transformers4rec.torch.masking.MaskSequence]]</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">**kwargs</span></em><span class="sig-paren">)</span> &#x2192; <a class="reference internal" href="#transformers4rec.torch.features.sequence.TabularSequenceFeatures" title="transformers4rec.torch.features.sequence.TabularSequenceFeatures"><span class="pre">transformers4rec.torch.features.sequence.TabularSequenceFeatures</span></a><a class="reference internal" href="../_modules/transformers4rec/torch/features/sequence.html#TabularSequenceFeatures.from_schema"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.features.sequence.TabularSequenceFeatures.from_schema" title="Permalink to this definition"></a></dt>
<dd><p>Instantiates <code class="docutils literal notranslate"><span class="pre">TabularFeatures</span></code> from a <code class="docutils literal notranslate"><span class="pre">DatasetSchema</span></code></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>schema</strong> (<em>DatasetSchema</em>) – Dataset schema</p></li>
<li><p><strong>continuous_tags</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>DefaultTags</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.11)"><em>list</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><em>str</em></a><em>]</em><em>]</em><em>, </em><em>optional</em>) – Tags to filter the continuous features, by default Tag.CONTINUOUS</p></li>
<li><p><strong>categorical_tags</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>DefaultTags</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.11)"><em>list</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><em>str</em></a><em>]</em><em>]</em><em>, </em><em>optional</em>) – Tags to filter the categorical features, by default Tag.CATEGORICAL</p></li>
<li><p><strong>aggregation</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><em>str</em></a><em>]</em><em>, </em><em>optional</em>) – Feature aggregation option, by default None</p></li>
<li><p><strong>automatic_build</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.11)"><em>bool</em></a><em>, </em><em>optional</em>) – Automatically infers input size from features, by default True</p></li>
<li><p><strong>max_sequence_length</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><em>int</em></a><em>]</em><em>, </em><em>optional</em>) – Maximum sequence length for list features by default None</p></li>
<li><p><strong>continuous_projection</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><em>int</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><em>int</em></a><em>]</em><em>]</em><em>, </em><em>optional</em>) – If set, concatenate all numerical features and project them by a number of MLP layers.
The argument accepts a list with the dimensions of the MLP layers, by default None</p></li>
<li><p><strong>continuous_soft_embeddings</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.11)"><em>bool</em></a>) – Indicates if the  soft one-hot encoding technique must be used to represent
continuous features, by default False</p></li>
<li><p><strong>projection</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v1.13)"><em>torch.nn.Module</em></a><em>, </em><a class="reference internal" href="transformers4rec.torch.block.html#transformers4rec.torch.block.base.BuildableBlock" title="transformers4rec.torch.block.base.BuildableBlock"><em>BuildableBlock</em></a><em>]</em><em>]</em><em>, </em><em>optional</em>) – If set, project the aggregated embeddings vectors into hidden dimension vector space,
by default None</p></li>
<li><p><strong>d_output</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><em>int</em></a><em>]</em><em>, </em><em>optional</em>) – If set, init a MLPBlock as projection module to project embeddings vectors,
by default None</p></li>
<li><p><strong>masking</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><em>str</em></a><em>, </em><a class="reference internal" href="transformers4rec.torch.html#transformers4rec.torch.masking.MaskSequence" title="transformers4rec.torch.masking.MaskSequence"><em>MaskSequence</em></a><em>]</em><em>]</em><em>, </em><em>optional</em>) – If set, Apply masking to the input embeddings and compute masked labels, It requires
a categorical_module including an item_id column, by default None</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Returns <code class="docutils literal notranslate"><span class="pre">TabularFeatures</span></code> from a dataset schema</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="transformers4rec.torch.html#transformers4rec.torch.TabularFeatures" title="transformers4rec.torch.TabularFeatures">TabularFeatures</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="transformers4rec.torch.features.sequence.TabularSequenceFeatures.masking">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">masking</span></code><a class="headerlink" href="#transformers4rec.torch.features.sequence.TabularSequenceFeatures.masking" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="transformers4rec.torch.features.sequence.TabularSequenceFeatures.set_masking">
<code class="sig-name descname"><span class="pre">set_masking</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/features/sequence.html#TabularSequenceFeatures.set_masking"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.features.sequence.TabularSequenceFeatures.set_masking" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="transformers4rec.torch.features.sequence.TabularSequenceFeatures.item_id">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">item_id</span></code><a class="headerlink" href="#transformers4rec.torch.features.sequence.TabularSequenceFeatures.item_id" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="transformers4rec.torch.features.sequence.TabularSequenceFeatures.item_embedding_table">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">item_embedding_table</span></code><a class="headerlink" href="#transformers4rec.torch.features.sequence.TabularSequenceFeatures.item_embedding_table" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="transformers4rec.torch.features.sequence.TabularSequenceFeatures.forward">
<code class="sig-name descname"><span class="pre">forward</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">testing</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/features/sequence.html#TabularSequenceFeatures.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.features.sequence.TabularSequenceFeatures.forward" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="transformers4rec.torch.features.sequence.TabularSequenceFeatures.project_continuous_features">
<code class="sig-name descname"><span class="pre">project_continuous_features</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dimensions</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/features/sequence.html#TabularSequenceFeatures.project_continuous_features"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.features.sequence.TabularSequenceFeatures.project_continuous_features" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="transformers4rec.torch.features.sequence.TabularSequenceFeatures.forward_output_size">
<code class="sig-name descname"><span class="pre">forward_output_size</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/features/sequence.html#TabularSequenceFeatures.forward_output_size"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.features.sequence.TabularSequenceFeatures.forward_output_size" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-transformers4rec.torch.features.tabular">
<span id="transformers4rec-torch-features-tabular-module"></span><h2>transformers4rec.torch.features.tabular module<a class="headerlink" href="#module-transformers4rec.torch.features.tabular" title="Permalink to this headline"></a></h2>
<dl class="py class">
<dt id="transformers4rec.torch.features.tabular.TabularFeatures">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">transformers4rec.torch.features.tabular.</span></code><code class="sig-name descname"><span class="pre">TabularFeatures</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">continuous_module</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">transformers4rec.torch.tabular.base.TabularModule</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">categorical_module</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">transformers4rec.torch.tabular.base.TabularModule</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">text_embedding_module</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">transformers4rec.torch.tabular.base.TabularModule</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pre</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span> </span><span class="pre">transformers4rec.torch.tabular.base.TabularTransformation</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">post</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span> </span><span class="pre">transformers4rec.torch.tabular.base.TabularTransformation</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aggregation</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span> </span><span class="pre">transformers4rec.torch.tabular.base.TabularAggregation</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">schema</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="merlin_standard_lib.schema.html#merlin_standard_lib.schema.schema.Schema" title="merlin_standard_lib.schema.schema.Schema"><span class="pre">merlin_standard_lib.schema.schema.Schema</span></a><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/features/tabular.html#TabularFeatures"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.features.tabular.TabularFeatures" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">transformers4rec.torch.tabular.base.MergeTabular</span></code></p>
<p>Input module that combines different types of features: continuous, categorical &amp; text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>continuous_module</strong> (<a class="reference internal" href="transformers4rec.torch.html#transformers4rec.torch.TabularModule" title="transformers4rec.torch.TabularModule"><em>TabularModule</em></a><em>, </em><em>optional</em>) – Module used to process continuous features.</p></li>
<li><p><strong>categorical_module</strong> (<a class="reference internal" href="transformers4rec.torch.html#transformers4rec.torch.TabularModule" title="transformers4rec.torch.TabularModule"><em>TabularModule</em></a><em>, </em><em>optional</em>) – Module used to process categorical features.</p></li>
<li><p><strong>text_embedding_module</strong> (<a class="reference internal" href="transformers4rec.torch.html#transformers4rec.torch.TabularModule" title="transformers4rec.torch.TabularModule"><em>TabularModule</em></a><em>, </em><em>optional</em>) – Module used to process text features.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>pre: Union[str, TabularTransformation, List[str], List[TabularTransformation]], optional</dt><dd><p>Transformations to apply on the inputs when the module is called (so <strong>before</strong> <cite>forward</cite>).</p>
</dd>
<dt>post: Union[str, TabularTransformation, List[str], List[TabularTransformation]], optional</dt><dd><p>Transformations to apply on the inputs after the module is called (so <strong>after</strong> <cite>forward</cite>).</p>
</dd>
<dt>aggregation: Union[str, TabularAggregation], optional</dt><dd><p>Aggregation to apply after processing the <cite>forward</cite>-method to output a single Tensor.</p>
</dd>
</dl>
<dl class="py attribute">
<dt id="transformers4rec.torch.features.tabular.TabularFeatures.CONTINUOUS_MODULE_CLASS">
<code class="sig-name descname"><span class="pre">CONTINUOUS_MODULE_CLASS</span></code><a class="headerlink" href="#transformers4rec.torch.features.tabular.TabularFeatures.CONTINUOUS_MODULE_CLASS" title="Permalink to this definition"></a></dt>
<dd><p>alias of <a class="reference internal" href="#transformers4rec.torch.features.continuous.ContinuousFeatures" title="transformers4rec.torch.features.continuous.ContinuousFeatures"><code class="xref py py-class docutils literal notranslate"><span class="pre">transformers4rec.torch.features.continuous.ContinuousFeatures</span></code></a></p>
</dd></dl>

<dl class="py attribute">
<dt id="transformers4rec.torch.features.tabular.TabularFeatures.EMBEDDING_MODULE_CLASS">
<code class="sig-name descname"><span class="pre">EMBEDDING_MODULE_CLASS</span></code><a class="headerlink" href="#transformers4rec.torch.features.tabular.TabularFeatures.EMBEDDING_MODULE_CLASS" title="Permalink to this definition"></a></dt>
<dd><p>alias of <a class="reference internal" href="#transformers4rec.torch.features.embedding.EmbeddingFeatures" title="transformers4rec.torch.features.embedding.EmbeddingFeatures"><code class="xref py py-class docutils literal notranslate"><span class="pre">transformers4rec.torch.features.embedding.EmbeddingFeatures</span></code></a></p>
</dd></dl>

<dl class="py attribute">
<dt id="transformers4rec.torch.features.tabular.TabularFeatures.SOFT_EMBEDDING_MODULE_CLASS">
<code class="sig-name descname"><span class="pre">SOFT_EMBEDDING_MODULE_CLASS</span></code><a class="headerlink" href="#transformers4rec.torch.features.tabular.TabularFeatures.SOFT_EMBEDDING_MODULE_CLASS" title="Permalink to this definition"></a></dt>
<dd><p>alias of <a class="reference internal" href="#transformers4rec.torch.features.embedding.SoftEmbeddingFeatures" title="transformers4rec.torch.features.embedding.SoftEmbeddingFeatures"><code class="xref py py-class docutils literal notranslate"><span class="pre">transformers4rec.torch.features.embedding.SoftEmbeddingFeatures</span></code></a></p>
</dd></dl>

<dl class="py method">
<dt id="transformers4rec.torch.features.tabular.TabularFeatures.project_continuous_features">
<code class="sig-name descname"><span class="pre">project_continuous_features</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mlp_layers_dims</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><span class="pre">int</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><span class="pre">int</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> &#x2192; <a class="reference internal" href="#transformers4rec.torch.features.tabular.TabularFeatures" title="transformers4rec.torch.features.tabular.TabularFeatures"><span class="pre">transformers4rec.torch.features.tabular.TabularFeatures</span></a><a class="reference internal" href="../_modules/transformers4rec/torch/features/tabular.html#TabularFeatures.project_continuous_features"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.features.tabular.TabularFeatures.project_continuous_features" title="Permalink to this definition"></a></dt>
<dd><p>Combine all concatenated continuous features with stacked MLP layers</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>mlp_layers_dims</strong> (<em>Union</em><em>[</em><em>List</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><em>int</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><em>int</em></a><em>]</em>) – The MLP layer dimensions</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Returns the same <code class="docutils literal notranslate"><span class="pre">TabularFeatures</span></code> object with the continuous features projected</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#transformers4rec.torch.features.tabular.TabularFeatures" title="transformers4rec.torch.features.tabular.TabularFeatures">TabularFeatures</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="transformers4rec.torch.features.tabular.TabularFeatures.from_schema">
<em class="property"><span class="pre">classmethod</span> </em><code class="sig-name descname"><span class="pre">from_schema</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="pre">schema:</span> <span class="pre">merlin_standard_lib.schema.schema.Schema,</span> <span class="pre">continuous_tags:</span> <span class="pre">Optional[Union[List[str],</span> <span class="pre">List[merlin_standard_lib.schema.tag.Tag],</span> <span class="pre">List[Union[merlin_standard_lib.schema.tag.Tag,</span> <span class="pre">str]],</span> <span class="pre">Tuple[merlin_standard_lib.schema.tag.Tag]]]</span> <span class="pre">=</span> <span class="pre">(&lt;Tag.CONTINUOUS:</span> <span class="pre">'continuous'&gt;,),</span> <span class="pre">categorical_tags:</span> <span class="pre">Optional[Union[List[str],</span> <span class="pre">List[merlin_standard_lib.schema.tag.Tag],</span> <span class="pre">List[Union[merlin_standard_lib.schema.tag.Tag,</span> <span class="pre">str]],</span> <span class="pre">Tuple[merlin_standard_lib.schema.tag.Tag]]]</span> <span class="pre">=</span> <span class="pre">(&lt;Tag.CATEGORICAL:</span> <span class="pre">'categorical'&gt;,),</span> <span class="pre">aggregation:</span> <span class="pre">Optional[str]</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">automatic_build:</span> <span class="pre">bool</span> <span class="pre">=</span> <span class="pre">True,</span> <span class="pre">max_sequence_length:</span> <span class="pre">Optional[int]</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">continuous_projection:</span> <span class="pre">Optional[Union[List[int],</span> <span class="pre">int]]</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">continuous_soft_embeddings:</span> <span class="pre">bool</span> <span class="pre">=</span> <span class="pre">False,</span> <span class="pre">**kwargs</span></em><span class="sig-paren">)</span> &#x2192; <a class="reference internal" href="#transformers4rec.torch.features.tabular.TabularFeatures" title="transformers4rec.torch.features.tabular.TabularFeatures"><span class="pre">transformers4rec.torch.features.tabular.TabularFeatures</span></a><a class="reference internal" href="../_modules/transformers4rec/torch/features/tabular.html#TabularFeatures.from_schema"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.features.tabular.TabularFeatures.from_schema" title="Permalink to this definition"></a></dt>
<dd><p>Instantiates <code class="docutils literal notranslate"><span class="pre">TabularFeatures</span></code> from a <code class="docutils literal notranslate"><span class="pre">DatasetSchema</span></code></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>schema</strong> (<em>DatasetSchema</em>) – Dataset schema</p></li>
<li><p><strong>continuous_tags</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>DefaultTags</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.11)"><em>list</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><em>str</em></a><em>]</em><em>]</em><em>, </em><em>optional</em>) – Tags to filter the continuous features, by default Tag.CONTINUOUS</p></li>
<li><p><strong>categorical_tags</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>DefaultTags</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.11)"><em>list</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><em>str</em></a><em>]</em><em>]</em><em>, </em><em>optional</em>) – Tags to filter the categorical features, by default Tag.CATEGORICAL</p></li>
<li><p><strong>aggregation</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.11)"><em>str</em></a><em>]</em><em>, </em><em>optional</em>) – Feature aggregation option, by default None</p></li>
<li><p><strong>automatic_build</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.11)"><em>bool</em></a><em>, </em><em>optional</em>) – Automatically infers input size from features, by default True</p></li>
<li><p><strong>max_sequence_length</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><em>int</em></a><em>]</em><em>, </em><em>optional</em>) – Maximum sequence length for list features by default None</p></li>
<li><p><strong>continuous_projection</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><em>List</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><em>int</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.11)"><em>int</em></a><em>]</em><em>]</em><em>, </em><em>optional</em>) – If set, concatenate all numerical features and project them by a number of MLP layers.
The argument accepts a list with the dimensions of the MLP layers, by default None</p></li>
<li><p><strong>continuous_soft_embeddings</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.11)"><em>bool</em></a>) – Indicates if the  soft one-hot encoding technique must be used to
represent continuous features, by default False</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Returns <code class="docutils literal notranslate"><span class="pre">TabularFeatures</span></code> from a dataset schema</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#transformers4rec.torch.features.tabular.TabularFeatures" title="transformers4rec.torch.features.tabular.TabularFeatures">TabularFeatures</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="transformers4rec.torch.features.tabular.TabularFeatures.forward_output_size">
<code class="sig-name descname"><span class="pre">forward_output_size</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/transformers4rec/torch/features/tabular.html#TabularFeatures.forward_output_size"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#transformers4rec.torch.features.tabular.TabularFeatures.forward_output_size" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="transformers4rec.torch.features.tabular.TabularFeatures.continuous_module">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">continuous_module</span></code><a class="headerlink" href="#transformers4rec.torch.features.tabular.TabularFeatures.continuous_module" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="transformers4rec.torch.features.tabular.TabularFeatures.categorical_module">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">categorical_module</span></code><a class="headerlink" href="#transformers4rec.torch.features.tabular.TabularFeatures.categorical_module" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-transformers4rec.torch.features.text">
<span id="transformers4rec-torch-features-text-module"></span><h2>transformers4rec.torch.features.text module<a class="headerlink" href="#module-transformers4rec.torch.features.text" title="Permalink to this headline"></a></h2>
</div>
<div class="section" id="module-transformers4rec.torch.features">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-transformers4rec.torch.features" title="Permalink to this headline"></a></h2>
</div>
</div>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="transformers4rec.torch.block.html" class="btn btn-neutral float-left" title="transformers4rec.torch.block package" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="transformers4rec.torch.model.html" class="btn btn-neutral float-right" title="transformers4rec.torch.model package" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, NVIDIA.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
    <!-- Theme Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-NVJ1Y1YJHK"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-NVJ1Y1YJHK', {
          'anonymize_ip': false,
      });
    </script> 

</body>
</html>