<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Model Architectures &mdash; Transformers4Rec  documentation</title><link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/togglebutton.css" type="text/css" />
      <link rel="stylesheet" href="_static/mystnb.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script >let toggleHintShow = 'Click to show';</script>
        <script >let toggleHintHide = 'Click to hide';</script>
        <script >let toggleOpenOnPrint = 'true';</script>
        <script src="_static/togglebutton.js"></script>
        <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Training and Evaluation" href="training_eval.html" />
    <link rel="prev" title="Why Transformers4Rec?" href="why_transformers4rec.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> Transformers4Rec
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption"><span class="caption-text">Contents</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="README.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="why_transformers4rec.html">Why Transformers4Rec?</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Model Architectures</a></li>
<li class="toctree-l1"><a class="reference internal" href="training_eval.html">Training and Evaluation</a></li>
<li class="toctree-l1"><a class="reference internal" href="pipeline.html">End-to-end pipeline with NVIDIA Merlin</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples/index.html">Example Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="api/modules.html">API Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="resources.html">Additional Resources</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Transformers4Rec</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Model Architectures</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="tex2jax_ignore mathjax_ignore section" id="model-architectures">
<h1>Model Architectures<a class="headerlink" href="#model-architectures" title="Permalink to this headline"></a></h1>
<p>Transformers4Rec provides modularized building blocks that can be combined with plain PyTorch modules and Keras layers. This provides a great flexibility in the model definition, as you can use the blocks to build custom architectures, e.g., with multiple towers, multiple heads and losses (multi-task).</p>
<p>In Fig. 2, we provide a reference architecture for next-item prediction with Transformers, that can be used for both sequential and session-based recommendation. We can divide that reference architecture in four conceptual layers, described next.</p>
<div style="text-align: center; margin: 20pt"><img src="_images/transformers4rec_metaarchitecture.png" alt="Transformers4Rec meta-architecture" style="width:600px;"/><br><figcaption style="font-style: italic;">Fig. 2 - Transformers4Rec meta-architecture</figcaption></div>
<div class="section" id="feature-aggregation-input-block">
<h2>Feature Aggregation (Input Block)<a class="headerlink" href="#feature-aggregation-input-block" title="Permalink to this headline"></a></h2>
<p>In order to be fed into a transformer block the sequences of input features (user_ids, user metadata, item_ids, item metadata) must be aggregated into a single vector representation per element in the sequence which we call the <em>interaction embedding</em>.</p>
<p>Current feature aggregation options are:</p>
<ul class="simple">
<li><p><strong>Concat</strong> - Concatenation of the features</p></li>
<li><p><strong>Element-wise sum</strong> - Features are summed. For that, all features must have the same dimension, i.e. categorical embeddings must have the same dim and continuous features are projected to that dim.</p></li>
<li><p><strong>Element-wise sum &amp; item multiplication</strong> - Similar to <em>Element-wise sum</em>, as all features are summed. except for the item id embedding, which is multiplied by the other features sum. The aggregation formula is available in our <a class="reference external" href="https://dl.acm.org/doi/10.1145/3460231.3474255">paper</a>.</p></li>
</ul>
<p>Categorical features are represented by embeddings. Numerical features can be represented as a scalar, projected by a fully-connected (FC) layer to multiple dimensions, or represented as a weighted average of embeddings by the technique Soft One-Hot embeddings (more info in our <a class="reference external" href="https://github.com/NVIDIA-Merlin/publications/blob/main/2021_acm_recsys_transformers4rec/Appendices/Appendix_A-Techniques_used_in_Transformers4Rec_Meta-Architecture.md">paper online appendix</a>). Categorical input features are optionally normalized (with layer normalization) before aggregation.  Continuous features should be normalized during feature engineering of the dataset.</p>
<p>The core class of this module is the <code class="docutils literal notranslate"><span class="pre">TabularSequenceFeatures</span></code>, which is responsible for processing and aggregating all features and outputs a sequence of <em>interaction embeddings</em> to be fed into transformer blocks. It can be instantiated automatically from a dataset schema (<code class="docutils literal notranslate"><span class="pre">from_schema()</span></code>) generated by <a class="reference external" href="https://github.com/NVIDIA-Merlin/NVTabular">NVTabular</a>, which directly creates all the necessary layers to represent the categorical and continuous features in the dataset. In addition, it has options to aggregate the sequential features, and to prepare masked labels depending on the chosen sequence masking approach (see next section)).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">transformers4rec.torch</span> <span class="kn">import</span> <span class="n">TabularSequenceFeatures</span>
<span class="n">tabular_inputs</span> <span class="o">=</span> <span class="n">TabularSequenceFeatures</span><span class="o">.</span><span class="n">from_schema</span><span class="p">(</span>
        <span class="n">schema</span><span class="p">,</span>
        <span class="n">max_sequence_length</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
        <span class="n">d_output</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
        <span class="n">aggregation</span><span class="o">=</span><span class="s2">&quot;concat&quot;</span><span class="p">,</span>
        <span class="n">masking</span><span class="o">=</span><span class="s2">&quot;clm&quot;</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="sequence-masking">
<h2>Sequence Masking<a class="headerlink" href="#sequence-masking" title="Permalink to this headline"></a></h2>
<p>Transformer architectures can be trained in different ways. Depending on the training method, there is a specific masking schema. The masking schema sets the items to be predicted (labels) and masks some positions of the sequence that cannot be used by the Transformer layers for prediction. Transformers4Rec currently supports the following training approaches, inspired by NLP:</p>
<ul class="simple">
<li><p><strong>Causal LM (<code class="docutils literal notranslate"><span class="pre">masking=&quot;clm&quot;</span></code>)</strong> - Predicts the next item based on past positions of the sequence. Future positions are masked.</p></li>
<li><p><strong>Masked LM (<code class="docutils literal notranslate"><span class="pre">masking=&quot;mlm&quot;</span></code>)</strong> - Randomly select some positions of the sequence to be predicted, which are masked. The Transformer layer is allowed to use positions on the right (future information) during training. During inference, all past items are visible for the Transformer layer, which tries to predict the next item.</p></li>
<li><p><strong>Permutation LM (<code class="docutils literal notranslate"><span class="pre">masking=&quot;plm&quot;</span></code>)</strong> - Uses a permutation factorization at the level of the self-attention layer to define the accessible bidirectional context</p></li>
<li><p><strong>Replacement Token Detection (<code class="docutils literal notranslate"><span class="pre">masking=&quot;rtd&quot;</span></code>)</strong> - Uses MLM to randomly select some items, but replaces them by random tokens. Then, a discriminator model (that can share the weights with the generator or not), is asked to classify whether the item at each position belongs to the original sequence. The generator-discriminator architecture is jointly trained using Masked LM and RTD tasks.</p></li>
</ul>
<p>Note that not all transformer architectures support all of these training approaches.  Transformers4Rec will raise an exception when you attempt to use an invalid combination and will provide suggestions as to the appropriate masking techniques for that architecture.</p>
</div>
<div class="section" id="sequence-processing-transformer-rnn-block">
<h2>Sequence Processing (Transformer/RNN Block)<a class="headerlink" href="#sequence-processing-transformer-rnn-block" title="Permalink to this headline"></a></h2>
<p>The Transformer block processes the input sequences of <em>interaction embeddings</em> created by the input block using Transformer architectures like XLNet, GPT-2, etc, or RNN architectures like LSTM or GRU.  The created block is a standard keras layer or torch block depending on the underlying framework and is compatible with and substitutable by other blocks of the same type which support the input of a sequence.</p>
<p>In the following example, a <code class="docutils literal notranslate"><span class="pre">SequentialBlock</span></code> module is used to build the model body: a <code class="docutils literal notranslate"><span class="pre">TabularSequenceFeatures</span></code> object (<code class="docutils literal notranslate"><span class="pre">tabular_inputs</span></code> defined in the previous code snippet), followed by an MLP projection layer to 64 dim (to match the Transformer <code class="docutils literal notranslate"><span class="pre">d_model</span></code>), followed by an XLNet transformer block with 2 layers (4 heads each).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">transformers4rec.config</span> <span class="kn">import</span> <span class="n">transformer</span>
<span class="kn">from</span> <span class="nn">transformers4rec.torch</span> <span class="kn">import</span> <span class="n">MLPBlock</span><span class="p">,</span> <span class="n">SequentialBlock</span><span class="p">,</span> <span class="n">TransformerBlock</span>

<span class="c1"># Configures the XLNet Transformer architecture</span>
<span class="n">transformer_config</span> <span class="o">=</span> <span class="n">transformer</span><span class="o">.</span><span class="n">XLNetConfig</span><span class="o">.</span><span class="n">build</span><span class="p">(</span>
    <span class="n">d_model</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">n_head</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">n_layer</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">total_seq_length</span><span class="o">=</span><span class="mi">20</span>
<span class="p">)</span>

<span class="c1"># Defines the model body including: inputs, masking, projection and transformer block.</span>
<span class="n">model_body</span> <span class="o">=</span> <span class="n">SequentialBlock</span><span class="p">(</span>
    <span class="n">tabular_inputs</span><span class="p">,</span>
    <span class="n">torch4rec</span><span class="o">.</span><span class="n">MLPBlock</span><span class="p">([</span><span class="mi">64</span><span class="p">]),</span>
    <span class="n">torch4rec</span><span class="o">.</span><span class="n">TransformerBlock</span><span class="p">(</span><span class="n">transformer_config</span><span class="p">,</span> <span class="n">masking</span><span class="o">=</span><span class="n">tabular_inputs</span><span class="o">.</span><span class="n">masking</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="prediction-head-output-block">
<h2>Prediction head (Output Block)<a class="headerlink" href="#prediction-head-output-block" title="Permalink to this headline"></a></h2>
<p>Following the input and transformer blocks the model outputs its predictions.  The library supports the following prediction heads which can have multiple losses and can be combined for multi-task learning and multiple metrics.</p>
<ul class="simple">
<li><p><strong>Next Item Prediction</strong> - Predicts next items for a given sequence of interactions. During training it can be the next item or randomly selected items, depending on the masking scheme. For inference it is meant to always predict the next interacted item. Currently cross-entropy and pairwise losses are supported.</p></li>
<li><p><strong>Classification</strong> - Predicts a categorical feature using the whole sequence. In the context of recommendation, which can be used to predict for example if the user is going to abandon a product added to cart or proceed to its purchase.</p></li>
<li><p><strong>Regression</strong> - Predicts a continuous feature using the whole sequence, for example the elapsed time until the user returns to a service.</p></li>
</ul>
<p>In the following example we instantiate a head with the pre-defined <code class="docutils literal notranslate"><span class="pre">model_body</span></code> for the <code class="docutils literal notranslate"><span class="pre">NextItemPredictionTask</span></code>. That head enables the <code class="docutils literal notranslate"><span class="pre">weight_tying</span></code> option, which is described in the next section.
Decoupling model bodies and heads allow for a flexible model architecture definition, as it allows for multiple towers and/or heads. Finally, the <code class="docutils literal notranslate"><span class="pre">Model</span></code> class combines the heads and wraps the whole model.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">transformers4rec.torch</span> <span class="kn">import</span> <span class="n">Head</span><span class="p">,</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="nn">transformers4rec.torch.model.head</span> <span class="kn">import</span> <span class="n">NextItemPredictionTask</span>

<span class="c1"># Defines the head related to next item prediction task</span>
<span class="n">head</span> <span class="o">=</span> <span class="n">Head</span><span class="p">(</span>
    <span class="n">model_body</span><span class="p">,</span>
    <span class="n">NextItemPredictionTask</span><span class="p">(</span><span class="n">weight_tying</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">hf_format</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
    <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Get the end-to-end Model class</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">head</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="tying-embeddings">
<h3>Tying embeddings<a class="headerlink" href="#tying-embeddings" title="Permalink to this headline"></a></h3>
<p>For <code class="docutils literal notranslate"><span class="pre">NextItemPredictionTask</span></code> we have added a best practice, <strong>Tying Embeddings</strong>, proposed originally by the NLP community to tie the weights of the input (item id) embedding matrix with the output projection layer. Not only do tied embeddings reduce the memory requirements significantly, but our own experimentation during <a class="reference external" href="https://resources.nvidia.com/en-us-merlin/recommendation-syste?lx=97GH0Q">recent competitions</a> and empirical analysis detailed in our <a class="reference external" href="https://dl.acm.org/doi/10.1145/3460231.3474255">paper</a> and <a class="reference external" href="https://github.com/NVIDIA-Merlin/publications/blob/main/2021_acm_recsys_transformers4rec/Appendices/Appendix_A-Techniques_used_in_Transformers4Rec_Meta-Architecture.md">online appendix</a> show how effective this method is.  It is enabled by default, but can be disabled by setting weight_tying=False).</p>
</div>
</div>
<div class="section" id="regularization">
<h2>Regularization<a class="headerlink" href="#regularization" title="Permalink to this headline"></a></h2>
<p>The library supports a number of regularization techniques like Dropout, Weight Decay, Softmax Temperature Scaling, Stochastic Shared Embeddings, and Label Smoothing. In our extensive experimentation hypertuning all regularization techniques for different dataset we found that the Label Smoothing was particularly useful at improving both train and validation accuracy and better calibrating the predictions.</p>
<p>More details of the options available for each building block can be found in our <strong>API Documentation</strong>.</p>
</div>
</div>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="why_transformers4rec.html" class="btn btn-neutral float-left" title="Why Transformers4Rec?" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="training_eval.html" class="btn btn-neutral float-right" title="Training and Evaluation" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, NVIDIA.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  
<div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    <span class="fa fa-book"> Other Versions</span>
    v: v0.1.3
    <span class="fa fa-caret-down"></span>
  </span>
  <div class="rst-other-versions">
    <dl>
      <dt>Tags</dt>
      <dd><a href="model_definition.html">v0.1.3</a></dd>
      <dd><a href="../v0.1.4/model_definition.html">v0.1.4</a></dd>
      <dd><a href="../v0.1.5/model_definition.html">v0.1.5</a></dd>
      <dd><a href="../v0.1.6/model_definition.html">v0.1.6</a></dd>
      <dd><a href="../v0.1.7/model_definition.html">v0.1.7</a></dd>
      <dd><a href="../v0.1.8/model_definition.html">v0.1.8</a></dd>
    </dl>
    <dl>
      <dt>Branches</dt>
      <dd><a href="../main/model_definition.html">main</a></dd>
    </dl>
  </div>
</div><script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>