{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce1d7155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 1)) (0.13.7)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 2)) (1.3.5)\n",
      "Requirement already satisfied: nvidia-pyindex in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 3)) (1.0.9)\n",
      "Requirement already satisfied: dllogger from git+https://github.com/NVIDIA/dllogger#egg=dllogger in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 4)) (1.0.0)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb->-r requirements.txt (line 1)) (1.12.1)\n",
      "Requirement already satisfied: pathtools in /usr/local/lib/python3.8/dist-packages (from wandb->-r requirements.txt (line 1)) (0.1.2)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from wandb->-r requirements.txt (line 1)) (0.4.0)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.8/dist-packages (from wandb->-r requirements.txt (line 1)) (2.3)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb->-r requirements.txt (line 1)) (2.28.1)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.8/dist-packages (from wandb->-r requirements.txt (line 1)) (1.0.11)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from wandb->-r requirements.txt (line 1)) (45.2.0)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb->-r requirements.txt (line 1)) (3.1.30)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.8/dist-packages (from wandb->-r requirements.txt (line 1)) (8.1.3)\n",
      "Requirement already satisfied: setproctitle in /usr/local/lib/python3.8/dist-packages (from wandb->-r requirements.txt (line 1)) (1.3.2)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb->-r requirements.txt (line 1)) (5.9.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.12.0; python_version < \"3.9\" and sys_platform == \"linux\" in /usr/local/lib/python3.8/dist-packages (from wandb->-r requirements.txt (line 1)) (3.20.3)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from wandb->-r requirements.txt (line 1)) (6.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->-r requirements.txt (line 2)) (2022.7)\n",
      "Requirement already satisfied: numpy>=1.17.3; platform_machine != \"aarch64\" and platform_machine != \"arm64\" and python_version < \"3.10\" in /usr/local/lib/python3.8/dist-packages (from pandas->-r requirements.txt (line 2)) (1.22.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->-r requirements.txt (line 2)) (2.8.2)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from sentry-sdk>=1.0.0->wandb->-r requirements.txt (line 1)) (2019.11.28)\n",
      "Requirement already satisfied: urllib3>=1.26.11; python_version >= \"3.6\" in /usr/local/lib/python3.8/dist-packages (from sentry-sdk>=1.0.0->wandb->-r requirements.txt (line 1)) (1.26.13)\n",
      "Requirement already satisfied: six>=1.4.0 in /usr/lib/python3/dist-packages (from docker-pycreds>=0.4.0->wandb->-r requirements.txt (line 1)) (1.14.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 1)) (2.8)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 1)) (2.1.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.8/dist-packages (from GitPython>=1.0.0->wandb->-r requirements.txt (line 1)) (4.0.10)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.8/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb->-r requirements.txt (line 1)) (5.0.0)\n",
      "Requirement already satisfied: gdown in /usr/local/lib/python3.8/dist-packages (4.6.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from gdown) (4.64.1)\n",
      "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.8/dist-packages (from gdown) (2.28.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from gdown) (3.9.0)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from gdown) (1.14.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from gdown) (4.11.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests[socks]->gdown) (2019.11.28)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests[socks]->gdown) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.26.13)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.8/dist-packages (from beautifulsoup4->gdown) (2.3.2.post1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1NCFZ5ya3zyxPsrmupEoc9UEm4sslAddV\n",
      "To: /workspace/examples/t4rec_paper_experiments/t4r_paper_repro/rees46_ecom_dataset_small_for_ci.zip\n",
      "100%|██████████| 43.4M/43.4M [00:07<00:00, 6.15MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
      "Hit:2 http://archive.ubuntu.com/ubuntu focal InRelease\n",
      "Hit:3 http://security.ubuntu.com/ubuntu focal-security InRelease\n",
      "Hit:4 http://archive.ubuntu.com/ubuntu focal-updates InRelease\n",
      "Hit:5 http://archive.ubuntu.com/ubuntu focal-backports InRelease\n",
      "Reading package lists...\n",
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "unzip is already the newest version (6.0-25ubuntu1.1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 74 not upgraded.\n",
      "Archive:  rees46_ecom_dataset_small_for_ci.zip\n",
      "   creating: /transformers4rec/examples/t4rec_paper_experiments/t4r_paper_repro/0001/\n",
      "  inflating: /transformers4rec/examples/t4rec_paper_experiments/t4r_paper_repro/0001/valid.parquet  \n",
      " extracting: /transformers4rec/examples/t4rec_paper_experiments/t4r_paper_repro/0001/.zip  \n",
      "  inflating: /transformers4rec/examples/t4rec_paper_experiments/t4r_paper_repro/0001/train.parquet  \n",
      "  inflating: /transformers4rec/examples/t4rec_paper_experiments/t4r_paper_repro/0001/test.parquet  \n",
      "   creating: /transformers4rec/examples/t4rec_paper_experiments/t4r_paper_repro/0002/\n",
      "  inflating: /transformers4rec/examples/t4rec_paper_experiments/t4r_paper_repro/0002/valid.parquet  \n",
      "  inflating: /transformers4rec/examples/t4rec_paper_experiments/t4r_paper_repro/0002/train.parquet  \n",
      "  inflating: /transformers4rec/examples/t4rec_paper_experiments/t4r_paper_repro/0002/test.parquet  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=18EllaKaodqaesrNJ3YGEmv0YUD3NX0vK\n",
      "To: /workspace/examples/t4rec_paper_experiments/t4r_paper_repro/model.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  model.zip\n",
      "   creating: /transformers4rec/TF4Rec/models/t4r_pytorch_pt/\n",
      "  inflating: /transformers4rec/TF4Rec/models/t4r_pytorch_pt/config_GPU.pbtxt  \n",
      "   creating: /transformers4rec/TF4Rec/models/t4r_pytorch_pt/1/\n",
      "  inflating: /transformers4rec/TF4Rec/models/t4r_pytorch_pt/1/model.pkl  \n",
      "  inflating: /transformers4rec/TF4Rec/models/t4r_pytorch_pt/1/model_info.json  \n",
      "  inflating: /transformers4rec/TF4Rec/models/t4r_pytorch_pt/1/model.py  \n",
      "  inflating: /transformers4rec/TF4Rec/models/t4r_pytorch_pt/1/model.pth  \n",
      "   creating: /transformers4rec/TF4Rec/models/t4r_pytorch_pt/1/__pycache__/\n",
      "  inflating: /transformers4rec/TF4Rec/models/t4r_pytorch_pt/1/__pycache__/model.cpython-38.pyc  \n",
      "  inflating: /transformers4rec/TF4Rec/models/t4r_pytorch_pt/config.pbtxt  \n",
      "  inflating: /transformers4rec/TF4Rec/models/t4r_pytorch_pt/config_CPU.pbtxt  \n",
      "  inflating: /transformers4rec/TF4Rec/models/t4r_pytorch_pt/config.pbtxt.old  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-8' coro=<ScriptMagics.shebang.<locals>._handle_stream() done, defined at /usr/local/lib/python3.8/dist-packages/IPython/core/magics/script.py:211> exception=ValueError('Separator is not found, and chunk exceed the limit')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/asyncio/streams.py\", line 540, in readline\n",
      "    line = await self.readuntil(sep)\n",
      "  File \"/usr/lib/python3.8/asyncio/streams.py\", line 618, in readuntil\n",
      "    raise exceptions.LimitOverrunError(\n",
      "asyncio.exceptions.LimitOverrunError: Separator is not found, and chunk exceed the limit\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/magics/script.py\", line 213, in _handle_stream\n",
      "    line = (await stream.readline()).decode(\"utf8\")\n",
      "  File \"/usr/lib/python3.8/asyncio/streams.py\", line 549, in readline\n",
      "    raise ValueError(e.args[0])\n",
      "ValueError: Separator is not found, and chunk exceed the limit\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "set -e\n",
    "\n",
    "#### Install requirements\n",
    "cd examples/t4rec_paper_experiments\n",
    "pip install -r requirements.txt\n",
    "\n",
    "### Get data\n",
    "cd t4r_paper_repro\n",
    "\n",
    "FEATURE_SCHEMA_PATH=../datasets_configs/ecom_rees46/rees46_schema.pbtxt\n",
    "pip install gdown\n",
    "gdown https://drive.google.com/uc?id=1NCFZ5ya3zyxPsrmupEoc9UEm4sslAddV\n",
    "apt-get update -y\n",
    "apt-get install unzip -y\n",
    "DATA_PATH=/transformers4rec/examples/t4rec_paper_experiments/t4r_paper_repro/\n",
    "unzip -d $DATA_PATH \"rees46_ecom_dataset_small_for_ci.zip\"\n",
    "gdown https://drive.google.com/uc?id=18EllaKaodqaesrNJ3YGEmv0YUD3NX0vK\n",
    "MODEL_PATH=/transformers4rec/TF4Rec/models/\n",
    "mkdir -p /transformers4rec/TF4Rec/models/\n",
    "unzip -d $MODEL_PATH \"model.zip\"\n",
    "exit 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "513f52fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import logging\n",
    "import os\n",
    "from functools import partial\n",
    "import pandas as pd\n",
    "import cudf\n",
    "import numpy as np\n",
    "import nvtabular.inference.triton as nvt_triton\n",
    "import tritonclient.grpc as grpcclient\n",
    "import subprocess\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "163eef53",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/workspace/examples/t4rec_paper_experiments/t4r_paper_repro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4071799",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_path = os.path.join(\n",
    "    '/transformers4rec/examples/t4rec_paper_experiments/t4r_paper_repro/',\n",
    "    str(2,).zfill(4),\n",
    "    \"valid.parquet\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fb61268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tritonserver --model-repository=/workspace/TF4Rec/models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d7c12df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<subprocess.Popen at 0x7efd03c9ceb0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.Popen(['tritonserver',  '--model-repository=/transformers4rec/TF4Rec/models/'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b8f3a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0215 04:33:37.500518 1321 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7f0666000000' with size 268435456\n",
      "I0215 04:33:37.500846 1321 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864\n",
      "I0215 04:33:37.502759 1321 model_lifecycle.cc:459] loading: t4r_pytorch_pt:1\n",
      "I0215 04:33:41.177972 1321 python_be.cc:1856] TRITONBACKEND_ModelInstanceInitialize: t4r_pytorch_pt_0 (CPU device 0)\n",
      "I0215 04:33:45.490882 1321 model_lifecycle.cc:694] successfully loaded 't4r_pytorch_pt' version 1\n",
      "I0215 04:33:45.490943 1321 server.cc:563] \n",
      "+------------------+------+\n",
      "| Repository Agent | Path |\n",
      "+------------------+------+\n",
      "+------------------+------+\n",
      "\n",
      "I0215 04:33:45.490983 1321 server.cc:590] \n",
      "+---------+-------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Backend | Path                                                  | Config                                                                                                                                                        |\n",
      "+---------+-------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| python  | /opt/tritonserver/backends/python/libtriton_python.so | {\"cmdline\":{\"auto-complete-config\":\"true\",\"min-compute-capability\":\"6.000000\",\"backend-directory\":\"/opt/tritonserver/backends\",\"default-max-batch-size\":\"4\"}} |\n",
      "+---------+-------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "I0215 04:33:45.491000 1321 server.cc:633] \n",
      "+----------------+---------+--------+\n",
      "| Model          | Version | Status |\n",
      "+----------------+---------+--------+\n",
      "| t4r_pytorch_pt | 1       | READY  |\n",
      "+----------------+---------+--------+\n",
      "\n",
      "I0215 04:33:45.515911 1321 metrics.cc:864] Collecting metrics for GPU 0: Quadro RTX 8000\n",
      "I0215 04:33:45.516150 1321 metrics.cc:757] Collecting CPU metrics\n",
      "I0215 04:33:45.516282 1321 tritonserver.cc:2264] \n",
      "+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Option                           | Value                                                                                                                                                                                                |\n",
      "+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| server_id                        | triton                                                                                                                                                                                               |\n",
      "| server_version                   | 2.28.0                                                                                                                                                                                               |\n",
      "| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics trace logging |\n",
      "| model_repository_path[0]         | /transformers4rec/TF4Rec/models/                                                                                                                                                                     |\n",
      "| model_control_mode               | MODE_NONE                                                                                                                                                                                            |\n",
      "| strict_model_config              | 0                                                                                                                                                                                                    |\n",
      "| rate_limit                       | OFF                                                                                                                                                                                                  |\n",
      "| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                            |\n",
      "| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                                             |\n",
      "| response_cache_byte_size         | 0                                                                                                                                                                                                    |\n",
      "| min_supported_compute_capability | 6.0                                                                                                                                                                                                  |\n",
      "| strict_readiness                 | 1                                                                                                                                                                                                    |\n",
      "| exit_timeout                     | 30                                                                                                                                                                                                   |\n",
      "+----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "I0215 04:33:45.517131 1321 grpc_server.cc:4819] Started GRPCInferenceService at 0.0.0.0:8001\n",
      "I0215 04:33:45.517287 1321 http_server.cc:3477] Started HTTPService at 0.0.0.0:8000\n",
      "I0215 04:33:45.557965 1321 http_server.cc:184] Started Metrics Service at 0.0.0.0:8002\n"
     ]
    }
   ],
   "source": [
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2413171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client created.\n",
      "GET /v2/health/live, headers None\n",
      "<HTTPSocketPoolResponse status=200 headers={'content-length': '0', 'content-type': 'text/plain'}>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tritonhttpclient/__init__.py:31: DeprecationWarning: The package `tritonhttpclient` is deprecated and will be removed in a future version. Please use instead `tritonclient.http`\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tritonhttpclient\n",
    "try:\n",
    "    triton_client = tritonhttpclient.InferenceServerClient(url=\"localhost:8000\", verbose=True)\n",
    "    print(\"client created.\")\n",
    "except Exception as e:\n",
    "    print(\"channel creation failed: \" + str(e))\n",
    "triton_client.is_server_live()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1726cce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_data = cudf.read_parquet(eval_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a21bdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['sess_pid_seq']\n",
    "inputs = nvt_triton.convert_df_to_triton_input(col_names, prediction_data.loc[6, col_names], grpcclient.InferInput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e295e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.09 ms ± 221 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "output_names = [\"output\"]\n",
    "\n",
    "outputs = []\n",
    "for col in output_names:\n",
    "    outputs.append(grpcclient.InferRequestedOutput(col))\n",
    "    \n",
    "MODEL_NAME_PT = \"t4r_pytorch_pt\"\n",
    "payload = cudf.DataFrame(data={'sess_pid_seq': np.random.randint(0, 390001, 20), 'id': 0}).groupby('id').agg({'sess_pid_seq': list})\n",
    "\n",
    "with grpcclient.InferenceServerClient(\"localhost:8001\") as client:\n",
    "    col_names = ['sess_pid_seq']\n",
    "    inputs = nvt_triton.convert_df_to_triton_input(col_names, payload, grpcclient.InferInput)\n",
    "    response = client.infer(MODEL_NAME_PT, inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
