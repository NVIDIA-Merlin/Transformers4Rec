{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d48f073c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/10/2023 06:22:30 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: True\n",
      "03/10/2023 06:22:31 - WARNING - transformers4rec -   Projecting inputs of NextItemPredictionTask to'448' As weight tying requires the input dimension '192' to be equal to the item-id embedding dimension '448'\n",
      "[INFO|trainer.py:434] 2023-03-10 06:22:31,662 >> Using amp fp16 backend\n",
      "03/10/2023 06:22:31 - INFO - examples.t4rec_paper_experiments.t4r_paper_repro.exp_outputs -   Training, Model and Data parameters {'data_path': '/transformers4rec/examples/t4rec_paper_experiments/t4r_paper_repro/', 'features_schema_path': '/workspace/examples/t4rec_paper_experiments/datasets_configs/ecom_rees46/rees46_schema.pbtxt', 'start_time_window_index': 1, 'final_time_window_index': 2, 'time_window_folder_pad_digits': 4, 'no_incremental_training': False, 'training_time_window_size': 0, 'use_side_information_features': False, 'input_features_aggregation': 'concat', 'model_type': 'xlnet', 'tf_out_activation': 'tanh', 'mlm': True, 'mlm_probability': 0.30000000000000004, 'plm': False, 'plm_probability': 0.25, 'plm_max_span_length': 5, 'plm_mask_input': False, 'plm_permute_all': False, 'rtd': False, 'rtd_sample_from_batch': False, 'rtd_use_batch_interaction': False, 'rtd_discriminator_loss_weight': 50, 'rtd_generator_loss_weight': 1, 'rtd_tied_generator': False, 'd_model': 192, 'n_layer': 3, 'n_head': 16, 'layer_norm_eps': 1e-12, 'initializer_range': 0.02, 'hidden_act': 'gelu', 'dropout': 0.0, 'summary_type': 'last', 'num_hidden_groups': 1, 'inner_group_num': 1, 'eval_on_last_item_seq_only': True, 'train_on_last_item_seq_only': False, 'mf_constrained_embeddings': True, 'item_embedding_dim': 448, 'numeric_features_project_to_embedding_dim': 0, 'numeric_features_soft_one_hot_encoding_num_embeddings': 0, 'stochastic_shared_embeddings_replacement_prob': 0.1, 'softmax_temperature': 1.0, 'label_smoothing': 0.0, 'embedding_dim_from_cardinality_multiplier': 2.0, 'item_id_embeddings_init_std': 0.11, 'other_embeddings_init_std': 0.02, 'layer_norm_featurewise': True, 'attn_type': 'bi', 'input_dropout': 0.1, 'loss_type': 'cross_entropy', 'similarity_type': 'concat_mlp', 'inp_merge': 'mlp', 'learning_rate_warmup_steps': 0, 'avg_session_length': None, 'output_dir': './tmp/', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 128, 'per_device_eval_batch_size': 128, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0006667377132554976, 'weight_decay': 3.910060265627374e-05, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 5.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': -1, 'log_level_replica': -1, 'log_on_each_node': True, 'logging_dir': './tmp/runs/Mar10_06-22-28_7dfa224f788e', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_steps': 0, 'save_total_limit': None, 'save_on_each_node': False, 'no_cuda': False, 'seed': 100, 'fp16': True, 'fp16_opt_level': 'O1', 'fp16_backend': 'auto', 'fp16_full_eval': False, 'local_rank': -1, 'xpu_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': True, 'eval_steps': None, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': None, 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'sharded_ddp': [], 'deepspeed': None, 'label_smoothing_factor': 0.0, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': [], 'ddp_find_unused_parameters': None, 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_token': None, 'gradient_checkpointing': False, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': None, '_n_gpu': 1, 'mp_parameters': '', 'max_sequence_length': 20, 'shuffle_buffer_size': 0, 'data_loader_engine': 'merlin', 'eval_on_test_set': True, 'eval_steps_on_train_set': 20, 'predict_top_k': 0, 'learning_rate_num_cosine_cycles_by_epoch': 1.25, 'log_predictions': False, 'compute_metrics_each_n_steps': 1, 'experiments_group': 'default', 'session_seq_length_max': 20, 'learning_rate_schedule': 'linear_with_warmup', 'validate_every': -1}\n",
      "[INFO|trainer.py:1196] 2023-03-10 06:22:32,106 >> ***** Running training *****\n",
      "[INFO|trainer.py:1197] 2023-03-10 06:22:32,106 >>   Num examples = 86528\n",
      "[INFO|trainer.py:1198] 2023-03-10 06:22:32,106 >>   Num Epochs = 5\n",
      "[INFO|trainer.py:1199] 2023-03-10 06:22:32,106 >>   Instantaneous batch size per device = 128\n",
      "[INFO|trainer.py:1200] 2023-03-10 06:22:32,106 >>   Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "[INFO|trainer.py:1201] 2023-03-10 06:22:32,106 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1202] 2023-03-10 06:22:32,106 >>   Total optimization steps = 3380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DLL 2023-03-10 06:22:31.662852 - PARAMETER data_path : /transformers4rec/examples/t4rec_paper_experiments/t4r_paper_repro/  features_schema_path : /workspace/examples/t4rec_paper_experiments/datasets_configs/ecom_rees46/rees46_schema.pbtxt  start_time_window_index : 1  final_time_window_index : 2  time_window_folder_pad_digits : 4  no_incremental_training : False  training_time_window_size : 0  use_side_information_features : False  input_features_aggregation : concat  model_type : xlnet  tf_out_activation : tanh  mlm : True  mlm_probability : 0.30000000000000004  plm : False  plm_probability : 0.25  plm_max_span_length : 5  plm_mask_input : False  plm_permute_all : False  rtd : False  rtd_sample_from_batch : False  rtd_use_batch_interaction : False  rtd_discriminator_loss_weight : 50  rtd_generator_loss_weight : 1  rtd_tied_generator : False  d_model : 192  n_layer : 3  n_head : 16  layer_norm_eps : 1e-12  initializer_range : 0.02  hidden_act : gelu  dropout : 0.0  summary_type : last  num_hidden_groups : 1  inner_group_num : 1  eval_on_last_item_seq_only : True  train_on_last_item_seq_only : False  mf_constrained_embeddings : True  item_embedding_dim : 448  numeric_features_project_to_embedding_dim : 0  numeric_features_soft_one_hot_encoding_num_embeddings : 0  stochastic_shared_embeddings_replacement_prob : 0.1  softmax_temperature : 1.0  label_smoothing : 0.0  embedding_dim_from_cardinality_multiplier : 2.0  item_id_embeddings_init_std : 0.11  other_embeddings_init_std : 0.02  layer_norm_featurewise : True  attn_type : bi  input_dropout : 0.1  loss_type : cross_entropy  similarity_type : concat_mlp  inp_merge : mlp  learning_rate_warmup_steps : 0  avg_session_length : None  output_dir : ./tmp/  overwrite_output_dir : True  do_train : True  do_eval : True  do_predict : False  prediction_loss_only : False  per_device_train_batch_size : 128  per_device_eval_batch_size : 128  per_gpu_train_batch_size : None  per_gpu_eval_batch_size : None  gradient_accumulation_steps : 1  eval_accumulation_steps : None  learning_rate : 0.0006667377132554976  weight_decay : 3.910060265627374e-05  adam_beta1 : 0.9  adam_beta2 : 0.999  adam_epsilon : 1e-08  max_grad_norm : 1.0  num_train_epochs : 5.0  max_steps : -1  lr_scheduler_type : linear  warmup_ratio : 0.0  warmup_steps : 0  log_level : -1  log_level_replica : -1  log_on_each_node : True  logging_dir : ./tmp/runs/Mar10_06-22-28_7dfa224f788e  logging_first_step : False  logging_steps : 500  logging_nan_inf_filter : True  save_steps : 0  save_total_limit : None  save_on_each_node : False  no_cuda : False  seed : 100  fp16 : True  fp16_opt_level : O1  fp16_backend : auto  fp16_full_eval : False  local_rank : -1  xpu_backend : None  tpu_num_cores : None  tpu_metrics_debug : False  debug : []  dataloader_drop_last : True  eval_steps : None  dataloader_num_workers : 0  past_index : -1  run_name : None  disable_tqdm : False  remove_unused_columns : True  label_names : None  load_best_model_at_end : False  metric_for_best_model : None  greater_is_better : None  ignore_data_skip : False  sharded_ddp : []  deepspeed : None  label_smoothing_factor : 0.0  adafactor : False  group_by_length : False  length_column_name : length  report_to : []  ddp_find_unused_parameters : None  dataloader_pin_memory : True  skip_memory_metrics : True  use_legacy_prediction_loop : False  push_to_hub : False  resume_from_checkpoint : None  hub_model_id : None  hub_token : None  gradient_checkpointing : False  push_to_hub_model_id : None  push_to_hub_organization : None  push_to_hub_token : None  _n_gpu : 1  mp_parameters :   max_sequence_length : 20  shuffle_buffer_size : 0  data_loader_engine : merlin  eval_on_test_set : True  eval_steps_on_train_set : 20  predict_top_k : 0  learning_rate_num_cosine_cycles_by_epoch : 1.25  log_predictions : False  compute_metrics_each_n_steps : 1  experiments_group : default  session_seq_length_max : 20  learning_rate_schedule : linear_with_warmup  validate_every : -1 \n",
      "\n",
      "***** Launch training for day 1: *****\n",
      "{'loss': 10.1481, 'learning_rate': 0.0005681078740165187, 'epoch': 0.74}\n",
      "{'loss': 9.1622, 'learning_rate': 0.00046947803477753974, 'epoch': 1.48}\n",
      "{'loss': 8.8482, 'learning_rate': 0.0003708481955385607, 'epoch': 2.22}\n",
      "{'loss': 8.648, 'learning_rate': 0.0002722183562995818, 'epoch': 2.96}\n",
      "{'loss': 8.4446, 'learning_rate': 0.0001735885170606029, 'epoch': 3.7}\n",
      "{'loss': 8.3279, 'learning_rate': 7.4958677821624e-05, 'epoch': 4.44}\n",
      "{'train_runtime': 267.3924, 'train_samples_per_second': 0.019, 'train_steps_per_second': 12.641, 'train_loss': 8.856075417783838, 'epoch': 5.0}\n",
      "\n",
      "***** Evaluation results for day 2 (train set):*****\n",
      "\n",
      "{'train_/next-item/ndcg_at_10': 0.0946362242102623, 'train_/next-item/ndcg_at_20': 0.11049988120794296, 'train_/next-item/recall_at_10': 0.17226563394069672, 'train_/next-item/recall_at_20': 0.23593750596046448, 'train_/loss': 7.873326301574707, 'train_runtime': 0.6495, 'train_samples_per_second': 3941.348, 'train_steps_per_second': 30.792}\n",
      "\n",
      "***** Evaluation results for day 2 (eval set):*****\n",
      "\n",
      "{'eval_/next-item/ndcg_at_10': 0.08858750760555267, 'eval_/next-item/ndcg_at_20': 0.10536891222000122, 'eval_/next-item/recall_at_10': 0.16274471580982208, 'eval_/next-item/recall_at_20': 0.2292921543121338, 'eval_/loss': 8.278496742248535, 'eval_runtime': 2.2227, 'eval_samples_per_second': 4779.666, 'eval_steps_per_second': 37.341}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-8' coro=<ScriptMagics.shebang.<locals>._handle_stream() done, defined at /usr/local/lib/python3.8/dist-packages/IPython/core/magics/script.py:211> exception=ValueError('Separator is not found, and chunk exceed the limit')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/asyncio/streams.py\", line 540, in readline\n",
      "    line = await self.readuntil(sep)\n",
      "  File \"/usr/lib/python3.8/asyncio/streams.py\", line 618, in readuntil\n",
      "    raise exceptions.LimitOverrunError(\n",
      "asyncio.exceptions.LimitOverrunError: Separator is not found, and chunk exceed the limit\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/magics/script.py\", line 213, in _handle_stream\n",
      "    line = (await stream.readline()).decode(\"utf8\")\n",
      "  File \"/usr/lib/python3.8/asyncio/streams.py\", line 549, in readline\n",
      "    raise ValueError(e.args[0])\n",
      "ValueError: Separator is not found, and chunk exceed the limit\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "FEATURE_SCHEMA_PATH=/workspace/examples/t4rec_paper_experiments/datasets_configs/ecom_rees46/rees46_schema.pbtxt\n",
    "DATA_PATH=/transformers4rec/examples/t4rec_paper_experiments/t4r_paper_repro/\n",
    "NUM_EPOCHS=5\n",
    "\n",
    "python3 ../transf_exp_main_modified.py --output_dir ./tmp/ --overwrite_output_dir --do_train --do_eval --save_steps 0 --data_path $DATA_PATH --features_schema_path $FEATURE_SCHEMA_PATH --fp16 --data_loader_engine merlin --start_time_window_index 1 --final_time_window_index 2 --time_window_folder_pad_digits 4 --model_type xlnet --loss_type cross_entropy --per_device_eval_batch_size 128 --similarity_type concat_mlp --tf_out_activation tanh --inp_merge mlp --learning_rate_warmup_steps 0 --learning_rate_schedule linear_with_warmup --hidden_act gelu --num_train_epochs $NUM_EPOCHS --dataloader_drop_last --compute_metrics_each_n_steps 1 --session_seq_length_max 20 --eval_on_last_item_seq_only --mf_constrained_embeddings --layer_norm_featurewise --attn_type bi --mlm --per_device_train_batch_size 128 --learning_rate 0.0006667377132554976 --dropout 0.0 --input_dropout 0.1 --weight_decay 3.910060265627374e-05 --d_model 192 --item_embedding_dim 448 --n_layer 3 --n_head 16 --label_smoothing 0.0 --stochastic_shared_embeddings_replacement_prob 0.1 --item_id_embeddings_init_std 0.11 --other_embeddings_init_std 0.02 --mlm_probability 0.30000000000000004 --eval_on_test_set --seed 100 --report_to none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2b2ec29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/10/2023 06:27:11 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: True\n",
      "03/10/2023 06:27:12 - WARNING - transformers4rec -   Projecting inputs of NextItemPredictionTask to'448' As weight tying requires the input dimension '192' to be equal to the item-id embedding dimension '448'\n",
      "[INFO|trainer.py:434] 2023-03-10 06:27:12,976 >> Using amp fp16 backend\n",
      "03/10/2023 06:27:12 - INFO - examples.t4rec_paper_experiments.t4r_paper_repro.exp_outputs -   Training, Model and Data parameters {'data_path': '/transformers4rec/examples/t4rec_paper_experiments/t4r_paper_repro/', 'features_schema_path': '/workspace/examples/t4rec_paper_experiments/datasets_configs/ecom_rees46/rees46_schema.pbtxt', 'start_time_window_index': 1, 'final_time_window_index': 2, 'time_window_folder_pad_digits': 4, 'no_incremental_training': False, 'training_time_window_size': 0, 'use_side_information_features': False, 'input_features_aggregation': 'concat', 'model_type': 'xlnet', 'tf_out_activation': 'tanh', 'mlm': True, 'mlm_probability': 0.30000000000000004, 'plm': False, 'plm_probability': 0.25, 'plm_max_span_length': 5, 'plm_mask_input': False, 'plm_permute_all': False, 'rtd': False, 'rtd_sample_from_batch': False, 'rtd_use_batch_interaction': False, 'rtd_discriminator_loss_weight': 50, 'rtd_generator_loss_weight': 1, 'rtd_tied_generator': False, 'd_model': 192, 'n_layer': 3, 'n_head': 16, 'layer_norm_eps': 1e-12, 'initializer_range': 0.02, 'hidden_act': 'gelu', 'dropout': 0.0, 'summary_type': 'last', 'num_hidden_groups': 1, 'inner_group_num': 1, 'eval_on_last_item_seq_only': True, 'train_on_last_item_seq_only': False, 'mf_constrained_embeddings': True, 'item_embedding_dim': 448, 'numeric_features_project_to_embedding_dim': 0, 'numeric_features_soft_one_hot_encoding_num_embeddings': 0, 'stochastic_shared_embeddings_replacement_prob': 0.1, 'softmax_temperature': 1.0, 'label_smoothing': 0.0, 'embedding_dim_from_cardinality_multiplier': 2.0, 'item_id_embeddings_init_std': 0.11, 'other_embeddings_init_std': 0.02, 'layer_norm_featurewise': True, 'attn_type': 'bi', 'input_dropout': 0.1, 'loss_type': 'cross_entropy', 'similarity_type': 'concat_mlp', 'inp_merge': 'mlp', 'learning_rate_warmup_steps': 0, 'avg_session_length': None, 'output_dir': './tmp/', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 128, 'per_device_eval_batch_size': 128, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0006667377132554976, 'weight_decay': 3.910060265627374e-05, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 5.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': -1, 'log_level_replica': -1, 'log_on_each_node': True, 'logging_dir': './tmp/runs/Mar10_06-27-10_7dfa224f788e', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_steps': 0, 'save_total_limit': None, 'save_on_each_node': False, 'no_cuda': False, 'seed': 100, 'fp16': True, 'fp16_opt_level': 'O1', 'fp16_backend': 'auto', 'fp16_full_eval': False, 'local_rank': -1, 'xpu_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': True, 'eval_steps': None, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': None, 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'sharded_ddp': [], 'deepspeed': None, 'label_smoothing_factor': 0.0, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': [], 'ddp_find_unused_parameters': None, 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_token': None, 'gradient_checkpointing': False, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': None, '_n_gpu': 1, 'mp_parameters': '', 'max_sequence_length': 20, 'shuffle_buffer_size': 0, 'data_loader_engine': 'merlin', 'eval_on_test_set': True, 'eval_steps_on_train_set': 20, 'predict_top_k': 0, 'learning_rate_num_cosine_cycles_by_epoch': 1.25, 'log_predictions': False, 'compute_metrics_each_n_steps': 1, 'experiments_group': 'default', 'session_seq_length_max': 20, 'learning_rate_schedule': 'linear_with_warmup', 'validate_every': -1}\n",
      "[INFO|trainer.py:1196] 2023-03-10 06:27:13,448 >> ***** Running training *****\n",
      "[INFO|trainer.py:1197] 2023-03-10 06:27:13,448 >>   Num examples = 86528\n",
      "[INFO|trainer.py:1198] 2023-03-10 06:27:13,448 >>   Num Epochs = 5\n",
      "[INFO|trainer.py:1199] 2023-03-10 06:27:13,448 >>   Instantaneous batch size per device = 128\n",
      "[INFO|trainer.py:1200] 2023-03-10 06:27:13,448 >>   Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "[INFO|trainer.py:1201] 2023-03-10 06:27:13,448 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1202] 2023-03-10 06:27:13,448 >>   Total optimization steps = 3380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DLL 2023-03-10 06:27:12.976882 - PARAMETER data_path : /transformers4rec/examples/t4rec_paper_experiments/t4r_paper_repro/  features_schema_path : /workspace/examples/t4rec_paper_experiments/datasets_configs/ecom_rees46/rees46_schema.pbtxt  start_time_window_index : 1  final_time_window_index : 2  time_window_folder_pad_digits : 4  no_incremental_training : False  training_time_window_size : 0  use_side_information_features : False  input_features_aggregation : concat  model_type : xlnet  tf_out_activation : tanh  mlm : True  mlm_probability : 0.30000000000000004  plm : False  plm_probability : 0.25  plm_max_span_length : 5  plm_mask_input : False  plm_permute_all : False  rtd : False  rtd_sample_from_batch : False  rtd_use_batch_interaction : False  rtd_discriminator_loss_weight : 50  rtd_generator_loss_weight : 1  rtd_tied_generator : False  d_model : 192  n_layer : 3  n_head : 16  layer_norm_eps : 1e-12  initializer_range : 0.02  hidden_act : gelu  dropout : 0.0  summary_type : last  num_hidden_groups : 1  inner_group_num : 1  eval_on_last_item_seq_only : True  train_on_last_item_seq_only : False  mf_constrained_embeddings : True  item_embedding_dim : 448  numeric_features_project_to_embedding_dim : 0  numeric_features_soft_one_hot_encoding_num_embeddings : 0  stochastic_shared_embeddings_replacement_prob : 0.1  softmax_temperature : 1.0  label_smoothing : 0.0  embedding_dim_from_cardinality_multiplier : 2.0  item_id_embeddings_init_std : 0.11  other_embeddings_init_std : 0.02  layer_norm_featurewise : True  attn_type : bi  input_dropout : 0.1  loss_type : cross_entropy  similarity_type : concat_mlp  inp_merge : mlp  learning_rate_warmup_steps : 0  avg_session_length : None  output_dir : ./tmp/  overwrite_output_dir : True  do_train : True  do_eval : True  do_predict : False  prediction_loss_only : False  per_device_train_batch_size : 128  per_device_eval_batch_size : 128  per_gpu_train_batch_size : None  per_gpu_eval_batch_size : None  gradient_accumulation_steps : 1  eval_accumulation_steps : None  learning_rate : 0.0006667377132554976  weight_decay : 3.910060265627374e-05  adam_beta1 : 0.9  adam_beta2 : 0.999  adam_epsilon : 1e-08  max_grad_norm : 1.0  num_train_epochs : 5.0  max_steps : -1  lr_scheduler_type : linear  warmup_ratio : 0.0  warmup_steps : 0  log_level : -1  log_level_replica : -1  log_on_each_node : True  logging_dir : ./tmp/runs/Mar10_06-27-10_7dfa224f788e  logging_first_step : False  logging_steps : 500  logging_nan_inf_filter : True  save_steps : 0  save_total_limit : None  save_on_each_node : False  no_cuda : False  seed : 100  fp16 : True  fp16_opt_level : O1  fp16_backend : auto  fp16_full_eval : False  local_rank : -1  xpu_backend : None  tpu_num_cores : None  tpu_metrics_debug : False  debug : []  dataloader_drop_last : True  eval_steps : None  dataloader_num_workers : 0  past_index : -1  run_name : None  disable_tqdm : False  remove_unused_columns : True  label_names : None  load_best_model_at_end : False  metric_for_best_model : None  greater_is_better : None  ignore_data_skip : False  sharded_ddp : []  deepspeed : None  label_smoothing_factor : 0.0  adafactor : False  group_by_length : False  length_column_name : length  report_to : []  ddp_find_unused_parameters : None  dataloader_pin_memory : True  skip_memory_metrics : True  use_legacy_prediction_loop : False  push_to_hub : False  resume_from_checkpoint : None  hub_model_id : None  hub_token : None  gradient_checkpointing : False  push_to_hub_model_id : None  push_to_hub_organization : None  push_to_hub_token : None  _n_gpu : 1  mp_parameters :   max_sequence_length : 20  shuffle_buffer_size : 0  data_loader_engine : merlin  eval_on_test_set : True  eval_steps_on_train_set : 20  predict_top_k : 0  learning_rate_num_cosine_cycles_by_epoch : 1.25  log_predictions : False  compute_metrics_each_n_steps : 1  experiments_group : default  session_seq_length_max : 20  learning_rate_schedule : linear_with_warmup  validate_every : -1 \n",
      "\n",
      "***** Launch training for day 1: *****\n",
      "{'loss': 10.1707, 'learning_rate': 0.0005683051336949965, 'epoch': 0.74}\n",
      "{'loss': 9.1904, 'learning_rate': 0.0004696752944560177, 'epoch': 1.48}\n",
      "{'loss': 8.9014, 'learning_rate': 0.0003710454552170388, 'epoch': 2.22}\n",
      "{'loss': 8.7112, 'learning_rate': 0.0002724156159780598, 'epoch': 2.96}\n",
      "{'loss': 8.5372, 'learning_rate': 0.00017378577673908085, 'epoch': 3.7}\n",
      "{'loss': 8.4297, 'learning_rate': 7.515593750010194e-05, 'epoch': 4.44}\n",
      "{'train_runtime': 268.1719, 'train_samples_per_second': 0.019, 'train_steps_per_second': 12.604, 'train_loss': 8.918887816660503, 'epoch': 5.0}\n",
      "\n",
      "***** Evaluation results for day 2 (train set):*****\n",
      "\n",
      "{'train_/next-item/ndcg_at_10': 0.08740683645009995, 'train_/next-item/ndcg_at_20': 0.10400686413049698, 'train_/next-item/recall_at_10': 0.15468750894069672, 'train_/next-item/recall_at_20': 0.220703125, 'train_/loss': 7.998610019683838, 'train_runtime': 0.6448, 'train_samples_per_second': 3970.378, 'train_steps_per_second': 31.019}\n",
      "\n",
      "***** Evaluation results for day 2 (eval set):*****\n",
      "\n",
      "{'eval_/next-item/ndcg_at_10': 0.08547135442495346, 'eval_/next-item/ndcg_at_20': 0.10144450515508652, 'eval_/next-item/recall_at_10': 0.1554969847202301, 'eval_/next-item/recall_at_20': 0.21865586936473846, 'eval_/loss': 8.368797302246094, 'eval_runtime': 2.2149, 'eval_samples_per_second': 4796.548, 'eval_steps_per_second': 37.473}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-13' coro=<ScriptMagics.shebang.<locals>._handle_stream() done, defined at /usr/local/lib/python3.8/dist-packages/IPython/core/magics/script.py:211> exception=ValueError('Separator is not found, and chunk exceed the limit')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/asyncio/streams.py\", line 540, in readline\n",
      "    line = await self.readuntil(sep)\n",
      "  File \"/usr/lib/python3.8/asyncio/streams.py\", line 618, in readuntil\n",
      "    raise exceptions.LimitOverrunError(\n",
      "asyncio.exceptions.LimitOverrunError: Separator is not found, and chunk exceed the limit\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/magics/script.py\", line 213, in _handle_stream\n",
      "    line = (await stream.readline()).decode(\"utf8\")\n",
      "  File \"/usr/lib/python3.8/asyncio/streams.py\", line 549, in readline\n",
      "    raise ValueError(e.args[0])\n",
      "ValueError: Separator is not found, and chunk exceed the limit\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "FEATURE_SCHEMA_PATH=/workspace/examples/t4rec_paper_experiments/datasets_configs/ecom_rees46/rees46_schema.pbtxt\n",
    "DATA_PATH=/transformers4rec/examples/t4rec_paper_experiments/t4r_paper_repro/\n",
    "NUM_EPOCHS=5\n",
    "\n",
    "python3 ../transf_exp_main_modified.py --output_dir ./tmp/ --overwrite_output_dir --do_train --do_eval --save_steps 0 --data_path $DATA_PATH --features_schema_path $FEATURE_SCHEMA_PATH --fp16 --data_loader_engine merlin --start_time_window_index 1 --final_time_window_index 2 --time_window_folder_pad_digits 4 --model_type xlnet --loss_type cross_entropy --per_device_eval_batch_size 128 --similarity_type concat_mlp --tf_out_activation tanh --inp_merge mlp --learning_rate_warmup_steps 0 --learning_rate_schedule linear_with_warmup --hidden_act gelu --num_train_epochs $NUM_EPOCHS --dataloader_drop_last --compute_metrics_each_n_steps 1 --session_seq_length_max 20 --eval_on_last_item_seq_only --mf_constrained_embeddings --layer_norm_featurewise --attn_type bi --mlm --per_device_train_batch_size 128 --learning_rate 0.0006667377132554976 --dropout 0.0 --input_dropout 0.1 --weight_decay 3.910060265627374e-05 --d_model 192 --item_embedding_dim 448 --n_layer 3 --n_head 16 --label_smoothing 0.0 --stochastic_shared_embeddings_replacement_prob 0.1 --item_id_embeddings_init_std 0.11 --other_embeddings_init_std 0.02 --mlm_probability 0.30000000000000004 --eval_on_test_set --seed 100 --report_to none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ba3e539",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/10/2023 06:31:53 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: True\n",
      "03/10/2023 06:31:54 - WARNING - transformers4rec -   Projecting inputs of NextItemPredictionTask to'448' As weight tying requires the input dimension '192' to be equal to the item-id embedding dimension '448'\n",
      "[INFO|trainer.py:434] 2023-03-10 06:31:54,883 >> Using amp fp16 backend\n",
      "03/10/2023 06:31:54 - INFO - examples.t4rec_paper_experiments.t4r_paper_repro.exp_outputs -   Training, Model and Data parameters {'data_path': '/transformers4rec/examples/t4rec_paper_experiments/t4r_paper_repro/', 'features_schema_path': '/workspace/examples/t4rec_paper_experiments/datasets_configs/ecom_rees46/rees46_schema.pbtxt', 'start_time_window_index': 1, 'final_time_window_index': 2, 'time_window_folder_pad_digits': 4, 'no_incremental_training': False, 'training_time_window_size': 0, 'use_side_information_features': False, 'input_features_aggregation': 'concat', 'model_type': 'xlnet', 'tf_out_activation': 'tanh', 'mlm': True, 'mlm_probability': 0.30000000000000004, 'plm': False, 'plm_probability': 0.25, 'plm_max_span_length': 5, 'plm_mask_input': False, 'plm_permute_all': False, 'rtd': False, 'rtd_sample_from_batch': False, 'rtd_use_batch_interaction': False, 'rtd_discriminator_loss_weight': 50, 'rtd_generator_loss_weight': 1, 'rtd_tied_generator': False, 'd_model': 192, 'n_layer': 3, 'n_head': 16, 'layer_norm_eps': 1e-12, 'initializer_range': 0.02, 'hidden_act': 'gelu', 'dropout': 0.0, 'summary_type': 'last', 'num_hidden_groups': 1, 'inner_group_num': 1, 'eval_on_last_item_seq_only': True, 'train_on_last_item_seq_only': False, 'mf_constrained_embeddings': True, 'item_embedding_dim': 448, 'numeric_features_project_to_embedding_dim': 0, 'numeric_features_soft_one_hot_encoding_num_embeddings': 0, 'stochastic_shared_embeddings_replacement_prob': 0.1, 'softmax_temperature': 1.0, 'label_smoothing': 0.0, 'embedding_dim_from_cardinality_multiplier': 2.0, 'item_id_embeddings_init_std': 0.11, 'other_embeddings_init_std': 0.02, 'layer_norm_featurewise': True, 'attn_type': 'bi', 'input_dropout': 0.1, 'loss_type': 'cross_entropy', 'similarity_type': 'concat_mlp', 'inp_merge': 'mlp', 'learning_rate_warmup_steps': 0, 'avg_session_length': None, 'output_dir': './tmp/', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 128, 'per_device_eval_batch_size': 128, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0006667377132554976, 'weight_decay': 3.910060265627374e-05, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 5.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': -1, 'log_level_replica': -1, 'log_on_each_node': True, 'logging_dir': './tmp/runs/Mar10_06-31-52_7dfa224f788e', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_steps': 0, 'save_total_limit': None, 'save_on_each_node': False, 'no_cuda': False, 'seed': 0, 'fp16': True, 'fp16_opt_level': 'O1', 'fp16_backend': 'auto', 'fp16_full_eval': False, 'local_rank': -1, 'xpu_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': True, 'eval_steps': None, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': None, 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'sharded_ddp': [], 'deepspeed': None, 'label_smoothing_factor': 0.0, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': [], 'ddp_find_unused_parameters': None, 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_token': None, 'gradient_checkpointing': False, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': None, '_n_gpu': 1, 'mp_parameters': '', 'max_sequence_length': 20, 'shuffle_buffer_size': 0, 'data_loader_engine': 'merlin', 'eval_on_test_set': True, 'eval_steps_on_train_set': 20, 'predict_top_k': 0, 'learning_rate_num_cosine_cycles_by_epoch': 1.25, 'log_predictions': False, 'compute_metrics_each_n_steps': 1, 'experiments_group': 'default', 'session_seq_length_max': 20, 'learning_rate_schedule': 'linear_with_warmup', 'validate_every': -1}\n",
      "[INFO|trainer.py:1196] 2023-03-10 06:31:55,376 >> ***** Running training *****\n",
      "[INFO|trainer.py:1197] 2023-03-10 06:31:55,376 >>   Num examples = 86528\n",
      "[INFO|trainer.py:1198] 2023-03-10 06:31:55,376 >>   Num Epochs = 5\n",
      "[INFO|trainer.py:1199] 2023-03-10 06:31:55,376 >>   Instantaneous batch size per device = 128\n",
      "[INFO|trainer.py:1200] 2023-03-10 06:31:55,376 >>   Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "[INFO|trainer.py:1201] 2023-03-10 06:31:55,376 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1202] 2023-03-10 06:31:55,376 >>   Total optimization steps = 3380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DLL 2023-03-10 06:31:54.884501 - PARAMETER data_path : /transformers4rec/examples/t4rec_paper_experiments/t4r_paper_repro/  features_schema_path : /workspace/examples/t4rec_paper_experiments/datasets_configs/ecom_rees46/rees46_schema.pbtxt  start_time_window_index : 1  final_time_window_index : 2  time_window_folder_pad_digits : 4  no_incremental_training : False  training_time_window_size : 0  use_side_information_features : False  input_features_aggregation : concat  model_type : xlnet  tf_out_activation : tanh  mlm : True  mlm_probability : 0.30000000000000004  plm : False  plm_probability : 0.25  plm_max_span_length : 5  plm_mask_input : False  plm_permute_all : False  rtd : False  rtd_sample_from_batch : False  rtd_use_batch_interaction : False  rtd_discriminator_loss_weight : 50  rtd_generator_loss_weight : 1  rtd_tied_generator : False  d_model : 192  n_layer : 3  n_head : 16  layer_norm_eps : 1e-12  initializer_range : 0.02  hidden_act : gelu  dropout : 0.0  summary_type : last  num_hidden_groups : 1  inner_group_num : 1  eval_on_last_item_seq_only : True  train_on_last_item_seq_only : False  mf_constrained_embeddings : True  item_embedding_dim : 448  numeric_features_project_to_embedding_dim : 0  numeric_features_soft_one_hot_encoding_num_embeddings : 0  stochastic_shared_embeddings_replacement_prob : 0.1  softmax_temperature : 1.0  label_smoothing : 0.0  embedding_dim_from_cardinality_multiplier : 2.0  item_id_embeddings_init_std : 0.11  other_embeddings_init_std : 0.02  layer_norm_featurewise : True  attn_type : bi  input_dropout : 0.1  loss_type : cross_entropy  similarity_type : concat_mlp  inp_merge : mlp  learning_rate_warmup_steps : 0  avg_session_length : None  output_dir : ./tmp/  overwrite_output_dir : True  do_train : True  do_eval : True  do_predict : False  prediction_loss_only : False  per_device_train_batch_size : 128  per_device_eval_batch_size : 128  per_gpu_train_batch_size : None  per_gpu_eval_batch_size : None  gradient_accumulation_steps : 1  eval_accumulation_steps : None  learning_rate : 0.0006667377132554976  weight_decay : 3.910060265627374e-05  adam_beta1 : 0.9  adam_beta2 : 0.999  adam_epsilon : 1e-08  max_grad_norm : 1.0  num_train_epochs : 5.0  max_steps : -1  lr_scheduler_type : linear  warmup_ratio : 0.0  warmup_steps : 0  log_level : -1  log_level_replica : -1  log_on_each_node : True  logging_dir : ./tmp/runs/Mar10_06-31-52_7dfa224f788e  logging_first_step : False  logging_steps : 500  logging_nan_inf_filter : True  save_steps : 0  save_total_limit : None  save_on_each_node : False  no_cuda : False  seed : 0  fp16 : True  fp16_opt_level : O1  fp16_backend : auto  fp16_full_eval : False  local_rank : -1  xpu_backend : None  tpu_num_cores : None  tpu_metrics_debug : False  debug : []  dataloader_drop_last : True  eval_steps : None  dataloader_num_workers : 0  past_index : -1  run_name : None  disable_tqdm : False  remove_unused_columns : True  label_names : None  load_best_model_at_end : False  metric_for_best_model : None  greater_is_better : None  ignore_data_skip : False  sharded_ddp : []  deepspeed : None  label_smoothing_factor : 0.0  adafactor : False  group_by_length : False  length_column_name : length  report_to : []  ddp_find_unused_parameters : None  dataloader_pin_memory : True  skip_memory_metrics : True  use_legacy_prediction_loop : False  push_to_hub : False  resume_from_checkpoint : None  hub_model_id : None  hub_token : None  gradient_checkpointing : False  push_to_hub_model_id : None  push_to_hub_organization : None  push_to_hub_token : None  _n_gpu : 1  mp_parameters :   max_sequence_length : 20  shuffle_buffer_size : 0  data_loader_engine : merlin  eval_on_test_set : True  eval_steps_on_train_set : 20  predict_top_k : 0  learning_rate_num_cosine_cycles_by_epoch : 1.25  log_predictions : False  compute_metrics_each_n_steps : 1  experiments_group : default  session_seq_length_max : 20  learning_rate_schedule : linear_with_warmup  validate_every : -1 \n",
      "\n",
      "***** Launch training for day 1: *****\n",
      "{'loss': 10.1421, 'learning_rate': 0.0005681078740165187, 'epoch': 0.74}\n",
      "{'loss': 9.1819, 'learning_rate': 0.00046947803477753974, 'epoch': 1.48}\n",
      "{'loss': 8.9005, 'learning_rate': 0.0003708481955385607, 'epoch': 2.22}\n",
      "{'loss': 8.6487, 'learning_rate': 0.0002722183562995818, 'epoch': 2.96}\n",
      "{'loss': 8.4605, 'learning_rate': 0.0001735885170606029, 'epoch': 3.7}\n",
      "{'loss': 8.2935, 'learning_rate': 7.4958677821624e-05, 'epoch': 4.44}\n",
      "{'train_runtime': 268.4247, 'train_samples_per_second': 0.019, 'train_steps_per_second': 12.592, 'train_loss': 8.861479521079882, 'epoch': 5.0}\n",
      "\n",
      "***** Evaluation results for day 2 (train set):*****\n",
      "\n",
      "{'train_/next-item/ndcg_at_10': 0.09560234844684601, 'train_/next-item/ndcg_at_20': 0.1121138259768486, 'train_/next-item/recall_at_10': 0.17148438096046448, 'train_/next-item/recall_at_20': 0.23710937798023224, 'train_/loss': 7.855612754821777, 'train_runtime': 0.6468, 'train_samples_per_second': 3957.894, 'train_steps_per_second': 30.921}\n",
      "\n",
      "***** Evaluation results for day 2 (eval set):*****\n",
      "\n",
      "{'eval_/next-item/ndcg_at_10': 0.09119625389575958, 'eval_/next-item/ndcg_at_20': 0.10950089246034622, 'eval_/next-item/recall_at_10': 0.1640625, 'eval_/next-item/recall_at_20': 0.23644576966762543, 'eval_/loss': 8.2479248046875, 'eval_runtime': 2.2235, 'eval_samples_per_second': 4778.131, 'eval_steps_per_second': 37.329}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-18' coro=<ScriptMagics.shebang.<locals>._handle_stream() done, defined at /usr/local/lib/python3.8/dist-packages/IPython/core/magics/script.py:211> exception=ValueError('Separator is not found, and chunk exceed the limit')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/asyncio/streams.py\", line 540, in readline\n",
      "    line = await self.readuntil(sep)\n",
      "  File \"/usr/lib/python3.8/asyncio/streams.py\", line 618, in readuntil\n",
      "    raise exceptions.LimitOverrunError(\n",
      "asyncio.exceptions.LimitOverrunError: Separator is not found, and chunk exceed the limit\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/magics/script.py\", line 213, in _handle_stream\n",
      "    line = (await stream.readline()).decode(\"utf8\")\n",
      "  File \"/usr/lib/python3.8/asyncio/streams.py\", line 549, in readline\n",
      "    raise ValueError(e.args[0])\n",
      "ValueError: Separator is not found, and chunk exceed the limit\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "FEATURE_SCHEMA_PATH=/workspace/examples/t4rec_paper_experiments/datasets_configs/ecom_rees46/rees46_schema.pbtxt\n",
    "DATA_PATH=/transformers4rec/examples/t4rec_paper_experiments/t4r_paper_repro/\n",
    "NUM_EPOCHS=5\n",
    "SEED=0\n",
    "\n",
    "python3 ../transf_exp_main_modified.py --output_dir ./tmp/ --overwrite_output_dir --do_train --do_eval --save_steps 0 --data_path $DATA_PATH --features_schema_path $FEATURE_SCHEMA_PATH --fp16 --data_loader_engine merlin --start_time_window_index 1 --final_time_window_index 2 --time_window_folder_pad_digits 4 --model_type xlnet --loss_type cross_entropy --per_device_eval_batch_size 128 --similarity_type concat_mlp --tf_out_activation tanh --inp_merge mlp --learning_rate_warmup_steps 0 --learning_rate_schedule linear_with_warmup --hidden_act gelu --num_train_epochs $NUM_EPOCHS --dataloader_drop_last --compute_metrics_each_n_steps 1 --session_seq_length_max 20 --eval_on_last_item_seq_only --mf_constrained_embeddings --layer_norm_featurewise --attn_type bi --mlm --per_device_train_batch_size 128 --learning_rate 0.0006667377132554976 --dropout 0.0 --input_dropout 0.1 --weight_decay 3.910060265627374e-05 --d_model 192 --item_embedding_dim 448 --n_layer 3 --n_head 16 --label_smoothing 0.0 --stochastic_shared_embeddings_replacement_prob 0.1 --item_id_embeddings_init_std 0.11 --other_embeddings_init_std 0.02 --mlm_probability 0.30000000000000004 --eval_on_test_set --seed $SEED --report_to none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39c50e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/10/2023 06:36:35 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: True\n",
      "03/10/2023 06:36:37 - WARNING - transformers4rec -   Projecting inputs of NextItemPredictionTask to'448' As weight tying requires the input dimension '192' to be equal to the item-id embedding dimension '448'\n",
      "[INFO|trainer.py:434] 2023-03-10 06:36:37,141 >> Using amp fp16 backend\n",
      "03/10/2023 06:36:37 - INFO - examples.t4rec_paper_experiments.t4r_paper_repro.exp_outputs -   Training, Model and Data parameters {'data_path': '/transformers4rec/examples/t4rec_paper_experiments/t4r_paper_repro/', 'features_schema_path': '/workspace/examples/t4rec_paper_experiments/datasets_configs/ecom_rees46/rees46_schema.pbtxt', 'start_time_window_index': 1, 'final_time_window_index': 2, 'time_window_folder_pad_digits': 4, 'no_incremental_training': False, 'training_time_window_size': 0, 'use_side_information_features': False, 'input_features_aggregation': 'concat', 'model_type': 'xlnet', 'tf_out_activation': 'tanh', 'mlm': True, 'mlm_probability': 0.30000000000000004, 'plm': False, 'plm_probability': 0.25, 'plm_max_span_length': 5, 'plm_mask_input': False, 'plm_permute_all': False, 'rtd': False, 'rtd_sample_from_batch': False, 'rtd_use_batch_interaction': False, 'rtd_discriminator_loss_weight': 50, 'rtd_generator_loss_weight': 1, 'rtd_tied_generator': False, 'd_model': 192, 'n_layer': 3, 'n_head': 16, 'layer_norm_eps': 1e-12, 'initializer_range': 0.02, 'hidden_act': 'gelu', 'dropout': 0.0, 'summary_type': 'last', 'num_hidden_groups': 1, 'inner_group_num': 1, 'eval_on_last_item_seq_only': True, 'train_on_last_item_seq_only': False, 'mf_constrained_embeddings': True, 'item_embedding_dim': 448, 'numeric_features_project_to_embedding_dim': 0, 'numeric_features_soft_one_hot_encoding_num_embeddings': 0, 'stochastic_shared_embeddings_replacement_prob': 0.1, 'softmax_temperature': 1.0, 'label_smoothing': 0.0, 'embedding_dim_from_cardinality_multiplier': 2.0, 'item_id_embeddings_init_std': 0.11, 'other_embeddings_init_std': 0.02, 'layer_norm_featurewise': True, 'attn_type': 'bi', 'input_dropout': 0.1, 'loss_type': 'cross_entropy', 'similarity_type': 'concat_mlp', 'inp_merge': 'mlp', 'learning_rate_warmup_steps': 0, 'avg_session_length': None, 'output_dir': './tmp/', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 128, 'per_device_eval_batch_size': 128, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0006667377132554976, 'weight_decay': 3.910060265627374e-05, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 5.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': -1, 'log_level_replica': -1, 'log_on_each_node': True, 'logging_dir': './tmp/runs/Mar10_06-36-34_7dfa224f788e', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_steps': 0, 'save_total_limit': None, 'save_on_each_node': False, 'no_cuda': False, 'seed': 1, 'fp16': True, 'fp16_opt_level': 'O1', 'fp16_backend': 'auto', 'fp16_full_eval': False, 'local_rank': -1, 'xpu_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': True, 'eval_steps': None, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': None, 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'sharded_ddp': [], 'deepspeed': None, 'label_smoothing_factor': 0.0, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': [], 'ddp_find_unused_parameters': None, 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_token': None, 'gradient_checkpointing': False, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': None, '_n_gpu': 1, 'mp_parameters': '', 'max_sequence_length': 20, 'shuffle_buffer_size': 0, 'data_loader_engine': 'merlin', 'eval_on_test_set': True, 'eval_steps_on_train_set': 20, 'predict_top_k': 0, 'learning_rate_num_cosine_cycles_by_epoch': 1.25, 'log_predictions': False, 'compute_metrics_each_n_steps': 1, 'experiments_group': 'default', 'session_seq_length_max': 20, 'learning_rate_schedule': 'linear_with_warmup', 'validate_every': -1}\n",
      "[INFO|trainer.py:1196] 2023-03-10 06:36:37,612 >> ***** Running training *****\n",
      "[INFO|trainer.py:1197] 2023-03-10 06:36:37,612 >>   Num examples = 86528\n",
      "[INFO|trainer.py:1198] 2023-03-10 06:36:37,612 >>   Num Epochs = 5\n",
      "[INFO|trainer.py:1199] 2023-03-10 06:36:37,612 >>   Instantaneous batch size per device = 128\n",
      "[INFO|trainer.py:1200] 2023-03-10 06:36:37,612 >>   Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "[INFO|trainer.py:1201] 2023-03-10 06:36:37,612 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1202] 2023-03-10 06:36:37,612 >>   Total optimization steps = 3380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DLL 2023-03-10 06:36:37.142319 - PARAMETER data_path : /transformers4rec/examples/t4rec_paper_experiments/t4r_paper_repro/  features_schema_path : /workspace/examples/t4rec_paper_experiments/datasets_configs/ecom_rees46/rees46_schema.pbtxt  start_time_window_index : 1  final_time_window_index : 2  time_window_folder_pad_digits : 4  no_incremental_training : False  training_time_window_size : 0  use_side_information_features : False  input_features_aggregation : concat  model_type : xlnet  tf_out_activation : tanh  mlm : True  mlm_probability : 0.30000000000000004  plm : False  plm_probability : 0.25  plm_max_span_length : 5  plm_mask_input : False  plm_permute_all : False  rtd : False  rtd_sample_from_batch : False  rtd_use_batch_interaction : False  rtd_discriminator_loss_weight : 50  rtd_generator_loss_weight : 1  rtd_tied_generator : False  d_model : 192  n_layer : 3  n_head : 16  layer_norm_eps : 1e-12  initializer_range : 0.02  hidden_act : gelu  dropout : 0.0  summary_type : last  num_hidden_groups : 1  inner_group_num : 1  eval_on_last_item_seq_only : True  train_on_last_item_seq_only : False  mf_constrained_embeddings : True  item_embedding_dim : 448  numeric_features_project_to_embedding_dim : 0  numeric_features_soft_one_hot_encoding_num_embeddings : 0  stochastic_shared_embeddings_replacement_prob : 0.1  softmax_temperature : 1.0  label_smoothing : 0.0  embedding_dim_from_cardinality_multiplier : 2.0  item_id_embeddings_init_std : 0.11  other_embeddings_init_std : 0.02  layer_norm_featurewise : True  attn_type : bi  input_dropout : 0.1  loss_type : cross_entropy  similarity_type : concat_mlp  inp_merge : mlp  learning_rate_warmup_steps : 0  avg_session_length : None  output_dir : ./tmp/  overwrite_output_dir : True  do_train : True  do_eval : True  do_predict : False  prediction_loss_only : False  per_device_train_batch_size : 128  per_device_eval_batch_size : 128  per_gpu_train_batch_size : None  per_gpu_eval_batch_size : None  gradient_accumulation_steps : 1  eval_accumulation_steps : None  learning_rate : 0.0006667377132554976  weight_decay : 3.910060265627374e-05  adam_beta1 : 0.9  adam_beta2 : 0.999  adam_epsilon : 1e-08  max_grad_norm : 1.0  num_train_epochs : 5.0  max_steps : -1  lr_scheduler_type : linear  warmup_ratio : 0.0  warmup_steps : 0  log_level : -1  log_level_replica : -1  log_on_each_node : True  logging_dir : ./tmp/runs/Mar10_06-36-34_7dfa224f788e  logging_first_step : False  logging_steps : 500  logging_nan_inf_filter : True  save_steps : 0  save_total_limit : None  save_on_each_node : False  no_cuda : False  seed : 1  fp16 : True  fp16_opt_level : O1  fp16_backend : auto  fp16_full_eval : False  local_rank : -1  xpu_backend : None  tpu_num_cores : None  tpu_metrics_debug : False  debug : []  dataloader_drop_last : True  eval_steps : None  dataloader_num_workers : 0  past_index : -1  run_name : None  disable_tqdm : False  remove_unused_columns : True  label_names : None  load_best_model_at_end : False  metric_for_best_model : None  greater_is_better : None  ignore_data_skip : False  sharded_ddp : []  deepspeed : None  label_smoothing_factor : 0.0  adafactor : False  group_by_length : False  length_column_name : length  report_to : []  ddp_find_unused_parameters : None  dataloader_pin_memory : True  skip_memory_metrics : True  use_legacy_prediction_loop : False  push_to_hub : False  resume_from_checkpoint : None  hub_model_id : None  hub_token : None  gradient_checkpointing : False  push_to_hub_model_id : None  push_to_hub_organization : None  push_to_hub_token : None  _n_gpu : 1  mp_parameters :   max_sequence_length : 20  shuffle_buffer_size : 0  data_loader_engine : merlin  eval_on_test_set : True  eval_steps_on_train_set : 20  predict_top_k : 0  learning_rate_num_cosine_cycles_by_epoch : 1.25  log_predictions : False  compute_metrics_each_n_steps : 1  experiments_group : default  session_seq_length_max : 20  learning_rate_schedule : linear_with_warmup  validate_every : -1 \n",
      "\n",
      "***** Launch training for day 1: *****\n",
      "{'loss': 10.1835, 'learning_rate': 0.0005681078740165187, 'epoch': 0.74}\n",
      "{'loss': 9.1997, 'learning_rate': 0.00046947803477753974, 'epoch': 1.48}\n",
      "{'loss': 8.8927, 'learning_rate': 0.0003708481955385607, 'epoch': 2.22}\n",
      "{'loss': 8.6939, 'learning_rate': 0.0002722183562995818, 'epoch': 2.96}\n",
      "{'loss': 8.4857, 'learning_rate': 0.0001735885170606029, 'epoch': 3.7}\n",
      "{'loss': 8.4036, 'learning_rate': 7.4958677821624e-05, 'epoch': 4.44}\n",
      "{'train_runtime': 268.0277, 'train_samples_per_second': 0.019, 'train_steps_per_second': 12.611, 'train_loss': 8.904246891179733, 'epoch': 5.0}\n",
      "\n",
      "***** Evaluation results for day 2 (train set):*****\n",
      "\n",
      "{'train_/next-item/ndcg_at_10': 0.08619051426649094, 'train_/next-item/ndcg_at_20': 0.10135936737060547, 'train_/next-item/recall_at_10': 0.16093750298023224, 'train_/next-item/recall_at_20': 0.22109375894069672, 'train_/loss': 7.952397346496582, 'train_runtime': 0.6468, 'train_samples_per_second': 3958.17, 'train_steps_per_second': 30.923}\n",
      "\n",
      "***** Evaluation results for day 2 (eval set):*****\n",
      "\n",
      "{'eval_/next-item/ndcg_at_10': 0.08869394659996033, 'eval_/next-item/ndcg_at_20': 0.10502538084983826, 'eval_/next-item/recall_at_10': 0.16217996180057526, 'eval_/next-item/recall_at_20': 0.22693899273872375, 'eval_/loss': 8.337870597839355, 'eval_runtime': 2.2357, 'eval_samples_per_second': 4751.905, 'eval_steps_per_second': 37.124}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-23' coro=<ScriptMagics.shebang.<locals>._handle_stream() done, defined at /usr/local/lib/python3.8/dist-packages/IPython/core/magics/script.py:211> exception=ValueError('Separator is not found, and chunk exceed the limit')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/asyncio/streams.py\", line 540, in readline\n",
      "    line = await self.readuntil(sep)\n",
      "  File \"/usr/lib/python3.8/asyncio/streams.py\", line 618, in readuntil\n",
      "    raise exceptions.LimitOverrunError(\n",
      "asyncio.exceptions.LimitOverrunError: Separator is not found, and chunk exceed the limit\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/magics/script.py\", line 213, in _handle_stream\n",
      "    line = (await stream.readline()).decode(\"utf8\")\n",
      "  File \"/usr/lib/python3.8/asyncio/streams.py\", line 549, in readline\n",
      "    raise ValueError(e.args[0])\n",
      "ValueError: Separator is not found, and chunk exceed the limit\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "FEATURE_SCHEMA_PATH=/workspace/examples/t4rec_paper_experiments/datasets_configs/ecom_rees46/rees46_schema.pbtxt\n",
    "DATA_PATH=/transformers4rec/examples/t4rec_paper_experiments/t4r_paper_repro/\n",
    "NUM_EPOCHS=5\n",
    "SEED=1\n",
    "\n",
    "python3 ../transf_exp_main_modified.py --output_dir ./tmp/ --overwrite_output_dir --do_train --do_eval --save_steps 0 --data_path $DATA_PATH --features_schema_path $FEATURE_SCHEMA_PATH --fp16 --data_loader_engine merlin --start_time_window_index 1 --final_time_window_index 2 --time_window_folder_pad_digits 4 --model_type xlnet --loss_type cross_entropy --per_device_eval_batch_size 128 --similarity_type concat_mlp --tf_out_activation tanh --inp_merge mlp --learning_rate_warmup_steps 0 --learning_rate_schedule linear_with_warmup --hidden_act gelu --num_train_epochs $NUM_EPOCHS --dataloader_drop_last --compute_metrics_each_n_steps 1 --session_seq_length_max 20 --eval_on_last_item_seq_only --mf_constrained_embeddings --layer_norm_featurewise --attn_type bi --mlm --per_device_train_batch_size 128 --learning_rate 0.0006667377132554976 --dropout 0.0 --input_dropout 0.1 --weight_decay 3.910060265627374e-05 --d_model 192 --item_embedding_dim 448 --n_layer 3 --n_head 16 --label_smoothing 0.0 --stochastic_shared_embeddings_replacement_prob 0.1 --item_id_embeddings_init_std 0.11 --other_embeddings_init_std 0.02 --mlm_probability 0.30000000000000004 --eval_on_test_set --seed $SEED --report_to none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7012acaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/10/2023 06:41:17 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: True\n",
      "03/10/2023 06:41:18 - WARNING - transformers4rec -   Projecting inputs of NextItemPredictionTask to'448' As weight tying requires the input dimension '192' to be equal to the item-id embedding dimension '448'\n",
      "[INFO|trainer.py:434] 2023-03-10 06:41:18,925 >> Using amp fp16 backend\n",
      "03/10/2023 06:41:18 - INFO - examples.t4rec_paper_experiments.t4r_paper_repro.exp_outputs -   Training, Model and Data parameters {'data_path': '/transformers4rec/examples/t4rec_paper_experiments/t4r_paper_repro/', 'features_schema_path': '/workspace/examples/t4rec_paper_experiments/datasets_configs/ecom_rees46/rees46_schema.pbtxt', 'start_time_window_index': 1, 'final_time_window_index': 2, 'time_window_folder_pad_digits': 4, 'no_incremental_training': False, 'training_time_window_size': 0, 'use_side_information_features': False, 'input_features_aggregation': 'concat', 'model_type': 'xlnet', 'tf_out_activation': 'tanh', 'mlm': True, 'mlm_probability': 0.30000000000000004, 'plm': False, 'plm_probability': 0.25, 'plm_max_span_length': 5, 'plm_mask_input': False, 'plm_permute_all': False, 'rtd': False, 'rtd_sample_from_batch': False, 'rtd_use_batch_interaction': False, 'rtd_discriminator_loss_weight': 50, 'rtd_generator_loss_weight': 1, 'rtd_tied_generator': False, 'd_model': 192, 'n_layer': 3, 'n_head': 16, 'layer_norm_eps': 1e-12, 'initializer_range': 0.02, 'hidden_act': 'gelu', 'dropout': 0.0, 'summary_type': 'last', 'num_hidden_groups': 1, 'inner_group_num': 1, 'eval_on_last_item_seq_only': True, 'train_on_last_item_seq_only': False, 'mf_constrained_embeddings': True, 'item_embedding_dim': 448, 'numeric_features_project_to_embedding_dim': 0, 'numeric_features_soft_one_hot_encoding_num_embeddings': 0, 'stochastic_shared_embeddings_replacement_prob': 0.1, 'softmax_temperature': 1.0, 'label_smoothing': 0.0, 'embedding_dim_from_cardinality_multiplier': 2.0, 'item_id_embeddings_init_std': 0.11, 'other_embeddings_init_std': 0.02, 'layer_norm_featurewise': True, 'attn_type': 'bi', 'input_dropout': 0.1, 'loss_type': 'cross_entropy', 'similarity_type': 'concat_mlp', 'inp_merge': 'mlp', 'learning_rate_warmup_steps': 0, 'avg_session_length': None, 'output_dir': './tmp/', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 128, 'per_device_eval_batch_size': 128, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0006667377132554976, 'weight_decay': 3.910060265627374e-05, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 5.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': -1, 'log_level_replica': -1, 'log_on_each_node': True, 'logging_dir': './tmp/runs/Mar10_06-41-16_7dfa224f788e', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_steps': 0, 'save_total_limit': None, 'save_on_each_node': False, 'no_cuda': False, 'seed': 2, 'fp16': True, 'fp16_opt_level': 'O1', 'fp16_backend': 'auto', 'fp16_full_eval': False, 'local_rank': -1, 'xpu_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': True, 'eval_steps': None, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': None, 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'sharded_ddp': [], 'deepspeed': None, 'label_smoothing_factor': 0.0, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': [], 'ddp_find_unused_parameters': None, 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_token': None, 'gradient_checkpointing': False, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': None, '_n_gpu': 1, 'mp_parameters': '', 'max_sequence_length': 20, 'shuffle_buffer_size': 0, 'data_loader_engine': 'merlin', 'eval_on_test_set': True, 'eval_steps_on_train_set': 20, 'predict_top_k': 0, 'learning_rate_num_cosine_cycles_by_epoch': 1.25, 'log_predictions': False, 'compute_metrics_each_n_steps': 1, 'experiments_group': 'default', 'session_seq_length_max': 20, 'learning_rate_schedule': 'linear_with_warmup', 'validate_every': -1}\n",
      "[INFO|trainer.py:1196] 2023-03-10 06:41:19,383 >> ***** Running training *****\n",
      "[INFO|trainer.py:1197] 2023-03-10 06:41:19,383 >>   Num examples = 86528\n",
      "[INFO|trainer.py:1198] 2023-03-10 06:41:19,383 >>   Num Epochs = 5\n",
      "[INFO|trainer.py:1199] 2023-03-10 06:41:19,384 >>   Instantaneous batch size per device = 128\n",
      "[INFO|trainer.py:1200] 2023-03-10 06:41:19,384 >>   Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "[INFO|trainer.py:1201] 2023-03-10 06:41:19,384 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1202] 2023-03-10 06:41:19,384 >>   Total optimization steps = 3380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DLL 2023-03-10 06:41:18.926096 - PARAMETER data_path : /transformers4rec/examples/t4rec_paper_experiments/t4r_paper_repro/  features_schema_path : /workspace/examples/t4rec_paper_experiments/datasets_configs/ecom_rees46/rees46_schema.pbtxt  start_time_window_index : 1  final_time_window_index : 2  time_window_folder_pad_digits : 4  no_incremental_training : False  training_time_window_size : 0  use_side_information_features : False  input_features_aggregation : concat  model_type : xlnet  tf_out_activation : tanh  mlm : True  mlm_probability : 0.30000000000000004  plm : False  plm_probability : 0.25  plm_max_span_length : 5  plm_mask_input : False  plm_permute_all : False  rtd : False  rtd_sample_from_batch : False  rtd_use_batch_interaction : False  rtd_discriminator_loss_weight : 50  rtd_generator_loss_weight : 1  rtd_tied_generator : False  d_model : 192  n_layer : 3  n_head : 16  layer_norm_eps : 1e-12  initializer_range : 0.02  hidden_act : gelu  dropout : 0.0  summary_type : last  num_hidden_groups : 1  inner_group_num : 1  eval_on_last_item_seq_only : True  train_on_last_item_seq_only : False  mf_constrained_embeddings : True  item_embedding_dim : 448  numeric_features_project_to_embedding_dim : 0  numeric_features_soft_one_hot_encoding_num_embeddings : 0  stochastic_shared_embeddings_replacement_prob : 0.1  softmax_temperature : 1.0  label_smoothing : 0.0  embedding_dim_from_cardinality_multiplier : 2.0  item_id_embeddings_init_std : 0.11  other_embeddings_init_std : 0.02  layer_norm_featurewise : True  attn_type : bi  input_dropout : 0.1  loss_type : cross_entropy  similarity_type : concat_mlp  inp_merge : mlp  learning_rate_warmup_steps : 0  avg_session_length : None  output_dir : ./tmp/  overwrite_output_dir : True  do_train : True  do_eval : True  do_predict : False  prediction_loss_only : False  per_device_train_batch_size : 128  per_device_eval_batch_size : 128  per_gpu_train_batch_size : None  per_gpu_eval_batch_size : None  gradient_accumulation_steps : 1  eval_accumulation_steps : None  learning_rate : 0.0006667377132554976  weight_decay : 3.910060265627374e-05  adam_beta1 : 0.9  adam_beta2 : 0.999  adam_epsilon : 1e-08  max_grad_norm : 1.0  num_train_epochs : 5.0  max_steps : -1  lr_scheduler_type : linear  warmup_ratio : 0.0  warmup_steps : 0  log_level : -1  log_level_replica : -1  log_on_each_node : True  logging_dir : ./tmp/runs/Mar10_06-41-16_7dfa224f788e  logging_first_step : False  logging_steps : 500  logging_nan_inf_filter : True  save_steps : 0  save_total_limit : None  save_on_each_node : False  no_cuda : False  seed : 2  fp16 : True  fp16_opt_level : O1  fp16_backend : auto  fp16_full_eval : False  local_rank : -1  xpu_backend : None  tpu_num_cores : None  tpu_metrics_debug : False  debug : []  dataloader_drop_last : True  eval_steps : None  dataloader_num_workers : 0  past_index : -1  run_name : None  disable_tqdm : False  remove_unused_columns : True  label_names : None  load_best_model_at_end : False  metric_for_best_model : None  greater_is_better : None  ignore_data_skip : False  sharded_ddp : []  deepspeed : None  label_smoothing_factor : 0.0  adafactor : False  group_by_length : False  length_column_name : length  report_to : []  ddp_find_unused_parameters : None  dataloader_pin_memory : True  skip_memory_metrics : True  use_legacy_prediction_loop : False  push_to_hub : False  resume_from_checkpoint : None  hub_model_id : None  hub_token : None  gradient_checkpointing : False  push_to_hub_model_id : None  push_to_hub_organization : None  push_to_hub_token : None  _n_gpu : 1  mp_parameters :   max_sequence_length : 20  shuffle_buffer_size : 0  data_loader_engine : merlin  eval_on_test_set : True  eval_steps_on_train_set : 20  predict_top_k : 0  learning_rate_num_cosine_cycles_by_epoch : 1.25  log_predictions : False  compute_metrics_each_n_steps : 1  experiments_group : default  session_seq_length_max : 20  learning_rate_schedule : linear_with_warmup  validate_every : -1 \n",
      "\n",
      "***** Launch training for day 1: *****\n",
      "{'loss': 10.1984, 'learning_rate': 0.0005683051336949965, 'epoch': 0.74}\n",
      "{'loss': 9.1995, 'learning_rate': 0.0004696752944560177, 'epoch': 1.48}\n",
      "{'loss': 8.9484, 'learning_rate': 0.0003710454552170388, 'epoch': 2.22}\n",
      "{'loss': 8.7082, 'learning_rate': 0.0002724156159780598, 'epoch': 2.96}\n",
      "{'loss': 8.5479, 'learning_rate': 0.00017378577673908085, 'epoch': 3.7}\n",
      "{'loss': 8.4013, 'learning_rate': 7.515593750010194e-05, 'epoch': 4.44}\n",
      "{'train_runtime': 267.6305, 'train_samples_per_second': 0.019, 'train_steps_per_second': 12.629, 'train_loss': 8.929472757373336, 'epoch': 5.0}\n",
      "\n",
      "***** Evaluation results for day 2 (train set):*****\n",
      "\n",
      "{'train_/next-item/ndcg_at_10': 0.0865924283862114, 'train_/next-item/ndcg_at_20': 0.10158973932266235, 'train_/next-item/recall_at_10': 0.15976563096046448, 'train_/next-item/recall_at_20': 0.21914063394069672, 'train_/loss': 7.99446964263916, 'train_runtime': 0.6446, 'train_samples_per_second': 3971.675, 'train_steps_per_second': 31.029}\n",
      "\n",
      "***** Evaluation results for day 2 (eval set):*****\n",
      "\n",
      "{'eval_/next-item/ndcg_at_10': 0.08677017688751221, 'eval_/next-item/ndcg_at_20': 0.10235893726348877, 'eval_/next-item/recall_at_10': 0.16114456951618195, 'eval_/next-item/recall_at_20': 0.223268061876297, 'eval_/loss': 8.346117973327637, 'eval_runtime': 2.2174, 'eval_samples_per_second': 4791.094, 'eval_steps_per_second': 37.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-28' coro=<ScriptMagics.shebang.<locals>._handle_stream() done, defined at /usr/local/lib/python3.8/dist-packages/IPython/core/magics/script.py:211> exception=ValueError('Separator is not found, and chunk exceed the limit')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/asyncio/streams.py\", line 540, in readline\n",
      "    line = await self.readuntil(sep)\n",
      "  File \"/usr/lib/python3.8/asyncio/streams.py\", line 618, in readuntil\n",
      "    raise exceptions.LimitOverrunError(\n",
      "asyncio.exceptions.LimitOverrunError: Separator is not found, and chunk exceed the limit\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/magics/script.py\", line 213, in _handle_stream\n",
      "    line = (await stream.readline()).decode(\"utf8\")\n",
      "  File \"/usr/lib/python3.8/asyncio/streams.py\", line 549, in readline\n",
      "    raise ValueError(e.args[0])\n",
      "ValueError: Separator is not found, and chunk exceed the limit\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "FEATURE_SCHEMA_PATH=/workspace/examples/t4rec_paper_experiments/datasets_configs/ecom_rees46/rees46_schema.pbtxt\n",
    "DATA_PATH=/transformers4rec/examples/t4rec_paper_experiments/t4r_paper_repro/\n",
    "NUM_EPOCHS=5\n",
    "SEED=2\n",
    "\n",
    "python3 ../transf_exp_main_modified.py --output_dir ./tmp/ --overwrite_output_dir --do_train --do_eval --save_steps 0 --data_path $DATA_PATH --features_schema_path $FEATURE_SCHEMA_PATH --fp16 --data_loader_engine merlin --start_time_window_index 1 --final_time_window_index 2 --time_window_folder_pad_digits 4 --model_type xlnet --loss_type cross_entropy --per_device_eval_batch_size 128 --similarity_type concat_mlp --tf_out_activation tanh --inp_merge mlp --learning_rate_warmup_steps 0 --learning_rate_schedule linear_with_warmup --hidden_act gelu --num_train_epochs $NUM_EPOCHS --dataloader_drop_last --compute_metrics_each_n_steps 1 --session_seq_length_max 20 --eval_on_last_item_seq_only --mf_constrained_embeddings --layer_norm_featurewise --attn_type bi --mlm --per_device_train_batch_size 128 --learning_rate 0.0006667377132554976 --dropout 0.0 --input_dropout 0.1 --weight_decay 3.910060265627374e-05 --d_model 192 --item_embedding_dim 448 --n_layer 3 --n_head 16 --label_smoothing 0.0 --stochastic_shared_embeddings_replacement_prob 0.1 --item_id_embeddings_init_std 0.11 --other_embeddings_init_std 0.02 --mlm_probability 0.30000000000000004 --eval_on_test_set --seed $SEED --report_to none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8abb213",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/10/2023 06:50:42 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: True\n",
      "03/10/2023 06:50:44 - WARNING - transformers4rec -   Projecting inputs of NextItemPredictionTask to'448' As weight tying requires the input dimension '192' to be equal to the item-id embedding dimension '448'\n",
      "[INFO|trainer.py:434] 2023-03-10 06:50:44,307 >> Using amp fp16 backend\n",
      "03/10/2023 06:50:44 - INFO - examples.t4rec_paper_experiments.t4r_paper_repro.exp_outputs -   Training, Model and Data parameters {'data_path': '/transformers4rec/examples/t4rec_paper_experiments/t4r_paper_repro/', 'features_schema_path': '/workspace/examples/t4rec_paper_experiments/datasets_configs/ecom_rees46/rees46_schema.pbtxt', 'start_time_window_index': 1, 'final_time_window_index': 2, 'time_window_folder_pad_digits': 4, 'no_incremental_training': False, 'training_time_window_size': 0, 'use_side_information_features': False, 'input_features_aggregation': 'concat', 'model_type': 'xlnet', 'tf_out_activation': 'tanh', 'mlm': True, 'mlm_probability': 0.30000000000000004, 'plm': False, 'plm_probability': 0.25, 'plm_max_span_length': 5, 'plm_mask_input': False, 'plm_permute_all': False, 'rtd': False, 'rtd_sample_from_batch': False, 'rtd_use_batch_interaction': False, 'rtd_discriminator_loss_weight': 50, 'rtd_generator_loss_weight': 1, 'rtd_tied_generator': False, 'd_model': 192, 'n_layer': 3, 'n_head': 16, 'layer_norm_eps': 1e-12, 'initializer_range': 0.02, 'hidden_act': 'gelu', 'dropout': 0.0, 'summary_type': 'last', 'num_hidden_groups': 1, 'inner_group_num': 1, 'eval_on_last_item_seq_only': True, 'train_on_last_item_seq_only': False, 'mf_constrained_embeddings': True, 'item_embedding_dim': 448, 'numeric_features_project_to_embedding_dim': 0, 'numeric_features_soft_one_hot_encoding_num_embeddings': 0, 'stochastic_shared_embeddings_replacement_prob': 0.1, 'softmax_temperature': 1.0, 'label_smoothing': 0.0, 'embedding_dim_from_cardinality_multiplier': 2.0, 'item_id_embeddings_init_std': 0.11, 'other_embeddings_init_std': 0.02, 'layer_norm_featurewise': True, 'attn_type': 'bi', 'input_dropout': 0.1, 'loss_type': 'cross_entropy', 'similarity_type': 'concat_mlp', 'inp_merge': 'mlp', 'learning_rate_warmup_steps': 0, 'avg_session_length': None, 'output_dir': './tmp/', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 128, 'per_device_eval_batch_size': 128, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0006667377132554976, 'weight_decay': 3.910060265627374e-05, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 5.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': -1, 'log_level_replica': -1, 'log_on_each_node': True, 'logging_dir': './tmp/runs/Mar10_06-50-41_7dfa224f788e', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_steps': 0, 'save_total_limit': None, 'save_on_each_node': False, 'no_cuda': False, 'seed': 3, 'fp16': True, 'fp16_opt_level': 'O1', 'fp16_backend': 'auto', 'fp16_full_eval': False, 'local_rank': -1, 'xpu_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': True, 'eval_steps': None, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': None, 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'sharded_ddp': [], 'deepspeed': None, 'label_smoothing_factor': 0.0, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': [], 'ddp_find_unused_parameters': None, 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_token': None, 'gradient_checkpointing': False, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': None, '_n_gpu': 1, 'mp_parameters': '', 'max_sequence_length': 20, 'shuffle_buffer_size': 0, 'data_loader_engine': 'merlin', 'eval_on_test_set': True, 'eval_steps_on_train_set': 20, 'predict_top_k': 0, 'learning_rate_num_cosine_cycles_by_epoch': 1.25, 'log_predictions': False, 'compute_metrics_each_n_steps': 1, 'experiments_group': 'default', 'session_seq_length_max': 20, 'learning_rate_schedule': 'linear_with_warmup', 'validate_every': -1}\n",
      "[INFO|trainer.py:1196] 2023-03-10 06:50:44,786 >> ***** Running training *****\n",
      "[INFO|trainer.py:1197] 2023-03-10 06:50:44,786 >>   Num examples = 86528\n",
      "[INFO|trainer.py:1198] 2023-03-10 06:50:44,786 >>   Num Epochs = 5\n",
      "[INFO|trainer.py:1199] 2023-03-10 06:50:44,786 >>   Instantaneous batch size per device = 128\n",
      "[INFO|trainer.py:1200] 2023-03-10 06:50:44,786 >>   Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "[INFO|trainer.py:1201] 2023-03-10 06:50:44,786 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1202] 2023-03-10 06:50:44,786 >>   Total optimization steps = 3380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DLL 2023-03-10 06:50:44.307714 - PARAMETER data_path : /transformers4rec/examples/t4rec_paper_experiments/t4r_paper_repro/  features_schema_path : /workspace/examples/t4rec_paper_experiments/datasets_configs/ecom_rees46/rees46_schema.pbtxt  start_time_window_index : 1  final_time_window_index : 2  time_window_folder_pad_digits : 4  no_incremental_training : False  training_time_window_size : 0  use_side_information_features : False  input_features_aggregation : concat  model_type : xlnet  tf_out_activation : tanh  mlm : True  mlm_probability : 0.30000000000000004  plm : False  plm_probability : 0.25  plm_max_span_length : 5  plm_mask_input : False  plm_permute_all : False  rtd : False  rtd_sample_from_batch : False  rtd_use_batch_interaction : False  rtd_discriminator_loss_weight : 50  rtd_generator_loss_weight : 1  rtd_tied_generator : False  d_model : 192  n_layer : 3  n_head : 16  layer_norm_eps : 1e-12  initializer_range : 0.02  hidden_act : gelu  dropout : 0.0  summary_type : last  num_hidden_groups : 1  inner_group_num : 1  eval_on_last_item_seq_only : True  train_on_last_item_seq_only : False  mf_constrained_embeddings : True  item_embedding_dim : 448  numeric_features_project_to_embedding_dim : 0  numeric_features_soft_one_hot_encoding_num_embeddings : 0  stochastic_shared_embeddings_replacement_prob : 0.1  softmax_temperature : 1.0  label_smoothing : 0.0  embedding_dim_from_cardinality_multiplier : 2.0  item_id_embeddings_init_std : 0.11  other_embeddings_init_std : 0.02  layer_norm_featurewise : True  attn_type : bi  input_dropout : 0.1  loss_type : cross_entropy  similarity_type : concat_mlp  inp_merge : mlp  learning_rate_warmup_steps : 0  avg_session_length : None  output_dir : ./tmp/  overwrite_output_dir : True  do_train : True  do_eval : True  do_predict : False  prediction_loss_only : False  per_device_train_batch_size : 128  per_device_eval_batch_size : 128  per_gpu_train_batch_size : None  per_gpu_eval_batch_size : None  gradient_accumulation_steps : 1  eval_accumulation_steps : None  learning_rate : 0.0006667377132554976  weight_decay : 3.910060265627374e-05  adam_beta1 : 0.9  adam_beta2 : 0.999  adam_epsilon : 1e-08  max_grad_norm : 1.0  num_train_epochs : 5.0  max_steps : -1  lr_scheduler_type : linear  warmup_ratio : 0.0  warmup_steps : 0  log_level : -1  log_level_replica : -1  log_on_each_node : True  logging_dir : ./tmp/runs/Mar10_06-50-41_7dfa224f788e  logging_first_step : False  logging_steps : 500  logging_nan_inf_filter : True  save_steps : 0  save_total_limit : None  save_on_each_node : False  no_cuda : False  seed : 3  fp16 : True  fp16_opt_level : O1  fp16_backend : auto  fp16_full_eval : False  local_rank : -1  xpu_backend : None  tpu_num_cores : None  tpu_metrics_debug : False  debug : []  dataloader_drop_last : True  eval_steps : None  dataloader_num_workers : 0  past_index : -1  run_name : None  disable_tqdm : False  remove_unused_columns : True  label_names : None  load_best_model_at_end : False  metric_for_best_model : None  greater_is_better : None  ignore_data_skip : False  sharded_ddp : []  deepspeed : None  label_smoothing_factor : 0.0  adafactor : False  group_by_length : False  length_column_name : length  report_to : []  ddp_find_unused_parameters : None  dataloader_pin_memory : True  skip_memory_metrics : True  use_legacy_prediction_loop : False  push_to_hub : False  resume_from_checkpoint : None  hub_model_id : None  hub_token : None  gradient_checkpointing : False  push_to_hub_model_id : None  push_to_hub_organization : None  push_to_hub_token : None  _n_gpu : 1  mp_parameters :   max_sequence_length : 20  shuffle_buffer_size : 0  data_loader_engine : merlin  eval_on_test_set : True  eval_steps_on_train_set : 20  predict_top_k : 0  learning_rate_num_cosine_cycles_by_epoch : 1.25  log_predictions : False  compute_metrics_each_n_steps : 1  experiments_group : default  session_seq_length_max : 20  learning_rate_schedule : linear_with_warmup  validate_every : -1 \n",
      "\n",
      "***** Launch training for day 1: *****\n",
      "{'loss': 10.1517, 'learning_rate': 0.0005681078740165187, 'epoch': 0.74}\n",
      "{'loss': 9.1378, 'learning_rate': 0.00046947803477753974, 'epoch': 1.48}\n",
      "{'loss': 8.8854, 'learning_rate': 0.0003708481955385607, 'epoch': 2.22}\n",
      "{'loss': 8.668, 'learning_rate': 0.0002722183562995818, 'epoch': 2.96}\n",
      "{'loss': 8.4887, 'learning_rate': 0.0001735885170606029, 'epoch': 3.7}\n",
      "{'loss': 8.3778, 'learning_rate': 7.4958677821624e-05, 'epoch': 4.44}\n",
      "{'train_runtime': 267.4244, 'train_samples_per_second': 0.019, 'train_steps_per_second': 12.639, 'train_loss': 8.881638241378512, 'epoch': 5.0}\n",
      "\n",
      "***** Evaluation results for day 2 (train set):*****\n",
      "\n",
      "{'train_/next-item/ndcg_at_10': 0.08869679272174835, 'train_/next-item/ndcg_at_20': 0.10546129196882248, 'train_/next-item/recall_at_10': 0.15507812798023224, 'train_/next-item/recall_at_20': 0.22148437798023224, 'train_/loss': 7.946734428405762, 'train_runtime': 0.6445, 'train_samples_per_second': 3972.268, 'train_steps_per_second': 31.033}\n",
      "\n",
      "***** Evaluation results for day 2 (eval set):*****\n",
      "\n",
      "{'eval_/next-item/ndcg_at_10': 0.08494117110967636, 'eval_/next-item/ndcg_at_20': 0.10106566548347473, 'eval_/next-item/recall_at_10': 0.15568523108959198, 'eval_/next-item/recall_at_20': 0.21940888464450836, 'eval_/loss': 8.320558547973633, 'eval_runtime': 2.2146, 'eval_samples_per_second': 4797.31, 'eval_steps_per_second': 37.479}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-33' coro=<ScriptMagics.shebang.<locals>._handle_stream() done, defined at /usr/local/lib/python3.8/dist-packages/IPython/core/magics/script.py:211> exception=ValueError('Separator is not found, and chunk exceed the limit')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/asyncio/streams.py\", line 540, in readline\n",
      "    line = await self.readuntil(sep)\n",
      "  File \"/usr/lib/python3.8/asyncio/streams.py\", line 618, in readuntil\n",
      "    raise exceptions.LimitOverrunError(\n",
      "asyncio.exceptions.LimitOverrunError: Separator is not found, and chunk exceed the limit\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/magics/script.py\", line 213, in _handle_stream\n",
      "    line = (await stream.readline()).decode(\"utf8\")\n",
      "  File \"/usr/lib/python3.8/asyncio/streams.py\", line 549, in readline\n",
      "    raise ValueError(e.args[0])\n",
      "ValueError: Separator is not found, and chunk exceed the limit\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "FEATURE_SCHEMA_PATH=/workspace/examples/t4rec_paper_experiments/datasets_configs/ecom_rees46/rees46_schema.pbtxt\n",
    "DATA_PATH=/transformers4rec/examples/t4rec_paper_experiments/t4r_paper_repro/\n",
    "NUM_EPOCHS=5\n",
    "SEED=3\n",
    "\n",
    "python3 ../transf_exp_main_modified.py --output_dir ./tmp/ --overwrite_output_dir --do_train --do_eval --save_steps 0 --data_path $DATA_PATH --features_schema_path $FEATURE_SCHEMA_PATH --fp16 --data_loader_engine merlin --start_time_window_index 1 --final_time_window_index 2 --time_window_folder_pad_digits 4 --model_type xlnet --loss_type cross_entropy --per_device_eval_batch_size 128 --similarity_type concat_mlp --tf_out_activation tanh --inp_merge mlp --learning_rate_warmup_steps 0 --learning_rate_schedule linear_with_warmup --hidden_act gelu --num_train_epochs $NUM_EPOCHS --dataloader_drop_last --compute_metrics_each_n_steps 1 --session_seq_length_max 20 --eval_on_last_item_seq_only --mf_constrained_embeddings --layer_norm_featurewise --attn_type bi --mlm --per_device_train_batch_size 128 --learning_rate 0.0006667377132554976 --dropout 0.0 --input_dropout 0.1 --weight_decay 3.910060265627374e-05 --d_model 192 --item_embedding_dim 448 --n_layer 3 --n_head 16 --label_smoothing 0.0 --stochastic_shared_embeddings_replacement_prob 0.1 --item_id_embeddings_init_std 0.11 --other_embeddings_init_std 0.02 --mlm_probability 0.30000000000000004 --eval_on_test_set --seed $SEED --report_to none"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
