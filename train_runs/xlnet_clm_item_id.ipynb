{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ce2e001",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/10/2023 07:14:19 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: True\n",
      "03/10/2023 07:14:21 - WARNING - transformers4rec -   Projecting inputs of NextItemPredictionTask to'448' As weight tying requires the input dimension '192' to be equal to the item-id embedding dimension '448'\n",
      "[INFO|trainer.py:434] 2023-03-10 07:14:21,395 >> Using amp fp16 backend\n",
      "03/10/2023 07:14:21 - INFO - examples.t4rec_paper_experiments.t4r_paper_repro.exp_outputs -   Training, Model and Data parameters {'data_path': '/transformers4rec/examples/t4rec_paper_experiments/t4r_paper_repro/', 'features_schema_path': '/workspace/examples/t4rec_paper_experiments/datasets_configs/ecom_rees46/rees46_schema.pbtxt', 'start_time_window_index': 1, 'final_time_window_index': 2, 'time_window_folder_pad_digits': 4, 'no_incremental_training': False, 'training_time_window_size': 0, 'use_side_information_features': False, 'input_features_aggregation': 'concat', 'model_type': 'xlnet', 'tf_out_activation': 'tanh', 'mlm': False, 'mlm_probability': 0.15, 'plm': False, 'plm_probability': 0.25, 'plm_max_span_length': 5, 'plm_mask_input': False, 'plm_permute_all': False, 'rtd': False, 'rtd_sample_from_batch': False, 'rtd_use_batch_interaction': False, 'rtd_discriminator_loss_weight': 50, 'rtd_generator_loss_weight': 1, 'rtd_tied_generator': False, 'd_model': 192, 'n_layer': 3, 'n_head': 16, 'layer_norm_eps': 1e-12, 'initializer_range': 0.02, 'hidden_act': 'gelu', 'dropout': 0.0, 'summary_type': 'last', 'num_hidden_groups': 1, 'inner_group_num': 1, 'eval_on_last_item_seq_only': True, 'train_on_last_item_seq_only': False, 'mf_constrained_embeddings': True, 'item_embedding_dim': 448, 'numeric_features_project_to_embedding_dim': 0, 'numeric_features_soft_one_hot_encoding_num_embeddings': 0, 'stochastic_shared_embeddings_replacement_prob': 0.1, 'softmax_temperature': 1.0, 'label_smoothing': 0.0, 'embedding_dim_from_cardinality_multiplier': 2.0, 'item_id_embeddings_init_std': 0.11, 'other_embeddings_init_std': 0.02, 'layer_norm_featurewise': True, 'attn_type': 'bi', 'input_dropout': 0.1, 'loss_type': 'cross_entropy', 'similarity_type': 'concat_mlp', 'inp_merge': 'mlp', 'learning_rate_warmup_steps': 0, 'avg_session_length': None, 'output_dir': './tmp/', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 128, 'per_device_eval_batch_size': 128, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0006667377132554976, 'weight_decay': 3.910060265627374e-05, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 5.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': -1, 'log_level_replica': -1, 'log_on_each_node': True, 'logging_dir': './tmp/runs/Mar10_07-14-18_7dfa224f788e', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_steps': 0, 'save_total_limit': None, 'save_on_each_node': False, 'no_cuda': False, 'seed': 100, 'fp16': True, 'fp16_opt_level': 'O1', 'fp16_backend': 'auto', 'fp16_full_eval': False, 'local_rank': -1, 'xpu_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': True, 'eval_steps': None, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': None, 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'sharded_ddp': [], 'deepspeed': None, 'label_smoothing_factor': 0.0, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': [], 'ddp_find_unused_parameters': None, 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_token': None, 'gradient_checkpointing': False, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': None, '_n_gpu': 1, 'mp_parameters': '', 'max_sequence_length': 20, 'shuffle_buffer_size': 0, 'data_loader_engine': 'merlin', 'eval_on_test_set': True, 'eval_steps_on_train_set': 20, 'predict_top_k': 0, 'learning_rate_num_cosine_cycles_by_epoch': 1.25, 'log_predictions': False, 'compute_metrics_each_n_steps': 1, 'experiments_group': 'default', 'session_seq_length_max': 20, 'learning_rate_schedule': 'linear_with_warmup', 'validate_every': -1}\n",
      "[INFO|trainer.py:1196] 2023-03-10 07:14:21,846 >> ***** Running training *****\n",
      "[INFO|trainer.py:1197] 2023-03-10 07:14:21,846 >>   Num examples = 86528\n",
      "[INFO|trainer.py:1198] 2023-03-10 07:14:21,846 >>   Num Epochs = 5\n",
      "[INFO|trainer.py:1199] 2023-03-10 07:14:21,846 >>   Instantaneous batch size per device = 128\n",
      "[INFO|trainer.py:1200] 2023-03-10 07:14:21,846 >>   Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "[INFO|trainer.py:1201] 2023-03-10 07:14:21,846 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1202] 2023-03-10 07:14:21,846 >>   Total optimization steps = 3380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DLL 2023-03-10 07:14:21.396153 - PARAMETER data_path : /transformers4rec/examples/t4rec_paper_experiments/t4r_paper_repro/  features_schema_path : /workspace/examples/t4rec_paper_experiments/datasets_configs/ecom_rees46/rees46_schema.pbtxt  start_time_window_index : 1  final_time_window_index : 2  time_window_folder_pad_digits : 4  no_incremental_training : False  training_time_window_size : 0  use_side_information_features : False  input_features_aggregation : concat  model_type : xlnet  tf_out_activation : tanh  mlm : False  mlm_probability : 0.15  plm : False  plm_probability : 0.25  plm_max_span_length : 5  plm_mask_input : False  plm_permute_all : False  rtd : False  rtd_sample_from_batch : False  rtd_use_batch_interaction : False  rtd_discriminator_loss_weight : 50  rtd_generator_loss_weight : 1  rtd_tied_generator : False  d_model : 192  n_layer : 3  n_head : 16  layer_norm_eps : 1e-12  initializer_range : 0.02  hidden_act : gelu  dropout : 0.0  summary_type : last  num_hidden_groups : 1  inner_group_num : 1  eval_on_last_item_seq_only : True  train_on_last_item_seq_only : False  mf_constrained_embeddings : True  item_embedding_dim : 448  numeric_features_project_to_embedding_dim : 0  numeric_features_soft_one_hot_encoding_num_embeddings : 0  stochastic_shared_embeddings_replacement_prob : 0.1  softmax_temperature : 1.0  label_smoothing : 0.0  embedding_dim_from_cardinality_multiplier : 2.0  item_id_embeddings_init_std : 0.11  other_embeddings_init_std : 0.02  layer_norm_featurewise : True  attn_type : bi  input_dropout : 0.1  loss_type : cross_entropy  similarity_type : concat_mlp  inp_merge : mlp  learning_rate_warmup_steps : 0  avg_session_length : None  output_dir : ./tmp/  overwrite_output_dir : True  do_train : True  do_eval : True  do_predict : False  prediction_loss_only : False  per_device_train_batch_size : 128  per_device_eval_batch_size : 128  per_gpu_train_batch_size : None  per_gpu_eval_batch_size : None  gradient_accumulation_steps : 1  eval_accumulation_steps : None  learning_rate : 0.0006667377132554976  weight_decay : 3.910060265627374e-05  adam_beta1 : 0.9  adam_beta2 : 0.999  adam_epsilon : 1e-08  max_grad_norm : 1.0  num_train_epochs : 5.0  max_steps : -1  lr_scheduler_type : linear  warmup_ratio : 0.0  warmup_steps : 0  log_level : -1  log_level_replica : -1  log_on_each_node : True  logging_dir : ./tmp/runs/Mar10_07-14-18_7dfa224f788e  logging_first_step : False  logging_steps : 500  logging_nan_inf_filter : True  save_steps : 0  save_total_limit : None  save_on_each_node : False  no_cuda : False  seed : 100  fp16 : True  fp16_opt_level : O1  fp16_backend : auto  fp16_full_eval : False  local_rank : -1  xpu_backend : None  tpu_num_cores : None  tpu_metrics_debug : False  debug : []  dataloader_drop_last : True  eval_steps : None  dataloader_num_workers : 0  past_index : -1  run_name : None  disable_tqdm : False  remove_unused_columns : True  label_names : None  load_best_model_at_end : False  metric_for_best_model : None  greater_is_better : None  ignore_data_skip : False  sharded_ddp : []  deepspeed : None  label_smoothing_factor : 0.0  adafactor : False  group_by_length : False  length_column_name : length  report_to : []  ddp_find_unused_parameters : None  dataloader_pin_memory : True  skip_memory_metrics : True  use_legacy_prediction_loop : False  push_to_hub : False  resume_from_checkpoint : None  hub_model_id : None  hub_token : None  gradient_checkpointing : False  push_to_hub_model_id : None  push_to_hub_organization : None  push_to_hub_token : None  _n_gpu : 1  mp_parameters :   max_sequence_length : 20  shuffle_buffer_size : 0  data_loader_engine : merlin  eval_on_test_set : True  eval_steps_on_train_set : 20  predict_top_k : 0  learning_rate_num_cosine_cycles_by_epoch : 1.25  log_predictions : False  compute_metrics_each_n_steps : 1  experiments_group : default  session_seq_length_max : 20  learning_rate_schedule : linear_with_warmup  validate_every : -1 \n",
      "\n",
      "***** Launch training for day 1: *****\n",
      "{'loss': 6.6475, 'learning_rate': 0.0005681078740165187, 'epoch': 0.74}\n",
      "{'loss': 2.4218, 'learning_rate': 0.00046947803477753974, 'epoch': 1.48}\n",
      "{'loss': 1.9739, 'learning_rate': 0.0003708481955385607, 'epoch': 2.22}\n",
      "{'loss': 1.858, 'learning_rate': 0.0002722183562995818, 'epoch': 2.96}\n",
      "{'loss': 1.7681, 'learning_rate': 0.0001735885170606029, 'epoch': 3.7}\n",
      "{'loss': 1.7082, 'learning_rate': 7.4958677821624e-05, 'epoch': 4.44}\n",
      "{'train_runtime': 337.7129, 'train_samples_per_second': 0.015, 'train_steps_per_second': 10.009, 'train_loss': 2.6110303890070266, 'epoch': 5.0}\n",
      "\n",
      "***** Evaluation results for day 2 (train set):*****\n",
      "\n",
      "{'train_/next-item/ndcg_at_10': 0.11942513287067413, 'train_/next-item/ndcg_at_20': 0.132638081908226, 'train_/next-item/recall_at_10': 0.19570313394069672, 'train_/next-item/recall_at_20': 0.24843750894069672, 'train_/loss': 7.65301513671875, 'train_runtime': 0.6484, 'train_samples_per_second': 3948.127, 'train_steps_per_second': 30.845}\n",
      "\n",
      "***** Evaluation results for day 2 (eval set):*****\n",
      "\n",
      "{'eval_/next-item/ndcg_at_10': 0.08762501925230026, 'eval_/next-item/ndcg_at_20': 0.09899389743804932, 'eval_/next-item/recall_at_10': 0.14928463101387024, 'eval_/next-item/recall_at_20': 0.1945594847202301, 'eval_/loss': 8.972926139831543, 'eval_runtime': 2.286, 'eval_samples_per_second': 4647.323, 'eval_steps_per_second': 36.307}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-18' coro=<ScriptMagics.shebang.<locals>._handle_stream() done, defined at /usr/local/lib/python3.8/dist-packages/IPython/core/magics/script.py:211> exception=ValueError('Separator is not found, and chunk exceed the limit')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/asyncio/streams.py\", line 540, in readline\n",
      "    line = await self.readuntil(sep)\n",
      "  File \"/usr/lib/python3.8/asyncio/streams.py\", line 618, in readuntil\n",
      "    raise exceptions.LimitOverrunError(\n",
      "asyncio.exceptions.LimitOverrunError: Separator is not found, and chunk exceed the limit\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/magics/script.py\", line 213, in _handle_stream\n",
      "    line = (await stream.readline()).decode(\"utf8\")\n",
      "  File \"/usr/lib/python3.8/asyncio/streams.py\", line 549, in readline\n",
      "    raise ValueError(e.args[0])\n",
      "ValueError: Separator is not found, and chunk exceed the limit\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "FEATURE_SCHEMA_PATH=/workspace/examples/t4rec_paper_experiments/datasets_configs/ecom_rees46/rees46_schema.pbtxt\n",
    "DATA_PATH=/transformers4rec/examples/t4rec_paper_experiments/t4r_paper_repro/\n",
    "NUM_EPOCHS=5\n",
    "\n",
    "python3 ../transf_exp_main_modified.py --output_dir ./tmp/ --overwrite_output_dir --do_train --do_eval --save_steps 0 --data_path $DATA_PATH --features_schema_path $FEATURE_SCHEMA_PATH --fp16 --data_loader_engine merlin --start_time_window_index 1 --final_time_window_index 2 --time_window_folder_pad_digits 4 --model_type xlnet --loss_type cross_entropy --per_device_eval_batch_size 128 --similarity_type concat_mlp --tf_out_activation tanh --inp_merge mlp --learning_rate_warmup_steps 0 --learning_rate_schedule linear_with_warmup --hidden_act gelu --num_train_epochs $NUM_EPOCHS --dataloader_drop_last --compute_metrics_each_n_steps 1 --session_seq_length_max 20 --eval_on_last_item_seq_only --mf_constrained_embeddings --layer_norm_featurewise --attn_type bi --per_device_train_batch_size 128 --learning_rate 0.0006667377132554976 --dropout 0.0 --input_dropout 0.1 --weight_decay 3.910060265627374e-05 --d_model 192 --item_embedding_dim 448 --n_layer 3 --n_head 16 --label_smoothing 0.0 --stochastic_shared_embeddings_replacement_prob 0.1 --item_id_embeddings_init_std 0.11 --other_embeddings_init_std 0.02 --eval_on_test_set --seed 100 --report_to none\n",
    "exit 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "770b3d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/10/2023 07:20:26 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: True\n",
      "03/10/2023 07:20:27 - WARNING - transformers4rec -   Projecting inputs of NextItemPredictionTask to'448' As weight tying requires the input dimension '192' to be equal to the item-id embedding dimension '448'\n",
      "[INFO|trainer.py:434] 2023-03-10 07:20:28,053 >> Using amp fp16 backend\n",
      "03/10/2023 07:20:28 - INFO - examples.t4rec_paper_experiments.t4r_paper_repro.exp_outputs -   Training, Model and Data parameters {'data_path': '/transformers4rec/examples/t4rec_paper_experiments/t4r_paper_repro/', 'features_schema_path': '/workspace/examples/t4rec_paper_experiments/datasets_configs/ecom_rees46/rees46_schema.pbtxt', 'start_time_window_index': 1, 'final_time_window_index': 2, 'time_window_folder_pad_digits': 4, 'no_incremental_training': False, 'training_time_window_size': 0, 'use_side_information_features': False, 'input_features_aggregation': 'concat', 'model_type': 'xlnet', 'tf_out_activation': 'tanh', 'mlm': False, 'mlm_probability': 0.15, 'plm': False, 'plm_probability': 0.25, 'plm_max_span_length': 5, 'plm_mask_input': False, 'plm_permute_all': False, 'rtd': False, 'rtd_sample_from_batch': False, 'rtd_use_batch_interaction': False, 'rtd_discriminator_loss_weight': 50, 'rtd_generator_loss_weight': 1, 'rtd_tied_generator': False, 'd_model': 192, 'n_layer': 3, 'n_head': 16, 'layer_norm_eps': 1e-12, 'initializer_range': 0.02, 'hidden_act': 'gelu', 'dropout': 0.0, 'summary_type': 'last', 'num_hidden_groups': 1, 'inner_group_num': 1, 'eval_on_last_item_seq_only': True, 'train_on_last_item_seq_only': False, 'mf_constrained_embeddings': True, 'item_embedding_dim': 448, 'numeric_features_project_to_embedding_dim': 0, 'numeric_features_soft_one_hot_encoding_num_embeddings': 0, 'stochastic_shared_embeddings_replacement_prob': 0.1, 'softmax_temperature': 1.0, 'label_smoothing': 0.0, 'embedding_dim_from_cardinality_multiplier': 2.0, 'item_id_embeddings_init_std': 0.11, 'other_embeddings_init_std': 0.02, 'layer_norm_featurewise': True, 'attn_type': 'bi', 'input_dropout': 0.1, 'loss_type': 'cross_entropy', 'similarity_type': 'concat_mlp', 'inp_merge': 'mlp', 'learning_rate_warmup_steps': 0, 'avg_session_length': None, 'output_dir': './tmp/', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 128, 'per_device_eval_batch_size': 128, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0006667377132554976, 'weight_decay': 3.910060265627374e-05, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 5.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': -1, 'log_level_replica': -1, 'log_on_each_node': True, 'logging_dir': './tmp/runs/Mar10_07-20-25_7dfa224f788e', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_steps': 0, 'save_total_limit': None, 'save_on_each_node': False, 'no_cuda': False, 'seed': 0, 'fp16': True, 'fp16_opt_level': 'O1', 'fp16_backend': 'auto', 'fp16_full_eval': False, 'local_rank': -1, 'xpu_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': True, 'eval_steps': None, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': None, 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'sharded_ddp': [], 'deepspeed': None, 'label_smoothing_factor': 0.0, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': [], 'ddp_find_unused_parameters': None, 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_token': None, 'gradient_checkpointing': False, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': None, '_n_gpu': 1, 'mp_parameters': '', 'max_sequence_length': 20, 'shuffle_buffer_size': 0, 'data_loader_engine': 'merlin', 'eval_on_test_set': True, 'eval_steps_on_train_set': 20, 'predict_top_k': 0, 'learning_rate_num_cosine_cycles_by_epoch': 1.25, 'log_predictions': False, 'compute_metrics_each_n_steps': 1, 'experiments_group': 'default', 'session_seq_length_max': 20, 'learning_rate_schedule': 'linear_with_warmup', 'validate_every': -1}\n",
      "[INFO|trainer.py:1196] 2023-03-10 07:20:28,547 >> ***** Running training *****\n",
      "[INFO|trainer.py:1197] 2023-03-10 07:20:28,547 >>   Num examples = 86528\n",
      "[INFO|trainer.py:1198] 2023-03-10 07:20:28,547 >>   Num Epochs = 5\n",
      "[INFO|trainer.py:1199] 2023-03-10 07:20:28,547 >>   Instantaneous batch size per device = 128\n",
      "[INFO|trainer.py:1200] 2023-03-10 07:20:28,547 >>   Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "[INFO|trainer.py:1201] 2023-03-10 07:20:28,547 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1202] 2023-03-10 07:20:28,547 >>   Total optimization steps = 3380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DLL 2023-03-10 07:20:28.053983 - PARAMETER data_path : /transformers4rec/examples/t4rec_paper_experiments/t4r_paper_repro/  features_schema_path : /workspace/examples/t4rec_paper_experiments/datasets_configs/ecom_rees46/rees46_schema.pbtxt  start_time_window_index : 1  final_time_window_index : 2  time_window_folder_pad_digits : 4  no_incremental_training : False  training_time_window_size : 0  use_side_information_features : False  input_features_aggregation : concat  model_type : xlnet  tf_out_activation : tanh  mlm : False  mlm_probability : 0.15  plm : False  plm_probability : 0.25  plm_max_span_length : 5  plm_mask_input : False  plm_permute_all : False  rtd : False  rtd_sample_from_batch : False  rtd_use_batch_interaction : False  rtd_discriminator_loss_weight : 50  rtd_generator_loss_weight : 1  rtd_tied_generator : False  d_model : 192  n_layer : 3  n_head : 16  layer_norm_eps : 1e-12  initializer_range : 0.02  hidden_act : gelu  dropout : 0.0  summary_type : last  num_hidden_groups : 1  inner_group_num : 1  eval_on_last_item_seq_only : True  train_on_last_item_seq_only : False  mf_constrained_embeddings : True  item_embedding_dim : 448  numeric_features_project_to_embedding_dim : 0  numeric_features_soft_one_hot_encoding_num_embeddings : 0  stochastic_shared_embeddings_replacement_prob : 0.1  softmax_temperature : 1.0  label_smoothing : 0.0  embedding_dim_from_cardinality_multiplier : 2.0  item_id_embeddings_init_std : 0.11  other_embeddings_init_std : 0.02  layer_norm_featurewise : True  attn_type : bi  input_dropout : 0.1  loss_type : cross_entropy  similarity_type : concat_mlp  inp_merge : mlp  learning_rate_warmup_steps : 0  avg_session_length : None  output_dir : ./tmp/  overwrite_output_dir : True  do_train : True  do_eval : True  do_predict : False  prediction_loss_only : False  per_device_train_batch_size : 128  per_device_eval_batch_size : 128  per_gpu_train_batch_size : None  per_gpu_eval_batch_size : None  gradient_accumulation_steps : 1  eval_accumulation_steps : None  learning_rate : 0.0006667377132554976  weight_decay : 3.910060265627374e-05  adam_beta1 : 0.9  adam_beta2 : 0.999  adam_epsilon : 1e-08  max_grad_norm : 1.0  num_train_epochs : 5.0  max_steps : -1  lr_scheduler_type : linear  warmup_ratio : 0.0  warmup_steps : 0  log_level : -1  log_level_replica : -1  log_on_each_node : True  logging_dir : ./tmp/runs/Mar10_07-20-25_7dfa224f788e  logging_first_step : False  logging_steps : 500  logging_nan_inf_filter : True  save_steps : 0  save_total_limit : None  save_on_each_node : False  no_cuda : False  seed : 0  fp16 : True  fp16_opt_level : O1  fp16_backend : auto  fp16_full_eval : False  local_rank : -1  xpu_backend : None  tpu_num_cores : None  tpu_metrics_debug : False  debug : []  dataloader_drop_last : True  eval_steps : None  dataloader_num_workers : 0  past_index : -1  run_name : None  disable_tqdm : False  remove_unused_columns : True  label_names : None  load_best_model_at_end : False  metric_for_best_model : None  greater_is_better : None  ignore_data_skip : False  sharded_ddp : []  deepspeed : None  label_smoothing_factor : 0.0  adafactor : False  group_by_length : False  length_column_name : length  report_to : []  ddp_find_unused_parameters : None  dataloader_pin_memory : True  skip_memory_metrics : True  use_legacy_prediction_loop : False  push_to_hub : False  resume_from_checkpoint : None  hub_model_id : None  hub_token : None  gradient_checkpointing : False  push_to_hub_model_id : None  push_to_hub_organization : None  push_to_hub_token : None  _n_gpu : 1  mp_parameters :   max_sequence_length : 20  shuffle_buffer_size : 0  data_loader_engine : merlin  eval_on_test_set : True  eval_steps_on_train_set : 20  predict_top_k : 0  learning_rate_num_cosine_cycles_by_epoch : 1.25  log_predictions : False  compute_metrics_each_n_steps : 1  experiments_group : default  session_seq_length_max : 20  learning_rate_schedule : linear_with_warmup  validate_every : -1 \n",
      "\n",
      "***** Launch training for day 1: *****\n",
      "{'loss': 6.6784, 'learning_rate': 0.0005681078740165187, 'epoch': 0.74}\n",
      "{'loss': 2.4454, 'learning_rate': 0.00046947803477753974, 'epoch': 1.48}\n",
      "{'loss': 1.9754, 'learning_rate': 0.0003708481955385607, 'epoch': 2.22}\n",
      "{'loss': 1.8708, 'learning_rate': 0.0002722183562995818, 'epoch': 2.96}\n",
      "{'loss': 1.7958, 'learning_rate': 0.0001735885170606029, 'epoch': 3.7}\n",
      "{'loss': 1.7419, 'learning_rate': 7.4958677821624e-05, 'epoch': 4.44}\n",
      "{'train_runtime': 337.8916, 'train_samples_per_second': 0.015, 'train_steps_per_second': 10.003, 'train_loss': 2.6348056228908563, 'epoch': 5.0}\n",
      "\n",
      "***** Evaluation results for day 2 (train set):*****\n",
      "\n",
      "{'train_/next-item/ndcg_at_10': 0.12325046211481094, 'train_/next-item/ndcg_at_20': 0.137022003531456, 'train_/next-item/recall_at_10': 0.19960938394069672, 'train_/next-item/recall_at_20': 0.25390625, 'train_/loss': 7.624682426452637, 'train_runtime': 0.6451, 'train_samples_per_second': 3968.659, 'train_steps_per_second': 31.005}\n",
      "\n",
      "***** Evaluation results for day 2 (eval set):*****\n",
      "\n",
      "{'eval_/next-item/ndcg_at_10': 0.08722994476556778, 'eval_/next-item/ndcg_at_20': 0.0991109311580658, 'eval_/next-item/recall_at_10': 0.145143061876297, 'eval_/next-item/recall_at_20': 0.1927710771560669, 'eval_/loss': 9.022594451904297, 'eval_runtime': 2.2602, 'eval_samples_per_second': 4700.388, 'eval_steps_per_second': 36.722}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-30' coro=<ScriptMagics.shebang.<locals>._handle_stream() done, defined at /usr/local/lib/python3.8/dist-packages/IPython/core/magics/script.py:211> exception=ValueError('Separator is not found, and chunk exceed the limit')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/asyncio/streams.py\", line 540, in readline\n",
      "    line = await self.readuntil(sep)\n",
      "  File \"/usr/lib/python3.8/asyncio/streams.py\", line 618, in readuntil\n",
      "    raise exceptions.LimitOverrunError(\n",
      "asyncio.exceptions.LimitOverrunError: Separator is not found, and chunk exceed the limit\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/magics/script.py\", line 213, in _handle_stream\n",
      "    line = (await stream.readline()).decode(\"utf8\")\n",
      "  File \"/usr/lib/python3.8/asyncio/streams.py\", line 549, in readline\n",
      "    raise ValueError(e.args[0])\n",
      "ValueError: Separator is not found, and chunk exceed the limit\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "FEATURE_SCHEMA_PATH=/workspace/examples/t4rec_paper_experiments/datasets_configs/ecom_rees46/rees46_schema.pbtxt\n",
    "DATA_PATH=/transformers4rec/examples/t4rec_paper_experiments/t4r_paper_repro/\n",
    "NUM_EPOCHS=5\n",
    "SEED=0\n",
    "\n",
    "python3 ../transf_exp_main_modified.py --output_dir ./tmp/ --overwrite_output_dir --do_train --do_eval --save_steps 0 --data_path $DATA_PATH --features_schema_path $FEATURE_SCHEMA_PATH --fp16 --data_loader_engine merlin --start_time_window_index 1 --final_time_window_index 2 --time_window_folder_pad_digits 4 --model_type xlnet --loss_type cross_entropy --per_device_eval_batch_size 128 --similarity_type concat_mlp --tf_out_activation tanh --inp_merge mlp --learning_rate_warmup_steps 0 --learning_rate_schedule linear_with_warmup --hidden_act gelu --num_train_epochs $NUM_EPOCHS --dataloader_drop_last --compute_metrics_each_n_steps 1 --session_seq_length_max 20 --eval_on_last_item_seq_only --mf_constrained_embeddings --layer_norm_featurewise --attn_type bi --per_device_train_batch_size 128 --learning_rate 0.0006667377132554976 --dropout 0.0 --input_dropout 0.1 --weight_decay 3.910060265627374e-05 --d_model 192 --item_embedding_dim 448 --n_layer 3 --n_head 16 --label_smoothing 0.0 --stochastic_shared_embeddings_replacement_prob 0.1 --item_id_embeddings_init_std 0.11 --other_embeddings_init_std 0.02 --eval_on_test_set --seed $SEED --report_to none\n",
    "exit 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32e29315",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/10/2023 07:26:15 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: True\n",
      "03/10/2023 07:26:17 - WARNING - transformers4rec -   Projecting inputs of NextItemPredictionTask to'448' As weight tying requires the input dimension '192' to be equal to the item-id embedding dimension '448'\n",
      "[INFO|trainer.py:434] 2023-03-10 07:26:17,384 >> Using amp fp16 backend\n",
      "03/10/2023 07:26:17 - INFO - examples.t4rec_paper_experiments.t4r_paper_repro.exp_outputs -   Training, Model and Data parameters {'data_path': '/transformers4rec/examples/t4rec_paper_experiments/t4r_paper_repro/', 'features_schema_path': '/workspace/examples/t4rec_paper_experiments/datasets_configs/ecom_rees46/rees46_schema.pbtxt', 'start_time_window_index': 1, 'final_time_window_index': 2, 'time_window_folder_pad_digits': 4, 'no_incremental_training': False, 'training_time_window_size': 0, 'use_side_information_features': False, 'input_features_aggregation': 'concat', 'model_type': 'xlnet', 'tf_out_activation': 'tanh', 'mlm': False, 'mlm_probability': 0.15, 'plm': False, 'plm_probability': 0.25, 'plm_max_span_length': 5, 'plm_mask_input': False, 'plm_permute_all': False, 'rtd': False, 'rtd_sample_from_batch': False, 'rtd_use_batch_interaction': False, 'rtd_discriminator_loss_weight': 50, 'rtd_generator_loss_weight': 1, 'rtd_tied_generator': False, 'd_model': 192, 'n_layer': 3, 'n_head': 16, 'layer_norm_eps': 1e-12, 'initializer_range': 0.02, 'hidden_act': 'gelu', 'dropout': 0.0, 'summary_type': 'last', 'num_hidden_groups': 1, 'inner_group_num': 1, 'eval_on_last_item_seq_only': True, 'train_on_last_item_seq_only': False, 'mf_constrained_embeddings': True, 'item_embedding_dim': 448, 'numeric_features_project_to_embedding_dim': 0, 'numeric_features_soft_one_hot_encoding_num_embeddings': 0, 'stochastic_shared_embeddings_replacement_prob': 0.1, 'softmax_temperature': 1.0, 'label_smoothing': 0.0, 'embedding_dim_from_cardinality_multiplier': 2.0, 'item_id_embeddings_init_std': 0.11, 'other_embeddings_init_std': 0.02, 'layer_norm_featurewise': True, 'attn_type': 'bi', 'input_dropout': 0.1, 'loss_type': 'cross_entropy', 'similarity_type': 'concat_mlp', 'inp_merge': 'mlp', 'learning_rate_warmup_steps': 0, 'avg_session_length': None, 'output_dir': './tmp/', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 128, 'per_device_eval_batch_size': 128, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0006667377132554976, 'weight_decay': 3.910060265627374e-05, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 5.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': -1, 'log_level_replica': -1, 'log_on_each_node': True, 'logging_dir': './tmp/runs/Mar10_07-26-14_7dfa224f788e', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_steps': 0, 'save_total_limit': None, 'save_on_each_node': False, 'no_cuda': False, 'seed': 1, 'fp16': True, 'fp16_opt_level': 'O1', 'fp16_backend': 'auto', 'fp16_full_eval': False, 'local_rank': -1, 'xpu_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': True, 'eval_steps': None, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': None, 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'sharded_ddp': [], 'deepspeed': None, 'label_smoothing_factor': 0.0, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': [], 'ddp_find_unused_parameters': None, 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_token': None, 'gradient_checkpointing': False, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': None, '_n_gpu': 1, 'mp_parameters': '', 'max_sequence_length': 20, 'shuffle_buffer_size': 0, 'data_loader_engine': 'merlin', 'eval_on_test_set': True, 'eval_steps_on_train_set': 20, 'predict_top_k': 0, 'learning_rate_num_cosine_cycles_by_epoch': 1.25, 'log_predictions': False, 'compute_metrics_each_n_steps': 1, 'experiments_group': 'default', 'session_seq_length_max': 20, 'learning_rate_schedule': 'linear_with_warmup', 'validate_every': -1}\n",
      "[INFO|trainer.py:1196] 2023-03-10 07:26:17,872 >> ***** Running training *****\n",
      "[INFO|trainer.py:1197] 2023-03-10 07:26:17,872 >>   Num examples = 86528\n",
      "[INFO|trainer.py:1198] 2023-03-10 07:26:17,872 >>   Num Epochs = 5\n",
      "[INFO|trainer.py:1199] 2023-03-10 07:26:17,872 >>   Instantaneous batch size per device = 128\n",
      "[INFO|trainer.py:1200] 2023-03-10 07:26:17,872 >>   Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "[INFO|trainer.py:1201] 2023-03-10 07:26:17,872 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1202] 2023-03-10 07:26:17,872 >>   Total optimization steps = 3380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DLL 2023-03-10 07:26:17.385530 - PARAMETER data_path : /transformers4rec/examples/t4rec_paper_experiments/t4r_paper_repro/  features_schema_path : /workspace/examples/t4rec_paper_experiments/datasets_configs/ecom_rees46/rees46_schema.pbtxt  start_time_window_index : 1  final_time_window_index : 2  time_window_folder_pad_digits : 4  no_incremental_training : False  training_time_window_size : 0  use_side_information_features : False  input_features_aggregation : concat  model_type : xlnet  tf_out_activation : tanh  mlm : False  mlm_probability : 0.15  plm : False  plm_probability : 0.25  plm_max_span_length : 5  plm_mask_input : False  plm_permute_all : False  rtd : False  rtd_sample_from_batch : False  rtd_use_batch_interaction : False  rtd_discriminator_loss_weight : 50  rtd_generator_loss_weight : 1  rtd_tied_generator : False  d_model : 192  n_layer : 3  n_head : 16  layer_norm_eps : 1e-12  initializer_range : 0.02  hidden_act : gelu  dropout : 0.0  summary_type : last  num_hidden_groups : 1  inner_group_num : 1  eval_on_last_item_seq_only : True  train_on_last_item_seq_only : False  mf_constrained_embeddings : True  item_embedding_dim : 448  numeric_features_project_to_embedding_dim : 0  numeric_features_soft_one_hot_encoding_num_embeddings : 0  stochastic_shared_embeddings_replacement_prob : 0.1  softmax_temperature : 1.0  label_smoothing : 0.0  embedding_dim_from_cardinality_multiplier : 2.0  item_id_embeddings_init_std : 0.11  other_embeddings_init_std : 0.02  layer_norm_featurewise : True  attn_type : bi  input_dropout : 0.1  loss_type : cross_entropy  similarity_type : concat_mlp  inp_merge : mlp  learning_rate_warmup_steps : 0  avg_session_length : None  output_dir : ./tmp/  overwrite_output_dir : True  do_train : True  do_eval : True  do_predict : False  prediction_loss_only : False  per_device_train_batch_size : 128  per_device_eval_batch_size : 128  per_gpu_train_batch_size : None  per_gpu_eval_batch_size : None  gradient_accumulation_steps : 1  eval_accumulation_steps : None  learning_rate : 0.0006667377132554976  weight_decay : 3.910060265627374e-05  adam_beta1 : 0.9  adam_beta2 : 0.999  adam_epsilon : 1e-08  max_grad_norm : 1.0  num_train_epochs : 5.0  max_steps : -1  lr_scheduler_type : linear  warmup_ratio : 0.0  warmup_steps : 0  log_level : -1  log_level_replica : -1  log_on_each_node : True  logging_dir : ./tmp/runs/Mar10_07-26-14_7dfa224f788e  logging_first_step : False  logging_steps : 500  logging_nan_inf_filter : True  save_steps : 0  save_total_limit : None  save_on_each_node : False  no_cuda : False  seed : 1  fp16 : True  fp16_opt_level : O1  fp16_backend : auto  fp16_full_eval : False  local_rank : -1  xpu_backend : None  tpu_num_cores : None  tpu_metrics_debug : False  debug : []  dataloader_drop_last : True  eval_steps : None  dataloader_num_workers : 0  past_index : -1  run_name : None  disable_tqdm : False  remove_unused_columns : True  label_names : None  load_best_model_at_end : False  metric_for_best_model : None  greater_is_better : None  ignore_data_skip : False  sharded_ddp : []  deepspeed : None  label_smoothing_factor : 0.0  adafactor : False  group_by_length : False  length_column_name : length  report_to : []  ddp_find_unused_parameters : None  dataloader_pin_memory : True  skip_memory_metrics : True  use_legacy_prediction_loop : False  push_to_hub : False  resume_from_checkpoint : None  hub_model_id : None  hub_token : None  gradient_checkpointing : False  push_to_hub_model_id : None  push_to_hub_organization : None  push_to_hub_token : None  _n_gpu : 1  mp_parameters :   max_sequence_length : 20  shuffle_buffer_size : 0  data_loader_engine : merlin  eval_on_test_set : True  eval_steps_on_train_set : 20  predict_top_k : 0  learning_rate_num_cosine_cycles_by_epoch : 1.25  log_predictions : False  compute_metrics_each_n_steps : 1  experiments_group : default  session_seq_length_max : 20  learning_rate_schedule : linear_with_warmup  validate_every : -1 \n",
      "\n",
      "***** Launch training for day 1: *****\n",
      "{'loss': 6.6644, 'learning_rate': 0.0005681078740165187, 'epoch': 0.74}\n",
      "{'loss': 2.3778, 'learning_rate': 0.00046947803477753974, 'epoch': 1.48}\n",
      "{'loss': 1.9486, 'learning_rate': 0.0003708481955385607, 'epoch': 2.22}\n",
      "{'loss': 1.8619, 'learning_rate': 0.0002722183562995818, 'epoch': 2.96}\n",
      "{'loss': 1.7841, 'learning_rate': 0.0001735885170606029, 'epoch': 3.7}\n",
      "{'loss': 1.7368, 'learning_rate': 7.4958677821624e-05, 'epoch': 4.44}\n",
      "{'train_runtime': 337.8499, 'train_samples_per_second': 0.015, 'train_steps_per_second': 10.004, 'train_loss': 2.613156272391596, 'epoch': 5.0}\n",
      "\n",
      "***** Evaluation results for day 2 (train set):*****\n",
      "\n",
      "{'train_/next-item/ndcg_at_10': 0.12271016836166382, 'train_/next-item/ndcg_at_20': 0.1380811482667923, 'train_/next-item/recall_at_10': 0.19843749701976776, 'train_/next-item/recall_at_20': 0.25859376788139343, 'train_/loss': 7.584864616394043, 'train_runtime': 0.6478, 'train_samples_per_second': 3951.826, 'train_steps_per_second': 30.874}\n",
      "\n",
      "***** Evaluation results for day 2 (eval set):*****\n",
      "\n",
      "{'eval_/next-item/ndcg_at_10': 0.08986585587263107, 'eval_/next-item/ndcg_at_20': 0.10167953372001648, 'eval_/next-item/recall_at_10': 0.14956700801849365, 'eval_/next-item/recall_at_20': 0.19663026928901672, 'eval_/loss': 9.000876426696777, 'eval_runtime': 2.2765, 'eval_samples_per_second': 4666.864, 'eval_steps_per_second': 36.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-35' coro=<ScriptMagics.shebang.<locals>._handle_stream() done, defined at /usr/local/lib/python3.8/dist-packages/IPython/core/magics/script.py:211> exception=ValueError('Separator is not found, and chunk exceed the limit')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/asyncio/streams.py\", line 540, in readline\n",
      "    line = await self.readuntil(sep)\n",
      "  File \"/usr/lib/python3.8/asyncio/streams.py\", line 618, in readuntil\n",
      "    raise exceptions.LimitOverrunError(\n",
      "asyncio.exceptions.LimitOverrunError: Separator is not found, and chunk exceed the limit\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/magics/script.py\", line 213, in _handle_stream\n",
      "    line = (await stream.readline()).decode(\"utf8\")\n",
      "  File \"/usr/lib/python3.8/asyncio/streams.py\", line 549, in readline\n",
      "    raise ValueError(e.args[0])\n",
      "ValueError: Separator is not found, and chunk exceed the limit\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "FEATURE_SCHEMA_PATH=/workspace/examples/t4rec_paper_experiments/datasets_configs/ecom_rees46/rees46_schema.pbtxt\n",
    "DATA_PATH=/transformers4rec/examples/t4rec_paper_experiments/t4r_paper_repro/\n",
    "NUM_EPOCHS=5\n",
    "SEED=1\n",
    "\n",
    "python3 ../transf_exp_main_modified.py --output_dir ./tmp/ --overwrite_output_dir --do_train --do_eval --save_steps 0 --data_path $DATA_PATH --features_schema_path $FEATURE_SCHEMA_PATH --fp16 --data_loader_engine merlin --start_time_window_index 1 --final_time_window_index 2 --time_window_folder_pad_digits 4 --model_type xlnet --loss_type cross_entropy --per_device_eval_batch_size 128 --similarity_type concat_mlp --tf_out_activation tanh --inp_merge mlp --learning_rate_warmup_steps 0 --learning_rate_schedule linear_with_warmup --hidden_act gelu --num_train_epochs $NUM_EPOCHS --dataloader_drop_last --compute_metrics_each_n_steps 1 --session_seq_length_max 20 --eval_on_last_item_seq_only --mf_constrained_embeddings --layer_norm_featurewise --attn_type bi --per_device_train_batch_size 128 --learning_rate 0.0006667377132554976 --dropout 0.0 --input_dropout 0.1 --weight_decay 3.910060265627374e-05 --d_model 192 --item_embedding_dim 448 --n_layer 3 --n_head 16 --label_smoothing 0.0 --stochastic_shared_embeddings_replacement_prob 0.1 --item_id_embeddings_init_std 0.11 --other_embeddings_init_std 0.02 --eval_on_test_set --seed $SEED --report_to none\n",
    "exit 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b87e4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/10/2023 07:32:05 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: True\n",
      "03/10/2023 07:32:06 - WARNING - transformers4rec -   Projecting inputs of NextItemPredictionTask to'448' As weight tying requires the input dimension '192' to be equal to the item-id embedding dimension '448'\n",
      "[INFO|trainer.py:434] 2023-03-10 07:32:06,807 >> Using amp fp16 backend\n",
      "03/10/2023 07:32:06 - INFO - examples.t4rec_paper_experiments.t4r_paper_repro.exp_outputs -   Training, Model and Data parameters {'data_path': '/transformers4rec/examples/t4rec_paper_experiments/t4r_paper_repro/', 'features_schema_path': '/workspace/examples/t4rec_paper_experiments/datasets_configs/ecom_rees46/rees46_schema.pbtxt', 'start_time_window_index': 1, 'final_time_window_index': 2, 'time_window_folder_pad_digits': 4, 'no_incremental_training': False, 'training_time_window_size': 0, 'use_side_information_features': False, 'input_features_aggregation': 'concat', 'model_type': 'xlnet', 'tf_out_activation': 'tanh', 'mlm': False, 'mlm_probability': 0.15, 'plm': False, 'plm_probability': 0.25, 'plm_max_span_length': 5, 'plm_mask_input': False, 'plm_permute_all': False, 'rtd': False, 'rtd_sample_from_batch': False, 'rtd_use_batch_interaction': False, 'rtd_discriminator_loss_weight': 50, 'rtd_generator_loss_weight': 1, 'rtd_tied_generator': False, 'd_model': 192, 'n_layer': 3, 'n_head': 16, 'layer_norm_eps': 1e-12, 'initializer_range': 0.02, 'hidden_act': 'gelu', 'dropout': 0.0, 'summary_type': 'last', 'num_hidden_groups': 1, 'inner_group_num': 1, 'eval_on_last_item_seq_only': True, 'train_on_last_item_seq_only': False, 'mf_constrained_embeddings': True, 'item_embedding_dim': 448, 'numeric_features_project_to_embedding_dim': 0, 'numeric_features_soft_one_hot_encoding_num_embeddings': 0, 'stochastic_shared_embeddings_replacement_prob': 0.1, 'softmax_temperature': 1.0, 'label_smoothing': 0.0, 'embedding_dim_from_cardinality_multiplier': 2.0, 'item_id_embeddings_init_std': 0.11, 'other_embeddings_init_std': 0.02, 'layer_norm_featurewise': True, 'attn_type': 'bi', 'input_dropout': 0.1, 'loss_type': 'cross_entropy', 'similarity_type': 'concat_mlp', 'inp_merge': 'mlp', 'learning_rate_warmup_steps': 0, 'avg_session_length': None, 'output_dir': './tmp/', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 128, 'per_device_eval_batch_size': 128, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0006667377132554976, 'weight_decay': 3.910060265627374e-05, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 5.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': -1, 'log_level_replica': -1, 'log_on_each_node': True, 'logging_dir': './tmp/runs/Mar10_07-32-04_7dfa224f788e', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_steps': 0, 'save_total_limit': None, 'save_on_each_node': False, 'no_cuda': False, 'seed': 2, 'fp16': True, 'fp16_opt_level': 'O1', 'fp16_backend': 'auto', 'fp16_full_eval': False, 'local_rank': -1, 'xpu_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': True, 'eval_steps': None, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': None, 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'sharded_ddp': [], 'deepspeed': None, 'label_smoothing_factor': 0.0, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': [], 'ddp_find_unused_parameters': None, 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_token': None, 'gradient_checkpointing': False, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': None, '_n_gpu': 1, 'mp_parameters': '', 'max_sequence_length': 20, 'shuffle_buffer_size': 0, 'data_loader_engine': 'merlin', 'eval_on_test_set': True, 'eval_steps_on_train_set': 20, 'predict_top_k': 0, 'learning_rate_num_cosine_cycles_by_epoch': 1.25, 'log_predictions': False, 'compute_metrics_each_n_steps': 1, 'experiments_group': 'default', 'session_seq_length_max': 20, 'learning_rate_schedule': 'linear_with_warmup', 'validate_every': -1}\n",
      "[INFO|trainer.py:1196] 2023-03-10 07:32:07,286 >> ***** Running training *****\n",
      "[INFO|trainer.py:1197] 2023-03-10 07:32:07,286 >>   Num examples = 86528\n",
      "[INFO|trainer.py:1198] 2023-03-10 07:32:07,286 >>   Num Epochs = 5\n",
      "[INFO|trainer.py:1199] 2023-03-10 07:32:07,286 >>   Instantaneous batch size per device = 128\n",
      "[INFO|trainer.py:1200] 2023-03-10 07:32:07,286 >>   Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "[INFO|trainer.py:1201] 2023-03-10 07:32:07,286 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1202] 2023-03-10 07:32:07,286 >>   Total optimization steps = 3380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DLL 2023-03-10 07:32:06.807964 - PARAMETER data_path : /transformers4rec/examples/t4rec_paper_experiments/t4r_paper_repro/  features_schema_path : /workspace/examples/t4rec_paper_experiments/datasets_configs/ecom_rees46/rees46_schema.pbtxt  start_time_window_index : 1  final_time_window_index : 2  time_window_folder_pad_digits : 4  no_incremental_training : False  training_time_window_size : 0  use_side_information_features : False  input_features_aggregation : concat  model_type : xlnet  tf_out_activation : tanh  mlm : False  mlm_probability : 0.15  plm : False  plm_probability : 0.25  plm_max_span_length : 5  plm_mask_input : False  plm_permute_all : False  rtd : False  rtd_sample_from_batch : False  rtd_use_batch_interaction : False  rtd_discriminator_loss_weight : 50  rtd_generator_loss_weight : 1  rtd_tied_generator : False  d_model : 192  n_layer : 3  n_head : 16  layer_norm_eps : 1e-12  initializer_range : 0.02  hidden_act : gelu  dropout : 0.0  summary_type : last  num_hidden_groups : 1  inner_group_num : 1  eval_on_last_item_seq_only : True  train_on_last_item_seq_only : False  mf_constrained_embeddings : True  item_embedding_dim : 448  numeric_features_project_to_embedding_dim : 0  numeric_features_soft_one_hot_encoding_num_embeddings : 0  stochastic_shared_embeddings_replacement_prob : 0.1  softmax_temperature : 1.0  label_smoothing : 0.0  embedding_dim_from_cardinality_multiplier : 2.0  item_id_embeddings_init_std : 0.11  other_embeddings_init_std : 0.02  layer_norm_featurewise : True  attn_type : bi  input_dropout : 0.1  loss_type : cross_entropy  similarity_type : concat_mlp  inp_merge : mlp  learning_rate_warmup_steps : 0  avg_session_length : None  output_dir : ./tmp/  overwrite_output_dir : True  do_train : True  do_eval : True  do_predict : False  prediction_loss_only : False  per_device_train_batch_size : 128  per_device_eval_batch_size : 128  per_gpu_train_batch_size : None  per_gpu_eval_batch_size : None  gradient_accumulation_steps : 1  eval_accumulation_steps : None  learning_rate : 0.0006667377132554976  weight_decay : 3.910060265627374e-05  adam_beta1 : 0.9  adam_beta2 : 0.999  adam_epsilon : 1e-08  max_grad_norm : 1.0  num_train_epochs : 5.0  max_steps : -1  lr_scheduler_type : linear  warmup_ratio : 0.0  warmup_steps : 0  log_level : -1  log_level_replica : -1  log_on_each_node : True  logging_dir : ./tmp/runs/Mar10_07-32-04_7dfa224f788e  logging_first_step : False  logging_steps : 500  logging_nan_inf_filter : True  save_steps : 0  save_total_limit : None  save_on_each_node : False  no_cuda : False  seed : 2  fp16 : True  fp16_opt_level : O1  fp16_backend : auto  fp16_full_eval : False  local_rank : -1  xpu_backend : None  tpu_num_cores : None  tpu_metrics_debug : False  debug : []  dataloader_drop_last : True  eval_steps : None  dataloader_num_workers : 0  past_index : -1  run_name : None  disable_tqdm : False  remove_unused_columns : True  label_names : None  load_best_model_at_end : False  metric_for_best_model : None  greater_is_better : None  ignore_data_skip : False  sharded_ddp : []  deepspeed : None  label_smoothing_factor : 0.0  adafactor : False  group_by_length : False  length_column_name : length  report_to : []  ddp_find_unused_parameters : None  dataloader_pin_memory : True  skip_memory_metrics : True  use_legacy_prediction_loop : False  push_to_hub : False  resume_from_checkpoint : None  hub_model_id : None  hub_token : None  gradient_checkpointing : False  push_to_hub_model_id : None  push_to_hub_organization : None  push_to_hub_token : None  _n_gpu : 1  mp_parameters :   max_sequence_length : 20  shuffle_buffer_size : 0  data_loader_engine : merlin  eval_on_test_set : True  eval_steps_on_train_set : 20  predict_top_k : 0  learning_rate_num_cosine_cycles_by_epoch : 1.25  log_predictions : False  compute_metrics_each_n_steps : 1  experiments_group : default  session_seq_length_max : 20  learning_rate_schedule : linear_with_warmup  validate_every : -1 \n",
      "\n",
      "***** Launch training for day 1: *****\n",
      "{'loss': 6.624, 'learning_rate': 0.0005681078740165187, 'epoch': 0.74}\n",
      "{'loss': 2.3857, 'learning_rate': 0.00046947803477753974, 'epoch': 1.48}\n",
      "{'loss': 1.962, 'learning_rate': 0.0003708481955385607, 'epoch': 2.22}\n",
      "{'loss': 1.8662, 'learning_rate': 0.0002722183562995818, 'epoch': 2.96}\n",
      "{'loss': 1.784, 'learning_rate': 0.0001735885170606029, 'epoch': 3.7}\n",
      "{'loss': 1.7199, 'learning_rate': 7.4958677821624e-05, 'epoch': 4.44}\n",
      "{'train_runtime': 337.7988, 'train_samples_per_second': 0.015, 'train_steps_per_second': 10.006, 'train_loss': 2.6095561732907266, 'epoch': 5.0}\n",
      "\n",
      "***** Evaluation results for day 2 (train set):*****\n",
      "\n",
      "{'train_/next-item/ndcg_at_10': 0.12347330152988434, 'train_/next-item/ndcg_at_20': 0.137996107339859, 'train_/next-item/recall_at_10': 0.20078125596046448, 'train_/next-item/recall_at_20': 0.25859376788139343, 'train_/loss': 7.582167148590088, 'train_runtime': 0.6507, 'train_samples_per_second': 3934.492, 'train_steps_per_second': 30.738}\n",
      "\n",
      "***** Evaluation results for day 2 (eval set):*****\n",
      "\n",
      "{'eval_/next-item/ndcg_at_10': 0.08896206319332123, 'eval_/next-item/ndcg_at_20': 0.10121969878673553, 'eval_/next-item/recall_at_10': 0.1499435156583786, 'eval_/next-item/recall_at_20': 0.1987951695919037, 'eval_/loss': 8.977458953857422, 'eval_runtime': 2.2602, 'eval_samples_per_second': 4700.428, 'eval_steps_per_second': 36.722}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-40' coro=<ScriptMagics.shebang.<locals>._handle_stream() done, defined at /usr/local/lib/python3.8/dist-packages/IPython/core/magics/script.py:211> exception=ValueError('Separator is not found, and chunk exceed the limit')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/asyncio/streams.py\", line 540, in readline\n",
      "    line = await self.readuntil(sep)\n",
      "  File \"/usr/lib/python3.8/asyncio/streams.py\", line 618, in readuntil\n",
      "    raise exceptions.LimitOverrunError(\n",
      "asyncio.exceptions.LimitOverrunError: Separator is not found, and chunk exceed the limit\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/magics/script.py\", line 213, in _handle_stream\n",
      "    line = (await stream.readline()).decode(\"utf8\")\n",
      "  File \"/usr/lib/python3.8/asyncio/streams.py\", line 549, in readline\n",
      "    raise ValueError(e.args[0])\n",
      "ValueError: Separator is not found, and chunk exceed the limit\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "FEATURE_SCHEMA_PATH=/workspace/examples/t4rec_paper_experiments/datasets_configs/ecom_rees46/rees46_schema.pbtxt\n",
    "DATA_PATH=/transformers4rec/examples/t4rec_paper_experiments/t4r_paper_repro/\n",
    "NUM_EPOCHS=5\n",
    "SEED=2\n",
    "\n",
    "python3 ../transf_exp_main_modified.py --output_dir ./tmp/ --overwrite_output_dir --do_train --do_eval --save_steps 0 --data_path $DATA_PATH --features_schema_path $FEATURE_SCHEMA_PATH --fp16 --data_loader_engine merlin --start_time_window_index 1 --final_time_window_index 2 --time_window_folder_pad_digits 4 --model_type xlnet --loss_type cross_entropy --per_device_eval_batch_size 128 --similarity_type concat_mlp --tf_out_activation tanh --inp_merge mlp --learning_rate_warmup_steps 0 --learning_rate_schedule linear_with_warmup --hidden_act gelu --num_train_epochs $NUM_EPOCHS --dataloader_drop_last --compute_metrics_each_n_steps 1 --session_seq_length_max 20 --eval_on_last_item_seq_only --mf_constrained_embeddings --layer_norm_featurewise --attn_type bi --per_device_train_batch_size 128 --learning_rate 0.0006667377132554976 --dropout 0.0 --input_dropout 0.1 --weight_decay 3.910060265627374e-05 --d_model 192 --item_embedding_dim 448 --n_layer 3 --n_head 16 --label_smoothing 0.0 --stochastic_shared_embeddings_replacement_prob 0.1 --item_id_embeddings_init_std 0.11 --other_embeddings_init_std 0.02 --eval_on_test_set --seed $SEED --report_to none\n",
    "exit 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c0d111b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/10/2023 07:37:54 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: True\n",
      "03/10/2023 07:37:56 - WARNING - transformers4rec -   Projecting inputs of NextItemPredictionTask to'448' As weight tying requires the input dimension '192' to be equal to the item-id embedding dimension '448'\n",
      "[INFO|trainer.py:434] 2023-03-10 07:37:56,124 >> Using amp fp16 backend\n",
      "03/10/2023 07:37:56 - INFO - examples.t4rec_paper_experiments.t4r_paper_repro.exp_outputs -   Training, Model and Data parameters {'data_path': '/transformers4rec/examples/t4rec_paper_experiments/t4r_paper_repro/', 'features_schema_path': '/workspace/examples/t4rec_paper_experiments/datasets_configs/ecom_rees46/rees46_schema.pbtxt', 'start_time_window_index': 1, 'final_time_window_index': 2, 'time_window_folder_pad_digits': 4, 'no_incremental_training': False, 'training_time_window_size': 0, 'use_side_information_features': False, 'input_features_aggregation': 'concat', 'model_type': 'xlnet', 'tf_out_activation': 'tanh', 'mlm': False, 'mlm_probability': 0.15, 'plm': False, 'plm_probability': 0.25, 'plm_max_span_length': 5, 'plm_mask_input': False, 'plm_permute_all': False, 'rtd': False, 'rtd_sample_from_batch': False, 'rtd_use_batch_interaction': False, 'rtd_discriminator_loss_weight': 50, 'rtd_generator_loss_weight': 1, 'rtd_tied_generator': False, 'd_model': 192, 'n_layer': 3, 'n_head': 16, 'layer_norm_eps': 1e-12, 'initializer_range': 0.02, 'hidden_act': 'gelu', 'dropout': 0.0, 'summary_type': 'last', 'num_hidden_groups': 1, 'inner_group_num': 1, 'eval_on_last_item_seq_only': True, 'train_on_last_item_seq_only': False, 'mf_constrained_embeddings': True, 'item_embedding_dim': 448, 'numeric_features_project_to_embedding_dim': 0, 'numeric_features_soft_one_hot_encoding_num_embeddings': 0, 'stochastic_shared_embeddings_replacement_prob': 0.1, 'softmax_temperature': 1.0, 'label_smoothing': 0.0, 'embedding_dim_from_cardinality_multiplier': 2.0, 'item_id_embeddings_init_std': 0.11, 'other_embeddings_init_std': 0.02, 'layer_norm_featurewise': True, 'attn_type': 'bi', 'input_dropout': 0.1, 'loss_type': 'cross_entropy', 'similarity_type': 'concat_mlp', 'inp_merge': 'mlp', 'learning_rate_warmup_steps': 0, 'avg_session_length': None, 'output_dir': './tmp/', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 128, 'per_device_eval_batch_size': 128, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0006667377132554976, 'weight_decay': 3.910060265627374e-05, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 5.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': -1, 'log_level_replica': -1, 'log_on_each_node': True, 'logging_dir': './tmp/runs/Mar10_07-37-53_7dfa224f788e', 'logging_first_step': False, 'logging_steps': 500, 'logging_nan_inf_filter': True, 'save_steps': 0, 'save_total_limit': None, 'save_on_each_node': False, 'no_cuda': False, 'seed': 3, 'fp16': True, 'fp16_opt_level': 'O1', 'fp16_backend': 'auto', 'fp16_full_eval': False, 'local_rank': -1, 'xpu_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': True, 'eval_steps': None, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': None, 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'sharded_ddp': [], 'deepspeed': None, 'label_smoothing_factor': 0.0, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': [], 'ddp_find_unused_parameters': None, 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_token': None, 'gradient_checkpointing': False, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': None, '_n_gpu': 1, 'mp_parameters': '', 'max_sequence_length': 20, 'shuffle_buffer_size': 0, 'data_loader_engine': 'merlin', 'eval_on_test_set': True, 'eval_steps_on_train_set': 20, 'predict_top_k': 0, 'learning_rate_num_cosine_cycles_by_epoch': 1.25, 'log_predictions': False, 'compute_metrics_each_n_steps': 1, 'experiments_group': 'default', 'session_seq_length_max': 20, 'learning_rate_schedule': 'linear_with_warmup', 'validate_every': -1}\n",
      "[INFO|trainer.py:1196] 2023-03-10 07:37:56,606 >> ***** Running training *****\n",
      "[INFO|trainer.py:1197] 2023-03-10 07:37:56,606 >>   Num examples = 86528\n",
      "[INFO|trainer.py:1198] 2023-03-10 07:37:56,606 >>   Num Epochs = 5\n",
      "[INFO|trainer.py:1199] 2023-03-10 07:37:56,606 >>   Instantaneous batch size per device = 128\n",
      "[INFO|trainer.py:1200] 2023-03-10 07:37:56,606 >>   Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "[INFO|trainer.py:1201] 2023-03-10 07:37:56,606 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1202] 2023-03-10 07:37:56,606 >>   Total optimization steps = 3380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DLL 2023-03-10 07:37:56.124693 - PARAMETER data_path : /transformers4rec/examples/t4rec_paper_experiments/t4r_paper_repro/  features_schema_path : /workspace/examples/t4rec_paper_experiments/datasets_configs/ecom_rees46/rees46_schema.pbtxt  start_time_window_index : 1  final_time_window_index : 2  time_window_folder_pad_digits : 4  no_incremental_training : False  training_time_window_size : 0  use_side_information_features : False  input_features_aggregation : concat  model_type : xlnet  tf_out_activation : tanh  mlm : False  mlm_probability : 0.15  plm : False  plm_probability : 0.25  plm_max_span_length : 5  plm_mask_input : False  plm_permute_all : False  rtd : False  rtd_sample_from_batch : False  rtd_use_batch_interaction : False  rtd_discriminator_loss_weight : 50  rtd_generator_loss_weight : 1  rtd_tied_generator : False  d_model : 192  n_layer : 3  n_head : 16  layer_norm_eps : 1e-12  initializer_range : 0.02  hidden_act : gelu  dropout : 0.0  summary_type : last  num_hidden_groups : 1  inner_group_num : 1  eval_on_last_item_seq_only : True  train_on_last_item_seq_only : False  mf_constrained_embeddings : True  item_embedding_dim : 448  numeric_features_project_to_embedding_dim : 0  numeric_features_soft_one_hot_encoding_num_embeddings : 0  stochastic_shared_embeddings_replacement_prob : 0.1  softmax_temperature : 1.0  label_smoothing : 0.0  embedding_dim_from_cardinality_multiplier : 2.0  item_id_embeddings_init_std : 0.11  other_embeddings_init_std : 0.02  layer_norm_featurewise : True  attn_type : bi  input_dropout : 0.1  loss_type : cross_entropy  similarity_type : concat_mlp  inp_merge : mlp  learning_rate_warmup_steps : 0  avg_session_length : None  output_dir : ./tmp/  overwrite_output_dir : True  do_train : True  do_eval : True  do_predict : False  prediction_loss_only : False  per_device_train_batch_size : 128  per_device_eval_batch_size : 128  per_gpu_train_batch_size : None  per_gpu_eval_batch_size : None  gradient_accumulation_steps : 1  eval_accumulation_steps : None  learning_rate : 0.0006667377132554976  weight_decay : 3.910060265627374e-05  adam_beta1 : 0.9  adam_beta2 : 0.999  adam_epsilon : 1e-08  max_grad_norm : 1.0  num_train_epochs : 5.0  max_steps : -1  lr_scheduler_type : linear  warmup_ratio : 0.0  warmup_steps : 0  log_level : -1  log_level_replica : -1  log_on_each_node : True  logging_dir : ./tmp/runs/Mar10_07-37-53_7dfa224f788e  logging_first_step : False  logging_steps : 500  logging_nan_inf_filter : True  save_steps : 0  save_total_limit : None  save_on_each_node : False  no_cuda : False  seed : 3  fp16 : True  fp16_opt_level : O1  fp16_backend : auto  fp16_full_eval : False  local_rank : -1  xpu_backend : None  tpu_num_cores : None  tpu_metrics_debug : False  debug : []  dataloader_drop_last : True  eval_steps : None  dataloader_num_workers : 0  past_index : -1  run_name : None  disable_tqdm : False  remove_unused_columns : True  label_names : None  load_best_model_at_end : False  metric_for_best_model : None  greater_is_better : None  ignore_data_skip : False  sharded_ddp : []  deepspeed : None  label_smoothing_factor : 0.0  adafactor : False  group_by_length : False  length_column_name : length  report_to : []  ddp_find_unused_parameters : None  dataloader_pin_memory : True  skip_memory_metrics : True  use_legacy_prediction_loop : False  push_to_hub : False  resume_from_checkpoint : None  hub_model_id : None  hub_token : None  gradient_checkpointing : False  push_to_hub_model_id : None  push_to_hub_organization : None  push_to_hub_token : None  _n_gpu : 1  mp_parameters :   max_sequence_length : 20  shuffle_buffer_size : 0  data_loader_engine : merlin  eval_on_test_set : True  eval_steps_on_train_set : 20  predict_top_k : 0  learning_rate_num_cosine_cycles_by_epoch : 1.25  log_predictions : False  compute_metrics_each_n_steps : 1  experiments_group : default  session_seq_length_max : 20  learning_rate_schedule : linear_with_warmup  validate_every : -1 \n",
      "\n",
      "***** Launch training for day 1: *****\n",
      "{'loss': 6.7871, 'learning_rate': 0.0005681078740165187, 'epoch': 0.74}\n",
      "{'loss': 2.4843, 'learning_rate': 0.00046947803477753974, 'epoch': 1.48}\n",
      "{'loss': 1.9926, 'learning_rate': 0.0003708481955385607, 'epoch': 2.22}\n",
      "{'loss': 1.872, 'learning_rate': 0.0002722183562995818, 'epoch': 2.96}\n",
      "{'loss': 1.7884, 'learning_rate': 0.0001735885170606029, 'epoch': 3.7}\n",
      "{'loss': 1.7512, 'learning_rate': 7.4958677821624e-05, 'epoch': 4.44}\n",
      "{'train_runtime': 337.9889, 'train_samples_per_second': 0.015, 'train_steps_per_second': 10.0, 'train_loss': 2.6576913867476426, 'epoch': 5.0}\n",
      "\n",
      "***** Evaluation results for day 2 (train set):*****\n",
      "\n",
      "{'train_/next-item/ndcg_at_10': 0.12272482365369797, 'train_/next-item/ndcg_at_20': 0.13889344036579132, 'train_/next-item/recall_at_10': 0.1953125, 'train_/next-item/recall_at_20': 0.25859376788139343, 'train_/loss': 7.600445747375488, 'train_runtime': 0.6514, 'train_samples_per_second': 3930.07, 'train_steps_per_second': 30.704}\n",
      "\n",
      "***** Evaluation results for day 2 (eval set):*****\n",
      "\n",
      "{'eval_/next-item/ndcg_at_10': 0.08895686268806458, 'eval_/next-item/ndcg_at_20': 0.09970034658908844, 'eval_/next-item/recall_at_10': 0.14909638464450836, 'eval_/next-item/recall_at_20': 0.19145330786705017, 'eval_/loss': 9.008366584777832, 'eval_runtime': 2.2737, 'eval_samples_per_second': 4672.54, 'eval_steps_per_second': 36.504}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-45' coro=<ScriptMagics.shebang.<locals>._handle_stream() done, defined at /usr/local/lib/python3.8/dist-packages/IPython/core/magics/script.py:211> exception=ValueError('Separator is not found, and chunk exceed the limit')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/asyncio/streams.py\", line 540, in readline\n",
      "    line = await self.readuntil(sep)\n",
      "  File \"/usr/lib/python3.8/asyncio/streams.py\", line 618, in readuntil\n",
      "    raise exceptions.LimitOverrunError(\n",
      "asyncio.exceptions.LimitOverrunError: Separator is not found, and chunk exceed the limit\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/magics/script.py\", line 213, in _handle_stream\n",
      "    line = (await stream.readline()).decode(\"utf8\")\n",
      "  File \"/usr/lib/python3.8/asyncio/streams.py\", line 549, in readline\n",
      "    raise ValueError(e.args[0])\n",
      "ValueError: Separator is not found, and chunk exceed the limit\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "FEATURE_SCHEMA_PATH=/workspace/examples/t4rec_paper_experiments/datasets_configs/ecom_rees46/rees46_schema.pbtxt\n",
    "DATA_PATH=/transformers4rec/examples/t4rec_paper_experiments/t4r_paper_repro/\n",
    "NUM_EPOCHS=5\n",
    "SEED=3\n",
    "\n",
    "python3 ../transf_exp_main_modified.py --output_dir ./tmp/ --overwrite_output_dir --do_train --do_eval --save_steps 0 --data_path $DATA_PATH --features_schema_path $FEATURE_SCHEMA_PATH --fp16 --data_loader_engine merlin --start_time_window_index 1 --final_time_window_index 2 --time_window_folder_pad_digits 4 --model_type xlnet --loss_type cross_entropy --per_device_eval_batch_size 128 --similarity_type concat_mlp --tf_out_activation tanh --inp_merge mlp --learning_rate_warmup_steps 0 --learning_rate_schedule linear_with_warmup --hidden_act gelu --num_train_epochs $NUM_EPOCHS --dataloader_drop_last --compute_metrics_each_n_steps 1 --session_seq_length_max 20 --eval_on_last_item_seq_only --mf_constrained_embeddings --layer_norm_featurewise --attn_type bi --per_device_train_batch_size 128 --learning_rate 0.0006667377132554976 --dropout 0.0 --input_dropout 0.1 --weight_decay 3.910060265627374e-05 --d_model 192 --item_embedding_dim 448 --n_layer 3 --n_head 16 --label_smoothing 0.0 --stochastic_shared_embeddings_replacement_prob 0.1 --item_id_embeddings_init_std 0.11 --other_embeddings_init_std 0.02 --eval_on_test_set --seed $SEED --report_to none\n",
    "exit 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
