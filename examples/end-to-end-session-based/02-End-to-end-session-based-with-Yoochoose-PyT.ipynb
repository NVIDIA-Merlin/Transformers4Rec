{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fb18ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2022 NVIDIA Corporation. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "# Each user is responsible for checking the content of datasets and the\n",
    "# applicable licenses and determining if suitable for the intended use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378ff149",
   "metadata": {
    "tags": []
   },
   "source": [
    "<img src=\"https://developer.download.nvidia.com/notebooks/dlsw-notebooks/merlin_transformers4rec_end-to-end-session-based-02-end-to-end-session-based-with-yoochoose-pyt/nvidia_logo.png\" style=\"width: 90px; float: right;\">\n",
    "\n",
    "# End-to-end session-based recommendations with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe975de6",
   "metadata": {},
   "source": [
    "In recent years, several deep learning-based algorithms have been proposed for recommendation systems while its adoption in industry deployments have been steeply growing. In particular, NLP inspired approaches have been successfully adapted for sequential and session-based recommendation problems, which are important for many domains like e-commerce, news and streaming media. Session-Based Recommender Systems (SBRS) have been proposed to model the sequence of interactions within the current user session, where a session is a short sequence of user interactions typically bounded by user inactivity. They have recently gained popularity due to their ability to capture short-term or contextual user preferences towards items. \n",
    "\n",
    "The field of NLP has evolved significantly within the last decade, particularly due to the increased usage of deep learning. As a result, state of the art NLP approaches have inspired RecSys practitioners and researchers to adapt those architectures, especially for sequential and session-based recommendation problems. Here, we leverage one of the state-of-the-art Transformer-based architecture, [XLNet](https://arxiv.org/abs/1906.08237) with Masked Language Modeling (MLM) training technique (see our [tutorial](https://github.com/NVIDIA-Merlin/Transformers4Rec/tree/main/examples/tutorial) for details) for training a session-based model.\n",
    "\n",
    "In this end-to-end-session-based recommnender model example, we use `Transformers4Rec` library, which leverages the popular [HuggingFaceâ€™s Transformers](https://github.com/huggingface/transformers) NLP library and make it possible to experiment with cutting-edge implementation of such architectures for sequential and session-based recommendation problems. For detailed explanations of the building blocks of Transformers4Rec meta-architecture visit [getting-started-session-based](https://github.com/NVIDIA-Merlin/Transformers4Rec/tree/main/examples/getting-started-session-based) and [tutorial](https://github.com/NVIDIA-Merlin/Transformers4Rec/tree/main/examples/tutorial) example notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7516d46",
   "metadata": {},
   "source": [
    "## 1. Model definition using Transformers4Rec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8642b00",
   "metadata": {},
   "source": [
    "In the previous notebook, we have created sequential features and saved our processed data frames as parquet files. Now we use these processed parquet files to train a session-based recommendation model with the XLNet architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bc0fdb",
   "metadata": {},
   "source": [
    "### 1.1 Get the schema "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d52653",
   "metadata": {},
   "source": [
    "The library uses a schema format to configure the input features and automatically creates the necessary layers. This *protobuf* text file contains the description of each input feature by defining: the name, the type, the number of elements of a list column,  the cardinality of a categorical feature and the min and max values of each feature. In addition, the annotation field contains the tags such as specifying the `continuous` and `categorical` features, the `target` column or the `item_id` feature, among others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83162988-58c7-45b2-9be2-a1039a786553",
   "metadata": {},
   "source": [
    "We create the schema object by reading the processed train parquet file generated by NVTabular pipeline in the previous, 01-ETL-with-NVTabular, notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdc53326-860b-4cc3-b465-9cf6d4586c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "INPUT_DATA_DIR = os.environ.get(\"INPUT_DATA_DIR\", \"/workspace/data\")\n",
    "OUTPUT_DIR = os.environ.get(\"OUTPUT_DIR\", f\"{INPUT_DATA_DIR}/preproc_sessions_by_day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c80c3dd1-7390-46b1-97ba-0768b95502ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/merlin/dtypes/mappings/tf.py:52: UserWarning: Tensorflow dtype mappings did not load successfully due to an error: No module named 'tensorflow'\n",
      "  warn(f\"Tensorflow dtype mappings did not load successfully due to an error: {exc.msg}\")\n",
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/usr/local/lib/python3.8/dist-packages/merlin/schema/tags.py:149: UserWarning: Compound tags like Tags.ITEM_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [<Tags.ITEM: 'item'>, <Tags.ID: 'id'>].\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from merlin.schema import Schema\n",
    "from merlin.io import Dataset\n",
    "\n",
    "train = Dataset(os.path.join(INPUT_DATA_DIR, \"processed_nvt/part_0.parquet\"))\n",
    "schema = train.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab6407d",
   "metadata": {},
   "source": [
    "We can select the subset of features we want to use for training the model by their tags or their names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2a57f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = schema.select_by_name(\n",
    "   ['item_id-list', 'category-list', 'product_recency_days_log_norm-list', 'et_dayofweek_sin-list']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaba9e00-23cc-49fb-9c57-1ec4f2a7c7eb",
   "metadata": {},
   "source": [
    "We can print out the schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25fc2490-1daa-43f7-a052-1eb0d262bd5c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>tags</th>\n",
       "      <th>dtype</th>\n",
       "      <th>is_list</th>\n",
       "      <th>is_ragged</th>\n",
       "      <th>properties.num_buckets</th>\n",
       "      <th>properties.freq_threshold</th>\n",
       "      <th>properties.max_size</th>\n",
       "      <th>properties.start_index</th>\n",
       "      <th>properties.cat_path</th>\n",
       "      <th>properties.embedding_sizes.cardinality</th>\n",
       "      <th>properties.embedding_sizes.dimension</th>\n",
       "      <th>properties.domain.min</th>\n",
       "      <th>properties.domain.max</th>\n",
       "      <th>properties.domain.name</th>\n",
       "      <th>properties.value_count.min</th>\n",
       "      <th>properties.value_count.max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>item_id-list</td>\n",
       "      <td>(Tags.LIST, Tags.ID, Tags.ITEM_ID, Tags.CATEGO...</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>.//categories/unique.item_id.parquet</td>\n",
       "      <td>52741.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52740.0</td>\n",
       "      <td>item_id</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>category-list</td>\n",
       "      <td>(Tags.CATEGORICAL, Tags.LIST)</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>.//categories/unique.category.parquet</td>\n",
       "      <td>336.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>category</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>product_recency_days_log_norm-list</td>\n",
       "      <td>(Tags.CONTINUOUS, Tags.LIST)</td>\n",
       "      <td>DType(name='float32', element_type=&lt;ElementTyp...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>et_dayofweek_sin-list</td>\n",
       "      <td>(Tags.CONTINUOUS, Tags.LIST)</td>\n",
       "      <td>DType(name='float32', element_type=&lt;ElementTyp...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "[{'name': 'item_id-list', 'tags': {<Tags.LIST: 'list'>, <Tags.ID: 'id'>, <Tags.ITEM_ID: 'item_id'>, <Tags.CATEGORICAL: 'categorical'>, <Tags.ITEM: 'item'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0.0, 'max_size': 0.0, 'start_index': 1.0, 'cat_path': './/categories/unique.item_id.parquet', 'embedding_sizes': {'cardinality': 52741.0, 'dimension': 512.0}, 'domain': {'min': 0, 'max': 52740, 'name': 'item_id'}, 'value_count': {'min': 20, 'max': 20}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=20, max=20)))), 'is_list': True, 'is_ragged': False}, {'name': 'category-list', 'tags': {<Tags.CATEGORICAL: 'categorical'>, <Tags.LIST: 'list'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0.0, 'max_size': 0.0, 'start_index': 1.0, 'cat_path': './/categories/unique.category.parquet', 'embedding_sizes': {'cardinality': 336.0, 'dimension': 42.0}, 'domain': {'min': 0, 'max': 335, 'name': 'category'}, 'value_count': {'min': 20, 'max': 20}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=20, max=20)))), 'is_list': True, 'is_ragged': False}, {'name': 'product_recency_days_log_norm-list', 'tags': {<Tags.CONTINUOUS: 'continuous'>, <Tags.LIST: 'list'>}, 'properties': {'value_count': {'min': 20, 'max': 20}}, 'dtype': DType(name='float32', element_type=<ElementType.Float: 'float'>, element_size=32, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=20, max=20)))), 'is_list': True, 'is_ragged': False}, {'name': 'et_dayofweek_sin-list', 'tags': {<Tags.CONTINUOUS: 'continuous'>, <Tags.LIST: 'list'>}, 'properties': {'value_count': {'min': 20, 'max': 20}}, 'dtype': DType(name='float32', element_type=<ElementType.Float: 'float'>, element_size=32, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=20, max=20)))), 'is_list': True, 'is_ragged': False}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79ca4c0",
   "metadata": {},
   "source": [
    "### 1.2 Define the end-to-end Session-based Transformer-based recommendation model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e74ac27",
   "metadata": {
    "tags": []
   },
   "source": [
    "For defining a session-based recommendation model, the end-to-end model definition requires four steps:\n",
    "\n",
    "1. Instantiate [TabularSequenceFeatures](https://nvidia-merlin.github.io/Transformers4Rec/main/api/transformers4rec.tf.features.html?highlight=tabularsequence#transformers4rec.tf.features.sequence.TabularSequenceFeatures) input-module from schema to prepare the embedding tables of categorical variables and project continuous features, if specified. In addition, the module provides different aggregation methods (e.g. 'concat', 'elementwise-sum') to merge input features and generate the sequence of interactions embeddings. The module also supports language modeling tasks to prepare masked labels for training and evaluation (e.g: 'mlm' for masked language modeling) \n",
    "\n",
    "2. Next, we need to define one or multiple prediction tasks. For this demo, we are going to use [NextItemPredictionTask](https://nvidia-merlin.github.io/Transformers4Rec/main/api/transformers4rec.tf.model.html?highlight=nextitem#transformers4rec.tf.model.prediction_task.NextItemPredictionTask) with `Masked Language modeling`: during training, randomly selected items are masked and predicted using the unmasked sequence items. For inference, it is meant to always predict the next item to be interacted with.\n",
    "\n",
    "3. Then we construct a `transformer_config` based on the architectures provided by [Hugging Face Transformers](https://github.com/huggingface/transformers) framework. </a>\n",
    "\n",
    "4. Finally we link the transformer-body to the inputs and the prediction tasks to get the final pytorch `Model` class.\n",
    "    \n",
    "For more details about the features supported by each sub-module, please check out the library [documentation](https://nvidia-merlin.github.io/Transformers4Rec/main/index.html) page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d79c0e1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Projecting inputs of NextItemPredictionTask to'64' As weight tying requires the input dimension '320' to be equal to the item-id embedding dimension '64'\n"
     ]
    }
   ],
   "source": [
    "from transformers4rec import torch as tr\n",
    "\n",
    "max_sequence_length, d_model = 20, 320\n",
    "# Define input module to process tabular input-features and to prepare masked inputs\n",
    "input_module = tr.TabularSequenceFeatures.from_schema(\n",
    "    schema,\n",
    "    max_sequence_length=max_sequence_length,\n",
    "    continuous_projection=64,\n",
    "    aggregation=\"concat\",\n",
    "    d_output=d_model,\n",
    "    masking=\"mlm\",\n",
    ")\n",
    "\n",
    "# Define Next item prediction-task \n",
    "prediction_task = tr.NextItemPredictionTask(weight_tying=True)\n",
    "\n",
    "# Define the config of the XLNet Transformer architecture\n",
    "transformer_config = tr.XLNetConfig.build(\n",
    "    d_model=d_model, n_head=8, n_layer=2, total_seq_length=max_sequence_length\n",
    ")\n",
    "\n",
    "# Get the end-to-end model \n",
    "model = transformer_config.to_torch_model(input_module, prediction_task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847757ca-3c91-4504-b9dc-29127563da01",
   "metadata": {},
   "source": [
    "You can print out the model structure by uncommenting the line below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9d4a3f7-f495-4504-bfe1-94f1a6cc8328",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fa0aa0",
   "metadata": {},
   "source": [
    "### 1.3. Daily Fine-Tuning: Training over a time windowÂ¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdecb72a",
   "metadata": {},
   "source": [
    "Now that the model is defined, we are going to launch training. For that, Transfromers4rec extends HF Transformers Trainer class to adapt the evaluation loop for session-based recommendation task and the calculation of ranking metrics. The original `train()` method is not modified meaning that we leverage the efficient training implementation from that library, which manages, for example, half-precision (FP16) training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6186d69",
   "metadata": {},
   "source": [
    "#### Set the training arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818197e2",
   "metadata": {},
   "source": [
    "An additional argument `data_loader_engine` is defined to automatically load the features needed for training using the schema. The default value is `merlin` for optimized GPU-based data-loading.  Optionally a `PyarrowDataLoader` (`pyarrow`) can also be used as a basic option, but it is slower and works only for small datasets, as the full data is loaded to CPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fec3739",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_args = tr.trainer.T4RecTrainingArguments(\n",
    "            output_dir=\"./tmp\",\n",
    "            max_sequence_length=20,\n",
    "            data_loader_engine='merlin',\n",
    "            num_train_epochs=10, \n",
    "            dataloader_drop_last=False,\n",
    "            per_device_train_batch_size = 384,\n",
    "            per_device_eval_batch_size = 512,\n",
    "            learning_rate=0.0005,\n",
    "            fp16=True,\n",
    "            report_to = [],\n",
    "            logging_steps=200\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836df805",
   "metadata": {},
   "source": [
    "#### Instantiate the trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e707cb8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp fp16 backend\n"
     ]
    }
   ],
   "source": [
    "recsys_trainer = tr.Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    schema=schema,\n",
    "    compute_metrics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f116800b",
   "metadata": {},
   "source": [
    "#### Launch daily training and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709592a2",
   "metadata": {},
   "source": [
    "In this demo, we will use the `fit_and_evaluate` method that allows us to conduct a time-based finetuning by iteratively training and evaluating using a sliding time window: At each iteration, we use the training data of a specific time index $t$ to train the model; then we evaluate on the validation data of the next index $t + 1$. Particularly, we set start time to 178 and end time to 180."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85be5b12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 28800\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 384\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 384\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Launch training for day 178: *****\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='750' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [750/750 00:21, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>7.771200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>6.614500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>6.324600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./tmp/checkpoint-500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:29]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 20736\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 384\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 384\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Evaluation results for day 179:*****\n",
      "\n",
      " eval_/next-item/avg_precision@10 = 0.08016683906316757\n",
      " eval_/next-item/avg_precision@20 = 0.08494126051664352\n",
      " eval_/next-item/ndcg@10 = 0.11179226636886597\n",
      " eval_/next-item/ndcg@20 = 0.12969404458999634\n",
      " eval_/next-item/recall@10 = 0.21040461957454681\n",
      " eval_/next-item/recall@20 = 0.28169557452201843\n",
      "\n",
      "***** Launch training for day 179: *****\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='540' max='540' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [540/540 00:15, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>6.843200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>6.404700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./tmp/checkpoint-500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running training *****\n",
      "  Num examples = 16896\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 384\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 384\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Evaluation results for day 180:*****\n",
      "\n",
      " eval_/next-item/avg_precision@10 = 0.06267862021923065\n",
      " eval_/next-item/avg_precision@20 = 0.06632088124752045\n",
      " eval_/next-item/ndcg@10 = 0.08807522058486938\n",
      " eval_/next-item/ndcg@20 = 0.10101056843996048\n",
      " eval_/next-item/recall@10 = 0.16876456141471863\n",
      " eval_/next-item/recall@20 = 0.22051282227039337\n",
      "\n",
      "***** Launch training for day 180: *****\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='440' max='440' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [440/440 00:12, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>6.899100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>6.494700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Evaluation results for day 181:*****\n",
      "\n",
      " eval_/next-item/avg_precision@10 = 0.13884949684143066\n",
      " eval_/next-item/avg_precision@20 = 0.14580118656158447\n",
      " eval_/next-item/ndcg@10 = 0.17901290953159332\n",
      " eval_/next-item/ndcg@20 = 0.2048875242471695\n",
      " eval_/next-item/recall@10 = 0.3107606768608093\n",
      " eval_/next-item/recall@20 = 0.41372913122177124\n"
     ]
    }
   ],
   "source": [
    "from transformers4rec.torch.utils.examples_utils import fit_and_evaluate\n",
    "OT_results = fit_and_evaluate(recsys_trainer, start_time_index=178, end_time_index=180, input_dir=OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c0aeb3",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Visualize the average of metrics over time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93aaace3",
   "metadata": {},
   "source": [
    "`OT_results` is a list of scores (accuracy metrics) for evaluation based on given start and end time_index. Since in this example we do evaluation on days 179, 180 and 181, we get three metrics in the list one for each day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c90423f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'indexed_by_time_eval_/next-item/avg_precision@10': [0.08016683906316757,\n",
       "  0.06267862021923065,\n",
       "  0.13884949684143066],\n",
       " 'indexed_by_time_eval_/next-item/avg_precision@20': [0.08494126051664352,\n",
       "  0.06632088124752045,\n",
       "  0.14580118656158447],\n",
       " 'indexed_by_time_eval_/next-item/ndcg@10': [0.11179226636886597,\n",
       "  0.08807522058486938,\n",
       "  0.17901290953159332],\n",
       " 'indexed_by_time_eval_/next-item/ndcg@20': [0.12969404458999634,\n",
       "  0.10101056843996048,\n",
       "  0.2048875242471695],\n",
       " 'indexed_by_time_eval_/next-item/recall@10': [0.21040461957454681,\n",
       "  0.16876456141471863,\n",
       "  0.3107606768608093],\n",
       " 'indexed_by_time_eval_/next-item/recall@20': [0.28169557452201843,\n",
       "  0.22051282227039337,\n",
       "  0.41372913122177124]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OT_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6eaf2040",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " indexed_by_time_eval_/next-item/avg_precision@10 = 0.09389831870794296\n",
      " indexed_by_time_eval_/next-item/avg_precision@20 = 0.09902110944191615\n",
      " indexed_by_time_eval_/next-item/ndcg@10 = 0.12629346549510956\n",
      " indexed_by_time_eval_/next-item/ndcg@20 = 0.14519737909237543\n",
      " indexed_by_time_eval_/next-item/recall@10 = 0.22997661928335825\n",
      " indexed_by_time_eval_/next-item/recall@20 = 0.30531250933806103\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# take the average of metric values over time\n",
    "avg_results = {k: np.mean(v) for k,v in OT_results.items()}\n",
    "for key in sorted(avg_results.keys()): \n",
    "    print(\" %s = %s\" % (key, str(avg_results[key]))) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fb8ca9",
   "metadata": {},
   "source": [
    "#### Trace the model\n",
    "\n",
    "We serve the model with the PyTorch backend that is used to execute TorchScript models. All models created in PyTorch using the python API must be traced/scripted to produce a TorchScript model. For tracing the model, we use [torch.jit.trace](https://pytorch.org/docs/stable/generated/torch.jit.trace.html) api that takes the model as a Python function or torch.nn.Module, and an example input  that will be passed to the function while tracing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9e0b1daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch \n",
    "from merlin.io import Dataset\n",
    "from nvtabular import Workflow\n",
    "\n",
    "from merlin.systems.dag import Ensemble\n",
    "from merlin.systems.dag.ops.pytorch import PredictPyTorch\n",
    "from merlin.systems.dag.ops.workflow import TransformWorkflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc38a304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>item_id-count</th>\n",
       "      <th>item_id-list</th>\n",
       "      <th>et_dayofweek_sin-list</th>\n",
       "      <th>product_recency_days_log_norm-list</th>\n",
       "      <th>category-list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11255549</td>\n",
       "      <td>12</td>\n",
       "      <td>[604, 878, 742, 90, 4777, 1583, 3446, 8083, 34...</td>\n",
       "      <td>[-0.43388462, -0.43388462, -0.43388462, -0.433...</td>\n",
       "      <td>[1.5241543, 1.5238742, 1.5239332, 1.5241623, 1...</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11255552</td>\n",
       "      <td>2</td>\n",
       "      <td>[184, 12288, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[-0.43388462, -0.43388462, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[-0.53300583, 1.5214932, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "      <td>[2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11255562</td>\n",
       "      <td>2</td>\n",
       "      <td>[2065, 430, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[-0.43388462, -0.43388462, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[1.5217637, 1.5218583, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>[2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11255566</td>\n",
       "      <td>3</td>\n",
       "      <td>[6, 30, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[-0.43388462, -0.43388462, -0.43388462, 0.0, 0...</td>\n",
       "      <td>[0.33446133, 0.22619988, 0.33446613, 0.0, 0.0,...</td>\n",
       "      <td>[5, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11255593</td>\n",
       "      <td>2</td>\n",
       "      <td>[157, 1987, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[-0.43388462, -0.43388462, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[1.5234982, -1.0130814, 0.0, 0.0, 0.0, 0.0, 0....</td>\n",
       "      <td>[2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session_id  item_id-count  \\\n",
       "0    11255549             12   \n",
       "1    11255552              2   \n",
       "2    11255562              2   \n",
       "4    11255566              3   \n",
       "5    11255593              2   \n",
       "\n",
       "                                        item_id-list  \\\n",
       "0  [604, 878, 742, 90, 4777, 1583, 3446, 8083, 34...   \n",
       "1  [184, 12288, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [2065, 430, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
       "4  [6, 30, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "5  [157, 1987, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
       "\n",
       "                               et_dayofweek_sin-list  \\\n",
       "0  [-0.43388462, -0.43388462, -0.43388462, -0.433...   \n",
       "1  [-0.43388462, -0.43388462, 0.0, 0.0, 0.0, 0.0,...   \n",
       "2  [-0.43388462, -0.43388462, 0.0, 0.0, 0.0, 0.0,...   \n",
       "4  [-0.43388462, -0.43388462, -0.43388462, 0.0, 0...   \n",
       "5  [-0.43388462, -0.43388462, 0.0, 0.0, 0.0, 0.0,...   \n",
       "\n",
       "                  product_recency_days_log_norm-list  \\\n",
       "0  [1.5241543, 1.5238742, 1.5239332, 1.5241623, 1...   \n",
       "1  [-0.53300583, 1.5214932, 0.0, 0.0, 0.0, 0.0, 0...   \n",
       "2  [1.5217637, 1.5218583, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "4  [0.33446133, 0.22619988, 0.33446613, 0.0, 0.0,...   \n",
       "5  [1.5234982, -1.0130814, 0.0, 0.0, 0.0, 0.0, 0....   \n",
       "\n",
       "                                       category-list  \n",
       "0  [3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 0, 0, 0, ...  \n",
       "1  [2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  [5, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "5  [2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a927a1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_max = {'session_id': 20,\n",
    " 'item_id-list': 20,\n",
    " 'item_id-count': 20,\n",
    " 'et_dayofweek_sin-list': 20,\n",
    " 'product_recency_days_log_norm-list': 20,\n",
    " 'category-list': 20}\n",
    "\n",
    "from transformers4rec.torch.utils.data_utils import MerlinDataLoader\n",
    "\n",
    "def generate_dataloader(schema, dataset, batch_size=128, seq_length=20):\n",
    "    loader = MerlinDataLoader.from_schema(\n",
    "            schema,\n",
    "            dataset,\n",
    "            batch_size=batch_size,\n",
    "            max_sequence_length=seq_length,\n",
    "            shuffle=False,\n",
    "            sparse_as_dense=True,\n",
    "            sparse_max=sparse_max\n",
    "        )\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0a800e",
   "metadata": {},
   "source": [
    "Create a dict of tensors to feed it as example inputs in the `torch.jit.trace()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6615f7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = generate_dataloader(schema, dataset)\n",
    "train_dict = next(iter(loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf4c231",
   "metadata": {},
   "source": [
    "Let's check out the `item_id-list` column in the `train_dict` dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "61fb75fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  604,   878,   742,  ...,     0,     0,     0],\n",
       "        [  184, 12288,     0,  ...,     0,     0,     0],\n",
       "        [ 2065,   430,     0,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [   88,   480,   166,  ...,     0,     0,     0],\n",
       "        [ 9987,  1636,     0,  ...,     0,     0,     0],\n",
       "        [ 3064,  1798,  1393,  ...,     0,     0,     0]], device='cuda:0')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dict[0]['item_id-list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9cb6bb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_model = torch.jit.trace(model, train_dict[0], strict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5a7589",
   "metadata": {},
   "source": [
    "Generate model input and output schemas to feed in the `PredictPyTorch` operator below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5151efe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_schema = model.input_schema\n",
    "output_schema = model.output_schema\n",
    "\n",
    "for col_name, col_schema in input_schema.column_schemas.items():\n",
    "    input_schema[col_name] = input_schema[col_name].with_shape((None, sparse_max[col_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c4dfed18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>tags</th>\n",
       "      <th>dtype</th>\n",
       "      <th>is_list</th>\n",
       "      <th>is_ragged</th>\n",
       "      <th>properties.value_count.min</th>\n",
       "      <th>properties.value_count.max</th>\n",
       "      <th>properties.num_buckets</th>\n",
       "      <th>properties.freq_threshold</th>\n",
       "      <th>properties.max_size</th>\n",
       "      <th>properties.start_index</th>\n",
       "      <th>properties.cat_path</th>\n",
       "      <th>properties.embedding_sizes.cardinality</th>\n",
       "      <th>properties.embedding_sizes.dimension</th>\n",
       "      <th>properties.domain.min</th>\n",
       "      <th>properties.domain.max</th>\n",
       "      <th>properties.domain.name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>product_recency_days_log_norm-list</td>\n",
       "      <td>(Tags.CONTINUOUS, Tags.LIST)</td>\n",
       "      <td>DType(name='float32', element_type=&lt;ElementTyp...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>et_dayofweek_sin-list</td>\n",
       "      <td>(Tags.CONTINUOUS, Tags.LIST)</td>\n",
       "      <td>DType(name='float32', element_type=&lt;ElementTyp...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>item_id-list</td>\n",
       "      <td>(Tags.LIST, Tags.ID, Tags.ITEM_ID, Tags.CATEGO...</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>.//categories/unique.item_id.parquet</td>\n",
       "      <td>52741.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52740.0</td>\n",
       "      <td>item_id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>category-list</td>\n",
       "      <td>(Tags.CATEGORICAL, Tags.LIST)</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>.//categories/unique.category.parquet</td>\n",
       "      <td>336.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>category</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "[{'name': 'product_recency_days_log_norm-list', 'tags': {<Tags.CONTINUOUS: 'continuous'>, <Tags.LIST: 'list'>}, 'properties': {'value_count': {'min': 20, 'max': 20}}, 'dtype': DType(name='float32', element_type=<ElementType.Float: 'float'>, element_size=32, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=20, max=20)))), 'is_list': True, 'is_ragged': False}, {'name': 'et_dayofweek_sin-list', 'tags': {<Tags.CONTINUOUS: 'continuous'>, <Tags.LIST: 'list'>}, 'properties': {'value_count': {'min': 20, 'max': 20}}, 'dtype': DType(name='float32', element_type=<ElementType.Float: 'float'>, element_size=32, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=20, max=20)))), 'is_list': True, 'is_ragged': False}, {'name': 'item_id-list', 'tags': {<Tags.LIST: 'list'>, <Tags.ID: 'id'>, <Tags.ITEM_ID: 'item_id'>, <Tags.CATEGORICAL: 'categorical'>, <Tags.ITEM: 'item'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0.0, 'max_size': 0.0, 'start_index': 1.0, 'cat_path': './/categories/unique.item_id.parquet', 'embedding_sizes': {'cardinality': 52741.0, 'dimension': 512.0}, 'domain': {'min': 0, 'max': 52740, 'name': 'item_id'}, 'value_count': {'min': 20, 'max': 20}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=20, max=20)))), 'is_list': True, 'is_ragged': False}, {'name': 'category-list', 'tags': {<Tags.CATEGORICAL: 'categorical'>, <Tags.LIST: 'list'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0.0, 'max_size': 0.0, 'start_index': 1.0, 'cat_path': './/categories/unique.category.parquet', 'embedding_sizes': {'cardinality': 336.0, 'dimension': 42.0}, 'domain': {'min': 0, 'max': 335, 'name': 'category'}, 'value_count': {'min': 20, 'max': 20}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=20, max=20)))), 'is_list': True, 'is_ragged': False}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb035d3",
   "metadata": {},
   "source": [
    "Let's create a folder that we can store the exported models and the config files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f15ff429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "ens_model_path = os.environ.get(\"ens_model_path\", f\"{INPUT_DATA_DIR}/models\")\n",
    "# Make sure we have a clean stats space for Dask\n",
    "if os.path.isdir(ens_model_path):\n",
    "    shutil.rmtree(ens_model_path)\n",
    "os.mkdir(ens_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "68def546",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = Workflow.load(os.path.join(INPUT_DATA_DIR, \"workflow_etl\"))\n",
    "dataset = Dataset(os.path.join(INPUT_DATA_DIR, \"./preproc_sessions_by_day/178/train.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5ca2e0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_op = workflow.input_schema.column_names >> TransformWorkflow(workflow) >> PredictPyTorch(\n",
    "    model, workflow.input_schema, model.output_schema\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9c492d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/merlin/systems/dag/node.py:100: UserWarning: Operator 'TransformWorkflowTriton' is producing the output column 'item_id-count', which is not being used by any downstream operator in the ensemble graph.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/merlin/systems/dag/node.py:100: UserWarning: Operator 'TransformWorkflowTriton' is producing the output column 'item_id-list', which is not being used by any downstream operator in the ensemble graph.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/merlin/systems/dag/node.py:100: UserWarning: Operator 'TransformWorkflowTriton' is producing the output column 'et_dayofweek_sin-list', which is not being used by any downstream operator in the ensemble graph.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/merlin/systems/dag/node.py:100: UserWarning: Operator 'TransformWorkflowTriton' is producing the output column 'product_recency_days_log_norm-list', which is not being used by any downstream operator in the ensemble graph.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/merlin/systems/dag/node.py:100: UserWarning: Operator 'TransformWorkflowTriton' is producing the output column 'category-list', which is not being used by any downstream operator in the ensemble graph.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/merlin/systems/dag/node.py:100: UserWarning: Operator 'TransformWorkflowTriton' is producing the output column 'day_index', which is not being used by any downstream operator in the ensemble graph.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ensemble = Ensemble(torch_op, workflow.input_schema)\n",
    "ens_config, node_configs = ensemble.export(ens_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e4430b",
   "metadata": {},
   "source": [
    "## 2. Serving Ensemble Model to the Triton Inference Server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1615cc",
   "metadata": {},
   "source": [
    "NVIDIA [Triton Inference Server (TIS)](https://github.com/triton-inference-server/server) simplifies the deployment of AI models at scale in production. TIS provides a cloud and edge inferencing solution optimized for both CPUs and GPUs. It supports a number of different machine learning frameworks such as TensorFlow and PyTorch.\n",
    "\n",
    "The last step of a machine learning (ML)/deep learning (DL) pipeline is to deploy the ETL workflow and saved model to production. In the production setting, we want to transform the input data as done during training (ETL). We need to apply the same mean/std for continuous features and use the same categorical mapping to convert the categories to continuous integer before we use the DL model for a prediction. Therefore, we deploy the NVTabular workflow with the PyTorch model as an ensemble model to Triton Inference. The ensemble model guarantees that the same transformation is applied to the raw inputs.\n",
    "\n",
    "\n",
    "In this section, you will learn how to\n",
    "- to deploy saved NVTabular and PyTorch models to Triton Inference Server \n",
    "- send requests for predictions and get responses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29b67ad",
   "metadata": {},
   "source": [
    "### 2.1. Pull and Start Inference Container\n",
    "\n",
    "At this point, we start the Triton Inference Server (TIS). \n",
    "\n",
    "**Start triton server**<br>\n",
    "You can start triton server with the command below. You need to provide correct path of the models folder.\n",
    "\n",
    "```\n",
    "tritonserver --model-repository=<path_to_models> --model-control-mode=explicit\n",
    "```\n",
    "Note: The model-repository path for our example is `/workspace/data/models/`. The models have not been loaded yet. Below, we will request the Triton server to load the saved ensemble model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e76b0ed",
   "metadata": {},
   "source": [
    "### 2.2. Connect to the Triton Inference Server and check if the server is alive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dcfb4acd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tritonhttpclient/__init__.py:31: DeprecationWarning: The package `tritonhttpclient` is deprecated and will be removed in a future version. Please use instead `tritonclient.http`\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client created.\n",
      "GET /v2/health/live, headers None\n"
     ]
    },
    {
     "ename": "ConnectionRefusedError",
     "evalue": "[Errno 111] Connection refused",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/geventhttpclient/connectionpool.py:163\u001b[0m, in \u001b[0;36mConnectionPool.get_socket\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_socket_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m gevent\u001b[38;5;241m.\u001b[39mqueue\u001b[38;5;241m.\u001b[39mEmpty:\n",
      "File \u001b[0;32msrc/gevent/queue.py:335\u001b[0m, in \u001b[0;36mgevent._gevent_cqueue.Queue.get\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/gevent/queue.py:350\u001b[0m, in \u001b[0;36mgevent._gevent_cqueue.Queue.get\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/gevent/queue.py:319\u001b[0m, in \u001b[0;36mgevent._gevent_cqueue.Queue._Queue__get_or_peek\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mEmpty\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchannel creation failed: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e))\n\u001b[0;32m----> 7\u001b[0m \u001b[43mtriton_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_server_live\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tritonclient/http/__init__.py:375\u001b[0m, in \u001b[0;36mInferenceServerClient.is_server_live\u001b[0;34m(self, headers, query_params)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Contact the inference server and get liveness.\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \n\u001b[1;32m    353\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    371\u001b[0m \n\u001b[1;32m    372\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    374\u001b[0m request_uri \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv2/health/live\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 375\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest_uri\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_uri\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tritonclient/http/__init__.py:269\u001b[0m, in \u001b[0;36mInferenceServerClient._get\u001b[0;34m(self, request_uri, headers, query_params)\u001b[0m\n\u001b[1;32m    267\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client_stub\u001b[38;5;241m.\u001b[39mget(request_uri, headers\u001b[38;5;241m=\u001b[39mheaders)\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 269\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client_stub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest_uri\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_verbose:\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28mprint\u001b[39m(response)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/geventhttpclient/client.py:266\u001b[0m, in \u001b[0;36mHTTPClient.get\u001b[0;34m(self, request_uri, headers)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, request_uri, headers\u001b[38;5;241m=\u001b[39m{}):\n\u001b[0;32m--> 266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMETHOD_GET\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/geventhttpclient/client.py:226\u001b[0m, in \u001b[0;36mHTTPClient.request\u001b[0;34m(self, method, request_uri, body, headers)\u001b[0m\n\u001b[1;32m    223\u001b[0m attempts_left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection_pool\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 226\u001b[0m     sock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    228\u001b[0m         _request \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mencode()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/geventhttpclient/connectionpool.py:166\u001b[0m, in \u001b[0;36mConnectionPool.get_socket\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m gevent\u001b[38;5;241m.\u001b[39mqueue\u001b[38;5;241m.\u001b[39mEmpty:\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    168\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_semaphore\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/geventhttpclient/connectionpool.py:127\u001b[0m, in \u001b[0;36mConnectionPool._create_socket\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_error:\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m first_error\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    130\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot resolve \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_host, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_port))\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/geventhttpclient/connectionpool.py:114\u001b[0m, in \u001b[0;36mConnectionPool._create_socket\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    113\u001b[0m     sock\u001b[38;5;241m.\u001b[39msettimeout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnection_timeout)\n\u001b[0;32m--> 114\u001b[0m     sock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connect_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msock_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter_connect(sock)\n\u001b[1;32m    116\u001b[0m     sock\u001b[38;5;241m.\u001b[39msettimeout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork_timeout)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/geventhttpclient/connectionpool.py:136\u001b[0m, in \u001b[0;36mConnectionPool._connect_socket\u001b[0;34m(self, sock, address)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_connect_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, address):\n\u001b[0;32m--> 136\u001b[0m     \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43maddress\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setup_proxy(sock)\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sock\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/gevent/_socketcommon.py:607\u001b[0m, in \u001b[0;36mSocketMixin.connect\u001b[0;34m(self, address)\u001b[0m\n\u001b[1;32m    605\u001b[0m err \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgetsockopt(__socket__\u001b[38;5;241m.\u001b[39mSOL_SOCKET, __socket__\u001b[38;5;241m.\u001b[39mSO_ERROR)\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m err:\n\u001b[0;32m--> 607\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _SocketError(err, strerror(err))\n\u001b[1;32m    608\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mconnect_ex(address)\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result \u001b[38;5;129;01mor\u001b[39;00m result \u001b[38;5;241m==\u001b[39m EISCONN:\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused"
     ]
    }
   ],
   "source": [
    "import tritonhttpclient\n",
    "try:\n",
    "    triton_client = tritonhttpclient.InferenceServerClient(url=\"localhost:8000\", verbose=True)\n",
    "    print(\"client created.\")\n",
    "except Exception as e:\n",
    "    print(\"channel creation failed: \" + str(e))\n",
    "triton_client.is_server_live()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5067e84",
   "metadata": {},
   "source": [
    "### 2.3. Load raw data for inference\n",
    "We select the last 50 interactions and filter out sessions with less than 2 interactions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "61a27083",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "interactions_merged_df = pd.read_parquet(os.path.join(INPUT_DATA_DIR, \"interactions_merged_df.parquet\"))\n",
    "interactions_merged_df = interactions_merged_df.sort_values('timestamp')\n",
    "batch = interactions_merged_df[-50:]\n",
    "sessions_to_use = batch.session_id.value_counts()\n",
    "filtered_batch = batch[batch.session_id.isin(sessions_to_use[sessions_to_use.values>1].index.values)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4944262f-b9a4-4465-9877-938946a93907",
   "metadata": {},
   "source": [
    "### 2.4. Load the ensemble model to triton"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a8ad13-59fa-4c55-8a36-f4fff41480e9",
   "metadata": {},
   "source": [
    "The models should be loaded successfully before we send a request to TIS. If all models are loaded successfully, you should be seeing `successfully loaded` status next to each model name on your terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "216cafd5-4fb3-47dd-9763-f43dc95851fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POST /v2/repository/models/t4r_pytorch/load, headers None\n",
      "{}\n",
      "<HTTPSocketPoolResponse status=200 headers={'content-type': 'application/json', 'content-length': '0'}>\n",
      "Loaded model 't4r_pytorch'\n"
     ]
    }
   ],
   "source": [
    "triton_client.load_model(model_name=\"t4r_pytorch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e022da",
   "metadata": {},
   "source": [
    "### 2.5. Send the request to triton server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e98c6068",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POST /v2/repository/index, headers None\n",
      "\n",
      "<HTTPSocketPoolResponse status=200 headers={'content-type': 'application/json', 'content-length': '167'}>\n",
      "bytearray(b'[{\"name\":\"t4r_pytorch\",\"version\":\"1\",\"state\":\"READY\"},{\"name\":\"t4r_pytorch_nvt\",\"version\":\"1\",\"state\":\"READY\"},{\"name\":\"t4r_pytorch_pt\",\"version\":\"1\",\"state\":\"READY\"}]')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'name': 't4r_pytorch', 'version': '1', 'state': 'READY'},\n",
       " {'name': 't4r_pytorch_nvt', 'version': '1', 'state': 'READY'},\n",
       " {'name': 't4r_pytorch_pt', 'version': '1', 'state': 'READY'}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triton_client.get_model_repository_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8083b9ab",
   "metadata": {},
   "source": [
    "If all models are loaded successfully, you should be seeing `READY` status next to each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a979bdad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output :\n",
      " [[-12.359397  -12.863064   -8.659327  ... -12.52291   -13.386017\n",
      "  -12.252247 ]\n",
      " [-16.44956   -16.089582   -8.681267  ... -17.113033  -18.37918\n",
      "  -16.107119 ]\n",
      " [-13.414572  -13.681402   -8.590441  ... -14.162938  -15.2169285\n",
      "  -13.981831 ]\n",
      " ...\n",
      " [-17.573406  -16.371202   -9.535273  ... -17.32026   -18.294775\n",
      "  -16.001776 ]\n",
      " [-13.201723  -13.092476   -8.6168995 ... -13.6306    -14.307053\n",
      "  -12.9177685]\n",
      " [-17.229147  -16.887306   -9.369176  ... -17.403896  -18.368675\n",
      "  -16.291914 ]]\n"
     ]
    }
   ],
   "source": [
    "import nvtabular.inference.triton as nvt_triton\n",
    "import tritonclient.grpc as grpcclient\n",
    "\n",
    "inputs = nvt_triton.convert_df_to_triton_input(filtered_batch.columns, filtered_batch, grpcclient.InferInput)\n",
    "\n",
    "output_names = [\"output\"]\n",
    "\n",
    "outputs = []\n",
    "for col in output_names:\n",
    "    outputs.append(grpcclient.InferRequestedOutput(col))\n",
    "    \n",
    "MODEL_NAME_NVT = \"t4r_pytorch\"\n",
    "\n",
    "with grpcclient.InferenceServerClient(\"localhost:8001\") as client:\n",
    "    response = client.infer(MODEL_NAME_NVT, inputs)\n",
    "    print(col, ':\\n', response.as_numpy(col))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97d0ee4",
   "metadata": {},
   "source": [
    "- Visualise top-k predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ca739176",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Top-5 predictions for session `11457123`: 1761 || 186 || 2651 || 2383 || 1987\n",
      "\n",
      "- Top-5 predictions for session `11467406`: 4136 || 224 || 2774 || 2693 || 2759\n",
      "\n",
      "- Top-5 predictions for session `11528554`: 135 || 183 || 1697 || 1359 || 1340\n",
      "\n",
      "- Top-5 predictions for session `11336059`: 2556 || 2651 || 186 || 6989 || 7284\n",
      "\n",
      "- Top-5 predictions for session `11445777`: 2789 || 5591 || 2891 || 2759 || 4541\n",
      "\n",
      "- Top-5 predictions for session `11493827`: 6510 || 4136 || 4204 || 4155 || 4541\n",
      "\n",
      "- Top-5 predictions for session `11425751`: 2788 || 2556 || 224 || 1987 || 2050\n",
      "\n",
      "- Top-5 predictions for session `11399751`: 3841 || 2214 || 2556 || 224 || 2651\n",
      "\n",
      "- Top-5 predictions for session `11311424`: 6461 || 4713 || 4136 || 9285 || 4155\n",
      "\n",
      "- Top-5 predictions for session `11257991`: 5932 || 620 || 1334 || 633 || 224\n",
      "\n",
      "- Top-5 predictions for session `11561822`: 2956 || 6488 || 8084 || 4713 || 4136\n",
      "\n",
      "- Top-5 predictions for session `11421333`: 224 || 9285 || 6488 || 11389 || 8084\n",
      "\n",
      "- Top-5 predictions for session `11270119`: 5932 || 6488 || 4136 || 4541 || 4204\n",
      "\n",
      "- Top-5 predictions for session `11401481`: 4204 || 11389 || 6488 || 4136 || 224\n",
      "\n",
      "- Top-5 predictions for session `11394056`: 2759 || 5591 || 4541 || 4204 || 4136\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers4rec.torch.utils.examples_utils import visualize_response\n",
    "visualize_response(filtered_batch, response, top_k=5, session_col='session_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f576abb9",
   "metadata": {},
   "source": [
    "As you noticed, we first got prediction results (logits) from the trained model head, and then by using a handy util function `visualize_response` we extracted top-k encoded item-ids from logits. Basically, we generated recommended items for a given session.\n",
    "\n",
    "This is the end of the tutorial. You successfully\n",
    "\n",
    "- performed feature engineering with NVTabular\n",
    "- trained transformer architecture based session-based recommendation models with Transformers4Rec\n",
    "- deployed a trained model to Triton Inference Server, sent request and got responses from the server."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365e8f11",
   "metadata": {},
   "source": [
    "**Unload models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0713f660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POST /v2/repository/models/t4r_pytorch/unload, headers None\n",
      "{\"parameters\":{\"unload_dependents\":false}}\n",
      "<HTTPSocketPoolResponse status=200 headers={'content-type': 'application/json', 'content-length': '0'}>\n",
      "Loaded model 't4r_pytorch'\n",
      "POST /v2/repository/models/t4r_pytorch_nvt/unload, headers None\n",
      "{\"parameters\":{\"unload_dependents\":false}}\n",
      "<HTTPSocketPoolResponse status=200 headers={'content-type': 'application/json', 'content-length': '0'}>\n",
      "Loaded model 't4r_pytorch_nvt'\n",
      "POST /v2/repository/models/t4r_pytorch_pt/unload, headers None\n",
      "{\"parameters\":{\"unload_dependents\":false}}\n",
      "<HTTPSocketPoolResponse status=200 headers={'content-type': 'application/json', 'content-length': '0'}>\n",
      "Loaded model 't4r_pytorch_pt'\n"
     ]
    }
   ],
   "source": [
    "triton_client.unload_model(model_name=\"t4r_pytorch\")\n",
    "triton_client.unload_model(model_name=\"t4r_pytorch_nvt\")\n",
    "triton_client.unload_model(model_name=\"t4r_pytorch_pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68dd532f",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f9073e",
   "metadata": {},
   "source": [
    "- Merlin Transformers4rec: https://github.com/NVIDIA-Merlin/Transformers4Rec\n",
    "\n",
    "- Merlin NVTabular: https://github.com/NVIDIA-Merlin/NVTabular/tree/main/nvtabular\n",
    "\n",
    "- Merlin Dataloader: https://github.com/NVIDIA-Merlin/dataloader\n",
    "\n",
    "- Triton inference server: https://github.com/triton-inference-server"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "d795d7ca5d3ec3bd6293cc80853205a74ce23d484a2b8f537732a716747107c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
