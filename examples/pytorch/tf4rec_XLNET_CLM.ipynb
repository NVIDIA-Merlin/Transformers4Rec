{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fifteen-notebook",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch \n",
    "import numpy\n",
    "import pandas as pd \n",
    "import cudf\n",
    "import cupy\n",
    "import nvtabular as nvt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-conspiracy",
   "metadata": {},
   "source": [
    "### Create random input data similar to pre-processed Yoochoose dataset structure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "shaped-collectible",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>day</th>\n",
       "      <th>item_id</th>\n",
       "      <th>category</th>\n",
       "      <th>timestamp/age_days</th>\n",
       "      <th>timestamp/weekday/sin</th>\n",
       "      <th>purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77270</td>\n",
       "      <td>7</td>\n",
       "      <td>26757</td>\n",
       "      <td>321</td>\n",
       "      <td>0.508369</td>\n",
       "      <td>0.994320</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70860</td>\n",
       "      <td>2</td>\n",
       "      <td>21548</td>\n",
       "      <td>118</td>\n",
       "      <td>0.264226</td>\n",
       "      <td>0.939826</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75390</td>\n",
       "      <td>4</td>\n",
       "      <td>5289</td>\n",
       "      <td>69</td>\n",
       "      <td>0.049086</td>\n",
       "      <td>0.085271</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75191</td>\n",
       "      <td>5</td>\n",
       "      <td>15107</td>\n",
       "      <td>81</td>\n",
       "      <td>0.249507</td>\n",
       "      <td>0.388882</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75734</td>\n",
       "      <td>3</td>\n",
       "      <td>37267</td>\n",
       "      <td>67</td>\n",
       "      <td>0.757183</td>\n",
       "      <td>0.145604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>77126</td>\n",
       "      <td>3</td>\n",
       "      <td>37088</td>\n",
       "      <td>281</td>\n",
       "      <td>0.635821</td>\n",
       "      <td>0.561732</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>72318</td>\n",
       "      <td>4</td>\n",
       "      <td>35382</td>\n",
       "      <td>267</td>\n",
       "      <td>0.448604</td>\n",
       "      <td>0.724329</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>78772</td>\n",
       "      <td>8</td>\n",
       "      <td>8071</td>\n",
       "      <td>294</td>\n",
       "      <td>0.592731</td>\n",
       "      <td>0.980665</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>78542</td>\n",
       "      <td>4</td>\n",
       "      <td>44769</td>\n",
       "      <td>91</td>\n",
       "      <td>0.868292</td>\n",
       "      <td>0.893382</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>72458</td>\n",
       "      <td>2</td>\n",
       "      <td>30113</td>\n",
       "      <td>31</td>\n",
       "      <td>0.174848</td>\n",
       "      <td>0.740812</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        session_id  day  item_id  category  timestamp/age_days  \\\n",
       "0            77270    7    26757       321            0.508369   \n",
       "1            70860    2    21548       118            0.264226   \n",
       "2            75390    4     5289        69            0.049086   \n",
       "3            75191    5    15107        81            0.249507   \n",
       "4            75734    3    37267        67            0.757183   \n",
       "...            ...  ...      ...       ...                 ...   \n",
       "199995       77126    3    37088       281            0.635821   \n",
       "199996       72318    4    35382       267            0.448604   \n",
       "199997       78772    8     8071       294            0.592731   \n",
       "199998       78542    4    44769        91            0.868292   \n",
       "199999       72458    2    30113        31            0.174848   \n",
       "\n",
       "        timestamp/weekday/sin  purchase  \n",
       "0                    0.994320         0  \n",
       "1                    0.939826         1  \n",
       "2                    0.085271         1  \n",
       "3                    0.388882         1  \n",
       "4                    0.145604         1  \n",
       "...                       ...       ...  \n",
       "199995               0.561732         0  \n",
       "199996               0.724329         1  \n",
       "199997               0.980665         1  \n",
       "199998               0.893382         0  \n",
       "199999               0.740812         0  \n",
       "\n",
       "[200000 rows x 7 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_ROWS = 200000\n",
    "session_length = 20\n",
    "inputs = {\n",
    "    'session_id': numpy.random.randint(70000, 80000, NUM_ROWS),\n",
    "    'day': numpy.random.randint(1, 10, NUM_ROWS),\n",
    "    'item_id': numpy.random.randint(1, 51996, NUM_ROWS),\n",
    "    'category': numpy.random.randint(0, 332, NUM_ROWS),\n",
    "    'timestamp/age_days': numpy.random.uniform(0, 1, NUM_ROWS),\n",
    "    'timestamp/weekday/sin' : numpy.random.uniform(0, 1, NUM_ROWS),\n",
    "    'purchase': numpy.random.randint(0, 2, NUM_ROWS)\n",
    "    }\n",
    "random_data = cudf.DataFrame(inputs)\n",
    "random_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "embedded-means",
   "metadata": {},
   "source": [
    "### NVTabular workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lonely-flash",
   "metadata": {},
   "source": [
    "- #TODO : Change the workflow using tagging API once it is finalized  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "interested-officer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Groupby Workflow\n",
    "groupby_features = list(inputs.keys()) >> nvt.ops.Groupby(\n",
    "    groupby_cols=[\"session_id\"], \n",
    "    aggs={\n",
    "        \"item_id\": [\"list\"],\n",
    "        \"category\": [\"list\"],     \n",
    "        \"day\": [\"first\"],\n",
    "        \"purchase\": [\"first\"],\n",
    "        \"timestamp/age_days\": [\"list\"],\n",
    "        'timestamp/weekday/sin': [\"list\"],\n",
    "        },\n",
    "    name_sep=\"-\")\n",
    "# Trim sessions to first 20 items \n",
    "groupby_features_list = [x for x in groupby_features.output_columns.names if '-list' in x]\n",
    "\n",
    "#groupby_features_nonlist:  need to fix a BUG related to adding two workflow nodes\n",
    "#groupby_features_trim = groupby_features_list >> nvt.ops.ListSlice(0,20) >> nvt.ops.Rename(postfix = '_trim')\n",
    "workflow = nvt.Workflow(groupby_features)\n",
    "dataset = nvt.Dataset(random_data, cpu=False)\n",
    "workflow.fit(dataset)\n",
    "sessions_gdf = workflow.transform(dataset).to_ddf().compute()\n",
    "\n",
    "# Re-compute tri: to be removed when the BUG of two workflow nodes is fixed : \n",
    "groupby_features_trim =  groupby_features_list >> nvt.ops.ListSlice(0,20) >> nvt.ops.Rename(postfix = '_trim')\n",
    "workflow = nvt.Workflow(list(sessions_gdf.columns)  + groupby_features_trim)\n",
    "dataset = nvt.Dataset(sessions_gdf, cpu=False)\n",
    "workflow.fit(dataset)\n",
    "sessions_gdf = workflow.transform(dataset).to_ddf().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "northern-munich",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category-list_trim</th>\n",
       "      <th>timestamp/age_days-list_trim</th>\n",
       "      <th>item_id-list_trim</th>\n",
       "      <th>timestamp/weekday/sin-list_trim</th>\n",
       "      <th>session_id</th>\n",
       "      <th>category-list</th>\n",
       "      <th>purchase-first</th>\n",
       "      <th>timestamp/age_days-list</th>\n",
       "      <th>item_id-list</th>\n",
       "      <th>timestamp/weekday/sin-list</th>\n",
       "      <th>day-first</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[146, 228, 269, 262, 252, 144, 241, 139, 85, 2...</td>\n",
       "      <td>[0.8433147126150244, 0.36594029226833047, 0.48...</td>\n",
       "      <td>[35969, 7218, 4254, 43307, 24474, 46468, 17340...</td>\n",
       "      <td>[0.8425804078540428, 0.4314946368378889, 0.217...</td>\n",
       "      <td>70000</td>\n",
       "      <td>[146, 228, 269, 262, 252, 144, 241, 139, 85, 2...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.8433147126150244, 0.36594029226833047, 0.48...</td>\n",
       "      <td>[35969, 7218, 4254, 43307, 24474, 46468, 17340...</td>\n",
       "      <td>[0.8425804078540428, 0.4314946368378889, 0.217...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[164, 131, 117, 294, 283, 207, 94, 8, 112, 232...</td>\n",
       "      <td>[0.09507837731997637, 0.5639704696082977, 0.67...</td>\n",
       "      <td>[163, 6506, 35424, 24708, 1004, 2914, 20464, 2...</td>\n",
       "      <td>[0.4388505546993573, 0.8208003416295997, 0.297...</td>\n",
       "      <td>70001</td>\n",
       "      <td>[164, 131, 117, 294, 283, 207, 94, 8, 112, 232...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.09507837731997637, 0.5639704696082977, 0.67...</td>\n",
       "      <td>[163, 6506, 35424, 24708, 1004, 2914, 20464, 2...</td>\n",
       "      <td>[0.4388505546993573, 0.8208003416295997, 0.297...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[130, 323, 18, 328, 191, 224, 107, 44, 65, 63]</td>\n",
       "      <td>[0.2557564379821403, 0.37390035704678004, 0.07...</td>\n",
       "      <td>[40696, 31278, 1489, 16792, 34465, 17258, 4452...</td>\n",
       "      <td>[0.7795720554649077, 0.8084530571788069, 0.730...</td>\n",
       "      <td>70002</td>\n",
       "      <td>[130, 323, 18, 328, 191, 224, 107, 44, 65, 63]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.2557564379821403, 0.37390035704678004, 0.07...</td>\n",
       "      <td>[40696, 31278, 1489, 16792, 34465, 17258, 4452...</td>\n",
       "      <td>[0.7795720554649077, 0.8084530571788069, 0.730...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  category-list_trim  \\\n",
       "0  [146, 228, 269, 262, 252, 144, 241, 139, 85, 2...   \n",
       "1  [164, 131, 117, 294, 283, 207, 94, 8, 112, 232...   \n",
       "2     [130, 323, 18, 328, 191, 224, 107, 44, 65, 63]   \n",
       "\n",
       "                        timestamp/age_days-list_trim  \\\n",
       "0  [0.8433147126150244, 0.36594029226833047, 0.48...   \n",
       "1  [0.09507837731997637, 0.5639704696082977, 0.67...   \n",
       "2  [0.2557564379821403, 0.37390035704678004, 0.07...   \n",
       "\n",
       "                                   item_id-list_trim  \\\n",
       "0  [35969, 7218, 4254, 43307, 24474, 46468, 17340...   \n",
       "1  [163, 6506, 35424, 24708, 1004, 2914, 20464, 2...   \n",
       "2  [40696, 31278, 1489, 16792, 34465, 17258, 4452...   \n",
       "\n",
       "                     timestamp/weekday/sin-list_trim  session_id  \\\n",
       "0  [0.8425804078540428, 0.4314946368378889, 0.217...       70000   \n",
       "1  [0.4388505546993573, 0.8208003416295997, 0.297...       70001   \n",
       "2  [0.7795720554649077, 0.8084530571788069, 0.730...       70002   \n",
       "\n",
       "                                       category-list  purchase-first  \\\n",
       "0  [146, 228, 269, 262, 252, 144, 241, 139, 85, 2...               0   \n",
       "1  [164, 131, 117, 294, 283, 207, 94, 8, 112, 232...               1   \n",
       "2     [130, 323, 18, 328, 191, 224, 107, 44, 65, 63]               0   \n",
       "\n",
       "                             timestamp/age_days-list  \\\n",
       "0  [0.8433147126150244, 0.36594029226833047, 0.48...   \n",
       "1  [0.09507837731997637, 0.5639704696082977, 0.67...   \n",
       "2  [0.2557564379821403, 0.37390035704678004, 0.07...   \n",
       "\n",
       "                                        item_id-list  \\\n",
       "0  [35969, 7218, 4254, 43307, 24474, 46468, 17340...   \n",
       "1  [163, 6506, 35424, 24708, 1004, 2914, 20464, 2...   \n",
       "2  [40696, 31278, 1489, 16792, 34465, 17258, 4452...   \n",
       "\n",
       "                          timestamp/weekday/sin-list  day-first  \n",
       "0  [0.8425804078540428, 0.4314946368378889, 0.217...          8  \n",
       "1  [0.4388505546993573, 0.8208003416295997, 0.297...          2  \n",
       "2  [0.7795720554649077, 0.8084530571788069, 0.730...          8  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sessions_gdf.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "novel-determination",
   "metadata": {},
   "source": [
    "- We can save the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "informative-paint",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.save('workflow_inference_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "running-marker",
   "metadata": {},
   "source": [
    "### Export pre-processed data by day "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "suspended-serial",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating time-based splits: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:03<00:00,  2.45it/s]\n"
     ]
    }
   ],
   "source": [
    "# requires cudf + cupy + nvtabular + dask_cudf\n",
    "from transformers4rec.utils.processing_utils import save_time_based_splits\n",
    "save_time_based_splits(data=nvt.Dataset(sessions_gdf),\n",
    "                       output_dir= \"./preproc_sessions_by_day_ts\",\n",
    "                       partition_col='day-first',\n",
    "                       timestamp_col='session_id', \n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuing-inside",
   "metadata": {},
   "source": [
    "# Transformers4rec model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "plastic-commission",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import transformers4rec.torch as torch4rec\n",
    "from transformers4rec.torch import TabularSequenceFeatures, MLPBlock, SequentialBlock, Head, TransformerBlock\n",
    "\n",
    "from transformers4rec.utils.schema import DatasetSchema\n",
    "from transformers4rec.torch.head import NextItemPredictionTask\n",
    "from transformers4rec.config import transformer\n",
    "from transformers4rec.torch.ranking_metric import NDCGAt, AvgPrecisionAt, RecallAt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "linear-upgrade",
   "metadata": {},
   "source": [
    "- Manually set the schema "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "skilled-convertible",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define schema object to pass it to the SequentialTabularFeatures\n",
    "schema = DatasetSchema.from_schema(\"schema.pb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brave-hotel",
   "metadata": {},
   "source": [
    "### Define the sequential input module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "under-notion",
   "metadata": {},
   "source": [
    "Below we define our `input` bloc using [`SequentialTabularFeatures` class](https://github.com/NVIDIA-Merlin/Transformers4Rec/blob/main/transformers4rec/torch/features/sequential.py). The `from_schema` module directly parse schema and accepts categorical and continuous sequential inputs and supports data augmentation, data aggregation, `sequential-concat` and `elementwise-sum` aggregations, the projection of the interaction embeddings and the masking tasks.\n",
    "\n",
    "`max_sequence_length` defines the maximum sequence length of our sequential input, and if `continuous_projection` argument is set,  all numerical features are concatenated and projected by a number of MLP layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "thermal-manchester",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = TabularSequenceFeatures.from_schema(\n",
    "        schema,\n",
    "        max_sequence_length=20,\n",
    "        continuous_projection=64,\n",
    "        d_output=100,\n",
    "        masking=\"causal\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neural-tourism",
   "metadata": {},
   "source": [
    "### End-to-end session-based Transformer-based model for item prediction:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functional-japanese",
   "metadata": {},
   "source": [
    "- LM task + HF Transformer architecture + Next item-prediction task. \n",
    "- We build a [T4RecConfig](https://github.com/NVIDIA-Merlin/Transformers4Rec/blob/main/transformers4rec/config/transformer.py#L8) class to update the config class of the transformer architecture with the specified arguments, then load the related model. Here we use it to instantiate an XLNET model according to the  arguments (d_model, n_head, etc.), defining the model architecture.\n",
    "- [TransformerBlock](https://github.com/NVIDIA-Merlin/Transformers4Rec/blob/main/transformers4rec/torch/block/transformer.py#L37) class is created to support HF Transformers for session-based and sequential-based recommendation models.\n",
    "- [NextItemPredictionTask](https://github.com/NVIDIA-Merlin/Transformers4Rec/blob/main/transformers4rec/torch/head.py#L212) is the class to support next item prediction task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "celtic-quebec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Define XLNetConfig class and set default parameters \n",
    "\n",
    "# Set HF config of XLNet \n",
    "transformer_config = transformer.XLNetConfig.build(\n",
    "    d_model=64, n_head=4, n_layer=2, total_seq_length=20\n",
    ")\n",
    "# Define the model block including: inputs, masking, projection and transformer block.\n",
    "body = torch4rec.SequentialBlock(\n",
    "    inputs, torch4rec.MLPBlock([64]), torch4rec.TransformerBlock(transformer=transformer_config, masking=inputs.masking)\n",
    ")\n",
    "\n",
    "# Define the head related to next item prediction task \n",
    "head = torch4rec.Head(\n",
    "    body,\n",
    "    torch4rec.NextItemPredictionTask(weight_tying=True, hf_format=True),\n",
    "    inputs=inputs,\n",
    "    \n",
    ")\n",
    "\n",
    "# Get the end-to-end Model class \n",
    "model = torch4rec.Model(head, device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moderate-executive",
   "metadata": {},
   "source": [
    "# Training and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "matched-security",
   "metadata": {},
   "source": [
    "- **Set Training arguments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "medical-hostel",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers4rec.config.trainer import T4RecTrainingArguments\n",
    "from transformers4rec.torch import Trainer\n",
    "#Set argumentd for training \n",
    "train_args = T4RecTrainingArguments(local_rank = -1, dataloader_drop_last = True, data_loader_engine='nvtabular',\n",
    "                                  report_to = [], debug = [\"r\"], gradient_accumulation_steps = 32,\n",
    "                                  per_device_train_batch_size = 512, per_device_eval_batch_size = 32,\n",
    "                                  output_dir = \".\", use_legacy_prediction_loop = False,\n",
    "                                  max_sequence_length=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescribed-perth",
   "metadata": {},
   "source": [
    "- **Define paths to train and eval data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "demonstrated-poetry",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "train_data_paths = glob.glob(\"./preproc_sessions_by_day_ts/*/train.parquet\")[:-1]\n",
    "eval_data_paths = glob.glob(\"./preproc_sessions_by_day_ts/*/valid.parquet\")[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automotive-swing",
   "metadata": {},
   "source": [
    "- **Define Trainer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "toxic-intention",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the T4Rec Trainer, which manages training and evaluation\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=train_args,\n",
    "    schema=schema,\n",
    "    compute_metrics=True,\n",
    "    train_dataset_or_path=train_data_paths,\n",
    "    eval_dataset_or_path=eval_data_paths,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promotional-blend",
   "metadata": {},
   "source": [
    "- **Train the model**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "pointed-resource",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:04, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3, training_loss=5.827318827311198, metrics={'train_runtime': 6.673, 'train_samples_per_second': 0.45, 'total_flos': 0.0, 'epoch': 3.0, 'init_mem_cpu_alloc_delta': 0, 'init_mem_gpu_alloc_delta': 0, 'init_mem_cpu_peaked_delta': 0, 'init_mem_gpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 131072, 'train_mem_gpu_alloc_delta': 42939904, 'train_mem_cpu_peaked_delta': 3162112, 'train_mem_gpu_peaked_delta': 7599885824})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.reset_lr_scheduler()\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "municipal-innocent",
   "metadata": {},
   "source": [
    "- **Compute evaluation metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "exact-community",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='72' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:24]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch = 3.0\n",
      "  eval_avgprecisionat_10 = 3.509510861476883e-05\n",
      "  eval_avgprecisionat_20 = 5.472534030559473e-05\n",
      "  eval_loss = 10.933452606201172\n",
      "  eval_mem_cpu_alloc_delta = 12288\n",
      "  eval_mem_cpu_peaked_delta = 2265088\n",
      "  eval_mem_gpu_alloc_delta = 275456\n",
      "  eval_mem_gpu_peaked_delta = 728570368\n",
      "  eval_ndcgat_10 = 6.961845065234229e-05\n",
      "  eval_ndcgat_20 = 0.00014665150956716388\n",
      "  eval_recallat_10 = 0.00018951357924379408\n",
      "  eval_recallat_20 = 0.0005053695640526712\n",
      "  eval_runtime = 6.3765\n",
      "  eval_samples_per_second = 145.534\n"
     ]
    }
   ],
   "source": [
    "eval_metrics = trainer.evaluate(eval_dataset=eval_data_paths, metric_key_prefix='eval')\n",
    "for key in sorted(eval_metrics.keys()):\n",
    "    print(\"  %s = %s\" % (key, str(eval_metrics[key])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "downtown-robin",
   "metadata": {},
   "source": [
    "- **Compute Train metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "unavailable-sucking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch = 3.0\n",
      "  eval_mem_cpu_alloc_delta = 458752\n",
      "  eval_mem_cpu_peaked_delta = 2932736\n",
      "  eval_mem_gpu_alloc_delta = 1244160\n",
      "  eval_mem_gpu_peaked_delta = 732026368\n",
      "  train_avgprecisionat_10 = 1.2897899978270289e-05\n",
      "  train_avgprecisionat_20 = 2.3556582164019346e-05\n",
      "  train_loss = 10.931257247924805\n",
      "  train_ndcgat_10 = 3.009509964613244e-05\n",
      "  train_ndcgat_20 = 7.34374116291292e-05\n",
      "  train_recallat_10 = 9.028529893839732e-05\n",
      "  train_recallat_20 = 0.00027085590409114957\n",
      "  train_runtime = 4.8739\n",
      "  train_samples_per_second = 131.312\n"
     ]
    }
   ],
   "source": [
    "train_metrics = trainer.evaluate(eval_dataset=train_data_paths, metric_key_prefix='train')\n",
    "for key in sorted(train_metrics.keys()):\n",
    "    print(\"  %s = %s\" % (key, str(train_metrics[key])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "partial-array",
   "metadata": {},
   "source": [
    "* **Save the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "revolutionary-compilation",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer._save_model_and_checkpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simplified-syndrome",
   "metadata": {},
   "source": [
    "* **Reload model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "underlying-sight",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.load_model_trainer_states_from_checkpoint('./checkpoint-%s'%trainer.state.global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authentic-hypothesis",
   "metadata": {},
   "source": [
    "- **Re-compute eval metrics of train data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "opposite-geometry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch = 3.0\n",
      "  eval_mem_cpu_alloc_delta = 765952\n",
      "  eval_mem_cpu_peaked_delta = 2945024\n",
      "  eval_mem_gpu_alloc_delta = 1365504\n",
      "  eval_mem_gpu_peaked_delta = 732042752\n",
      "  train_avgprecisionat_10 = 1.2897899978270289e-05\n",
      "  train_avgprecisionat_20 = 2.3556582164019346e-05\n",
      "  train_loss = 10.931257247924805\n",
      "  train_ndcgat_10 = 3.009509964613244e-05\n",
      "  train_ndcgat_20 = 7.34374116291292e-05\n",
      "  train_recallat_10 = 9.028529893839732e-05\n",
      "  train_recallat_20 = 0.00027085590409114957\n",
      "  train_runtime = 5.7332\n",
      "  train_samples_per_second = 111.63\n"
     ]
    }
   ],
   "source": [
    "train_metrics = trainer.evaluate(eval_dataset=train_data_paths, metric_key_prefix='train')\n",
    "for key in sorted(train_metrics.keys()):\n",
    "    print(\"  %s = %s\" % (key, str(train_metrics[key])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thrown-ready",
   "metadata": {},
   "source": [
    "* **Resume Training** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "composed-acoustic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5a1a6d0499f4b15b3afc15124eb3c1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 : < :, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3, training_loss=0.0, metrics={'train_runtime': 0.4482, 'train_samples_per_second': 6.693, 'total_flos': 0, 'epoch': 3.0, 'train_mem_cpu_alloc_delta': 303104, 'train_mem_gpu_alloc_delta': 512, 'train_mem_cpu_peaked_delta': 3067904, 'train_mem_gpu_peaked_delta': 56577536})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reset lr scheduler to train on new day data\n",
    "trainer.reset_lr_scheduler()\n",
    "# set new data from last day\n",
    "trainer.train_dataset = train_data_paths[-1]\n",
    "trainer.train(resume_from_checkpoint='./checkpoint-3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fallen-petite",
   "metadata": {},
   "source": [
    "- **Evaluate on last day**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "independent-founder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  epoch = 3.0\n",
      "  eval_avgprecisionat_10 = 0.0\n",
      "  eval_avgprecisionat_20 = 3.010234831890557e-05\n",
      "  eval_loss = 10.933640480041504\n",
      "  eval_mem_cpu_alloc_delta = 0\n",
      "  eval_mem_cpu_peaked_delta = 2207744\n",
      "  eval_mem_gpu_alloc_delta = -231424\n",
      "  eval_mem_gpu_peaked_delta = 717337088\n",
      "  eval_ndcgat_10 = 0.0\n",
      "  eval_ndcgat_20 = 0.00013706818572245538\n",
      "  eval_recallat_10 = 0.0\n",
      "  eval_recallat_20 = 0.0006020469591021538\n",
      "  eval_runtime = 0.8499\n",
      "  eval_samples_per_second = 112.953\n"
     ]
    }
   ],
   "source": [
    "# set new data from last day\n",
    "eval_metrics = trainer.evaluate(eval_dataset=eval_data_paths[-1], metric_key_prefix='eval')\n",
    "for key in sorted(eval_metrics.keys()):\n",
    "    print(\"  %s = %s\" % (key, str(eval_metrics[key])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behind-astrology",
   "metadata": {},
   "source": [
    "### Incremental Training over a time window "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "appreciated-organic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the T4Rec Trainer, which manages training and evaluation\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=train_args,\n",
    "    schema=schema,\n",
    "    compute_metrics=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "improving-radical",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "Launch training for day 1 are:\n",
      "********************\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "Eval results for day 2 are:\t\n",
      "\n",
      "********************\n",
      "\n",
      " epoch = 3.0\n",
      " eval_avgprecisionat_10 = 0.0003058103902731091\n",
      " eval_avgprecisionat_20 = 0.00040218696813099086\n",
      " eval_loss = 10.881290435791016\n",
      " eval_mem_cpu_alloc_delta = 0\n",
      " eval_mem_cpu_peaked_delta = 2203648\n",
      " eval_mem_gpu_alloc_delta = -80896\n",
      " eval_mem_gpu_peaked_delta = 694926336\n",
      " eval_ndcgat_10 = 0.0003858897543977946\n",
      " eval_ndcgat_20 = 0.0007094023167155683\n",
      " eval_recallat_10 = 0.0006116207805462182\n",
      " eval_recallat_20 = 0.0018348623998463154\n",
      " eval_runtime = 0.9769\n",
      " eval_samples_per_second = 98.27\n",
      "********************\n",
      "Launch training for day 2 are:\n",
      "********************\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "Eval results for day 3 are:\t\n",
      "\n",
      "********************\n",
      "\n",
      " epoch = 3.0\n",
      " eval_avgprecisionat_10 = 0.0\n",
      " eval_avgprecisionat_20 = 8.886857540346682e-05\n",
      " eval_loss = 10.90975570678711\n",
      " eval_mem_cpu_alloc_delta = 0\n",
      " eval_mem_cpu_peaked_delta = 2228224\n",
      " eval_mem_gpu_alloc_delta = -80896\n",
      " eval_mem_gpu_peaked_delta = 706768384\n",
      " eval_ndcgat_10 = 0.0\n",
      " eval_ndcgat_20 = 0.0003137651947326958\n",
      " eval_recallat_10 = 0.0\n",
      " eval_recallat_20 = 0.0012187690008431673\n",
      " eval_runtime = 1.0994\n",
      " eval_samples_per_second = 87.317\n",
      "********************\n",
      "Launch training for day 3 are:\n",
      "********************\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "Eval results for day 4 are:\t\n",
      "\n",
      "********************\n",
      "\n",
      " epoch = 3.0\n",
      " eval_avgprecisionat_10 = 0.0\n",
      " eval_avgprecisionat_20 = 0.0\n",
      " eval_loss = 10.90018367767334\n",
      " eval_mem_cpu_alloc_delta = 0\n",
      " eval_mem_cpu_peaked_delta = 2240512\n",
      " eval_mem_gpu_alloc_delta = -80896\n",
      " eval_mem_gpu_peaked_delta = 694238720\n",
      " eval_ndcgat_10 = 0.0\n",
      " eval_ndcgat_20 = 0.0\n",
      " eval_recallat_10 = 0.0\n",
      " eval_recallat_20 = 0.0\n",
      " eval_runtime = 0.8968\n",
      " eval_samples_per_second = 107.052\n",
      "********************\n",
      "Launch training for day 4 are:\n",
      "********************\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "Eval results for day 5 are:\t\n",
      "\n",
      "********************\n",
      "\n",
      " epoch = 3.0\n",
      " eval_avgprecisionat_10 = 0.0\n",
      " eval_avgprecisionat_20 = 0.0\n",
      " eval_loss = 10.874518394470215\n",
      " eval_mem_cpu_alloc_delta = 0\n",
      " eval_mem_cpu_peaked_delta = 2207744\n",
      " eval_mem_gpu_alloc_delta = -80896\n",
      " eval_mem_gpu_peaked_delta = 698803200\n",
      " eval_ndcgat_10 = 0.0\n",
      " eval_ndcgat_20 = 0.0\n",
      " eval_recallat_10 = 0.0\n",
      " eval_recallat_20 = 0.0\n",
      " eval_runtime = 0.9528\n",
      " eval_samples_per_second = 100.752\n",
      "********************\n",
      "Launch training for day 5 are:\n",
      "********************\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:01, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "Eval results for day 6 are:\t\n",
      "\n",
      "********************\n",
      "\n",
      " epoch = 3.0\n",
      " eval_avgprecisionat_10 = 0.0\n",
      " eval_avgprecisionat_20 = 4.256768443156034e-05\n",
      " eval_loss = 10.89849853515625\n",
      " eval_mem_cpu_alloc_delta = 0\n",
      " eval_mem_cpu_peaked_delta = 2199552\n",
      " eval_mem_gpu_alloc_delta = -80896\n",
      " eval_mem_gpu_peaked_delta = 725211136\n",
      " eval_ndcgat_10 = 0.0\n",
      " eval_ndcgat_20 = 0.00015253755555022508\n",
      " eval_recallat_10 = 0.0\n",
      " eval_recallat_20 = 0.0005959475529380143\n",
      " eval_runtime = 0.9274\n",
      " eval_samples_per_second = 103.519\n",
      "********************\n",
      "Launch training for day 6 are:\n",
      "********************\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "Eval results for day 7 are:\t\n",
      "\n",
      "********************\n",
      "\n",
      " epoch = 3.0\n",
      " eval_avgprecisionat_10 = 0.00012040939327562228\n",
      " eval_avgprecisionat_20 = 0.00012040939327562228\n",
      " eval_loss = 10.92831802368164\n",
      " eval_mem_cpu_alloc_delta = 0\n",
      " eval_mem_cpu_peaked_delta = 2207744\n",
      " eval_mem_gpu_alloc_delta = -80896\n",
      " eval_mem_gpu_peaked_delta = 717337088\n",
      " eval_ndcgat_10 = 0.00023290354874916375\n",
      " eval_ndcgat_20 = 0.00023290354874916375\n",
      " eval_recallat_10 = 0.0006020469591021538\n",
      " eval_recallat_20 = 0.0006020469591021538\n",
      " eval_runtime = 0.9351\n",
      " eval_samples_per_second = 102.661\n"
     ]
    }
   ],
   "source": [
    "start_time_window_index = 1\n",
    "final_time_window_index = 7\n",
    "for time_index in range(start_time_window_index, final_time_window_index):\n",
    "    # Set data \n",
    "    time_index_train = time_index\n",
    "    time_index_eval = time_index + 1\n",
    "    train_paths = glob.glob(f\"./preproc_sessions_by_day_ts/{time_index_train}/train.parquet\")\n",
    "    eval_paths = glob.glob(f\"./preproc_sessions_by_day_ts/{time_index_eval}/valid.parquet\")  \n",
    "    \n",
    "    # Train on day related to time_index \n",
    "    print('*'*20)\n",
    "    print(\"Launch training for day %s are:\" %time_index)\n",
    "    print('*'*20 + '\\n')\n",
    "    trainer.train_dataset = train_paths\n",
    "    trainer.reset_lr_scheduler()\n",
    "    trainer.train()\n",
    "    \n",
    "    # Evaluate on the following day\n",
    "    trainer.eval_dataset = eval_paths\n",
    "    train_metrics = trainer.evaluate(metric_key_prefix='eval')\n",
    "    print('*'*20)\n",
    "    print(\"Eval results for day %s are:\\t\" %time_index_eval)\n",
    "    print('\\n' + '*'*20 + '\\n')\n",
    "    for key in sorted(train_metrics.keys()):\n",
    "        print(\" %s = %s\" % (key, str(train_metrics[key]))) \n",
    "    trainer.wipe_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generous-construction",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
