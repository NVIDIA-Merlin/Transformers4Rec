{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07441647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2021 NVIDIA Corporation. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2503864",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8ae933",
   "metadata": {},
   "source": [
    "In the previous notebook we went through our ETL pipeline with NVTabular library, and created session-based features to be used in training a session-based recommendation model. In this notebook we will learn:\n",
    "\n",
    "- Accelerating data loading of multiple features on PyTorch using NVTabular library\n",
    "- Training and evaluating an RNN-based (GRU) session-based recommendation model \n",
    "- Training and evaluating a Transformer-based (XLNET-MLM) session-based recommendation model\n",
    "- Integrate side information (additional features) into transformer architectures in order to improve recommendation accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff93059",
   "metadata": {},
   "source": [
    "# 2. Session-based Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac57f542",
   "metadata": {},
   "source": [
    "Session-based recommendation, a sub-area of sequential recommendation, has been an important task in online services like e-commerce and news portals, where most users either browse anonymously or may have very distinct interests for different sessions. Session-Based Recommender Systems (SBRS) have\n",
    "been proposed to model the sequence of interactions within the current user session, where a session is a short sequence of user interactions typically bounded by user inactivity. They have recently gained popularity due to their ability to capture short-term and contextual user preferences towards items.\n",
    "\n",
    "\n",
    "Many methods have been proposed to leverage the sequence of interactions that occur during a session, including session-based k-NN algorithms like V-SkNN [1] and neural approaches like GRU4Rec [2]. In addition,  state of the art NLP approaches have inspired RecSys practitioners and researchers to leverage the self-attention mechanism and the Transformer-based architectures for sequential and session-based recommendation[3]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0f2e1d",
   "metadata": {},
   "source": [
    "# 3. Transformers4Rec Library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3290886",
   "metadata": {},
   "source": [
    "In this tutorial, we introduce an open source library, [Transformers4Rec](https://github.com/NVIDIA-Merlin/Transformers4Rec), which leverages the popular [HuggingFace’s Transformers](https://github.com/huggingface/transformers) NLP library and make it possible to experiment with cutting-edge implementation of such architectures for sequential and session-based recommendation problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d863f9e6",
   "metadata": {},
   "source": [
    "Transformers4Rec supports multiple input features and provides configurable building blocks that can be easily combined for custom architectures:\n",
    "\n",
    "- [TabularSequenceFeatures](https://github.com/NVIDIA-Merlin/Transformers4Rec/blob/main/transformers4rec/torch/features/sequence.py#L74) class that reads from schema and creates an input block. This input module combines different types of features (continuous, categorical & text) to a sequence.\n",
    "-  [MaskSequence](https://github.com/NVIDIA-Merlin/Transformers4Rec/blob/main/transformers4rec/torch/masking.py#L28) to define masking schema and prepare the masked inputs and labels for the selected LM task.\n",
    "- [TransformerBlock](https://github.com/NVIDIA-Merlin/Transformers4Rec/blob/main/transformers4rec/torch/block/transformer.py#L38) class that supports HuggingFace Transformers for session-based and sequential-based recommendation models.\n",
    "- [SequentialBlock](https://github.com/NVIDIA-Merlin/Transformers4Rec/blob/main/transformers4rec/torch/block/base.py#L61) that creates the body by mimicking [torch.nn.sequential](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html) class. It is designed to define our model as a sequence of layers.\n",
    "- [Head](https://github.com/NVIDIA-Merlin/Transformers4Rec/blob/main/transformers4rec/torch/model/head.py) where we define the prediction task of the model.\n",
    "- [NextItemPredictionTask](https://github.com/NVIDIA-Merlin/Transformers4Rec/blob/main/transformers4rec/torch/model/head.py#L236) that is the class to support next item prediction task.\n",
    "- [Trainer](https://github.com/NVIDIA-Merlin/Transformers4Rec/blob/main/transformers4rec/torch/trainer.py#L34) manages the model training and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669e30d6",
   "metadata": {},
   "source": [
    "In Figure 1, we define our Transformers4Rec meta-architecure that we train for next-item prediction in this tutorial. Although, we can only use `product-id` as input feature, you can notice that in the figure, we have both categorical and numerical features. That means we can also use side information in traning a Transformers4Rec model, which we will do in Section 3.2.4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d69cf38",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"./images/tf4rec_meta.png\", width=500, height=500></div>\n",
    "<p><center>Figure 1. Transformers4Rec meta-architecure.</center></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186d9b4c",
   "metadata": {},
   "source": [
    "In Transformers4Rec we leverage from HF Transformers only the transformer architectures building block and their configuration classes. Transformers4Rec provides additional blocks necessary for recommendation, e.g., input features normalization and aggregation, and heads for recommendation and sequence classification/prediction. We also extend their Trainer class to allow for the evaluation with RecSys metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5351387",
   "metadata": {},
   "source": [
    "In the `Features Processing Module` of the meta-architecture, the input features are processed. Categorical features are represented by embeddings. Numerical features can be represented as a scalar, projected by a fully-connected (FC) layer to multiple dimensions, or represented as a weighted average of embeddings by the technique Soft One-Hot embeddings (more info in our [paper's online appendix](https://github.com/NVIDIA-Merlin/publications/blob/main/2021_acm_recsys_transformers4rec/Appendices/Appendix_A-Techniques_used_in_Transformers4Rec_Meta-Architecture.md)).\n",
    "\n",
    "The features are optionally normalized (with layer normalization) and then aggregated. The current feature aggregation options are: `concat`, `stack`,\n",
    "`Element-wise sum`  and  `Element-wise sum & item multiplication`.  You can learn more about these aggregation methods [here](https://github.com/NVIDIA-Merlin/Transformers4Rec/blob/main/docs/source/core_features.md).\n",
    "\n",
    "The other blocks of the meta-architecture is explained in the following sections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b0d5d3",
   "metadata": {},
   "source": [
    "## 3.1 Training an RNN-based Session-based Recommendation Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcf772a",
   "metadata": {},
   "source": [
    "In this section, we use a Recurrent Neural Networks (RNN), A Gated Recurrent Unit (GRU)[4] architecture, to do next item prediction using a sequence of events per user in a given session. There is obviously some sequence information that want to capture to do accurate/relevant recommendations. The input of the GRU network is the actual state of the session while the output is the next item to be interacted (e.g., click, view, or purchase) in the session. Basically, for each item in a given session, we generate the output as the predicted preference of the items, i.e. the likelihood of being the next.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adf9823",
   "metadata": {},
   "source": [
    "Figure 2 illustrates the logic of predicting next item in a given session. We treat the recommendation as a multi-class classification problem and use cross-entropy loss. In our first example, we use GRU architecture instead of `Transformer block` as shown in the Figure 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f275fd12",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"./images/gru_based.png\", width=600, height=600></div>\n",
    "<p><center>Figure 2. Next item prediction with RNN.</center></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba63ed6",
   "metadata": {},
   "source": [
    "### 3.1.1 Import Libraries and Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae72789b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import torch \n",
    "import transformers4rec.torch as tr\n",
    "\n",
    "from transformers4rec.torch.ranking_metric import NDCGAt, AvgPrecisionAt, RecallAt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1081a304",
   "metadata": {},
   "source": [
    "- Create the Schema object from `schema` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f89f42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from merlin_standard_lib import Schema\n",
    "# Define schema object to pass it to the TabularSequenceFeatures class\n",
    "SCHEMA_PATH = 'schema_tutorial.pb'\n",
    "schema = Schema().from_proto_text(SCHEMA_PATH)\n",
    "schema = schema.select_by_name(['product_id-list_seq'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338ddfd4",
   "metadata": {},
   "source": [
    "Transformers4Rec library relies on schema object in creation of TabularSequence features. As you can see below `schema.pb` is a protobuf file contains metadata including statistics about features such as cardinality, min and max values and also tags each feature based on their characteristics and dtypes (e.g., categorical, continuous, list, integer). We can tag our target column and even the add the prediction task such as `binary`, `regression` or `multiclass` as a tag for the target column in the `schema.pb` file. `schema.pb` provides a standard representations for metadata that are useful when training machine learning or deep learning models.\n",
    "\n",
    "The meta-data information loaded from `Schema` and their tags is used to automatically set the parameters of Transformers4rec models. Certain Transformers4rec modules have `from_schema` method to instantiate their parameters and layers from protobuf text file respectively. \n",
    "\n",
    "Although in this tutorial we did not automatically generate schema file from the NVTabular workflow, with the new NVTabular release we are able to define a standard and generic protobuf schema."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f387806",
   "metadata": {},
   "source": [
    "Let's view the content of `schema.pb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c983888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature {\n",
      "  name: \"user_session\"\n",
      "  type: INT\n",
      "  int_domain {\n",
      "    name: \"user_session\"\n",
      "    min: 1\n",
      "    max: 1877365\n",
      "    is_categorical: false\n",
      "  }\n",
      "  annotation {\n",
      "    tag: \"groupby_col\"\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"category_id-list_seq\"\n",
      "  value_count {\n",
      "    min: 2\n",
      "    max: 20\n",
      "  }\n",
      "  type: INT\n",
      "  int_domain {\n",
      "    name: \"category_id-list_seq\"\n",
      "    min: 1\n",
      "    max: 567\n",
      "    is_categorical: true\n",
      "  }\n",
      "  annotation {\n",
      "    tag: \"list\"\n",
      "    tag: \"categorical\"\n",
      "    tag: \"item\"\n"
     ]
    }
   ],
   "source": [
    "!head -30 $SCHEMA_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc5806a",
   "metadata": {},
   "source": [
    "Initialize the sequential tabular module that converts the inputs and aggregate them into one single interaction tensor. We use `sequential-concat` aggregation method here. In the input block we also define masking method (see Section 3.2.2 for details)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f552a20",
   "metadata": {},
   "source": [
    "\n",
    "We define our input block using `TabularSequenceFeatures` class. The `from_schema` module directly parse schema and accepts categorical and continuous sequential inputs and supports data augmentation, data aggregation, sequential-concat and elementwise-sum aggregations, the projection of the interaction embeddings and the masking tasks. `max_sequence_length` argument defines the maximum sequence length of our sequential input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98e4cf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length, d_model = 20, 128\n",
    "inputs = tr.TabularSequenceFeatures.from_schema(\n",
    "        schema,\n",
    "        max_sequence_length= sequence_length,\n",
    "        masking = 'causal',\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a264929b",
   "metadata": {},
   "source": [
    "- Define a SequentialBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e777f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "body = tr.SequentialBlock(\n",
    "        inputs,\n",
    "        tr.MLPBlock([d_model]),\n",
    "        tr.Block(torch.nn.GRU(input_size=d_model, hidden_size=d_model, num_layers=1), [None, 20, d_model])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ad1c9d",
   "metadata": {},
   "source": [
    "In our experiments published in our [ACM RecSys'21 paper](https://github.com/NVIDIA-Merlin/publications/blob/main/2021_acm_recsys_transformers4rec/recsys21_transformers4rec_paper.pdf) [7], we used the next item prediction head. It was composed by an output layer using the tying embeddings technique, i.e., weight-tying the projection layer to the item embedding matrix weights, followed by a softmax layer to predict the relevance scores over all items.\n",
    "\n",
    "Weight-tying, also known as `Tying Embeddings`, proposed originally by the NLP community to tie the weights of the input (item id) embedding matrix with the output projection layer, showed to be a very effective technique in extensive experimentation for competitions and empirical analysis (for more details see our [paper](https://github.com/NVIDIA-Merlin/publications/blob/main/2021_acm_recsys_transformers4rec/recsys21_transformers4rec_paper.pdf) and its online [appendix](https://github.com/NVIDIA-Merlin/publications/blob/main/2021_acm_recsys_transformers4rec/Appendices/Appendix_A-Techniques_used_in_Transformers4Rec_Meta-Architecture.md)). You can enable this option as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0bb415",
   "metadata": {},
   "source": [
    "- We link the transformer-body to the inputs and the prediction tasks to get the final pytorch `Model` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16aa2d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Projecting inputs of NextItemPredictionTask to'64' As weight tying requires the input dimension '128' to be equal to the item-id embedding dimension '64'\n"
     ]
    }
   ],
   "source": [
    "head = tr.Head(\n",
    "    body,\n",
    "    tr.NextItemPredictionTask(weight_tying=True, hf_format=True),\n",
    "    inputs=inputs,\n",
    ")\n",
    "model = tr.Model(head)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3c9428",
   "metadata": {},
   "source": [
    "- Initialize the Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda1eff0",
   "metadata": {},
   "source": [
    "We use optimized NVTabular PyTorch Dataloader which has the following benefits:\n",
    "- removing bottlenecks from dataloading by processing large chunks of data at a time instead of item by item\n",
    "- processing datasets that don’t fit within the GPU or CPU memory by streaming from the disk\n",
    "- reading data directly into the GPU memory and removing CPU-GPU communication\n",
    "- preparing batch asynchronously into the GPU to avoid CPU-GPU communication\n",
    "- supporting commonly used formats such as parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "586df367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NVTabular dependencies\n",
    "from nvtabular import Dataset as NVTDataset\n",
    "from nvtabular.loader.torch import DLDataLoader\n",
    "from nvtabular.loader.torch import TorchAsyncItr as NVTDataLoader\n",
    "\n",
    "\n",
    "x_cat_names, x_cont_names = ['product_id-list_seq'], []\n",
    "\n",
    "#   dictionary representing max sequence length for column\n",
    "sparse_features_max = {\n",
    "    fname: sequence_length\n",
    "    for fname in x_cat_names + x_cont_names\n",
    "}\n",
    "\n",
    "# define collate function\n",
    "def dataloader_collate_dict(inputs):\n",
    "    # Gets only the features dict\n",
    "    inputs = inputs[0][0]\n",
    "    return inputs\n",
    "\n",
    "class DLDataLoaderWrapper(DLDataLoader):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        if \"batch_size\" in kwargs:\n",
    "            self._batch_size = kwargs.pop(\"batch_size\")\n",
    "        super().__init__(*args, **kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f389e0",
   "metadata": {},
   "source": [
    "**Daily Fine-Tuning: Training over a time window**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86edae54",
   "metadata": {},
   "source": [
    "Now that the model is defined, we are going to launch training. For that, Transfromers4rec extends HF Transformers Trainer class to adapt the evaluation loop for session-based recommendation task and the calculation of ranking metrics. The original train() method is not modified meaning that we leverage the efficient training implementation from that library, which manages for example half-precision (FP16) training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b26f26",
   "metadata": {},
   "source": [
    "- Set training arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c3c9168",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers4rec.config.trainer import T4RecTrainingArguments\n",
    "from transformers4rec.torch import Trainer\n",
    "#Set argumentd for training \n",
    "train_args = T4RecTrainingArguments(local_rank = -1, \n",
    "                                    dataloader_drop_last = False,\n",
    "                                    report_to = [],   #set empy list to avoig w&b login\n",
    "                                    gradient_accumulation_steps = 1,\n",
    "                                    per_device_train_batch_size = 256, \n",
    "                                    per_device_eval_batch_size = 32,\n",
    "                                    output_dir = \"./tmp\", \n",
    "                                    max_sequence_length=sequence_length,\n",
    "                                    learning_rate=0.00071,\n",
    "                                    num_train_epochs=3,\n",
    "                                    logging_steps=200,\n",
    "                                    fp16=True\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf05ba77",
   "metadata": {},
   "source": [
    "**Instantiate the Trainer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0c329c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp fp16 backend\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the T4Rec Trainer, which manages training and evaluation\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=train_args,\n",
    "    schema=schema,\n",
    "    compute_metrics=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d59fc1c",
   "metadata": {},
   "source": [
    "Here, we use a for loop that allows us to do fit_and_evaluate method to conduct a time-based finetuning by iteratively training and evaluating using a sliding time window: At each iteration, we use training data of a specific time index $t$ to train the model then we evaluate on the validation data of next index $t + 1$. We set the start time to 1 and end time to 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "193c7abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 112128\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 256\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1024\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "Launch training for day 1 are:\n",
      "********************\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1314' max='1314' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1314/1314 00:41, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>9.778900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>8.600300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>8.914900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>8.256100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>8.755000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>8.260700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./tmp/checkpoint-500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ./tmp/checkpoint-1000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1285' max='415' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [415/415 01:53]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "Eval results for day 2 are:\t\n",
      "\n",
      "********************\n",
      "\n",
      " epoch = 3.0\n",
      " eval/loss = 8.929278373718262\n",
      " eval/next-item/avg_precision_at_10 = 0.026402698829770088\n",
      " eval/next-item/avg_precision_at_20 = 0.028756285086274147\n",
      " eval/next-item/ndcg_at_10 = 0.037264637649059296\n",
      " eval/next-item/ndcg_at_20 = 0.04631560295820236\n",
      " eval/next-item/recall_at_10 = 0.07246813923120499\n",
      " eval/next-item/recall_at_20 = 0.10866450518369675\n",
      " eval_runtime = 10.7994\n",
      " eval_samples_per_second = 1229.7\n",
      " eval_steps_per_second = 9.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 106240\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 256\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1024\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "Launch training for day 2 are:\n",
      "********************\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1245' max='1245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1245/1245 00:41, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>8.925700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>8.294500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>8.581000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>7.994200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>8.430800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>7.854800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./tmp/checkpoint-500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "/opt/conda/lib/python3.8/site-packages/transformers/trainer.py:1308: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  nn.utils.clip_grad_norm_(\n",
      "Saving model checkpoint to ./tmp/checkpoint-1000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "Eval results for day 3 are:\t\n",
      "\n",
      "********************\n",
      "\n",
      " epoch = 3.0\n",
      " eval/loss = 8.572248458862305\n",
      " eval/next-item/avg_precision_at_10 = 0.03747013211250305\n",
      " eval/next-item/avg_precision_at_20 = 0.04074178263545036\n",
      " eval/next-item/ndcg_at_10 = 0.05200152099132538\n",
      " eval/next-item/ndcg_at_20 = 0.06437703967094421\n",
      " eval/next-item/recall_at_10 = 0.09900505840778351\n",
      " eval/next-item/recall_at_20 = 0.14793671667575836\n",
      " eval_runtime = 9.8333\n",
      " eval_samples_per_second = 1249.632\n",
      " eval_steps_per_second = 9.763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 97792\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 256\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1024\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "Launch training for day 3 are:\n",
      "********************\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1146' max='1146' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1146/1146 00:37, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>8.579900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>8.078100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>8.147700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>7.907300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>7.907900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./tmp/checkpoint-500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ./tmp/checkpoint-1000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "Eval results for day 4 are:\t\n",
      "\n",
      "********************\n",
      "\n",
      " epoch = 3.0\n",
      " eval/loss = 8.276490211486816\n",
      " eval/next-item/avg_precision_at_10 = 0.04509400203824043\n",
      " eval/next-item/avg_precision_at_20 = 0.049110736697912216\n",
      " eval/next-item/ndcg_at_10 = 0.06254374980926514\n",
      " eval/next-item/ndcg_at_20 = 0.07782411575317383\n",
      " eval/next-item/recall_at_10 = 0.1184617355465889\n",
      " eval/next-item/recall_at_20 = 0.17907756567001343\n",
      " eval_runtime = 12.3829\n",
      " eval_samples_per_second = 1255.923\n",
      " eval_steps_per_second = 9.852\n",
      "CPU times: user 2min 15s, sys: 22.4 s, total: 2min 38s\n",
      "Wall time: 2min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_time_window_index = 1\n",
    "final_time_window_index = 4\n",
    "for time_index in range(start_time_window_index, final_time_window_index):\n",
    "    # Set data \n",
    "    time_index_train = time_index\n",
    "    time_index_eval = time_index + 1\n",
    "    train_paths = glob.glob(f\"/workspace/data/sessions_by_day/{time_index_train}/train.parquet\")\n",
    "    eval_paths = glob.glob(f\"/workspace/data/sessions_by_day/{time_index_eval}/valid.parquet\")  \n",
    "\n",
    "    train_dataset = NVTDataset(\n",
    "    train_paths,\n",
    "    engine=\"parquet\")\n",
    "    \n",
    "    eval_dataset = NVTDataset(\n",
    "    eval_paths,\n",
    "    engine=\"parquet\")\n",
    "\n",
    "    train_loader = NVTDataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size= train_args.per_device_train_batch_size,\n",
    "    shuffle=False,\n",
    "    cats=x_cat_names,\n",
    "    conts=x_cont_names,\n",
    "    device=0,\n",
    "    labels=[],\n",
    "    sparse_names=x_cat_names + x_cont_names,\n",
    "    sparse_max=sparse_features_max,\n",
    "    sparse_as_dense=True,\n",
    "    drop_last=False,\n",
    "    )\n",
    "\n",
    "    eval_loader = NVTDataLoader(\n",
    "    dataset=eval_dataset,\n",
    "    batch_size= train_args.per_device_eval_batch_size,\n",
    "    shuffle=False,\n",
    "    cats=x_cat_names,\n",
    "    conts=x_cont_names,\n",
    "    device=0,\n",
    "    labels=[],\n",
    "    sparse_names=x_cat_names + x_cont_names,\n",
    "    sparse_max=sparse_features_max,\n",
    "    sparse_as_dense=True,\n",
    "    drop_last=False,\n",
    "    )\n",
    "    \n",
    "    dl_loader = DLDataLoaderWrapper(\n",
    "    train_loader, collate_fn=dataloader_collate_dict, batch_size=train_args.per_device_train_batch_size,\n",
    "    )\n",
    "\n",
    "    dl_loader_eval = DLDataLoaderWrapper(\n",
    "    eval_loader, collate_fn=dataloader_collate_dict, batch_size=train_args.per_device_eval_batch_size,\n",
    "    )\n",
    "\n",
    "    trainer.train_dataloader = dl_loader\n",
    "    trainer.eval_dataloader = dl_loader_eval\n",
    "    \n",
    "    # Train on day related to time_index \n",
    "    print('*'*20)\n",
    "    print(\"Launch training for day %s are:\" %time_index)\n",
    "    print('*'*20 + '\\n')\n",
    "\n",
    "    trainer.reset_lr_scheduler()\n",
    "    trainer.train()\n",
    "    trainer.state.global_step +=1\n",
    "    # Evaluate on the following day\n",
    "    train_metrics = trainer.evaluate(metric_key_prefix='eval')\n",
    "    print('*'*20)\n",
    "    print(\"Eval results for day %s are:\\t\" %time_index_eval)\n",
    "    print('\\n' + '*'*20 + '\\n')\n",
    "    for key in sorted(train_metrics.keys()):\n",
    "        print(\" %s = %s\" % (key, str(train_metrics[key]))) \n",
    "    trainer.wipe_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8427fd60",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab103af",
   "metadata": {},
   "source": [
    "The following information\n",
    "retrieval metrics are used to compute the Top-20 accuracy of recommendation lists containing all items: <br> \n",
    "- **Normalized Discounted Cumulative Gain (NDCG@20):** NDCG accounts for rank of the relevant item in the recommendation list and is a more fine-grained metric than HR, which only verifies whether the relevant item is among the top-k items.\n",
    "\n",
    "- **Hit Rate (HR@20)**: Also known as `Recall@n` when there is only one relevant item in the recommendation list. HR just verifies whether the relevant item is among the top-n items."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517deb90",
   "metadata": {},
   "source": [
    "#### Restart the kernel to free our GPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fac23e4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a7bc9c",
   "metadata": {},
   "source": [
    "## 3.2. Training a Transformers-based Session-based Recommendation Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775709c3",
   "metadata": {},
   "source": [
    "### 3.2.1 What's Transformers?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4544cc4f",
   "metadata": {},
   "source": [
    "The Transformer is a competitive alternative to the models using Recurrent Neural Networks (RNNs) for a range of sequence modeling tasks. The Transformer architecture [5] was introduced as a novel architecture in NLP domain that aims to solve sequence-to-sequence tasks relying entirely on self-attention mechanism to compute representations of its input and output. Hence, the Transformer overperforms RNNs with their three mechanisms: \n",
    "\n",
    "- Non-sequential: Transformers network is parallelized where as RNN computations are inherently sequential. That resulted in significant speed-up in the training time.\n",
    "- Self-attention mechanisms: Transformers rely entirely on self-attention mechanisms that directly model relationships between all item-ids in a sequence.  \n",
    "- Positional encodings: A representation of the location or “position” of items in a sequence which is used to give the order context to the model architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90096655",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"./images/transformer_vs_rnn.png\", width=600, height=600></div>\n",
    "<p><center> Figure 3. Transformer vs vanilla RNN.</center></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3074a974",
   "metadata": {},
   "source": [
    "Figure 4 illustrates the differences of Transformer (self-attention based) and a vanilla RNN architecture. As we see, RNN cannot be parallelized because it uses sequential processing over time (notice the sequential path from previous cells to the current one). On the other hand, the Transformer is a more powerful architecture because the self-attention mechanism is capable of representing dependencies within the sequence of tokens, favors parallel processing and handle longer sequences.\n",
    "\n",
    "As illustrated in the [Attention is All You Need](https://arxiv.org/pdf/1706.03762.pdf) paper, the original transformer model is made up of an encoder and decoder where each is a stack we can call a transformer block. In our transformer-meta architecture we use the encoder block of transformer architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccb89a1",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"./images/encoder.png\", width=300, height=300></div>\n",
    "<p><center> Figure 4. Encoder block of the Transformer Architecture.</center></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03be1743",
   "metadata": {},
   "source": [
    "### 3.2.2. XLNet-MLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e7de1b",
   "metadata": {},
   "source": [
    "Here, we use XLNet as the Transformer block in our meta-architecture and train the model with `Masked Language Model (MLM)` masking method. XLNet [9] was proposed as a generalized autoregressive (AR) pretraining method that uses a permutation language modeling (PLM) objective to combine the advantages of AR and auoencoding (AE) methods. Here, we use XLNet as the Transformer block in our meta-architecture and train the model with `Masked Language Model (MLM)` masking method. XLNet's main contribution is a modified language model training objective which learns conditional distributions for all permutations of tokens in a sequence[8]. \n",
    "\n",
    "MLM  pre-training objective was introduced in `BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding` paper [7]. The Figure 5 illustrates the masking methods, causal language modeling (LM) and masked LM, that we use in RNN and XLNet-MLM, respectively. Causal LM is the task of predicting the token following a sequence of tokens, where the model only attends to the left context, i.e. models the probability of a token given the previous tokens in a sentence [6]. The MLM randomly masks some of the tokens from the input sequence, and the objective is to predict the original vocabulary id of the masked word based only on its context. The Transformer layer is allowed to use positions on the right (future information) during training. During inference, all past items are visible for the Transformer layer, which tries to predict the next item. In our experiments [7] we obtained very promising accuracy results with XLNET-MLM which allows the use of future information during training, and performs a type of data augmentation, by masking different positions of the sequences in each training epoch. Therefore, in this tutorial we use masked LM as masking method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6770345",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"./images/masking.png\", width=600, height=600></div>\n",
    "<p><center>Figure 5. Causal and Masked Language Model masking methods.</center></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5d225e",
   "metadata": {},
   "source": [
    "###  3.2.3 Train XLNET-MLM for Next Item Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987b4fcc",
   "metadata": {},
   "source": [
    "Now we are going to leverage XLNET-masked LM (MLM) model to do next item prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5581d985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import torch \n",
    "import transformers4rec.torch as tr\n",
    "\n",
    "from transformers4rec.torch.ranking_metric import NDCGAt, AvgPrecisionAt, RecallAt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3af572",
   "metadata": {},
   "source": [
    "As we did above, we start with defining our schema object and our sub-schema to chose only `product-id` feature to train our XLNET-MLM architecture with only one feature. For masking task, we use `mlm` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d612ba59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from merlin_standard_lib import Schema\n",
    "schema = Schema().from_proto_text(\"schema_tutorial.pb\")\n",
    "# create a sub-schema only with the selected features\n",
    "schema = schema.select_by_name(['product_id-list_seq'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50143d14",
   "metadata": {},
   "source": [
    "- Define Input block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40e42505",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input \n",
    "sequence_length, d_model = 20, 192\n",
    "# Define input module to process tabular input-features and to prepare masked inputs\n",
    "inputs= tr.TabularSequenceFeatures.from_schema(\n",
    "    schema,\n",
    "    max_sequence_length=sequence_length,\n",
    "    d_output=d_model,\n",
    "    masking=\"mlm\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be621b6d",
   "metadata": {},
   "source": [
    "We build a XLNetConfig class to update the config class of the transformer architecture with the specified arguments, then load the related model. Here we use it to instantiate an XLNET model according to the arguments (d_model, n_head, etc.), defining the model architecture.\n",
    "\n",
    "TransformerBlock class is created to support HF Transformers for session-based and sequential-based recommendation models. `NextItemPredictionTask` is the class to support next item prediction task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb3ae4d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Projecting inputs of NextItemPredictionTask to'64' As weight tying requires the input dimension '192' to be equal to the item-id embedding dimension '64'\n"
     ]
    }
   ],
   "source": [
    "# Define XLNetConfig class and set default parameters for HF XLNet config  \n",
    "transformer_config = tr.XLNetConfig.build(\n",
    "    d_model=d_model, n_head=4, n_layer=2, total_seq_length=sequence_length\n",
    ")\n",
    "# Define the model block including: inputs, masking, projection and transformer block.\n",
    "body = tr.SequentialBlock(\n",
    "    inputs, tr.MLPBlock([192]), tr.TransformerBlock(transformer_config, masking=inputs.masking)\n",
    ")\n",
    "\n",
    "# Define the head for to next item prediction task \n",
    "head = tr.Head(\n",
    "    body,\n",
    "    tr.NextItemPredictionTask(weight_tying=True, hf_format=True, \n",
    "                                     metrics=[NDCGAt(top_ks=[10, 20], labels_onehot=True),  RecallAt(top_ks=[10, 20], labels_onehot=True)]),\n",
    "    inputs=inputs,\n",
    ")\n",
    "\n",
    "# Get the end-to-end Model class \n",
    "model = tr.Model(head)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629dd7e3",
   "metadata": {},
   "source": [
    "**Set training arguments**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6463cf88",
   "metadata": {},
   "source": [
    "An additional argument `data_loader_engine` is defined to automatically load the features needed for training using the schema. The default value is nvtabular for optimized GPU-based data-loading. Optionally the PyarrowDataLoader (pyarrow) can also be used as a basic option, but it is slower and works only for small datasets, as the full data is loaded to CPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8d31138",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n"
     ]
    }
   ],
   "source": [
    "from transformers4rec.config.trainer import T4RecTrainingArguments\n",
    "from transformers4rec.torch import Trainer\n",
    "\n",
    "#Set arguments for training \n",
    "training_args = T4RecTrainingArguments(\n",
    "            output_dir=\"./tmp\",\n",
    "            max_sequence_length=20,\n",
    "            data_loader_engine='nvtabular',\n",
    "            num_train_epochs=3, \n",
    "            dataloader_drop_last=False,\n",
    "            per_device_train_batch_size = 256,\n",
    "            per_device_eval_batch_size = 32,\n",
    "            gradient_accumulation_steps = 1,\n",
    "            learning_rate=0.000666,\n",
    "            report_to = [],\n",
    "            logging_steps=200,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f032faad",
   "metadata": {},
   "source": [
    "**Instantiate the trainer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "306078d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the T4Rec Trainer, which manages training and evaluation\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    schema=schema,\n",
    "    compute_metrics=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2111229",
   "metadata": {},
   "source": [
    "- Now, we do time-based fine-tuning the model by iteratively training and evaluating using a sliding time window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10b6c509",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 112128\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 256\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1024\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/workspace/data/sessions_by_day/1/train.parquet']\n",
      "********************\n",
      "Launch training for day 1 are:\n",
      "********************\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1314' max='1314' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1314/1314 00:45, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>9.949500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>8.630800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>8.990900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>8.198900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>8.673500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>8.158600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./tmp/checkpoint-500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ./tmp/checkpoint-1000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1285' max='415' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [415/415 01:49]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "Eval results for day 2 are:\t\n",
      "\n",
      "********************\n",
      "\n",
      " epoch = 3.0\n",
      " eval/loss = 8.890445709228516\n",
      " eval/next-item/ndcg_at_10 = 0.0488111786544323\n",
      " eval/next-item/ndcg_at_20 = 0.058980487287044525\n",
      " eval/next-item/recall_at_10 = 0.0929040014743805\n",
      " eval/next-item/recall_at_20 = 0.13347409665584564\n",
      " eval_runtime = 6.9288\n",
      " eval_samples_per_second = 1916.646\n",
      " eval_steps_per_second = 15.01\n",
      "['/workspace/data/sessions_by_day/2/train.parquet']\n",
      "********************\n",
      "Launch training for day 2 are:\n",
      "********************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 106240\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 256\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1024\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1245\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1245' max='1245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1245/1245 00:43, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>8.786500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>8.122600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>8.559000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>7.912700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>8.409000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>7.769500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./tmp/checkpoint-500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ./tmp/checkpoint-1000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "Eval results for day 3 are:\t\n",
      "\n",
      "********************\n",
      "\n",
      " epoch = 3.0\n",
      " eval/loss = 8.53929328918457\n",
      " eval/next-item/ndcg_at_10 = 0.057730529457330704\n",
      " eval/next-item/ndcg_at_20 = 0.07115677744150162\n",
      " eval/next-item/recall_at_10 = 0.11099331825971603\n",
      " eval/next-item/recall_at_20 = 0.16416572034358978\n",
      " eval_runtime = 7.0637\n",
      " eval_samples_per_second = 1739.595\n",
      " eval_steps_per_second = 13.591\n",
      "['/workspace/data/sessions_by_day/3/train.parquet']\n",
      "********************\n",
      "Launch training for day 3 are:\n",
      "********************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 97792\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 256\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1024\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1146\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1146' max='1146' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1146/1146 00:41, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>8.461800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>7.949400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>8.122600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>7.886600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>7.917500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./tmp/checkpoint-500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ./tmp/checkpoint-1000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "Eval results for day 4 are:\t\n",
      "\n",
      "********************\n",
      "\n",
      " epoch = 3.0\n",
      " eval/loss = 8.245924949645996\n",
      " eval/next-item/ndcg_at_10 = 0.06760746985673904\n",
      " eval/next-item/ndcg_at_20 = 0.08345689624547958\n",
      " eval/next-item/recall_at_10 = 0.12690028548240662\n",
      " eval/next-item/recall_at_20 = 0.1897706836462021\n",
      " eval_runtime = 8.9579\n",
      " eval_samples_per_second = 1736.119\n",
      " eval_steps_per_second = 13.619\n",
      "CPU times: user 7min 5s, sys: 14.2 s, total: 7min 19s\n",
      "Wall time: 2min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_time_window_index = 1\n",
    "final_time_window_index = 4\n",
    "for time_index in range(start_time_window_index, final_time_window_index):\n",
    "    # Set data \n",
    "    time_index_train = time_index\n",
    "    time_index_eval = time_index + 1\n",
    "    train_paths = glob.glob(f\"/workspace/data/sessions_by_day/{time_index_train}/train.parquet\")\n",
    "    eval_paths = glob.glob(f\"/workspace/data/sessions_by_day/{time_index_eval}/valid.parquet\")  \n",
    "    print(train_paths)\n",
    "    # Train on day related to time_index \n",
    "    print('*'*20)\n",
    "    print(\"Launch training for day %s are:\" %time_index)\n",
    "    print('*'*20 + '\\n')\n",
    "    trainer.train_dataset_or_path = train_paths\n",
    "    trainer.reset_lr_scheduler()\n",
    "    trainer.train()\n",
    "    trainer.state.global_step +=1\n",
    "    # Evaluate on the following day\n",
    "    trainer.eval_dataset_or_path = eval_paths\n",
    "    train_metrics = trainer.evaluate(metric_key_prefix='eval')\n",
    "    print('*'*20)\n",
    "    print(\"Eval results for day %s are:\\t\" %time_index_eval)\n",
    "    print('\\n' + '*'*20 + '\\n')\n",
    "    for key in sorted(train_metrics.keys()):\n",
    "        print(\" %s = %s\" % (key, str(train_metrics[key]))) \n",
    "    trainer.wipe_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d482572",
   "metadata": {},
   "source": [
    "### Restart the kernel to free our GPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d9cfa88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)\n",
    "app.kernel.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee40ba7a",
   "metadata": {},
   "source": [
    "### 3.2.4 Train XLNET-MLM with Side Information for Next Item Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613fbcb5",
   "metadata": {},
   "source": [
    "It is a common practice in RecSys to leverage additional tabular features of item (product) metadata and user context, providing the model more\n",
    "information for meaningful predictions. With that motivation, in this section, we will use additional features to train our XLNET-MLM architecture. We already checked our `schema.pb`, saw that it includes features and their tags. Now it is time to use these additional features that we created in the `01_ETL_with_NVTAbular` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a02ac526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import nvtabular as nvt\n",
    "\n",
    "import torch \n",
    "import transformers4rec.torch as tr\n",
    "\n",
    "from transformers4rec.torch.ranking_metric import NDCGAt, AvgPrecisionAt, RecallAt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59946841",
   "metadata": {},
   "source": [
    "This time we want you to do some coding exercise and replace the `FIXME` in the cells with the proper codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd74eaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define categorical and continuous columns to fed to training model\n",
    "x_cat_names = ['product_id-list_seq', 'category_id-list_seq', 'brand-list_seq']\n",
    "x_cont_names = ['product_recency_days_log_norm-list_seq', 'et_dayofweek_sin-list_seq', 'et_dayofweek_cos-list_seq', \n",
    "                'price_log_norm-list_seq', 'relative_price_to_avg_categ_id-list_seq']\n",
    "\n",
    "\n",
    "from merlin_standard_lib import Schema\n",
    "schema = Schema().from_proto_text(\"schema_tutorial.pb\")\n",
    "# create a sub-schema only with the selected features\n",
    "schema = schema.select_by_name(x_cat_names + x_cont_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d93ad0",
   "metadata": {},
   "source": [
    "Below, we define `continuous_projection` argument, so that all numerical features are concatenated and projected by a number of MLP layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09fd7821",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Projecting inputs of NextItemPredictionTask to'64' As weight tying requires the input dimension '192' to be equal to the item-id embedding dimension '64'\n"
     ]
    }
   ],
   "source": [
    "#Input \n",
    "sequence_length, d_model = 20, 192\n",
    "# Define input module to process tabular input-features and to prepare masked inputs\n",
    "inputs= tr.TabularSequenceFeatures.from_schema(\n",
    "    schema,\n",
    "    max_sequence_length=sequence_length,\n",
    "    aggregation=\"concat\",\n",
    "    d_output=d_model,\n",
    "    masking=\"mlm\",\n",
    ")\n",
    "\n",
    "\n",
    "# Define XLNetConfig class and set default parameters for HF XLNet config  \n",
    "transformer_config = tr.XLNetConfig.build(\n",
    "    d_model=d_model, n_head=4, n_layer=2, total_seq_length=sequence_length\n",
    ")\n",
    "# Define the model block including: inputs, masking, projection and transformer block.\n",
    "body = tr.SequentialBlock(\n",
    "    inputs, tr.MLPBlock([192]), tr.TransformerBlock(transformer_config, masking=inputs.masking)\n",
    ")\n",
    "\n",
    "# Define the head related to next item prediction task \n",
    "head = tr.Head(\n",
    "    body,\n",
    "    tr.NextItemPredictionTask(weight_tying=True, hf_format=True, \n",
    "                                     metrics=[NDCGAt(top_ks=[10, 20], labels_onehot=True),  RecallAt(top_ks=[10, 20], labels_onehot=True)]),\n",
    "    inputs=inputs,\n",
    ")\n",
    "\n",
    "# Get the end-to-end Model class \n",
    "model = tr.Model(head)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e60661d",
   "metadata": {},
   "source": [
    "- Set training arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90ddf84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers4rec.config.trainer import T4RecTrainingArguments\n",
    "from transformers4rec.torch import Trainer\n",
    "\n",
    "#Set arguments for training \n",
    "training_args = T4RecTrainingArguments(\n",
    "            output_dir=\"./tmp\",\n",
    "            max_sequence_length=20,\n",
    "            data_loader_engine='nvtabular',\n",
    "            num_train_epochs=3, \n",
    "            dataloader_drop_last=False,\n",
    "            per_device_train_batch_size = 256,\n",
    "            per_device_eval_batch_size = 32,\n",
    "            gradient_accumulation_steps = 1,\n",
    "            learning_rate=0.000666,\n",
    "            report_to = [],\n",
    "            logging_steps=200,\n",
    "            fp16=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42064b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp fp16 backend\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the T4Rec Trainer, which manages training and evaluation\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    schema=schema,\n",
    "    compute_metrics=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "766b3f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/workspace/data/sessions_by_day/1/train.parquet']\n",
      "********************\n",
      "Launch training for day 1 are:\n",
      "********************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 112128\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 256\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1024\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1314\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1314' max='1314' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1314/1314 00:58, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>9.776300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>8.470700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>8.840600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>8.069200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>8.585600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>8.066300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./tmp/checkpoint-500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ./tmp/checkpoint-1000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1285' max='415' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [415/415 02:22]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "Eval results for day 2 are:\t\n",
      "\n",
      "********************\n",
      "\n",
      " epoch = 3.0\n",
      " eval/loss = 8.77418041229248\n",
      " eval/next-item/ndcg_at_10 = 0.05047212168574333\n",
      " eval/next-item/ndcg_at_20 = 0.061401452869176865\n",
      " eval/next-item/recall_at_10 = 0.09584496170282364\n",
      " eval/next-item/recall_at_20 = 0.1396576464176178\n",
      " eval_runtime = 10.441\n",
      " eval_samples_per_second = 1271.904\n",
      " eval_steps_per_second = 9.961\n",
      "['/workspace/data/sessions_by_day/2/train.parquet']\n",
      "********************\n",
      "Launch training for day 2 are:\n",
      "********************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 106240\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 256\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1024\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1245\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1245' max='1245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1245/1245 00:56, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>8.665400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>7.955000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>8.360900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>7.689000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>8.168700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>7.522300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./tmp/checkpoint-500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ./tmp/checkpoint-1000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "Eval results for day 3 are:\t\n",
      "\n",
      "********************\n",
      "\n",
      " epoch = 3.0\n",
      " eval/loss = 8.289910316467285\n",
      " eval/next-item/ndcg_at_10 = 0.06571312248706818\n",
      " eval/next-item/ndcg_at_20 = 0.08056033402681351\n",
      " eval/next-item/recall_at_10 = 0.12608057260513306\n",
      " eval/next-item/recall_at_20 = 0.18496167659759521\n",
      " eval_runtime = 9.8227\n",
      " eval_samples_per_second = 1250.984\n",
      " eval_steps_per_second = 9.773\n",
      "['/workspace/data/sessions_by_day/3/train.parquet']\n",
      "********************\n",
      "Launch training for day 3 are:\n",
      "********************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 97792\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 256\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1024\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1146\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1146' max='1146' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1146/1146 00:50, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>8.191800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>7.668200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>7.769100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>7.534700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>7.518400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./tmp/checkpoint-500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to ./tmp/checkpoint-1000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "Eval results for day 4 are:\t\n",
      "\n",
      "********************\n",
      "\n",
      " epoch = 3.0\n",
      " eval/loss = 7.87404203414917\n",
      " eval/next-item/ndcg_at_10 = 0.08250310271978378\n",
      " eval/next-item/ndcg_at_20 = 0.09957076609134674\n",
      " eval/next-item/recall_at_10 = 0.15479257702827454\n",
      " eval/next-item/recall_at_20 = 0.2225586175918579\n",
      " eval_runtime = 12.4518\n",
      " eval_samples_per_second = 1248.977\n",
      " eval_steps_per_second = 9.798\n",
      "CPU times: user 8min 7s, sys: 14.2 s, total: 8min 21s\n",
      "Wall time: 3min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_time_window_index = 1\n",
    "final_time_window_index = 4\n",
    "for time_index in range(start_time_window_index, final_time_window_index):\n",
    "    # Set data \n",
    "    time_index_train = time_index\n",
    "    time_index_eval = time_index + 1\n",
    "    train_paths = glob.glob(f\"/workspace/data/sessions_by_day/{time_index_train}/train.parquet\")\n",
    "    eval_paths = glob.glob(f\"/workspace/data/sessions_by_day/{time_index_eval}/valid.parquet\")  \n",
    "    print(train_paths)\n",
    "    # Train on day related to time_index \n",
    "    print('*'*20)\n",
    "    print(\"Launch training for day %s are:\" %time_index)\n",
    "    print('*'*20 + '\\n')\n",
    "    trainer.train_dataset_or_path = train_paths\n",
    "    trainer.reset_lr_scheduler()\n",
    "    trainer.train()\n",
    "    trainer.state.global_step +=1\n",
    "    # Evaluate on the following day\n",
    "    trainer.eval_dataset_or_path = eval_paths\n",
    "    train_metrics = trainer.evaluate(metric_key_prefix='eval')\n",
    "    print('*'*20)\n",
    "    print(\"Eval results for day %s are:\\t\" %time_index_eval)\n",
    "    print('\\n' + '*'*20 + '\\n')\n",
    "    for key in sorted(train_metrics.keys()):\n",
    "        print(\" %s = %s\" % (key, str(train_metrics[key]))) \n",
    "    trainer.wipe_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f536be38",
   "metadata": {},
   "source": [
    "- Export the worflow and model in the format required by Triton server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6807d10",
   "metadata": {},
   "source": [
    "After model training and evaluation is completed we can save our trained model. Here, we also use NVTabular’s `export_pytorch_ensemble` function which enables us to create model files and config files to be served to [Triton Inference Server](https://github.com/triton-inference-server/server). Nvidia Triton IS simplifies the deployment of AI models at scale in production."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88303d30",
   "metadata": {},
   "source": [
    "- Load the workflow that we saved in the ETL notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c24d439",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nvtabular as nvt\n",
    "workflow_path = 'workflow_etl'\n",
    "workflow = nvt.Workflow.load(workflow_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fa54750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'product_id-list_seq': 20,\n",
       " 'category_id-list_seq': 20,\n",
       " 'brand-list_seq': 20,\n",
       " 'product_recency_days_log_norm-list_seq': 20,\n",
       " 'et_dayofweek_sin-list_seq': 20,\n",
       " 'et_dayofweek_cos-list_seq': 20,\n",
       " 'price_log_norm-list_seq': 20,\n",
       " 'relative_price_to_avg_categ_id-list_seq': 20}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dictionary representing max sequence length for column\n",
    "sparse_features_max = {\n",
    "    fname: sequence_length\n",
    "    for fname in x_cat_names + x_cont_names\n",
    "}\n",
    "\n",
    "sparse_features_max"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6cf2e0",
   "metadata": {},
   "source": [
    "- Export the worflow and model in the format required by Triton Inference Server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee64f0a8",
   "metadata": {},
   "source": [
    "NVTabular’s `export_pytorch_ensemble` function enables us to create model files and config files to be served to Triton Inference Server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fe20b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nvtabular.inference.triton import export_pytorch_ensemble\n",
    "export_pytorch_ensemble(\n",
    "    model,\n",
    "    workflow,\n",
    "    sparse_max=sparse_features_max,\n",
    "    name= \"t4r_pytorch\",\n",
    "    model_path= \"/workspace/TF4Rec/models/\",\n",
    "    label_columns =[],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8988f1",
   "metadata": {},
   "source": [
    "# Wrap Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c5cf4f",
   "metadata": {},
   "source": [
    "Congratulations on finishing this notebook. In this tutorial, we have presented Transformers4Rec, an open source library designed to enable RecSys researchers and practitioners to quickly and easily explore the latest developments of the NLP for sequential and session-based recommendation tasks.\n",
    "\n",
    "In the end, using side information was the best approach. Why is that? Have an idea? Head back over to the notebook launcher to find out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea44f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)\n",
    "app.kernel.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60368d6d",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25703867",
   "metadata": {},
   "source": [
    "1. Malte Ludewig and Dietmar Jannach. 2018. Evaluation of session-based recommendation algorithms. User Modeling and User-Adapted Interaction 28, 4-5 (2018), 331–390.<br>\n",
    "2. Balázs Hidasi and Alexandros Karatzoglou. 2018. Recurrent neural networks with top-k gains for session-based recommendations. In Proceedings of the 27th ACMinternational conference on information and knowledge management. 843–852.<br>\n",
    "3. Fei Sun, Jun Liu, Jian Wu, Changhua Pei, Xiao Lin, Wenwu Ou, and Peng Jiang. 2019. BERT4Rec: Sequential recommendation with bidirectional encoder representations from transformer. In Proceedings of the 28th ACM international conference on information and knowledge management. 1441–1450.\n",
    "4. Kyunghyun Cho, Bart Van Merriënboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. 2014. Learning phrase representations using RNN encoder-decoder for statistical machine translation. arXiv preprint arXiv:1406.1078 (2014).\n",
    "5. Vaswani, A., et al. (2017). Attention is all you need. In Advances in neural information processing systems (pp. 5998-6008).\n",
    "6. Lample, Guillaume, and Alexis Conneau. \"Cross-lingual language model pretraining.\" arXiv preprint arXiv:1901.07291\n",
    "7. Gabriel De Souza P. Moreira, et al. (2021). Transformers4Rec: Bridging the Gap between NLP and Sequential / Session-Based Recommendation. RecSys'21.\n",
    "8. Understanding XLNet, BorealisAI. Online available: https://www.borealisai.com/en/blog/understanding-xlnet/\n",
    "9. Yang, Zhilin, et al. \"Xlnet: Generalized autoregressive pretraining for language understanding.\" Advances in neural information processing systems 32 (2019)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
