{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97250792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2022 NVIDIA Corporation. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2228da",
   "metadata": {},
   "source": [
    "<img src=\"https://developer.download.nvidia.com/notebooks/dlsw-notebooks/merlin_transformers4rec_getting-started-session-based-02-session-based-xlnet-with-pyt/nvidia_logo.png\" style=\"width: 90px; float: right;\">\n",
    "\n",
    "# Session-based Recommendation with XLNET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599efc90",
   "metadata": {},
   "source": [
    "### Imports required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ba89970",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "/usr/local/lib/python3.8/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Torchmetrics v0.9 introduced a new argument class property called `full_state_update` that has\n",
      "                not been set for this class (NDCGAt). The property determines if `update` by\n",
      "                default needs access to the full metric state. If this is not the case, significant speedups can be\n",
      "                achieved and we recommend setting this to `False`.\n",
      "                We provide an checking function\n",
      "                `from torchmetrics.utilities import check_forward_full_state_property`\n",
      "                that can be used to check if the `full_state_update=True` (old and potential slower behaviour,\n",
      "                default for now) or if `full_state_update=False` can be used safely.\n",
      "                \n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.8/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Torchmetrics v0.9 introduced a new argument class property called `full_state_update` that has\n",
      "                not been set for this class (DCGAt). The property determines if `update` by\n",
      "                default needs access to the full metric state. If this is not the case, significant speedups can be\n",
      "                achieved and we recommend setting this to `False`.\n",
      "                We provide an checking function\n",
      "                `from torchmetrics.utilities import check_forward_full_state_property`\n",
      "                that can be used to check if the `full_state_update=True` (old and potential slower behaviour,\n",
      "                default for now) or if `full_state_update=False` can be used safely.\n",
      "                \n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.8/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Torchmetrics v0.9 introduced a new argument class property called `full_state_update` that has\n",
      "                not been set for this class (AvgPrecisionAt). The property determines if `update` by\n",
      "                default needs access to the full metric state. If this is not the case, significant speedups can be\n",
      "                achieved and we recommend setting this to `False`.\n",
      "                We provide an checking function\n",
      "                `from torchmetrics.utilities import check_forward_full_state_property`\n",
      "                that can be used to check if the `full_state_update=True` (old and potential slower behaviour,\n",
      "                default for now) or if `full_state_update=False` can be used safely.\n",
      "                \n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.8/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Torchmetrics v0.9 introduced a new argument class property called `full_state_update` that has\n",
      "                not been set for this class (PrecisionAt). The property determines if `update` by\n",
      "                default needs access to the full metric state. If this is not the case, significant speedups can be\n",
      "                achieved and we recommend setting this to `False`.\n",
      "                We provide an checking function\n",
      "                `from torchmetrics.utilities import check_forward_full_state_property`\n",
      "                that can be used to check if the `full_state_update=True` (old and potential slower behaviour,\n",
      "                default for now) or if `full_state_update=False` can be used safely.\n",
      "                \n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.8/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Torchmetrics v0.9 introduced a new argument class property called `full_state_update` that has\n",
      "                not been set for this class (RecallAt). The property determines if `update` by\n",
      "                default needs access to the full metric state. If this is not the case, significant speedups can be\n",
      "                achieved and we recommend setting this to `False`.\n",
      "                We provide an checking function\n",
      "                `from torchmetrics.utilities import check_forward_full_state_property`\n",
      "                that can be used to check if the `full_state_update=True` (old and potential slower behaviour,\n",
      "                default for now) or if `full_state_update=False` can be used safely.\n",
      "                \n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import cudf\n",
    "import glob\n",
    "import torch \n",
    "\n",
    "from transformers4rec import torch as tr\n",
    "from transformers4rec.torch.ranking_metric import NDCGAt, AvgPrecisionAt, RecallAt\n",
    "from transformers4rec.torch.utils.examples_utils import wipe_memory\n",
    "from merlin.io import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea2a0c5",
   "metadata": {},
   "source": [
    "Transformers4Rec library relies on a schema object to automatically build all necessary layers to represent, normalize and aggregate input features. As you can see below, `schema.pb` is a protobuf file that contains metadata including statistics about features such as cardinality, min and max values and also tags features based on their characteristics and dtypes (e.g., categorical, continuous, list, integer)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a510b6ef",
   "metadata": {},
   "source": [
    "### Set the schema object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a0518a-eb01-4ac4-9c6d-36b328985765",
   "metadata": {},
   "source": [
    "We create the schema object by reading the `schema.pbtxt` file generated by NVTabular pipeline in the previous, `01-ETL-with-NVTabular`, notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d1299fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from merlin_standard_lib import Schema\n",
    "# import merlin.io\n",
    "# from merlin.models.utils import schema_utils\n",
    "# from merlin.schema import Schema, Tags\n",
    "# from merlin.schema.io.tensorflow_metadata import TensorflowMetadata\n",
    "# from merlin.schema import Schema\n",
    "SCHEMA_PATH = os.environ.get(\"INPUT_SCHEMA_PATH\", \"/workspace/data/processed_nvt/schema.pbtxt\")\n",
    "schema = Schema().from_proto_text(SCHEMA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "868f0317-d140-40d5-b4bd-29a27e12077b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'session_id', 'type': 'INT', 'int_domain': {'name': 'session_id', 'max': '19877', 'is_categorical': True}, 'annotation': {'tag': ['categorical'], 'comment': ['{\"num_buckets\": null, \"freq_threshold\": 0.0, \"max_size\": 0.0, \"start_index\": 1.0, \"cat_path\": \".//categories/unique.session_id.parquet\", \"embedding_sizes\": {\"cardinality\": 19878.0, \"dimension\": 409.0}, \"dtype_item_size\": 64.0, \"is_list\": false, \"is_ragged\": false}']}}, {'name': 'day-first', 'type': 'INT', 'annotation': {'comment': ['{\"dtype_item_size\": 64.0, \"is_list\": false, \"is_ragged\": false}']}}, {'name': 'item_id-count', 'type': 'INT', 'int_domain': {'name': 'item_id', 'max': '506', 'is_categorical': True}, 'annotation': {'tag': ['categorical'], 'comment': ['{\"num_buckets\": null, \"freq_threshold\": 0.0, \"max_size\": 0.0, \"start_index\": 1.0, \"cat_path\": \".//categories/unique.item_id.parquet\", \"embedding_sizes\": {\"cardinality\": 507.0, \"dimension\": 52.0}, \"dtype_item_size\": 32.0, \"is_list\": false, \"is_ragged\": false}']}}, {'name': 'item_id-list', 'value_count': {'min': '2', 'max': '15'}, 'type': 'INT', 'int_domain': {'name': 'item_id', 'max': '506', 'is_categorical': True}, 'annotation': {'tag': ['list', 'item_id', 'item', 'id', 'categorical'], 'comment': ['{\"num_buckets\": null, \"freq_threshold\": 0.0, \"max_size\": 0.0, \"start_index\": 1.0, \"cat_path\": \".//categories/unique.item_id.parquet\", \"embedding_sizes\": {\"cardinality\": 507.0, \"dimension\": 52.0}, \"dtype_item_size\": 64.0, \"is_list\": true, \"is_ragged\": true}']}}, {'name': 'category-list', 'value_count': {'min': '2', 'max': '15'}, 'type': 'INT', 'int_domain': {'name': 'category', 'max': '137', 'is_categorical': True}, 'annotation': {'tag': ['list', 'categorical'], 'comment': ['{\"num_buckets\": null, \"freq_threshold\": 0.0, \"max_size\": 0.0, \"start_index\": 1.0, \"cat_path\": \".//categories/unique.category.parquet\", \"embedding_sizes\": {\"cardinality\": 138.0, \"dimension\": 25.0}, \"dtype_item_size\": 64.0, \"is_list\": true, \"is_ragged\": true}']}}, {'name': 'age_days-list', 'value_count': {'min': '2', 'max': '15'}, 'type': 'FLOAT', 'annotation': {'tag': ['list', 'continuous'], 'comment': ['{\"dtype_item_size\": 32.0, \"is_list\": true, \"is_ragged\": true}']}}, {'name': 'weekday_sin-list', 'value_count': {'min': '2', 'max': '15'}, 'type': 'FLOAT', 'annotation': {'tag': ['list', 'continuous'], 'comment': ['{\"dtype_item_size\": 32.0, \"is_list\": true, \"is_ragged\": true}']}}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4f426f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # You can select a subset of features for training\n",
    "\n",
    "# You can select a subset of features for training\n",
    "schema = schema.select_by_name(['item_id-list', \n",
    "                                'category-list',\n",
    "                                'weekday_sin-list',\n",
    "                                'age_days-list'\n",
    "                               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31bd0f44-ecfe-489a-88ac-032b5a512622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'item_id-list', 'value_count': {'min': '2', 'max': '15'}, 'type': 'INT', 'int_domain': {'name': 'item_id', 'max': '506', 'is_categorical': True}, 'annotation': {'tag': ['list', 'item_id', 'item', 'id', 'categorical'], 'comment': ['{\"num_buckets\": null, \"freq_threshold\": 0.0, \"max_size\": 0.0, \"start_index\": 1.0, \"cat_path\": \".//categories/unique.item_id.parquet\", \"embedding_sizes\": {\"cardinality\": 507.0, \"dimension\": 52.0}, \"dtype_item_size\": 64.0, \"is_list\": true, \"is_ragged\": true}']}}, {'name': 'category-list', 'value_count': {'min': '2', 'max': '15'}, 'type': 'INT', 'int_domain': {'name': 'category', 'max': '137', 'is_categorical': True}, 'annotation': {'tag': ['list', 'categorical'], 'comment': ['{\"num_buckets\": null, \"freq_threshold\": 0.0, \"max_size\": 0.0, \"start_index\": 1.0, \"cat_path\": \".//categories/unique.category.parquet\", \"embedding_sizes\": {\"cardinality\": 138.0, \"dimension\": 25.0}, \"dtype_item_size\": 64.0, \"is_list\": true, \"is_ragged\": true}']}}, {'name': 'age_days-list', 'value_count': {'min': '2', 'max': '15'}, 'type': 'FLOAT', 'annotation': {'tag': ['list', 'continuous'], 'comment': ['{\"dtype_item_size\": 32.0, \"is_list\": true, \"is_ragged\": true}']}}, {'name': 'weekday_sin-list', 'value_count': {'min': '2', 'max': '15'}, 'type': 'FLOAT', 'annotation': {'tag': ['list', 'continuous'], 'comment': ['{\"dtype_item_size\": 32.0, \"is_list\": true, \"is_ragged\": true}']}}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cacefa",
   "metadata": {},
   "source": [
    "### Define the sequential input module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b38d30d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tr.TabularSequenceFeatures.from_schema(\n",
    "        schema,\n",
    "        max_sequence_length=15,\n",
    "        continuous_projection=64,\n",
    "        d_output=100,\n",
    "        masking=\"causal\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed749ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Torchmetrics v0.9 introduced a new argument class property called `full_state_update` that has\n",
      "                not been set for this class (NDCGAt). The property determines if `update` by\n",
      "                default needs access to the full metric state. If this is not the case, significant speedups can be\n",
      "                achieved and we recommend setting this to `False`.\n",
      "                We provide an checking function\n",
      "                `from torchmetrics.utilities import check_forward_full_state_property`\n",
      "                that can be used to check if the `full_state_update=True` (old and potential slower behaviour,\n",
      "                default for now) or if `full_state_update=False` can be used safely.\n",
      "                \n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.8/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Torchmetrics v0.9 introduced a new argument class property called `full_state_update` that has\n",
      "                not been set for this class (DCGAt). The property determines if `update` by\n",
      "                default needs access to the full metric state. If this is not the case, significant speedups can be\n",
      "                achieved and we recommend setting this to `False`.\n",
      "                We provide an checking function\n",
      "                `from torchmetrics.utilities import check_forward_full_state_property`\n",
      "                that can be used to check if the `full_state_update=True` (old and potential slower behaviour,\n",
      "                default for now) or if `full_state_update=False` can be used safely.\n",
      "                \n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.8/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Torchmetrics v0.9 introduced a new argument class property called `full_state_update` that has\n",
      "                not been set for this class (RecallAt). The property determines if `update` by\n",
      "                default needs access to the full metric state. If this is not the case, significant speedups can be\n",
      "                achieved and we recommend setting this to `False`.\n",
      "                We provide an checking function\n",
      "                `from torchmetrics.utilities import check_forward_full_state_property`\n",
      "                that can be used to check if the `full_state_update=True` (old and potential slower behaviour,\n",
      "                default for now) or if `full_state_update=False` can be used safely.\n",
      "                \n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Define XLNetConfig class and set default parameters for HF XLNet config  \n",
    "transformer_config = tr.XLNetConfig.build(\n",
    "    d_model=64, n_head=4, n_layer=2, total_seq_length=20\n",
    ")\n",
    "# Define the model block including: inputs, masking, projection and transformer block.\n",
    "body = tr.SequentialBlock(\n",
    "    inputs, tr.MLPBlock([64]), tr.TransformerBlock(transformer_config, masking=inputs.masking)\n",
    ")\n",
    "\n",
    "# Defines the evaluation top-N metrics and the cut-offs\n",
    "metrics = [NDCGAt(top_ks=[20, 40], labels_onehot=True),  \n",
    "           RecallAt(top_ks=[20, 40], labels_onehot=True)]\n",
    "\n",
    "# Define a head related to next item prediction task \n",
    "head = tr.Head(\n",
    "    body,\n",
    "    tr.NextItemPredictionTask(weight_tying=True, metrics=metrics),\n",
    "    inputs=inputs,\n",
    ")\n",
    "\n",
    "# Get the end-to-end Model class \n",
    "model = tr.Model(head)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57335ff",
   "metadata": {},
   "source": [
    "Note that we can easily define an RNN-based model inside the `SequentialBlock` instead of a Transformer-based model. You can explore this [tutorial](https://github.com/NVIDIA-Merlin/Transformers4Rec/tree/main/examples/tutorial) for a GRU-based model example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d51e39",
   "metadata": {},
   "source": [
    "### Train the model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26d7aec",
   "metadata": {},
   "source": [
    "We use the NVTabular PyTorch Dataloader for optimized loading of multiple features from input parquet files. You can learn more about this data loader [here](https://nvidia-merlin.github.io/NVTabular/main/training/pytorch.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fd4c22",
   "metadata": {},
   "source": [
    "### **Set Training arguments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "693974df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers4rec.config.trainer import T4RecTrainingArguments\n",
    "from transformers4rec.torch import Trainer\n",
    "# Set hyperparameters for training \n",
    "train_args = T4RecTrainingArguments(data_loader_engine='nvtabular', \n",
    "                                    dataloader_drop_last = True,\n",
    "                                    gradient_accumulation_steps = 1,\n",
    "                                    per_device_train_batch_size = 128, \n",
    "                                    per_device_eval_batch_size = 32,\n",
    "                                    output_dir = \"./tmp\", \n",
    "                                    learning_rate=0.0005,\n",
    "                                    lr_scheduler_type='cosine', \n",
    "                                    learning_rate_num_cosine_cycles_by_epoch=1.5,\n",
    "                                    num_train_epochs=5,\n",
    "                                    max_sequence_length=20, \n",
    "                                    report_to = [],\n",
    "                                    logging_steps=50,\n",
    "                                    no_cuda=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445ece64",
   "metadata": {},
   "source": [
    "Note that we add an argument `data_loader_engine='nvtabular'` to automatically load the features needed for training using the schema. The default value is nvtabular for optimized GPU-based data-loading. Optionally a PyarrowDataLoader (pyarrow) can also be used as a basic option, but it is slower and works only for small datasets, as the full data is loaded to CPU memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32554ea0",
   "metadata": {},
   "source": [
    "## Daily Fine-Tuning: Training over a time window"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef883061",
   "metadata": {},
   "source": [
    "Here we do daily fine-tuning meaning that we use the first day to train and second day to evaluate, then we use the second day data to train the model by resuming from the first step, and evaluate on the third day, so on so forth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f452d09",
   "metadata": {},
   "source": [
    "We have extended the HuggingFace transformers `Trainer` class (PyTorch only) to support evaluation of RecSys metrics. In this example, the evaluation of the session-based recommendation model is performed using traditional Top-N ranking metrics such as Normalized Discounted Cumulative Gain (NDCG@20) and Hit Rate (HR@20). NDCG accounts for rank of the relevant item in the recommendation list and is a more fine-grained metric than HR, which only verifies whether the relevant item is among the top-n items. HR@n is equivalent to Recall@n when there is only one relevant item in the recommendation list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2283f788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the T4Rec Trainer, which manages training and evaluation for the PyTorch API\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=train_args,\n",
    "    schema=schema,\n",
    "    compute_metrics=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d515127c",
   "metadata": {},
   "source": [
    "- Define the output folder of the processed parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae313150",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DATA_DIR = os.environ.get(\"INPUT_DATA_DIR\", \"/workspace/data\")\n",
    "OUTPUT_DIR = os.environ.get(\"OUTPUT_DIR\", f\"{INPUT_DATA_DIR}/sessions_by_day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ae51de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 1664\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/workspace/data/sessions_by_day/1/train.parquet']\n",
      "********************\n",
      "Launch training for day 1 are:\n",
      "********************\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='65' max='65' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [65/65 00:01, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>5.731000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "Eval results for day 2 are:\t\n",
      "\n",
      "********************\n",
      "\n",
      " eval_/loss = 4.892789840698242\n",
      " eval_/next-item/ndcg_at_20 = 0.2019212245941162\n",
      " eval_/next-item/ndcg_at_40 = 0.24986284971237183\n",
      " eval_/next-item/recall_at_20 = 0.5104166865348816\n",
      " eval_/next-item/recall_at_40 = 0.7447916865348816\n",
      " eval_runtime = 0.1608\n",
      " eval_samples_per_second = 1193.821\n",
      " eval_steps_per_second = 37.307\n",
      "['/workspace/data/sessions_by_day/2/train.parquet']\n",
      "********************\n",
      "Launch training for day 2 are:\n",
      "********************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 1664\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 65\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='65' max='65' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [65/65 00:01, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>4.795200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n",
      "********************\n",
      "Eval results for day 3 are:\t\n",
      "\n",
      "********************\n",
      "\n",
      " eval_/loss = 4.611485481262207\n",
      " eval_/next-item/ndcg_at_20 = 0.1681433618068695\n",
      " eval_/next-item/ndcg_at_40 = 0.22220981121063232\n",
      " eval_/next-item/recall_at_20 = 0.484375\n",
      " eval_/next-item/recall_at_40 = 0.7447916865348816\n",
      " eval_runtime = 0.1687\n",
      " eval_samples_per_second = 1138.188\n",
      " eval_steps_per_second = 35.568\n",
      "CPU times: user 15.9 s, sys: 247 ms, total: 16.1 s\n",
      "Wall time: 5.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_time_window_index = 1\n",
    "final_time_window_index = 3\n",
    "#Iterating over days of one week\n",
    "for time_index in range(start_time_window_index, final_time_window_index):\n",
    "    # Set data \n",
    "    time_index_train = time_index\n",
    "    time_index_eval = time_index + 1\n",
    "    train_paths = glob.glob(os.path.join(OUTPUT_DIR, f\"{time_index_train}/train.parquet\"))\n",
    "    eval_paths = glob.glob(os.path.join(OUTPUT_DIR, f\"{time_index_eval}/valid.parquet\"))\n",
    "    print(train_paths)\n",
    "    \n",
    "    # Train on day related to time_index \n",
    "    print('*'*20)\n",
    "    print(\"Launch training for day %s are:\" %time_index)\n",
    "    print('*'*20 + '\\n')\n",
    "    trainer.train_dataset_or_path = train_paths\n",
    "    trainer.reset_lr_scheduler()\n",
    "    trainer.train()\n",
    "    trainer.state.global_step +=1\n",
    "    print('finished')\n",
    "    \n",
    "    # Evaluate on the following day\n",
    "    trainer.eval_dataset_or_path = eval_paths\n",
    "    train_metrics = trainer.evaluate(metric_key_prefix='eval')\n",
    "    print('*'*20)\n",
    "    print(\"Eval results for day %s are:\\t\" %time_index_eval)\n",
    "    print('\\n' + '*'*20 + '\\n')\n",
    "    for key in sorted(train_metrics.keys()):\n",
    "        print(\" %s = %s\" % (key, str(train_metrics[key]))) \n",
    "    wipe_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8d7bd8",
   "metadata": {},
   "source": [
    "### Re-compute eval metrics of validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a34be66",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data_paths = glob.glob(os.path.join(OUTPUT_DIR, f\"{time_index_eval}/valid.parquet\"))\n",
    "\n",
    "# set new data from day 7\n",
    "eval_metrics = trainer.evaluate(eval_dataset=eval_data_paths, metric_key_prefix='eval')\n",
    "for key in sorted(eval_metrics.keys()):\n",
    "    print(\"  %s = %s\" % (key, str(eval_metrics[key])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a26a649",
   "metadata": {},
   "source": [
    "That's it!  \n",
    "You have just trained your session-based recommendation model using Transformers4Rec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e516a78d-2e1a-4124-ba46-f60b245d3329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (heads): ModuleList(\n",
       "    (0): Head(\n",
       "      (body): SequentialBlock(\n",
       "        (0): TabularSequenceFeatures(\n",
       "          (to_merge): ModuleDict(\n",
       "            (continuous_module): SequentialBlock(\n",
       "              (0): ContinuousFeatures(\n",
       "                (filter_features): FilterFeatures()\n",
       "                (_aggregation): ConcatFeatures()\n",
       "              )\n",
       "              (1): SequentialBlock(\n",
       "                (0): DenseBlock(\n",
       "                  (0): Linear(in_features=2, out_features=64, bias=True)\n",
       "                  (1): ReLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (2): AsTabular()\n",
       "            )\n",
       "            (categorical_module): SequenceEmbeddingFeatures(\n",
       "              (filter_features): FilterFeatures()\n",
       "              (embedding_tables): ModuleDict(\n",
       "                (item_id-list): Embedding(507, 64, padding_idx=0)\n",
       "                (category-list): Embedding(138, 64, padding_idx=0)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (_aggregation): ConcatFeatures()\n",
       "          (projection_module): SequentialBlock(\n",
       "            (0): DenseBlock(\n",
       "              (0): Linear(in_features=192, out_features=100, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (_masking): CausalLanguageModeling()\n",
       "        )\n",
       "        (1): SequentialBlock(\n",
       "          (0): DenseBlock(\n",
       "            (0): Linear(in_features=100, out_features=64, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (2): TansformerBlock(\n",
       "          (transformer): XLNetModel(\n",
       "            (word_embedding): Embedding(1, 64)\n",
       "            (layer): ModuleList(\n",
       "              (0): XLNetLayer(\n",
       "                (rel_attn): XLNetRelativeAttention(\n",
       "                  (layer_norm): LayerNorm((64,), eps=0.03, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.3, inplace=False)\n",
       "                )\n",
       "                (ff): XLNetFeedForward(\n",
       "                  (layer_norm): LayerNorm((64,), eps=0.03, elementwise_affine=True)\n",
       "                  (layer_1): Linear(in_features=64, out_features=256, bias=True)\n",
       "                  (layer_2): Linear(in_features=256, out_features=64, bias=True)\n",
       "                  (dropout): Dropout(p=0.3, inplace=False)\n",
       "                )\n",
       "                (dropout): Dropout(p=0.3, inplace=False)\n",
       "              )\n",
       "              (1): XLNetLayer(\n",
       "                (rel_attn): XLNetRelativeAttention(\n",
       "                  (layer_norm): LayerNorm((64,), eps=0.03, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.3, inplace=False)\n",
       "                )\n",
       "                (ff): XLNetFeedForward(\n",
       "                  (layer_norm): LayerNorm((64,), eps=0.03, elementwise_affine=True)\n",
       "                  (layer_1): Linear(in_features=64, out_features=256, bias=True)\n",
       "                  (layer_2): Linear(in_features=256, out_features=64, bias=True)\n",
       "                  (dropout): Dropout(p=0.3, inplace=False)\n",
       "                )\n",
       "                (dropout): Dropout(p=0.3, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (dropout): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "          (masking): CausalLanguageModeling()\n",
       "        )\n",
       "      )\n",
       "      (prediction_task_dict): ModuleDict(\n",
       "        (next-item): NextItemPredictionTask(\n",
       "          (sequence_summary): SequenceSummary(\n",
       "            (summary): Identity()\n",
       "            (activation): Identity()\n",
       "            (first_dropout): Identity()\n",
       "            (last_dropout): Identity()\n",
       "          )\n",
       "          (metrics): ModuleList(\n",
       "            (0): NDCGAt()\n",
       "            (1): RecallAt()\n",
       "          )\n",
       "          (loss): NLLLoss()\n",
       "          (embeddings): SequenceEmbeddingFeatures(\n",
       "            (filter_features): FilterFeatures()\n",
       "            (embedding_tables): ModuleDict(\n",
       "              (item_id-list): Embedding(507, 64, padding_idx=0)\n",
       "              (category-list): Embedding(138, 64, padding_idx=0)\n",
       "            )\n",
       "          )\n",
       "          (item_embedding_table): Embedding(507, 64, padding_idx=0)\n",
       "          (masking): CausalLanguageModeling()\n",
       "          (pre): Block(\n",
       "            (module): NextItemPredictionTask(\n",
       "              (item_embedding_table): Embedding(507, 64, padding_idx=0)\n",
       "              (log_softmax): LogSoftmax(dim=-1)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model.cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1e140ac-afd6-455d-9057-1bbd07116a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.hf_format = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef88f601-c7c0-4244-84f3-ee257b579205",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/merlin/schema/tags.py:148: UserWarning: Compound tags like Tags.ITEM_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [<Tags.ITEM: 'item'>, <Tags.ID: 'id'>].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>tags</th>\n",
       "      <th>dtype</th>\n",
       "      <th>is_list</th>\n",
       "      <th>is_ragged</th>\n",
       "      <th>properties.int_domain.min</th>\n",
       "      <th>properties.int_domain.max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age_days-list</td>\n",
       "      <td>(Tags.CONTINUOUS, Tags.LIST)</td>\n",
       "      <td>float32</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>weekday_sin-list</td>\n",
       "      <td>(Tags.CONTINUOUS, Tags.LIST)</td>\n",
       "      <td>float32</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>item_id-list</td>\n",
       "      <td>(Tags.ID, Tags.ITEM, Tags.CATEGORICAL, Tags.IT...</td>\n",
       "      <td>int64</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>category-list</td>\n",
       "      <td>(Tags.CATEGORICAL, Tags.LIST)</td>\n",
       "      <td>int64</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "[{'name': 'age_days-list', 'tags': {<Tags.CONTINUOUS: 'continuous'>, <Tags.LIST: 'list'>}, 'properties': {'int_domain': {'min': 0, 'max': 0}}, 'dtype': dtype('float32'), 'is_list': True, 'is_ragged': False}, {'name': 'weekday_sin-list', 'tags': {<Tags.CONTINUOUS: 'continuous'>, <Tags.LIST: 'list'>}, 'properties': {'int_domain': {'min': 0, 'max': 0}}, 'dtype': dtype('float32'), 'is_list': True, 'is_ragged': False}, {'name': 'item_id-list', 'tags': {<Tags.ID: 'id'>, <Tags.ITEM: 'item'>, <Tags.CATEGORICAL: 'categorical'>, <Tags.ITEM_ID: 'item_id'>, <Tags.LIST: 'list'>}, 'properties': {'int_domain': {'min': 0, 'max': 506}}, 'dtype': dtype('int64'), 'is_list': True, 'is_ragged': False}, {'name': 'category-list', 'tags': {<Tags.CATEGORICAL: 'categorical'>, <Tags.LIST: 'list'>}, 'properties': {'int_domain': {'min': 0, 'max': 137}}, 'dtype': dtype('int64'), 'is_list': True, 'is_ragged': False}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input_schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409c17c2-c81d-4f41-9577-bd380ae10921",
   "metadata": {},
   "source": [
    "Create a dict of tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6273c8e5-db62-4cc6-a4f3-945155a463d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(train_paths[0])\n",
    "trainer.train_dataset_or_path = dataset\n",
    "loader = trainer.get_train_dataloader()\n",
    "train_dict = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43e789a3-2423-44eb-ae5d-0c154557424f",
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_model = torch.jit.trace(model, train_dict, strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8cdbc288-baf5-4beb-a3ac-5fcb7315125c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(traced_model, torch.jit.TopLevelTracedModule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "896f4d80-3703-42af-a48e-2b81e839006d",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.allclose(\n",
    "    model(train_dict),\n",
    "    traced_model(train_dict),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6a814aa-4954-404b-bd2d-161ed8066f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_schema = model.input_schema\n",
    "output_schema = model.output_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "757cd0c5-f581-488b-a8de-b8d1188820d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>tags</th>\n",
       "      <th>dtype</th>\n",
       "      <th>is_list</th>\n",
       "      <th>is_ragged</th>\n",
       "      <th>properties.int_domain.min</th>\n",
       "      <th>properties.int_domain.max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age_days-list</td>\n",
       "      <td>(Tags.CONTINUOUS, Tags.LIST)</td>\n",
       "      <td>float32</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>weekday_sin-list</td>\n",
       "      <td>(Tags.CONTINUOUS, Tags.LIST)</td>\n",
       "      <td>float32</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>item_id-list</td>\n",
       "      <td>(Tags.ID, Tags.ITEM, Tags.CATEGORICAL, Tags.IT...</td>\n",
       "      <td>int64</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>category-list</td>\n",
       "      <td>(Tags.CATEGORICAL, Tags.LIST)</td>\n",
       "      <td>int64</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "[{'name': 'age_days-list', 'tags': {<Tags.CONTINUOUS: 'continuous'>, <Tags.LIST: 'list'>}, 'properties': {'int_domain': {'min': 0, 'max': 0}}, 'dtype': dtype('float32'), 'is_list': True, 'is_ragged': False}, {'name': 'weekday_sin-list', 'tags': {<Tags.CONTINUOUS: 'continuous'>, <Tags.LIST: 'list'>}, 'properties': {'int_domain': {'min': 0, 'max': 0}}, 'dtype': dtype('float32'), 'is_list': True, 'is_ragged': False}, {'name': 'item_id-list', 'tags': {<Tags.ID: 'id'>, <Tags.ITEM: 'item'>, <Tags.CATEGORICAL: 'categorical'>, <Tags.ITEM_ID: 'item_id'>, <Tags.LIST: 'list'>}, 'properties': {'int_domain': {'min': 0, 'max': 506}}, 'dtype': dtype('int64'), 'is_list': True, 'is_ragged': False}, {'name': 'category-list', 'tags': {<Tags.CATEGORICAL: 'categorical'>, <Tags.LIST: 'list'>}, 'properties': {'int_domain': {'min': 0, 'max': 137}}, 'dtype': dtype('int64'), 'is_list': True, 'is_ragged': False}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f96597c-1c05-4fb0-ad3e-c55c21599158",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/merlin/schema/tags.py:148: UserWarning: Compound tags like Tags.ITEM_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [<Tags.ITEM: 'item'>, <Tags.ID: 'id'>].\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from merlin.core.dispatch import make_df  # noqa\n",
    "from merlin.systems.dag import Ensemble  # noqa\n",
    "from merlin.systems.dag.ops.pytorch import PredictPyTorch  # noqa\n",
    "from merlin.systems.triton.utils import run_ensemble_on_tritonserver  # noqa\n",
    "\n",
    "torch_op = input_schema.column_names >> PredictPyTorch(\n",
    "    traced_model, input_schema, output_schema\n",
    ")\n",
    "\n",
    "ensemble = Ensemble(torch_op, input_schema)\n",
    "ens_config, node_configs = ensemble.export(str('./models'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5faba154-d4b2-4424-a1b2-badd2227e66e",
   "metadata": {},
   "source": [
    "Create a dataframe to send as a request. We need a dataset where the list columns are padded to the max sequence lenght that was set in the ETL pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c1ce3a29-5578-41ca-a033-abc4507adfef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_days-list</th>\n",
       "      <th>weekday_sin-list</th>\n",
       "      <th>item_id-list</th>\n",
       "      <th>category-list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.37403864, 0.42758772, 0.93743354, 0.0, 0.0,...</td>\n",
       "      <td>[0.9351001, 0.91299504, 0.9785595, 0.0, 0.0, 0...</td>\n",
       "      <td>[30, 24, 200, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[7, 6, 40, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.9327483, 0.36575532, 0.13967341, 0.45479113...</td>\n",
       "      <td>[0.5046626, 0.17492707, 0.12539314, 0.6640924,...</td>\n",
       "      <td>[190, 10, 7, 55, 27, 3, 6, 184, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[36, 3, 2, 11, 6, 4, 2, 36, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.57168996, 0.48532194, 0.89944935, 0.2171675...</td>\n",
       "      <td>[0.93685514, 0.5638695, 0.76670134, 0.6797855,...</td>\n",
       "      <td>[153, 8, 46, 58, 21, 19, 31, 15, 4, 104, 0, 0,...</td>\n",
       "      <td>[28, 2, 10, 11, 5, 5, 7, 3, 2, 18, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.8520663, 0.6690395, 0.92268515, 0.99163777,...</td>\n",
       "      <td>[0.58499664, 0.45736608, 0.88926136, 0.9139287...</td>\n",
       "      <td>[19, 28, 23, 34, 18, 10, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[5, 6, 6, 7, 5, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.67542243, 0.65952307, 0.7467189, 0.6136317,...</td>\n",
       "      <td>[0.09077961, 0.7920753, 0.35881928, 0.8545563,...</td>\n",
       "      <td>[17, 27, 70, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[5, 6, 14, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       age_days-list  \\\n",
       "0  [0.37403864, 0.42758772, 0.93743354, 0.0, 0.0,...   \n",
       "1  [0.9327483, 0.36575532, 0.13967341, 0.45479113...   \n",
       "2  [0.57168996, 0.48532194, 0.89944935, 0.2171675...   \n",
       "3  [0.8520663, 0.6690395, 0.92268515, 0.99163777,...   \n",
       "4  [0.67542243, 0.65952307, 0.7467189, 0.6136317,...   \n",
       "\n",
       "                                    weekday_sin-list  \\\n",
       "0  [0.9351001, 0.91299504, 0.9785595, 0.0, 0.0, 0...   \n",
       "1  [0.5046626, 0.17492707, 0.12539314, 0.6640924,...   \n",
       "2  [0.93685514, 0.5638695, 0.76670134, 0.6797855,...   \n",
       "3  [0.58499664, 0.45736608, 0.88926136, 0.9139287...   \n",
       "4  [0.09077961, 0.7920753, 0.35881928, 0.8545563,...   \n",
       "\n",
       "                                        item_id-list  \\\n",
       "0  [30, 24, 200, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "1  [190, 10, 7, 55, 27, 3, 6, 184, 0, 0, 0, 0, 0,...   \n",
       "2  [153, 8, 46, 58, 21, 19, 31, 15, 4, 104, 0, 0,...   \n",
       "3  [19, 28, 23, 34, 18, 10, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [17, 27, 70, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "\n",
       "                                       category-list  \n",
       "0  [7, 6, 40, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "1  [36, 3, 2, 11, 6, 4, 2, 36, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [28, 2, 10, 11, 5, 5, 7, 3, 2, 18, 0, 0, 0, 0,...  \n",
       "3  [5, 6, 6, 7, 5, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  [5, 6, 14, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset(eval_paths[0])\n",
    "# trainer.test_dataset_or_path = dataset\n",
    "loader = trainer.get_test_dataloader(dataset)\n",
    "test_dict = next(iter(loader))\n",
    "\n",
    "df_cols = {}\n",
    "for name, tensor in train_dict.items():\n",
    "    if name in input_schema.column_names:\n",
    "        dtype = input_schema[name].dtype\n",
    "\n",
    "        df_cols[name] = tensor.cpu().numpy().astype(dtype)\n",
    "        if len(tensor.shape) > 1:\n",
    "            df_cols[name] = list(df_cols[name])\n",
    "\n",
    "df = make_df(df_cols)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "617348d4-3493-4b68-ba9a-da9543147628",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1123 22:15:22.928458 2118 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7f428e000000' with size 268435456\n",
      "I1123 22:15:22.928899 2118 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864\n",
      "I1123 22:15:22.931602 2118 model_lifecycle.cc:459] loading: 0_predictpytorch:1\n",
      "I1123 22:15:23.299444 2118 libtorch.cc:1983] TRITONBACKEND_Initialize: pytorch\n",
      "I1123 22:15:23.299463 2118 libtorch.cc:1993] Triton TRITONBACKEND API version: 1.10\n",
      "I1123 22:15:23.299469 2118 libtorch.cc:1999] 'pytorch' TRITONBACKEND API version: 1.10\n",
      "I1123 22:15:23.299488 2118 libtorch.cc:2032] TRITONBACKEND_ModelInitialize: 0_predictpytorch (version 1)\n",
      "W1123 22:15:23.300039 2118 libtorch.cc:284] skipping model configuration auto-complete for '0_predictpytorch': not supported for pytorch backend\n",
      "I1123 22:15:23.300768 2118 libtorch.cc:313] Optimized execution is enabled for model instance '0_predictpytorch'\n",
      "I1123 22:15:23.300780 2118 libtorch.cc:332] Cache Cleaning is disabled for model instance '0_predictpytorch'\n",
      "I1123 22:15:23.300786 2118 libtorch.cc:349] Inference Mode is enabled for model instance '0_predictpytorch'\n",
      "I1123 22:15:23.300790 2118 libtorch.cc:444] NvFuser is not specified for model instance '0_predictpytorch'\n",
      "I1123 22:15:23.301026 2118 libtorch.cc:2076] TRITONBACKEND_ModelInstanceInitialize: 0_predictpytorch (GPU device 0)\n",
      "I1123 22:15:24.229933 2118 model_lifecycle.cc:693] successfully loaded '0_predictpytorch' version 1\n",
      "I1123 22:15:24.230204 2118 model_lifecycle.cc:459] loading: ensemble_model:1\n",
      "I1123 22:15:24.230490 2118 model_lifecycle.cc:693] successfully loaded 'ensemble_model' version 1\n",
      "I1123 22:15:24.230584 2118 server.cc:561] \n",
      "+------------------+------+\n",
      "| Repository Agent | Path |\n",
      "+------------------+------+\n",
      "+------------------+------+\n",
      "\n",
      "I1123 22:15:24.230668 2118 server.cc:588] \n",
      "+---------+---------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Backend | Path                                                    | Config                                                                                                                                                        |\n",
      "+---------+---------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| pytorch | /opt/tritonserver/backends/pytorch/libtriton_pytorch.so | {\"cmdline\":{\"auto-complete-config\":\"true\",\"min-compute-capability\":\"6.000000\",\"backend-directory\":\"/opt/tritonserver/backends\",\"default-max-batch-size\":\"4\"}} |\n",
      "+---------+---------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "I1123 22:15:24.230751 2118 server.cc:631] \n",
      "+------------------+---------+--------+\n",
      "| Model            | Version | Status |\n",
      "+------------------+---------+--------+\n",
      "| 0_predictpytorch | 1       | READY  |\n",
      "| ensemble_model   | 1       | READY  |\n",
      "+------------------+---------+--------+\n",
      "\n",
      "I1123 22:15:24.282945 2118 metrics.cc:650] Collecting metrics for GPU 0: Quadro GV100\n",
      "I1123 22:15:24.283260 2118 tritonserver.cc:2214] \n",
      "+----------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Option                           | Value                                                                                                                                                                                        |\n",
      "+----------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| server_id                        | triton                                                                                                                                                                                       |\n",
      "| server_version                   | 2.25.0                                                                                                                                                                                       |\n",
      "| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics trace |\n",
      "| model_repository_path[0]         | ./models                                                                                                                                                                                     |\n",
      "| model_control_mode               | MODE_NONE                                                                                                                                                                                    |\n",
      "| strict_model_config              | 0                                                                                                                                                                                            |\n",
      "| rate_limit                       | OFF                                                                                                                                                                                          |\n",
      "| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                    |\n",
      "| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                                     |\n",
      "| response_cache_byte_size         | 0                                                                                                                                                                                            |\n",
      "| min_supported_compute_capability | 6.0                                                                                                                                                                                          |\n",
      "| strict_readiness                 | 1                                                                                                                                                                                            |\n",
      "| exit_timeout                     | 30                                                                                                                                                                                           |\n",
      "+----------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "I1123 22:15:24.285008 2118 grpc_server.cc:4610] Started GRPCInferenceService at localhost:8001\n",
      "I1123 22:15:24.285227 2118 http_server.cc:3316] Started HTTPService at 0.0.0.0:8000\n",
      "I1123 22:15:24.326845 2118 http_server.cc:178] Started Metrics Service at 0.0.0.0:8002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal (2) received.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1123 22:15:26.364164 2118 server.cc:262] Waiting for in-flight requests to complete.\n",
      "I1123 22:15:26.364179 2118 server.cc:278] Timeout 30: Found 0 model versions that have in-flight inferences\n",
      "I1123 22:15:26.364255 2118 server.cc:293] All models are stopped, unloading models\n",
      "I1123 22:15:26.364263 2118 server.cc:300] Timeout 30: Found 2 live models and 0 in-flight non-inference requests\n",
      "I1123 22:15:26.364287 2118 model_lifecycle.cc:578] successfully unloaded 'ensemble_model' version 1\n",
      "I1123 22:15:26.364592 2118 libtorch.cc:2110] TRITONBACKEND_ModelInstanceFinalize: delete instance state\n",
      "I1123 22:15:26.372137 2118 libtorch.cc:2055] TRITONBACKEND_ModelFinalize: delete model state\n",
      "I1123 22:15:26.372333 2118 model_lifecycle.cc:578] successfully unloaded '0_predictpytorch' version 1\n",
      "I1123 22:15:27.364444 2118 server.cc:300] Timeout 29: Found 0 live models and 0 in-flight non-inference requests\n"
     ]
    }
   ],
   "source": [
    "# ===========================================\n",
    "# Send request to Triton and check response\n",
    "# ===========================================\n",
    "response = run_ensemble_on_tritonserver(\n",
    "    './models', input_schema, df[input_schema.column_names], output_schema.column_names, \"ensemble_model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "430555ac-d427-48ac-b93a-da2ea41b86d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'next-item': array([[-7.9947233, -8.747803 , -3.4068425, ..., -7.914096 , -8.571636 ,\n",
       "         -7.815837 ],\n",
       "        [-7.977386 , -8.727583 , -3.3388414, ..., -7.9091067, -8.508778 ,\n",
       "         -7.7708635],\n",
       "        [-8.000487 , -8.737406 , -3.4030848, ..., -7.921053 , -8.557445 ,\n",
       "         -7.798526 ],\n",
       "        ...,\n",
       "        [-7.998163 , -8.739789 , -3.3824148, ..., -7.9103565, -8.550226 ,\n",
       "         -7.8002963],\n",
       "        [-7.9968286, -8.753717 , -3.3801503, ..., -7.9066863, -8.55961  ,\n",
       "         -7.794828 ],\n",
       "        [-8.01243  , -8.753323 , -3.3656597, ..., -7.8982997, -8.546498 ,\n",
       "         -7.7921886]], dtype=float32)}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0581195-d496-4536-a93b-3071ed9088ea",
   "metadata": {},
   "source": [
    "We return a response for each request in the df. Each row in the `response['next-item']` array corresponds to the logit values per item in the catalog and for the OOV item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "26bbdcb4-1347-46bd-a3eb-1c140f8bacd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 507)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['next-item'].shape"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7b543a88d374ac88bf8df97911b380f671b13649694a5b49eb21e60fd27eb479"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
