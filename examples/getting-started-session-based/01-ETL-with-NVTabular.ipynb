{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7783917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2022 NVIDIA Corporation. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ======================================================================\n",
    "\n",
    "# Each user is responsible for checking the content of datasets and the\n",
    "# applicable licenses and determining if suitable for the intended use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba6b360",
   "metadata": {},
   "source": [
    "<img src=\"https://developer.download.nvidia.com/notebooks/dlsw-notebooks/merlin_transformers4rec_getting-started-session-based-01-etl-with-nvtabular/nvidia_logo.png\" style=\"width: 90px; float: right;\">\n",
    "\n",
    "# ETL with NVTabular"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6085c0",
   "metadata": {},
   "source": [
    "In this notebook we are going to generate synthetic data and then create sequential features with [NVTabular](https://github.com/NVIDIA-Merlin/NVTabular). Such data will be used in the next notebook to train a session-based recommendation model.\n",
    "\n",
    "NVTabular is a feature engineering and preprocessing library for tabular data designed to quickly and easily manipulate terabyte scale datasets used to train deep learning based recommender systems. It provides a high level abstraction to simplify code and accelerates computation on the GPU using the RAPIDS cuDF library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add26d16",
   "metadata": {},
   "source": [
    "### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e8dae24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nvtabular as nvt\n",
    "from nvtabular.ops import *\n",
    "from merlin.schema.tags import Tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3206b3f",
   "metadata": {},
   "source": [
    "### Define Input/Output Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "105dd71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DATA_DIR = os.environ.get(\"INPUT_DATA_DIR\", \"/workspace/data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36498a01",
   "metadata": {},
   "source": [
    "## Create a Synthetic Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "929036ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ROWS = os.environ.get(\"NUM_ROWS\", 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b6453d3-e5be-40ce-baaa-ca84a5857cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_tailed_item_distribution = np.clip(np.random.lognormal(3., 1., int(NUM_ROWS)).astype(np.int32), 1, 50000)\n",
    "# generate random item interaction features \n",
    "df = pd.DataFrame(np.random.randint(70000, 90000, int(NUM_ROWS)), columns=['session_id'])\n",
    "df['item_id'] = long_tailed_item_distribution\n",
    "\n",
    "# generate category mapping for each item-id\n",
    "df['category'] = pd.cut(df['item_id'], bins=334, labels=np.arange(1, 335)).astype(np.int32)\n",
    "df['age_days'] = np.random.uniform(0, 1, int(NUM_ROWS)).astype(np.float32)\n",
    "df['weekday_sin']= np.random.uniform(0, 1, int(NUM_ROWS)).astype(np.float32)\n",
    "\n",
    "# generate day mapping for each session \n",
    "map_day = dict(zip(df.session_id.unique(), np.random.randint(1, 10, size=(df.session_id.nunique()))))\n",
    "df['day'] =  df.session_id.map(map_day)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd861fcd",
   "metadata": {},
   "source": [
    "Visualize couple of rows of the synthetic dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5fa9320-7935-4a4c-ad7d-8f9e2b90801c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>category</th>\n",
       "      <th>age_days</th>\n",
       "      <th>weekday_sin</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75789</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.358370</td>\n",
       "      <td>0.707811</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>86997</td>\n",
       "      <td>43</td>\n",
       "      <td>9</td>\n",
       "      <td>0.577899</td>\n",
       "      <td>0.840965</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>71211</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.198717</td>\n",
       "      <td>0.119433</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>73360</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.791937</td>\n",
       "      <td>0.146101</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>86785</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>0.623115</td>\n",
       "      <td>0.617554</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session_id  item_id  category  age_days  weekday_sin  day\n",
       "0       75789        8         2  0.358370     0.707811    1\n",
       "1       86997       43         9  0.577899     0.840965    1\n",
       "2       71211        3         1  0.198717     0.119433    4\n",
       "3       73360       10         2  0.791937     0.146101    5\n",
       "4       86785       18         4  0.623115     0.617554    3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae36e04",
   "metadata": {},
   "source": [
    "## Feature Engineering with NVTabular"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139de226",
   "metadata": {},
   "source": [
    "Deep Learning models require dense input features. Categorical features are sparse, and need to be represented by dense embeddings in the model. To allow for that, categorical features first need to be encoded as contiguous integers `(0, ..., |C|)`, where `|C|` is the feature cardinality (number of unique values), so that their embeddings can be efficiently stored in embedding layers.  We will use NVTabular to preprocess the categorical features, so that all categorical columns are encoded as contiguous integers. Note that the `Categorify` op encodes OOVs or nulls to `0` automatically. In our synthetic dataset we do not have any nulls. On the other hand `0` is also used for padding the sequences in input block, therefore, you can set `start_index=1` arg in the Categorify op if you want the encoded null or OOV values to start from `1` instead of `0` because we reserve `0` for padding the sequence features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b3bb9c",
   "metadata": {},
   "source": [
    "Here our goal is to create sequential features. To do so, we are grouping the features together at the session level in the following cell. In this synthetically generated example dataset, we do not have a timestamp column, but if we had one (that's the case for most real-world datasets), we would be sorting the interactions by the timestamp column as in this [example notebook](https://github.com/NVIDIA-Merlin/Transformers4Rec/blob/main/examples/end-to-end-session-based/01-ETL-with-NVTabular.ipynb). Note that we also trim each feature sequence in a  session to a certain length. Here, we use the NVTabular library so that we can easily preprocess and create features on GPU with a few lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a256f195",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/merlin/schema/tags.py:148: UserWarning: Compound tags like Tags.ITEM_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [<Tags.ITEM: 'item'>, <Tags.ID: 'id'>].\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/merlin/schema/tags.py:148: UserWarning: Compound tags like Tags.ITEM_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [<Tags.ITEM: 'item'>, <Tags.ID: 'id'>].\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/merlin/schema/tags.py:148: UserWarning: Compound tags like Tags.ITEM_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [<Tags.ITEM: 'item'>, <Tags.ID: 'id'>].\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "SESSIONS_MAX_LENGTH =20\n",
    "\n",
    "# Categorify categorical features\n",
    "categ_feats = ['session_id', 'item_id', 'category'] >> nvt.ops.Categorify()\n",
    "\n",
    "# Define Groupby Workflow\n",
    "groupby_feats = categ_feats + ['day', 'age_days', 'weekday_sin']\n",
    "\n",
    "# Group interaction features by session\n",
    "groupby_features = groupby_feats >> nvt.ops.Groupby(\n",
    "    groupby_cols=[\"session_id\"], \n",
    "    aggs={\n",
    "        \"item_id\": [\"list\", \"count\"],\n",
    "        \"category\": [\"list\"],     \n",
    "        \"day\": [\"first\"],\n",
    "        \"age_days\": [\"list\"],\n",
    "        'weekday_sin': [\"list\"],\n",
    "        },\n",
    "    name_sep=\"-\")\n",
    "\n",
    "# Select and truncate the sequential features\n",
    "sequence_features_truncated = (\n",
    "    groupby_features['category-list']\n",
    "    >> nvt.ops.ListSlice(-SESSIONS_MAX_LENGTH) \n",
    ")\n",
    "\n",
    "sequence_features_truncated_item = (\n",
    "    groupby_features['item_id-list']\n",
    "    >> nvt.ops.ListSlice(-SESSIONS_MAX_LENGTH) \n",
    "    >> TagAsItemID()\n",
    ")  \n",
    "sequence_features_truncated_cont = (\n",
    "    groupby_features['age_days-list', 'weekday_sin-list'] \n",
    "    >> nvt.ops.ListSlice(-SESSIONS_MAX_LENGTH) \n",
    "    >> nvt.ops.AddMetadata(tags=[Tags.CONTINUOUS])\n",
    ")\n",
    "\n",
    "# Filter out sessions with length 1 (not valid for next-item prediction training and evaluation)\n",
    "MINIMUM_SESSION_LENGTH = 2\n",
    "selected_features = (\n",
    "    groupby_features['item_id-count', 'day-first', 'session_id'] + \n",
    "    sequence_features_truncated_item +\n",
    "    sequence_features_truncated + \n",
    "    sequence_features_truncated_cont\n",
    ")\n",
    "    \n",
    "filtered_sessions = selected_features >> nvt.ops.Filter(f=lambda df: df[\"item_id-count\"] >= MINIMUM_SESSION_LENGTH)\n",
    "\n",
    "seq_feats_list = filtered_sessions['item_id-list', 'category-list', 'age_days-list', 'weekday_sin-list'] >>  nvt.ops.ValueCount()\n",
    "\n",
    "\n",
    "workflow = nvt.Workflow(filtered_sessions['session_id', 'day-first', 'item_id-count'] + seq_feats_list)\n",
    "\n",
    "dataset = nvt.Dataset(df, cpu=False)\n",
    "# Generate statistics for the features\n",
    "workflow.fit(dataset)\n",
    "# Apply the preprocessing and return an NVTabular dataset\n",
    "sessions_ds = workflow.transform(dataset)\n",
    "# Convert the NVTabular dataset to a Dask cuDF dataframe (`to_ddf()`) and then to cuDF dataframe (`.compute()`)\n",
    "sessions_gdf = sessions_ds.to_ddf().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4dcbca33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>day-first</th>\n",
       "      <th>item_id-count</th>\n",
       "      <th>item_id-list</th>\n",
       "      <th>category-list</th>\n",
       "      <th>age_days-list</th>\n",
       "      <th>weekday_sin-list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>[3, 12, 9, 34, 119, 21, 22, 9, 32, 18, 38, 9, ...</td>\n",
       "      <td>[1, 3, 2, 7, 26, 5, 5, 2, 3, 5, 8, 2, 6, 7, 4, 2]</td>\n",
       "      <td>[0.85696095, 0.4300088, 0.033559408, 0.2394981...</td>\n",
       "      <td>[0.7585879, 0.27019486, 0.8184247, 0.553261, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>[12, 43, 16, 45, 44, 6, 7, 10, 36, 20, 49, 27,...</td>\n",
       "      <td>[3, 8, 4, 10, 10, 1, 2, 2, 9, 3, 10, 6, 10, 12...</td>\n",
       "      <td>[0.37208363, 0.99748486, 0.14058138, 0.5112176...</td>\n",
       "      <td>[0.5443008, 0.67776006, 0.39591455, 0.61404943...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>[11, 36, 12, 13, 11, 38, 7, 37, 2, 19, 8, 7, 1...</td>\n",
       "      <td>[2, 9, 3, 2, 2, 8, 2, 9, 1, 5, 3, 2, 1, 3, 2]</td>\n",
       "      <td>[0.56365025, 0.34677047, 0.94600457, 0.9574235...</td>\n",
       "      <td>[0.88817126, 0.47712854, 0.37194037, 0.2259221...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session_id  day-first  item_id-count  \\\n",
       "0           1          7             16   \n",
       "1           2          5             15   \n",
       "2           3          2             15   \n",
       "\n",
       "                                        item_id-list  \\\n",
       "0  [3, 12, 9, 34, 119, 21, 22, 9, 32, 18, 38, 9, ...   \n",
       "1  [12, 43, 16, 45, 44, 6, 7, 10, 36, 20, 49, 27,...   \n",
       "2  [11, 36, 12, 13, 11, 38, 7, 37, 2, 19, 8, 7, 1...   \n",
       "\n",
       "                                       category-list  \\\n",
       "0  [1, 3, 2, 7, 26, 5, 5, 2, 3, 5, 8, 2, 6, 7, 4, 2]   \n",
       "1  [3, 8, 4, 10, 10, 1, 2, 2, 9, 3, 10, 6, 10, 12...   \n",
       "2      [2, 9, 3, 2, 2, 8, 2, 9, 1, 5, 3, 2, 1, 3, 2]   \n",
       "\n",
       "                                       age_days-list  \\\n",
       "0  [0.85696095, 0.4300088, 0.033559408, 0.2394981...   \n",
       "1  [0.37208363, 0.99748486, 0.14058138, 0.5112176...   \n",
       "2  [0.56365025, 0.34677047, 0.94600457, 0.9574235...   \n",
       "\n",
       "                                    weekday_sin-list  \n",
       "0  [0.7585879, 0.27019486, 0.8184247, 0.553261, 0...  \n",
       "1  [0.5443008, 0.67776006, 0.39591455, 0.61404943...  \n",
       "2  [0.88817126, 0.47712854, 0.37194037, 0.2259221...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sessions_gdf.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2458c28f",
   "metadata": {},
   "source": [
    "It is possible to save the preprocessing workflow. That is useful to apply the same preprocessing to other data (with the same schema) and also to deploy the session-based recommendation pipeline to Triton Inference Server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78e42cbf-edd6-44af-af23-c026edb578c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>tags</th>\n",
       "      <th>dtype</th>\n",
       "      <th>is_list</th>\n",
       "      <th>is_ragged</th>\n",
       "      <th>properties.num_buckets</th>\n",
       "      <th>properties.freq_threshold</th>\n",
       "      <th>properties.max_size</th>\n",
       "      <th>properties.start_index</th>\n",
       "      <th>properties.cat_path</th>\n",
       "      <th>properties.domain.min</th>\n",
       "      <th>properties.domain.max</th>\n",
       "      <th>properties.domain.name</th>\n",
       "      <th>properties.embedding_sizes.cardinality</th>\n",
       "      <th>properties.embedding_sizes.dimension</th>\n",
       "      <th>properties.value_count.min</th>\n",
       "      <th>properties.value_count.max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>session_id</td>\n",
       "      <td>(Tags.CATEGORICAL)</td>\n",
       "      <td>int64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.session_id.parquet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19881.0</td>\n",
       "      <td>session_id</td>\n",
       "      <td>19882.0</td>\n",
       "      <td>409.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>day-first</td>\n",
       "      <td>()</td>\n",
       "      <td>int64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>item_id-count</td>\n",
       "      <td>(Tags.CATEGORICAL)</td>\n",
       "      <td>int32</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.item_id.parquet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>488.0</td>\n",
       "      <td>item_id</td>\n",
       "      <td>489.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>item_id-list</td>\n",
       "      <td>(Tags.ITEM, Tags.LIST, Tags.ID, Tags.CATEGORIC...</td>\n",
       "      <td>int64</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.item_id.parquet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>488.0</td>\n",
       "      <td>item_id</td>\n",
       "      <td>489.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>category-list</td>\n",
       "      <td>(Tags.CATEGORICAL, Tags.LIST)</td>\n",
       "      <td>int64</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.category.parquet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>category</td>\n",
       "      <td>145.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>age_days-list</td>\n",
       "      <td>(Tags.LIST, Tags.CONTINUOUS)</td>\n",
       "      <td>float32</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>weekday_sin-list</td>\n",
       "      <td>(Tags.LIST, Tags.CONTINUOUS)</td>\n",
       "      <td>float32</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "[{'name': 'session_id', 'tags': {<Tags.CATEGORICAL: 'categorical'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0, 'max_size': 0, 'start_index': 0, 'cat_path': './/categories/unique.session_id.parquet', 'domain': {'min': 0, 'max': 19881, 'name': 'session_id'}, 'embedding_sizes': {'cardinality': 19882, 'dimension': 409}}, 'dtype': dtype('int64'), 'is_list': False, 'is_ragged': False}, {'name': 'day-first', 'tags': set(), 'properties': {}, 'dtype': dtype('int64'), 'is_list': False, 'is_ragged': False}, {'name': 'item_id-count', 'tags': {<Tags.CATEGORICAL: 'categorical'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0, 'max_size': 0, 'start_index': 0, 'cat_path': './/categories/unique.item_id.parquet', 'domain': {'min': 0, 'max': 488, 'name': 'item_id'}, 'embedding_sizes': {'cardinality': 489, 'dimension': 51}}, 'dtype': dtype('int32'), 'is_list': False, 'is_ragged': False}, {'name': 'item_id-list', 'tags': {<Tags.ITEM: 'item'>, <Tags.LIST: 'list'>, <Tags.ID: 'id'>, <Tags.CATEGORICAL: 'categorical'>, <Tags.ITEM_ID: 'item_id'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0, 'max_size': 0, 'start_index': 0, 'cat_path': './/categories/unique.item_id.parquet', 'domain': {'min': 0, 'max': 488, 'name': 'item_id'}, 'embedding_sizes': {'cardinality': 489, 'dimension': 51}, 'value_count': {'min': 2, 'max': 16}}, 'dtype': dtype('int64'), 'is_list': True, 'is_ragged': True}, {'name': 'category-list', 'tags': {<Tags.CATEGORICAL: 'categorical'>, <Tags.LIST: 'list'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0, 'max_size': 0, 'start_index': 0, 'cat_path': './/categories/unique.category.parquet', 'domain': {'min': 0, 'max': 144, 'name': 'category'}, 'embedding_sizes': {'cardinality': 145, 'dimension': 26}, 'value_count': {'min': 2, 'max': 16}}, 'dtype': dtype('int64'), 'is_list': True, 'is_ragged': True}, {'name': 'age_days-list', 'tags': {<Tags.LIST: 'list'>, <Tags.CONTINUOUS: 'continuous'>}, 'properties': {'value_count': {'min': 2, 'max': 16}}, 'dtype': dtype('float32'), 'is_list': True, 'is_ragged': True}, {'name': 'weekday_sin-list', 'tags': {<Tags.LIST: 'list'>, <Tags.CONTINUOUS: 'continuous'>}, 'properties': {'value_count': {'min': 2, 'max': 16}}, 'dtype': dtype('float32'), 'is_list': True, 'is_ragged': True}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.output_schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8172ab8d-9248-4a38-8483-6797df792ab8",
   "metadata": {},
   "source": [
    "The following will generate `schema.pbtxt` file in the provided folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e71dd078-6116-4ac2-ba6f-0207aaa8d417",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/merlin/schema/tags.py:148: UserWarning: Compound tags like Tags.ITEM_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [<Tags.ITEM: 'item'>, <Tags.ID: 'id'>].\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "workflow.fit_transform(dataset).to_parquet(os.path.join(INPUT_DATA_DIR, \"processed_nvt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f498dce-69eb-4f88-8ddd-8629558825df",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.save(os.path.join(INPUT_DATA_DIR, \"workflow_etl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a41961",
   "metadata": {},
   "source": [
    "## Export pre-processed data by day"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cedca3",
   "metadata": {},
   "source": [
    "In this example we are going to split the preprocessed parquet files by days, to allow for temporal training and evaluation. There will be a folder for each day and three parquet files within each day folder: `train.parquet`, `validation.parquet` and `test.parquet`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12d3e59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = os.environ.get(\"OUTPUT_DIR\",os.path.join(INPUT_DATA_DIR, \"sessions_by_day\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c67a92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating time-based splits: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 31.76it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers4rec.data.preprocessing import save_time_based_splits\n",
    "save_time_based_splits(data=nvt.Dataset(sessions_gdf),\n",
    "                       output_dir= OUTPUT_DIR,\n",
    "                       partition_col='day-first',\n",
    "                       timestamp_col='session_id', \n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b72337b",
   "metadata": {},
   "source": [
    "## Checking the preprocessed outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd04ec82",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATHS = os.path.join(OUTPUT_DIR, \"1\", \"train.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e5e6358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>item_id-count</th>\n",
       "      <th>item_id-list</th>\n",
       "      <th>category-list</th>\n",
       "      <th>age_days-list</th>\n",
       "      <th>weekday_sin-list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>[55, 22, 1, 20, 25, 18, 75, 3, 15, 31, 13, 20,...</td>\n",
       "      <td>[13, 5, 1, 3, 6, 5, 15, 1, 4, 7, 2, 3, 3, 2]</td>\n",
       "      <td>[0.97995365, 0.067363486, 0.66040653, 0.494267...</td>\n",
       "      <td>[0.3487224, 0.9060633, 0.25998157, 0.0769127, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>[161, 70, 8, 20, 5, 12, 32, 33, 31, 32, 47, 50...</td>\n",
       "      <td>[36, 16, 3, 3, 3, 3, 3, 7, 7, 3, 10, 11, 8]</td>\n",
       "      <td>[0.10111435, 0.47324365, 0.2752711, 0.17544255...</td>\n",
       "      <td>[0.8532496, 0.83872354, 0.993718, 0.72692555, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>13</td>\n",
       "      <td>[3, 16, 8, 18, 4, 2, 49, 35, 9, 8, 79, 67, 2]</td>\n",
       "      <td>[1, 4, 3, 5, 1, 1, 10, 9, 2, 3, 17, 14, 1]</td>\n",
       "      <td>[0.5600003, 0.11820206, 0.6599864, 0.005933116...</td>\n",
       "      <td>[0.5309871, 0.71518654, 0.5602452, 0.37133983,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>13</td>\n",
       "      <td>[5, 1, 2, 2, 20, 28, 282, 73, 25, 68, 40, 146, 2]</td>\n",
       "      <td>[3, 1, 1, 1, 3, 7, 54, 16, 6, 16, 8, 30, 1]</td>\n",
       "      <td>[0.8373534, 0.35135373, 0.54747295, 0.91502804...</td>\n",
       "      <td>[0.37596887, 0.057511043, 0.22147927, 0.270423...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>40</td>\n",
       "      <td>13</td>\n",
       "      <td>[2, 3, 38, 2, 4, 12, 32, 13, 64, 39, 10, 32, 9]</td>\n",
       "      <td>[1, 1, 8, 1, 1, 3, 3, 2, 12, 9, 2, 3, 2]</td>\n",
       "      <td>[0.6041386, 0.92545164, 0.9951186, 0.9442425, ...</td>\n",
       "      <td>[0.65229225, 0.11658515, 0.17234567, 0.1389862...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130</th>\n",
       "      <td>19171</td>\n",
       "      <td>2</td>\n",
       "      <td>[47, 28]</td>\n",
       "      <td>[10, 7]</td>\n",
       "      <td>[0.023725191, 0.87022305]</td>\n",
       "      <td>[0.6921467, 0.50588226]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2131</th>\n",
       "      <td>19174</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 23]</td>\n",
       "      <td>[1, 5]</td>\n",
       "      <td>[0.7369641, 0.033553768]</td>\n",
       "      <td>[0.56077486, 0.8527744]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2132</th>\n",
       "      <td>19180</td>\n",
       "      <td>2</td>\n",
       "      <td>[8, 49]</td>\n",
       "      <td>[3, 10]</td>\n",
       "      <td>[0.48836, 0.5168656]</td>\n",
       "      <td>[0.9988041, 0.026354417]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2133</th>\n",
       "      <td>19189</td>\n",
       "      <td>2</td>\n",
       "      <td>[7, 4]</td>\n",
       "      <td>[2, 1]</td>\n",
       "      <td>[0.53906214, 0.6020796]</td>\n",
       "      <td>[0.6170275, 0.080708236]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2134</th>\n",
       "      <td>19196</td>\n",
       "      <td>2</td>\n",
       "      <td>[27, 19]</td>\n",
       "      <td>[6, 5]</td>\n",
       "      <td>[0.22739686, 0.5085092]</td>\n",
       "      <td>[0.08497808, 0.99234015]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1705 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      session_id  item_id-count  \\\n",
       "0              6             14   \n",
       "1             23             13   \n",
       "2             32             13   \n",
       "4             36             13   \n",
       "5             40             13   \n",
       "...          ...            ...   \n",
       "2130       19171              2   \n",
       "2131       19174              2   \n",
       "2132       19180              2   \n",
       "2133       19189              2   \n",
       "2134       19196              2   \n",
       "\n",
       "                                           item_id-list  \\\n",
       "0     [55, 22, 1, 20, 25, 18, 75, 3, 15, 31, 13, 20,...   \n",
       "1     [161, 70, 8, 20, 5, 12, 32, 33, 31, 32, 47, 50...   \n",
       "2         [3, 16, 8, 18, 4, 2, 49, 35, 9, 8, 79, 67, 2]   \n",
       "4     [5, 1, 2, 2, 20, 28, 282, 73, 25, 68, 40, 146, 2]   \n",
       "5       [2, 3, 38, 2, 4, 12, 32, 13, 64, 39, 10, 32, 9]   \n",
       "...                                                 ...   \n",
       "2130                                           [47, 28]   \n",
       "2131                                            [1, 23]   \n",
       "2132                                            [8, 49]   \n",
       "2133                                             [7, 4]   \n",
       "2134                                           [27, 19]   \n",
       "\n",
       "                                     category-list  \\\n",
       "0     [13, 5, 1, 3, 6, 5, 15, 1, 4, 7, 2, 3, 3, 2]   \n",
       "1      [36, 16, 3, 3, 3, 3, 3, 7, 7, 3, 10, 11, 8]   \n",
       "2       [1, 4, 3, 5, 1, 1, 10, 9, 2, 3, 17, 14, 1]   \n",
       "4      [3, 1, 1, 1, 3, 7, 54, 16, 6, 16, 8, 30, 1]   \n",
       "5         [1, 1, 8, 1, 1, 3, 3, 2, 12, 9, 2, 3, 2]   \n",
       "...                                            ...   \n",
       "2130                                       [10, 7]   \n",
       "2131                                        [1, 5]   \n",
       "2132                                       [3, 10]   \n",
       "2133                                        [2, 1]   \n",
       "2134                                        [6, 5]   \n",
       "\n",
       "                                          age_days-list  \\\n",
       "0     [0.97995365, 0.067363486, 0.66040653, 0.494267...   \n",
       "1     [0.10111435, 0.47324365, 0.2752711, 0.17544255...   \n",
       "2     [0.5600003, 0.11820206, 0.6599864, 0.005933116...   \n",
       "4     [0.8373534, 0.35135373, 0.54747295, 0.91502804...   \n",
       "5     [0.6041386, 0.92545164, 0.9951186, 0.9442425, ...   \n",
       "...                                                 ...   \n",
       "2130                          [0.023725191, 0.87022305]   \n",
       "2131                           [0.7369641, 0.033553768]   \n",
       "2132                               [0.48836, 0.5168656]   \n",
       "2133                            [0.53906214, 0.6020796]   \n",
       "2134                            [0.22739686, 0.5085092]   \n",
       "\n",
       "                                       weekday_sin-list  \n",
       "0     [0.3487224, 0.9060633, 0.25998157, 0.0769127, ...  \n",
       "1     [0.8532496, 0.83872354, 0.993718, 0.72692555, ...  \n",
       "2     [0.5309871, 0.71518654, 0.5602452, 0.37133983,...  \n",
       "4     [0.37596887, 0.057511043, 0.22147927, 0.270423...  \n",
       "5     [0.65229225, 0.11658515, 0.17234567, 0.1389862...  \n",
       "...                                                 ...  \n",
       "2130                            [0.6921467, 0.50588226]  \n",
       "2131                            [0.56077486, 0.8527744]  \n",
       "2132                           [0.9988041, 0.026354417]  \n",
       "2133                           [0.6170275, 0.080708236]  \n",
       "2134                           [0.08497808, 0.99234015]  \n",
       "\n",
       "[1705 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(TRAIN_PATHS)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a687f998-8905-42a4-bb92-d1f5244860b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "443"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6461a96",
   "metadata": {},
   "source": [
    "You have  just created session-level features to train a session-based recommendation model using NVTabular. Now you can move to the the next notebook,`02-session-based-XLNet-with-PyT.ipynb` to train a session-based recommendation model using [XLNet](https://arxiv.org/abs/1906.08237), one of the state-of-the-art NLP model. Please shut down this kernel to free the GPU memory before you start the next one."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "8da354bb7ba701cae52cd1a3a84502fe41cc6aebe6fe36bc9cca0806df816f73"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
