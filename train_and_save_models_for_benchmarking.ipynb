{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1571e258",
   "metadata": {},
   "source": [
    "This notebook trains and exports a model for benchmarking using scripts provided by Gabriel (the ones that has been used for the T4Rec paper)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9eccd5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 1)) (0.13.7)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 2)) (1.3.5)\n",
      "Requirement already satisfied: nvidia-pyindex in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 3)) (1.0.9)\n",
      "Collecting dllogger\n",
      "  Cloning https://github.com/NVIDIA/dllogger to /tmp/pip-install-qkhp_f4u/dllogger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone -q https://github.com/NVIDIA/dllogger /tmp/pip-install-qkhp_f4u/dllogger\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.8/dist-packages (from wandb->-r requirements.txt (line 1)) (1.0.11)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from wandb->-r requirements.txt (line 1)) (6.0)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from wandb->-r requirements.txt (line 1)) (45.2.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.12.0; python_version < \"3.9\" and sys_platform == \"linux\" in /usr/local/lib/python3.8/dist-packages (from wandb->-r requirements.txt (line 1)) (3.20.3)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from wandb->-r requirements.txt (line 1)) (0.4.0)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.8/dist-packages (from wandb->-r requirements.txt (line 1)) (8.1.3)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb->-r requirements.txt (line 1)) (2.28.1)\n",
      "Requirement already satisfied: pathtools in /usr/local/lib/python3.8/dist-packages (from wandb->-r requirements.txt (line 1)) (0.1.2)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb->-r requirements.txt (line 1)) (5.9.4)\n",
      "Requirement already satisfied: setproctitle in /usr/local/lib/python3.8/dist-packages (from wandb->-r requirements.txt (line 1)) (1.3.2)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb->-r requirements.txt (line 1)) (3.1.30)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.8/dist-packages (from wandb->-r requirements.txt (line 1)) (2.3)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb->-r requirements.txt (line 1)) (1.12.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->-r requirements.txt (line 2)) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.17.3; platform_machine != \"aarch64\" and platform_machine != \"arm64\" and python_version < \"3.10\" in /usr/local/lib/python3.8/dist-packages (from pandas->-r requirements.txt (line 2)) (1.22.4)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->-r requirements.txt (line 2)) (2022.7)\n",
      "Requirement already satisfied: six>=1.4.0 in /usr/lib/python3/dist-packages (from docker-pycreds>=0.4.0->wandb->-r requirements.txt (line 1)) (1.14.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 1)) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 1)) (2019.11.28)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 1)) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 1)) (1.26.13)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.8/dist-packages (from GitPython>=1.0.0->wandb->-r requirements.txt (line 1)) (4.0.10)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.8/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb->-r requirements.txt (line 1)) (5.0.0)\n",
      "Building wheels for collected packages: dllogger\n",
      "  Building wheel for dllogger (setup.py): started\n",
      "  Building wheel for dllogger (setup.py): finished with status 'done'\n",
      "  Created wheel for dllogger: filename=DLLogger-1.0.0-py3-none-any.whl size=5656 sha256=571a7a3df2e72b3d0c50aa54bda34ce6ded9c2d77053a1ad5336ff9a7dd3dfea\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-0f1jgvf3/wheels/ad/94/cf/8f3396cb8d62d532695ec557e193fada55cd366e14fd9a02be\n",
      "Successfully built dllogger\n",
      "Installing collected packages: dllogger\n",
      "Successfully installed dllogger-1.0.0\n",
      "Collecting gdown\n",
      "  Downloading gdown-4.6.3-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from gdown) (4.11.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from gdown) (3.9.0)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from gdown) (1.14.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from gdown) (4.64.1)\n",
      "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.8/dist-packages (from gdown) (2.28.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.8/dist-packages (from beautifulsoup4->gdown) (2.3.2.post1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests[socks]->gdown) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests[socks]->gdown) (2019.11.28)\n",
      "Collecting PySocks!=1.5.7,>=1.5.6; extra == \"socks\"\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: gdown, PySocks\n",
      "Successfully installed PySocks-1.7.1 gdown-4.6.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1NCFZ5ya3zyxPsrmupEoc9UEm4sslAddV\n",
      "To: /workspace/examples/t4rec_paper_experiments/t4r_paper_repro/rees46_ecom_dataset_small_for_ci.zip\n",
      "100%|██████████| 43.4M/43.4M [00:07<00:00, 6.18MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease [1581 B]\n",
      "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  Packages [871 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu focal InRelease [265 kB]\n",
      "Get:4 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
      "Get:5 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2496 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu focal/restricted amd64 Packages [33.4 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu focal/main amd64 Packages [1275 kB]\n",
      "Get:10 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [995 kB]\n",
      "Get:11 http://security.ubuntu.com/ubuntu focal-security/multiverse amd64 Packages [28.5 kB]\n",
      "Get:12 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [1937 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu focal/multiverse amd64 Packages [177 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu focal/universe amd64 Packages [11.3 MB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [2066 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [2970 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1296 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu focal-updates/multiverse amd64 Packages [31.2 kB]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu focal-backports/universe amd64 Packages [28.6 kB]\n",
      "Get:20 http://archive.ubuntu.com/ubuntu focal-backports/main amd64 Packages [55.2 kB]\n",
      "Fetched 26.2 MB in 10s (2536 kB/s)\n",
      "Reading package lists...\n",
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "unzip is already the newest version (6.0-25ubuntu1.1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 74 not upgraded.\n",
      "Archive:  rees46_ecom_dataset_small_for_ci.zip\n",
      "   creating: /transformers4rec/examples/t4rec_paper_experiments/t4r_paper_repro/0001/\n",
      "  inflating: /transformers4rec/examples/t4rec_paper_experiments/t4r_paper_repro/0001/valid.parquet  \n",
      " extracting: /transformers4rec/examples/t4rec_paper_experiments/t4r_paper_repro/0001/.zip  \n",
      "  inflating: /transformers4rec/examples/t4rec_paper_experiments/t4r_paper_repro/0001/train.parquet  \n",
      "  inflating: /transformers4rec/examples/t4rec_paper_experiments/t4r_paper_repro/0001/test.parquet  \n",
      "   creating: /transformers4rec/examples/t4rec_paper_experiments/t4r_paper_repro/0002/\n",
      "  inflating: /transformers4rec/examples/t4rec_paper_experiments/t4r_paper_repro/0002/valid.parquet  \n",
      "  inflating: /transformers4rec/examples/t4rec_paper_experiments/t4r_paper_repro/0002/train.parquet  \n",
      "  inflating: /transformers4rec/examples/t4rec_paper_experiments/t4r_paper_repro/0002/test.parquet  \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "set -e\n",
    "\n",
    "#### Install requirements\n",
    "cd examples/t4rec_paper_experiments\n",
    "pip install -r requirements.txt\n",
    "\n",
    "### Get data\n",
    "cd t4r_paper_repro\n",
    "\n",
    "FEATURE_SCHEMA_PATH=../datasets_configs/ecom_rees46/rees46_schema.pbtxt\n",
    "pip install gdown\n",
    "gdown https://drive.google.com/uc?id=1NCFZ5ya3zyxPsrmupEoc9UEm4sslAddV\n",
    "apt-get update -y\n",
    "apt-get install unzip -y\n",
    "DATA_PATH=/transformers4rec/examples/t4rec_paper_experiments/t4r_paper_repro/\n",
    "unzip -d $DATA_PATH \"rees46_ecom_dataset_small_for_ci.zip\"\n",
    "exit 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6089f14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/16/2023 03:08:43 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: True\n",
      "02/16/2023 03:08:44 - WARNING - transformers4rec -   Projecting inputs of NextItemPredictionTask to'448' As weight tying requires the input dimension '192' to be equal to the item-id embedding dimension '448'\n",
      "[INFO|trainer.py:434] 2023-02-16 03:08:44,633 >> Using amp fp16 backend\n",
      "02/16/2023 03:08:44 - INFO - examples.t4rec_paper_experiments.t4r_paper_repro.exp_outputs -   Training, Model and Data parameters {'data_path': '/transformers4rec/examples/t4rec_paper_experiments/t4r_paper_repro/', 'features_schema_path': '/workspace/examples/t4rec_paper_experiments/datasets_configs/ecom_rees46/rees46_schema.pbtxt', 'start_time_window_index': 1, 'final_time_window_index': 2, 'time_window_folder_pad_digits': 4, 'no_incremental_training': False, 'training_time_window_size': 0, 'use_side_information_features': False, 'input_features_aggregation': 'concat', 'model_type': 'xlnet', 'tf_out_activation': 'tanh', 'mlm': True, 'mlm_probability': 0.30000000000000004, 'plm': False, 'plm_probability': 0.25, 'plm_max_span_length': 5, 'plm_mask_input': False, 'plm_permute_all': False, 'rtd': False, 'rtd_sample_from_batch': False, 'rtd_use_batch_interaction': False, 'rtd_discriminator_loss_weight': 50, 'rtd_generator_loss_weight': 1, 'rtd_tied_generator': False, 'd_model': 192, 'n_layer': 3, 'n_head': 16, 'layer_norm_eps': 1e-12, 'initializer_range': 0.02, 'hidden_act': 'gelu', 'dropout': 0.0, 'summary_type': 'last', 'num_hidden_groups': 1, 'inner_group_num': 1, 'eval_on_last_item_seq_only': True, 'train_on_last_item_seq_only': False, 'mf_constrained_embeddings': True, 'item_embedding_dim': 448, 'numeric_features_project_to_embedding_dim': 0, 'numeric_features_soft_one_hot_encoding_num_embeddings': 0, 'stochastic_shared_embeddings_replacement_prob': 0.1, 'softmax_temperature': 1.0, 'label_smoothing': 0.0, 'embedding_dim_from_cardinality_multiplier': 2.0, 'item_id_embeddings_init_std': 0.11, 'other_embeddings_init_std': 0.02, 'layer_norm_featurewise': True, 'attn_type': 'bi', 'input_dropout': 0.1, 'loss_type': 'cross_entropy', 'similarity_type': 'concat_mlp', 'inp_merge': 'mlp', 'learning_rate_warmup_steps': 0, 'avg_session_length': None, 'output_dir': './tmp/', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'prediction_loss_only': False, 'per_device_train_batch_size': 128, 'per_device_eval_batch_size': 128, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 0.0006667377132554976, 'weight_decay': 3.910060265627374e-05, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 1.0, 'max_steps': -1, 'lr_scheduler_type': 'linear', 'warmup_ratio': 0.0, 'warmup_steps': 0, 'log_level': -1, 'log_level_replica': -1, 'log_on_each_node': True, 'logging_dir': './tmp/runs/Feb16_03-08-41_efd7fb71b7f9', 'logging_first_step': False, 'logging_steps': 20, 'logging_nan_inf_filter': True, 'save_steps': 0, 'save_total_limit': None, 'save_on_each_node': False, 'no_cuda': False, 'seed': 100, 'fp16': True, 'fp16_opt_level': 'O1', 'fp16_backend': 'auto', 'fp16_full_eval': False, 'local_rank': -1, 'xpu_backend': None, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': [], 'dataloader_drop_last': True, 'eval_steps': None, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': None, 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'ignore_data_skip': False, 'sharded_ddp': [], 'deepspeed': None, 'label_smoothing_factor': 0.0, 'adafactor': False, 'group_by_length': False, 'length_column_name': 'length', 'report_to': [], 'ddp_find_unused_parameters': None, 'dataloader_pin_memory': True, 'skip_memory_metrics': True, 'use_legacy_prediction_loop': False, 'push_to_hub': False, 'resume_from_checkpoint': None, 'hub_model_id': None, 'hub_token': None, 'gradient_checkpointing': False, 'push_to_hub_model_id': None, 'push_to_hub_organization': None, 'push_to_hub_token': None, '_n_gpu': 1, 'mp_parameters': '', 'max_sequence_length': 20, 'shuffle_buffer_size': 0, 'data_loader_engine': 'merlin', 'eval_on_test_set': True, 'eval_steps_on_train_set': 20, 'predict_top_k': 0, 'learning_rate_num_cosine_cycles_by_epoch': 1.25, 'log_predictions': False, 'compute_metrics_each_n_steps': 1, 'experiments_group': 'default', 'session_seq_length_max': 20, 'learning_rate_schedule': 'linear_with_warmup', 'validate_every': 10}\n",
      "[INFO|trainer.py:1196] 2023-02-16 03:08:45,079 >> ***** Running training *****\n",
      "[INFO|trainer.py:1197] 2023-02-16 03:08:45,079 >>   Num examples = 86528\n",
      "[INFO|trainer.py:1198] 2023-02-16 03:08:45,079 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1199] 2023-02-16 03:08:45,079 >>   Instantaneous batch size per device = 128\n",
      "[INFO|trainer.py:1200] 2023-02-16 03:08:45,079 >>   Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "[INFO|trainer.py:1201] 2023-02-16 03:08:45,079 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1202] 2023-02-16 03:08:45,079 >>   Total optimization steps = 676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DLL 2023-02-16 03:08:44.634316 - PARAMETER data_path : /transformers4rec/examples/t4rec_paper_experiments/t4r_paper_repro/  features_schema_path : /workspace/examples/t4rec_paper_experiments/datasets_configs/ecom_rees46/rees46_schema.pbtxt  start_time_window_index : 1  final_time_window_index : 2  time_window_folder_pad_digits : 4  no_incremental_training : False  training_time_window_size : 0  use_side_information_features : False  input_features_aggregation : concat  model_type : xlnet  tf_out_activation : tanh  mlm : True  mlm_probability : 0.30000000000000004  plm : False  plm_probability : 0.25  plm_max_span_length : 5  plm_mask_input : False  plm_permute_all : False  rtd : False  rtd_sample_from_batch : False  rtd_use_batch_interaction : False  rtd_discriminator_loss_weight : 50  rtd_generator_loss_weight : 1  rtd_tied_generator : False  d_model : 192  n_layer : 3  n_head : 16  layer_norm_eps : 1e-12  initializer_range : 0.02  hidden_act : gelu  dropout : 0.0  summary_type : last  num_hidden_groups : 1  inner_group_num : 1  eval_on_last_item_seq_only : True  train_on_last_item_seq_only : False  mf_constrained_embeddings : True  item_embedding_dim : 448  numeric_features_project_to_embedding_dim : 0  numeric_features_soft_one_hot_encoding_num_embeddings : 0  stochastic_shared_embeddings_replacement_prob : 0.1  softmax_temperature : 1.0  label_smoothing : 0.0  embedding_dim_from_cardinality_multiplier : 2.0  item_id_embeddings_init_std : 0.11  other_embeddings_init_std : 0.02  layer_norm_featurewise : True  attn_type : bi  input_dropout : 0.1  loss_type : cross_entropy  similarity_type : concat_mlp  inp_merge : mlp  learning_rate_warmup_steps : 0  avg_session_length : None  output_dir : ./tmp/  overwrite_output_dir : True  do_train : True  do_eval : True  do_predict : False  prediction_loss_only : False  per_device_train_batch_size : 128  per_device_eval_batch_size : 128  per_gpu_train_batch_size : None  per_gpu_eval_batch_size : None  gradient_accumulation_steps : 1  eval_accumulation_steps : None  learning_rate : 0.0006667377132554976  weight_decay : 3.910060265627374e-05  adam_beta1 : 0.9  adam_beta2 : 0.999  adam_epsilon : 1e-08  max_grad_norm : 1.0  num_train_epochs : 1.0  max_steps : -1  lr_scheduler_type : linear  warmup_ratio : 0.0  warmup_steps : 0  log_level : -1  log_level_replica : -1  log_on_each_node : True  logging_dir : ./tmp/runs/Feb16_03-08-41_efd7fb71b7f9  logging_first_step : False  logging_steps : 20  logging_nan_inf_filter : True  save_steps : 0  save_total_limit : None  save_on_each_node : False  no_cuda : False  seed : 100  fp16 : True  fp16_opt_level : O1  fp16_backend : auto  fp16_full_eval : False  local_rank : -1  xpu_backend : None  tpu_num_cores : None  tpu_metrics_debug : False  debug : []  dataloader_drop_last : True  eval_steps : None  dataloader_num_workers : 0  past_index : -1  run_name : None  disable_tqdm : False  remove_unused_columns : True  label_names : None  load_best_model_at_end : False  metric_for_best_model : None  greater_is_better : None  ignore_data_skip : False  sharded_ddp : []  deepspeed : None  label_smoothing_factor : 0.0  adafactor : False  group_by_length : False  length_column_name : length  report_to : []  ddp_find_unused_parameters : None  dataloader_pin_memory : True  skip_memory_metrics : True  use_legacy_prediction_loop : False  push_to_hub : False  resume_from_checkpoint : None  hub_model_id : None  hub_token : None  gradient_checkpointing : False  push_to_hub_model_id : None  push_to_hub_organization : None  push_to_hub_token : None  _n_gpu : 1  mp_parameters :   max_sequence_length : 20  shuffle_buffer_size : 0  data_loader_engine : merlin  eval_on_test_set : True  eval_steps_on_train_set : 20  predict_top_k : 0  learning_rate_num_cosine_cycles_by_epoch : 1.25  log_predictions : False  compute_metrics_each_n_steps : 1  experiments_group : default  session_seq_length_max : 20  learning_rate_schedule : linear_with_warmup  validate_every : 10 \n",
      "\n",
      "***** Launch training for day 1: *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/676 [00:00<?, ?it/s]\r",
      "  0%|          | 1/676 [00:00<07:37,  1.48it/s]\r",
      "  0%|          | 3/676 [00:00<02:38,  4.24it/s]\r",
      "  1%|          | 5/676 [00:00<01:44,  6.45it/s]\r",
      "  1%|          | 7/676 [00:01<01:22,  8.15it/s]\r",
      "  1%|▏         | 9/676 [00:01<01:10,  9.42it/s]\r",
      "  2%|▏         | 11/676 [00:01<01:04, 10.37it/s]\r",
      "  2%|▏         | 13/676 [00:01<00:59, 11.11it/s]\r",
      "  2%|▏         | 15/676 [00:01<00:56, 11.67it/s]\r",
      "  3%|▎         | 17/676 [00:01<00:54, 12.00it/s]\r",
      "  3%|▎         | 19/676 [00:02<00:53, 12.19it/s]\r",
      "                                                \r",
      "\r",
      "  3%|▎         | 20/676 [00:02<00:53, 12.19it/s]\r",
      "  3%|▎         | 21/676 [00:02<00:53, 12.36it/s]\r",
      "  3%|▎         | 23/676 [00:02<00:52, 12.41it/s]\r",
      "  4%|▎         | 25/676 [00:02<00:52, 12.51it/s]\r",
      "  4%|▍         | 27/676 [00:02<00:51, 12.57it/s]\r",
      "  4%|▍         | 29/676 [00:02<00:51, 12.63it/s]\r",
      "  5%|▍         | 31/676 [00:03<00:50, 12.66it/s]\r",
      "  5%|▍         | 33/676 [00:03<00:50, 12.73it/s]\r",
      "  5%|▌         | 35/676 [00:03<00:50, 12.73it/s]\r",
      "  5%|▌         | 37/676 [00:03<00:50, 12.75it/s]\r",
      "  6%|▌         | 39/676 [00:03<00:49, 12.75it/s]\r",
      "                                                \r",
      "\r",
      "  6%|▌         | 40/676 [00:03<00:49, 12.75it/s]\r",
      "  6%|▌         | 41/676 [00:03<00:49, 12.78it/s]\r",
      "  6%|▋         | 43/676 [00:03<00:49, 12.71it/s]\r",
      "  7%|▋         | 45/676 [00:04<00:49, 12.72it/s]\r",
      "  7%|▋         | 47/676 [00:04<00:49, 12.75it/s]\r",
      "  7%|▋         | 49/676 [00:04<00:49, 12.69it/s]\r",
      "  8%|▊         | 51/676 [00:04<00:49, 12.70it/s]\r",
      "  8%|▊         | 53/676 [00:04<00:48, 12.76it/s]\r",
      "  8%|▊         | 55/676 [00:04<00:48, 12.80it/s]\r",
      "  8%|▊         | 57/676 [00:05<00:48, 12.85it/s]\r",
      "  9%|▊         | 59/676 [00:05<00:48, 12.80it/s]\r",
      "                                                \r",
      "\r",
      "  9%|▉         | 60/676 [00:05<00:48, 12.80it/s]\r",
      "  9%|▉         | 61/676 [00:05<00:48, 12.80it/s]\r",
      "  9%|▉         | 63/676 [00:05<00:47, 12.82it/s]\r",
      " 10%|▉         | 65/676 [00:05<00:47, 12.84it/s]\r",
      " 10%|▉         | 67/676 [00:05<00:47, 12.89it/s]\r",
      " 10%|█         | 69/676 [00:06<00:47, 12.80it/s]\r",
      " 11%|█         | 71/676 [00:06<00:47, 12.77it/s]\r",
      " 11%|█         | 73/676 [00:06<00:47, 12.83it/s]\r",
      " 11%|█         | 75/676 [00:06<00:46, 12.83it/s]\r",
      " 11%|█▏        | 77/676 [00:06<00:46, 12.83it/s]\r",
      " 12%|█▏        | 79/676 [00:06<00:46, 12.83it/s]\r",
      "                                                \r",
      "\r",
      " 12%|█▏        | 80/676 [00:06<00:46, 12.83it/s]\r",
      " 12%|█▏        | 81/676 [00:06<00:46, 12.72it/s]\r",
      " 12%|█▏        | 83/676 [00:07<00:46, 12.75it/s]\r",
      " 13%|█▎        | 85/676 [00:07<00:46, 12.71it/s]\r",
      " 13%|█▎        | 87/676 [00:07<00:46, 12.70it/s]\r",
      " 13%|█▎        | 89/676 [00:07<00:46, 12.71it/s]\r",
      " 13%|█▎        | 91/676 [00:07<00:45, 12.75it/s]\r",
      " 14%|█▍        | 93/676 [00:07<00:45, 12.74it/s]\r",
      " 14%|█▍        | 95/676 [00:08<00:45, 12.87it/s]\r",
      " 14%|█▍        | 97/676 [00:08<00:45, 12.82it/s]\r",
      " 15%|█▍        | 99/676 [00:08<00:45, 12.79it/s]\r",
      "                                                \r",
      "\r",
      " 15%|█▍        | 100/676 [00:08<00:45, 12.79it/s]\r",
      " 15%|█▍        | 101/676 [00:08<00:45, 12.75it/s]\r",
      " 15%|█▌        | 103/676 [00:08<00:44, 12.74it/s]\r",
      " 16%|█▌        | 105/676 [00:08<00:44, 12.71it/s]\r",
      " 16%|█▌        | 107/676 [00:08<00:44, 12.78it/s]\r",
      " 16%|█▌        | 109/676 [00:09<00:44, 12.75it/s]\r",
      " 16%|█▋        | 111/676 [00:09<00:44, 12.74it/s]\r",
      " 17%|█▋        | 113/676 [00:09<00:44, 12.67it/s]\r",
      " 17%|█▋        | 115/676 [00:09<00:44, 12.71it/s]\r",
      " 17%|█▋        | 117/676 [00:09<00:43, 12.75it/s]\r",
      " 18%|█▊        | 119/676 [00:09<00:43, 12.71it/s]\r",
      "                                                 \r",
      "\r",
      " 18%|█▊        | 120/676 [00:10<00:43, 12.71it/s]\r",
      " 18%|█▊        | 121/676 [00:10<00:43, 12.69it/s]\r",
      " 18%|█▊        | 123/676 [00:10<00:43, 12.72it/s]\r",
      " 18%|█▊        | 125/676 [00:10<00:43, 12.72it/s]\r",
      " 19%|█▉        | 127/676 [00:10<00:43, 12.73it/s]\r",
      " 19%|█▉        | 129/676 [00:10<00:42, 12.74it/s]\r",
      " 19%|█▉        | 131/676 [00:10<00:42, 12.72it/s]\r",
      " 20%|█▉        | 133/676 [00:11<00:42, 12.76it/s]\r",
      " 20%|█▉        | 135/676 [00:11<00:42, 12.80it/s]\r",
      " 20%|██        | 137/676 [00:11<00:42, 12.82it/s]\r",
      " 21%|██        | 139/676 [00:11<00:41, 12.81it/s]\r",
      "                                                 \r",
      "\r",
      " 21%|██        | 140/676 [00:11<00:41, 12.81it/s]\r",
      " 21%|██        | 141/676 [00:11<00:42, 12.70it/s]\r",
      " 21%|██        | 143/676 [00:11<00:41, 12.71it/s]\r",
      " 21%|██▏       | 145/676 [00:11<00:41, 12.73it/s]\r",
      " 22%|██▏       | 147/676 [00:12<00:41, 12.69it/s]\r",
      " 22%|██▏       | 149/676 [00:12<00:41, 12.71it/s]\r",
      " 22%|██▏       | 151/676 [00:12<00:41, 12.77it/s]\r",
      " 23%|██▎       | 153/676 [00:12<00:40, 12.86it/s]\r",
      " 23%|██▎       | 155/676 [00:12<00:40, 12.82it/s]\r",
      " 23%|██▎       | 157/676 [00:12<00:40, 12.88it/s]\r",
      " 24%|██▎       | 159/676 [00:13<00:40, 12.78it/s]\r",
      "                                                 \r",
      "\r",
      " 24%|██▎       | 160/676 [00:13<00:40, 12.78it/s]\r",
      " 24%|██▍       | 161/676 [00:13<00:40, 12.74it/s]\r",
      " 24%|██▍       | 163/676 [00:13<00:40, 12.82it/s]\r",
      " 24%|██▍       | 165/676 [00:13<00:39, 12.83it/s]\r",
      " 25%|██▍       | 167/676 [00:13<00:39, 12.77it/s]\r",
      " 25%|██▌       | 169/676 [00:13<00:39, 12.81it/s]\r",
      " 25%|██▌       | 171/676 [00:13<00:39, 12.83it/s]\r",
      " 26%|██▌       | 173/676 [00:14<00:39, 12.86it/s]\r",
      " 26%|██▌       | 175/676 [00:14<00:38, 12.91it/s]\r",
      " 26%|██▌       | 177/676 [00:14<00:38, 12.83it/s]\r",
      " 26%|██▋       | 179/676 [00:14<00:38, 12.88it/s]\r",
      "                                                 \r",
      "\r",
      " 27%|██▋       | 180/676 [00:14<00:38, 12.88it/s]\r",
      " 27%|██▋       | 181/676 [00:14<00:38, 12.86it/s]\r",
      " 27%|██▋       | 183/676 [00:14<00:38, 12.81it/s]\r",
      " 27%|██▋       | 185/676 [00:15<00:38, 12.79it/s]\r",
      " 28%|██▊       | 187/676 [00:15<00:38, 12.81it/s]\r",
      " 28%|██▊       | 189/676 [00:15<00:38, 12.78it/s]\r",
      " 28%|██▊       | 191/676 [00:15<00:38, 12.73it/s]\r",
      " 29%|██▊       | 193/676 [00:15<00:37, 12.76it/s]\r",
      " 29%|██▉       | 195/676 [00:15<00:37, 12.78it/s]\r",
      " 29%|██▉       | 197/676 [00:16<00:37, 12.80it/s]\r",
      " 29%|██▉       | 199/676 [00:16<00:37, 12.77it/s]\r",
      "                                                 \r",
      "\r",
      " 30%|██▉       | 200/676 [00:16<00:37, 12.77it/s]\r",
      " 30%|██▉       | 201/676 [00:16<00:37, 12.77it/s]\r",
      " 30%|███       | 203/676 [00:16<00:37, 12.78it/s]\r",
      " 30%|███       | 205/676 [00:16<00:36, 12.79it/s]\r",
      " 31%|███       | 207/676 [00:16<00:36, 12.82it/s]\r",
      " 31%|███       | 209/676 [00:16<00:36, 12.70it/s]\r",
      " 31%|███       | 211/676 [00:17<00:36, 12.69it/s]\r",
      " 32%|███▏      | 213/676 [00:17<00:36, 12.84it/s]\r",
      " 32%|███▏      | 215/676 [00:17<00:35, 12.83it/s]\r",
      " 32%|███▏      | 217/676 [00:17<00:35, 12.82it/s]\r",
      " 32%|███▏      | 219/676 [00:17<00:35, 12.77it/s]\r",
      "                                                 \r",
      "\r",
      " 33%|███▎      | 220/676 [00:17<00:35, 12.77it/s]\r",
      " 33%|███▎      | 221/676 [00:17<00:35, 12.66it/s]\r",
      " 33%|███▎      | 223/676 [00:18<00:35, 12.69it/s]\r",
      " 33%|███▎      | 225/676 [00:18<00:35, 12.73it/s]\r",
      " 34%|███▎      | 227/676 [00:18<00:35, 12.72it/s]\r",
      " 34%|███▍      | 229/676 [00:18<00:35, 12.74it/s]\r",
      " 34%|███▍      | 231/676 [00:18<00:34, 12.83it/s]\r",
      " 34%|███▍      | 233/676 [00:18<00:34, 12.82it/s]\r",
      " 35%|███▍      | 235/676 [00:19<00:34, 12.85it/s]\r",
      " 35%|███▌      | 237/676 [00:19<00:34, 12.76it/s]\r",
      " 35%|███▌      | 239/676 [00:19<00:34, 12.75it/s]\r",
      "                                                 \r",
      "\r",
      " 36%|███▌      | 240/676 [00:19<00:34, 12.75it/s]\r",
      " 36%|███▌      | 241/676 [00:19<00:34, 12.77it/s]\r",
      " 36%|███▌      | 243/676 [00:19<00:33, 12.74it/s]\r",
      " 36%|███▌      | 245/676 [00:19<00:33, 12.70it/s]\r",
      " 37%|███▋      | 247/676 [00:19<00:33, 12.72it/s]\r",
      " 37%|███▋      | 249/676 [00:20<00:33, 12.70it/s]\r",
      " 37%|███▋      | 251/676 [00:20<00:33, 12.73it/s]\r",
      " 37%|███▋      | 253/676 [00:20<00:33, 12.72it/s]\r",
      " 38%|███▊      | 255/676 [00:20<00:33, 12.75it/s]\r",
      " 38%|███▊      | 257/676 [00:20<00:32, 12.73it/s]\r",
      " 38%|███▊      | 259/676 [00:20<00:32, 12.78it/s]\r",
      "                                                 \r",
      "\r",
      " 38%|███▊      | 260/676 [00:20<00:32, 12.78it/s]\r",
      " 39%|███▊      | 261/676 [00:21<00:32, 12.76it/s]\r",
      " 39%|███▉      | 263/676 [00:21<00:32, 12.75it/s]\r",
      " 39%|███▉      | 265/676 [00:21<00:32, 12.64it/s]\r",
      " 39%|███▉      | 267/676 [00:21<00:32, 12.64it/s]\r",
      " 40%|███▉      | 269/676 [00:21<00:32, 12.68it/s]\r",
      " 40%|████      | 271/676 [00:21<00:31, 12.75it/s]\r",
      " 40%|████      | 273/676 [00:21<00:31, 12.73it/s]\r",
      " 41%|████      | 275/676 [00:22<00:31, 12.70it/s]\r",
      " 41%|████      | 277/676 [00:22<00:31, 12.74it/s]\r",
      " 41%|████▏     | 279/676 [00:22<00:31, 12.76it/s]\r",
      "                                                 \r",
      "\r",
      " 41%|████▏     | 280/676 [00:22<00:31, 12.76it/s]\r",
      " 42%|████▏     | 281/676 [00:22<00:30, 12.74it/s]\r",
      " 42%|████▏     | 283/676 [00:22<00:30, 12.75it/s]\r",
      " 42%|████▏     | 285/676 [00:22<00:30, 12.77it/s]\r",
      " 42%|████▏     | 287/676 [00:23<00:30, 12.79it/s]\r",
      " 43%|████▎     | 289/676 [00:23<00:30, 12.83it/s]\r",
      " 43%|████▎     | 291/676 [00:23<00:30, 12.67it/s]\r",
      " 43%|████▎     | 293/676 [00:23<00:30, 12.70it/s]\r",
      " 44%|████▎     | 295/676 [00:23<00:29, 12.75it/s]\r",
      " 44%|████▍     | 297/676 [00:23<00:29, 12.73it/s]\r",
      " 44%|████▍     | 299/676 [00:24<00:29, 12.71it/s]\r",
      "                                                 \r",
      "\r",
      " 44%|████▍     | 300/676 [00:24<00:29, 12.71it/s]\r",
      " 45%|████▍     | 301/676 [00:24<00:29, 12.71it/s]\r",
      " 45%|████▍     | 303/676 [00:24<00:29, 12.69it/s]\r",
      " 45%|████▌     | 305/676 [00:24<00:29, 12.70it/s]\r",
      " 45%|████▌     | 307/676 [00:24<00:29, 12.69it/s]\r",
      " 46%|████▌     | 309/676 [00:24<00:28, 12.72it/s]\r",
      " 46%|████▌     | 311/676 [00:24<00:28, 12.71it/s]\r",
      " 46%|████▋     | 313/676 [00:25<00:28, 12.77it/s]\r",
      " 47%|████▋     | 315/676 [00:25<00:28, 12.70it/s]\r",
      " 47%|████▋     | 317/676 [00:25<00:28, 12.65it/s]\r",
      " 47%|████▋     | 319/676 [00:25<00:28, 12.69it/s]\r",
      "                                                 \r",
      "\r",
      " 47%|████▋     | 320/676 [00:25<00:28, 12.69it/s]\r",
      " 47%|████▋     | 321/676 [00:25<00:27, 12.74it/s]\r",
      " 48%|████▊     | 323/676 [00:25<00:27, 12.76it/s]\r",
      " 48%|████▊     | 325/676 [00:26<00:27, 12.69it/s]\r",
      " 48%|████▊     | 327/676 [00:26<00:27, 12.67it/s]\r",
      " 49%|████▊     | 329/676 [00:26<00:27, 12.66it/s]\r",
      " 49%|████▉     | 331/676 [00:26<00:27, 12.74it/s]\r",
      " 49%|████▉     | 333/676 [00:26<00:26, 12.77it/s]\r",
      " 50%|████▉     | 335/676 [00:26<00:26, 12.74it/s]\r",
      " 50%|████▉     | 337/676 [00:27<00:26, 12.69it/s]\r",
      " 50%|█████     | 339/676 [00:27<00:26, 12.66it/s]\r",
      "                                                 \r",
      "\r",
      " 50%|█████     | 340/676 [00:27<00:26, 12.66it/s]\r",
      " 50%|█████     | 341/676 [00:27<00:26, 12.67it/s]\r",
      " 51%|█████     | 343/676 [00:27<00:26, 12.71it/s]\r",
      " 51%|█████     | 345/676 [00:27<00:26, 12.71it/s]\r",
      " 51%|█████▏    | 347/676 [00:27<00:25, 12.73it/s]\r",
      " 52%|█████▏    | 349/676 [00:27<00:25, 12.72it/s]\r",
      " 52%|█████▏    | 351/676 [00:28<00:25, 12.72it/s]\r",
      " 52%|█████▏    | 353/676 [00:28<00:25, 12.70it/s]\r",
      " 53%|█████▎    | 355/676 [00:28<00:25, 12.73it/s]\r",
      " 53%|█████▎    | 357/676 [00:28<00:24, 12.77it/s]\r",
      " 53%|█████▎    | 359/676 [00:28<00:24, 12.80it/s]\r",
      "                                                 \r",
      "\r",
      " 53%|█████▎    | 360/676 [00:28<00:24, 12.80it/s]\r",
      " 53%|█████▎    | 361/676 [00:28<00:24, 12.78it/s]\r",
      " 54%|█████▎    | 363/676 [00:29<00:24, 12.76it/s]\r",
      " 54%|█████▍    | 365/676 [00:29<00:24, 12.77it/s]\r",
      " 54%|█████▍    | 367/676 [00:29<00:24, 12.70it/s]\r",
      " 55%|█████▍    | 369/676 [00:29<00:24, 12.65it/s]\r",
      " 55%|█████▍    | 371/676 [00:29<00:24, 12.69it/s]\r",
      " 55%|█████▌    | 373/676 [00:29<00:23, 12.68it/s]\r",
      " 55%|█████▌    | 375/676 [00:30<00:23, 12.73it/s]\r",
      " 56%|█████▌    | 377/676 [00:30<00:23, 12.77it/s]\r",
      " 56%|█████▌    | 379/676 [00:30<00:23, 12.77it/s]\r",
      "                                                 \r",
      "\r",
      " 56%|█████▌    | 380/676 [00:30<00:23, 12.77it/s]\r",
      " 56%|█████▋    | 381/676 [00:30<00:23, 12.73it/s]\r",
      " 57%|█████▋    | 383/676 [00:30<00:22, 12.77it/s]\r",
      " 57%|█████▋    | 385/676 [00:30<00:22, 12.76it/s]\r",
      " 57%|█████▋    | 387/676 [00:30<00:22, 12.83it/s]\r",
      " 58%|█████▊    | 389/676 [00:31<00:22, 12.80it/s]\r",
      " 58%|█████▊    | 391/676 [00:31<00:22, 12.78it/s]\r",
      " 58%|█████▊    | 393/676 [00:31<00:22, 12.74it/s]\r",
      " 58%|█████▊    | 395/676 [00:31<00:22, 12.71it/s]\r",
      " 59%|█████▊    | 397/676 [00:31<00:22, 12.65it/s]\r",
      " 59%|█████▉    | 399/676 [00:31<00:21, 12.64it/s]\r",
      "                                                 \r",
      "\r",
      " 59%|█████▉    | 400/676 [00:31<00:21, 12.64it/s]\r",
      " 59%|█████▉    | 401/676 [00:32<00:21, 12.61it/s]\r",
      " 60%|█████▉    | 403/676 [00:32<00:21, 12.61it/s]\r",
      " 60%|█████▉    | 405/676 [00:32<00:21, 12.61it/s]\r",
      " 60%|██████    | 407/676 [00:32<00:21, 12.62it/s]\r",
      " 61%|██████    | 409/676 [00:32<00:21, 12.66it/s]\r",
      " 61%|██████    | 411/676 [00:32<00:20, 12.72it/s]\r",
      " 61%|██████    | 413/676 [00:32<00:20, 12.81it/s]\r",
      " 61%|██████▏   | 415/676 [00:33<00:20, 12.82it/s]\r",
      " 62%|██████▏   | 417/676 [00:33<00:20, 12.77it/s]\r",
      " 62%|██████▏   | 419/676 [00:33<00:20, 12.74it/s]\r",
      "                                                 \r",
      "\r",
      " 62%|██████▏   | 420/676 [00:33<00:20, 12.74it/s]\r",
      " 62%|██████▏   | 421/676 [00:33<00:19, 12.78it/s]\r",
      " 63%|██████▎   | 423/676 [00:33<00:19, 12.75it/s]\r",
      " 63%|██████▎   | 425/676 [00:33<00:19, 12.77it/s]\r",
      " 63%|██████▎   | 427/676 [00:34<00:19, 12.73it/s]\r",
      " 63%|██████▎   | 429/676 [00:34<00:19, 12.79it/s]\r",
      " 64%|██████▍   | 431/676 [00:34<00:19, 12.73it/s]\r",
      " 64%|██████▍   | 433/676 [00:34<00:19, 12.71it/s]\r",
      " 64%|██████▍   | 435/676 [00:34<00:18, 12.74it/s]\r",
      " 65%|██████▍   | 437/676 [00:34<00:18, 12.70it/s]\r",
      " 65%|██████▍   | 439/676 [00:35<00:18, 12.73it/s]\r",
      "                                                 \r",
      "\r",
      " 65%|██████▌   | 440/676 [00:35<00:18, 12.73it/s]\r",
      " 65%|██████▌   | 441/676 [00:35<00:18, 12.75it/s]\r",
      " 66%|██████▌   | 443/676 [00:35<00:18, 12.78it/s]\r",
      " 66%|██████▌   | 445/676 [00:35<00:18, 12.80it/s]\r",
      " 66%|██████▌   | 447/676 [00:35<00:17, 12.83it/s]\r",
      " 66%|██████▋   | 449/676 [00:35<00:17, 12.84it/s]\r",
      " 67%|██████▋   | 451/676 [00:35<00:17, 12.77it/s]\r",
      " 67%|██████▋   | 453/676 [00:36<00:17, 12.76it/s]\r",
      " 67%|██████▋   | 455/676 [00:36<00:17, 12.83it/s]\r",
      " 68%|██████▊   | 457/676 [00:36<00:17, 12.83it/s]\r",
      " 68%|██████▊   | 459/676 [00:36<00:16, 12.81it/s]\r",
      "                                                 \r",
      "\r",
      " 68%|██████▊   | 460/676 [00:36<00:16, 12.81it/s]\r",
      " 68%|██████▊   | 461/676 [00:36<00:16, 12.79it/s]\r",
      " 68%|██████▊   | 463/676 [00:36<00:16, 12.80it/s]\r",
      " 69%|██████▉   | 465/676 [00:37<00:16, 12.81it/s]\r",
      " 69%|██████▉   | 467/676 [00:37<00:16, 12.82it/s]\r",
      " 69%|██████▉   | 469/676 [00:37<00:16, 12.71it/s]\r",
      " 70%|██████▉   | 471/676 [00:37<00:16, 12.72it/s]\r",
      " 70%|██████▉   | 473/676 [00:37<00:15, 12.72it/s]\r",
      " 70%|███████   | 475/676 [00:37<00:15, 12.75it/s]\r",
      " 71%|███████   | 477/676 [00:38<00:15, 12.77it/s]\r",
      " 71%|███████   | 479/676 [00:38<00:15, 12.73it/s]\r",
      "                                                 \r",
      "\r",
      " 71%|███████   | 480/676 [00:38<00:15, 12.73it/s]\r",
      " 71%|███████   | 481/676 [00:38<00:15, 12.70it/s]\r",
      " 71%|███████▏  | 483/676 [00:38<00:15, 12.71it/s]\r",
      " 72%|███████▏  | 485/676 [00:38<00:15, 12.67it/s]\r",
      " 72%|███████▏  | 487/676 [00:38<00:14, 12.65it/s]\r",
      " 72%|███████▏  | 489/676 [00:38<00:14, 12.63it/s]\r",
      " 73%|███████▎  | 491/676 [00:39<00:14, 12.59it/s]\r",
      " 73%|███████▎  | 493/676 [00:39<00:14, 12.59it/s]\r",
      " 73%|███████▎  | 495/676 [00:39<00:14, 12.61it/s]\r",
      " 74%|███████▎  | 497/676 [00:39<00:14, 12.66it/s]\r",
      " 74%|███████▍  | 499/676 [00:39<00:14, 12.58it/s]\r",
      "                                                 \r",
      "\r",
      " 74%|███████▍  | 500/676 [00:39<00:13, 12.58it/s]\r",
      " 74%|███████▍  | 501/676 [00:39<00:13, 12.60it/s]\r",
      " 74%|███████▍  | 503/676 [00:40<00:13, 12.63it/s]\r",
      " 75%|███████▍  | 505/676 [00:40<00:13, 12.60it/s]\r",
      " 75%|███████▌  | 507/676 [00:40<00:13, 12.66it/s]\r",
      " 75%|███████▌  | 509/676 [00:40<00:13, 12.64it/s]\r",
      " 76%|███████▌  | 511/676 [00:40<00:13, 12.68it/s]\r",
      " 76%|███████▌  | 513/676 [00:40<00:12, 12.69it/s]\r",
      " 76%|███████▌  | 515/676 [00:41<00:12, 12.66it/s]\r",
      " 76%|███████▋  | 517/676 [00:41<00:12, 12.60it/s]\r",
      " 77%|███████▋  | 519/676 [00:41<00:12, 12.62it/s]\r",
      "                                                 \r",
      "\r",
      " 77%|███████▋  | 520/676 [00:41<00:12, 12.62it/s]\r",
      " 77%|███████▋  | 521/676 [00:41<00:12, 12.64it/s]\r",
      " 77%|███████▋  | 523/676 [00:41<00:12, 12.66it/s]\r",
      " 78%|███████▊  | 525/676 [00:41<00:11, 12.60it/s]\r",
      " 78%|███████▊  | 527/676 [00:41<00:11, 12.66it/s]\r",
      " 78%|███████▊  | 529/676 [00:42<00:11, 12.61it/s]\r",
      " 79%|███████▊  | 531/676 [00:42<00:11, 12.64it/s]\r",
      " 79%|███████▉  | 533/676 [00:42<00:11, 12.66it/s]\r",
      " 79%|███████▉  | 535/676 [00:42<00:11, 12.66it/s]\r",
      " 79%|███████▉  | 537/676 [00:42<00:11, 12.62it/s]\r",
      " 80%|███████▉  | 539/676 [00:42<00:10, 12.62it/s]\r",
      "                                                 \r",
      "\r",
      " 80%|███████▉  | 540/676 [00:42<00:10, 12.62it/s]\r",
      " 80%|████████  | 541/676 [00:43<00:10, 12.67it/s]\r",
      " 80%|████████  | 543/676 [00:43<00:10, 12.67it/s]\r",
      " 81%|████████  | 545/676 [00:43<00:10, 12.65it/s]\r",
      " 81%|████████  | 547/676 [00:43<00:10, 12.65it/s]\r",
      " 81%|████████  | 549/676 [00:43<00:10, 12.68it/s]\r",
      " 82%|████████▏ | 551/676 [00:43<00:09, 12.72it/s]\r",
      " 82%|████████▏ | 553/676 [00:44<00:09, 12.76it/s]\r",
      " 82%|████████▏ | 555/676 [00:44<00:09, 12.69it/s]\r",
      " 82%|████████▏ | 557/676 [00:44<00:09, 12.66it/s]\r",
      " 83%|████████▎ | 559/676 [00:44<00:09, 12.64it/s]\r",
      "                                                 \r",
      "\r",
      " 83%|████████▎ | 560/676 [00:44<00:09, 12.64it/s]\r",
      " 83%|████████▎ | 561/676 [00:44<00:09, 12.64it/s]\r",
      " 83%|████████▎ | 563/676 [00:44<00:08, 12.62it/s]\r",
      " 84%|████████▎ | 565/676 [00:44<00:08, 12.64it/s]\r",
      " 84%|████████▍ | 567/676 [00:45<00:08, 12.65it/s]\r",
      " 84%|████████▍ | 569/676 [00:45<00:08, 12.63it/s]\r",
      " 84%|████████▍ | 571/676 [00:45<00:08, 12.67it/s]\r",
      " 85%|████████▍ | 573/676 [00:45<00:08, 12.71it/s]\r",
      " 85%|████████▌ | 575/676 [00:45<00:07, 12.70it/s]\r",
      " 85%|████████▌ | 577/676 [00:45<00:07, 12.72it/s]\r",
      " 86%|████████▌ | 579/676 [00:46<00:07, 12.68it/s]\r",
      "                                                 \r",
      "\r",
      " 86%|████████▌ | 580/676 [00:46<00:07, 12.68it/s]\r",
      " 86%|████████▌ | 581/676 [00:46<00:07, 12.67it/s]\r",
      " 86%|████████▌ | 583/676 [00:46<00:07, 12.73it/s]\r",
      " 87%|████████▋ | 585/676 [00:46<00:07, 12.78it/s]\r",
      " 87%|████████▋ | 587/676 [00:46<00:06, 12.74it/s]\r",
      " 87%|████████▋ | 589/676 [00:46<00:06, 12.72it/s]\r",
      " 87%|████████▋ | 591/676 [00:47<00:06, 12.74it/s]\r",
      " 88%|████████▊ | 593/676 [00:47<00:06, 12.74it/s]\r",
      " 88%|████████▊ | 595/676 [00:47<00:06, 12.72it/s]\r",
      " 88%|████████▊ | 597/676 [00:47<00:06, 12.69it/s]\r",
      " 89%|████████▊ | 599/676 [00:47<00:06, 12.66it/s]\r",
      "                                                 \r",
      "\r",
      " 89%|████████▉ | 600/676 [00:47<00:06, 12.66it/s]\r",
      " 89%|████████▉ | 601/676 [00:47<00:05, 12.69it/s]\r",
      " 89%|████████▉ | 603/676 [00:47<00:05, 12.65it/s]\r",
      " 89%|████████▉ | 605/676 [00:48<00:05, 12.65it/s]\r",
      " 90%|████████▉ | 607/676 [00:48<00:05, 12.69it/s]\r",
      " 90%|█████████ | 609/676 [00:48<00:05, 12.71it/s]\r",
      " 90%|█████████ | 611/676 [00:48<00:05, 12.74it/s]\r",
      " 91%|█████████ | 613/676 [00:48<00:04, 12.73it/s]\r",
      " 91%|█████████ | 615/676 [00:48<00:04, 12.71it/s]\r",
      " 91%|█████████▏| 617/676 [00:49<00:04, 12.65it/s]\r",
      " 92%|█████████▏| 619/676 [00:49<00:04, 12.60it/s]\r",
      "                                                 \r",
      "\r",
      " 92%|█████████▏| 620/676 [00:49<00:04, 12.60it/s]\r",
      " 92%|█████████▏| 621/676 [00:49<00:04, 12.67it/s]\r",
      " 92%|█████████▏| 623/676 [00:49<00:04, 12.64it/s]\r",
      " 92%|█████████▏| 625/676 [00:49<00:04, 12.66it/s]\r",
      " 93%|█████████▎| 627/676 [00:49<00:03, 12.66it/s]\r",
      " 93%|█████████▎| 629/676 [00:50<00:03, 12.69it/s]\r",
      " 93%|█████████▎| 631/676 [00:50<00:03, 12.68it/s]\r",
      " 94%|█████████▎| 633/676 [00:50<00:03, 12.70it/s]\r",
      " 94%|█████████▍| 635/676 [00:50<00:03, 12.74it/s]\r",
      " 94%|█████████▍| 637/676 [00:50<00:03, 12.70it/s]\r",
      " 95%|█████████▍| 639/676 [00:50<00:02, 12.70it/s]\r",
      "                                                 \r",
      "\r",
      " 95%|█████████▍| 640/676 [00:50<00:02, 12.70it/s]\r",
      " 95%|█████████▍| 641/676 [00:50<00:02, 12.72it/s]\r",
      " 95%|█████████▌| 643/676 [00:51<00:02, 12.67it/s]\r",
      " 95%|█████████▌| 645/676 [00:51<00:02, 12.71it/s]\r",
      " 96%|█████████▌| 647/676 [00:51<00:02, 12.73it/s]\r",
      " 96%|█████████▌| 649/676 [00:51<00:02, 12.71it/s]\r",
      " 96%|█████████▋| 651/676 [00:51<00:01, 12.69it/s]\r",
      " 97%|█████████▋| 653/676 [00:51<00:01, 12.63it/s]\r",
      " 97%|█████████▋| 655/676 [00:52<00:01, 12.65it/s]\r",
      " 97%|█████████▋| 657/676 [00:52<00:01, 12.69it/s]\r",
      " 97%|█████████▋| 659/676 [00:52<00:01, 12.64it/s]\r",
      "                                                 \r",
      "\r",
      " 98%|█████████▊| 660/676 [00:52<00:01, 12.64it/s]\r",
      " 98%|█████████▊| 661/676 [00:52<00:01, 12.65it/s]\r",
      " 98%|█████████▊| 663/676 [00:52<00:01, 12.58it/s]\r",
      " 98%|█████████▊| 665/676 [00:52<00:00, 12.62it/s]\r",
      " 99%|█████████▊| 667/676 [00:53<00:00, 12.77it/s]\r",
      " 99%|█████████▉| 669/676 [00:53<00:00, 12.72it/s]\r",
      " 99%|█████████▉| 671/676 [00:53<00:00, 12.74it/s]\r",
      "100%|█████████▉| 673/676 [00:53<00:00, 12.73it/s]\r",
      "100%|█████████▉| 675/676 [00:53<00:00, 12.73it/s][INFO|trainer.py:1409] 2023-02-16 03:09:38,793 >> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "100%|██████████| 676/676 [00:53<00:00, 12.59it/s]\n",
      "02/16/2023 03:09:39 - INFO - transformers4rec.torch.trainer -   ***** Running Evaluation *****\n",
      "02/16/2023 03:09:39 - INFO - transformers4rec.torch.trainer -     Batch size = 128\n",
      "02/16/2023 03:09:39 - INFO - transformers4rec.torch.trainer -     Num sessions (examples) = 2560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 12.9461, 'learning_rate': 0.0006479980438000916, 'epoch': 0.03}\n",
      "{'loss': 12.4993, 'learning_rate': 0.0006282720759522958, 'epoch': 0.06}\n",
      "{'loss': 11.5558, 'learning_rate': 0.0006085461081045, 'epoch': 0.09}\n",
      "{'loss': 10.8853, 'learning_rate': 0.0005888201402567042, 'epoch': 0.12}\n",
      "{'loss': 10.6505, 'learning_rate': 0.0005690941724089084, 'epoch': 0.15}\n",
      "{'loss': 10.3291, 'learning_rate': 0.0005493682045611127, 'epoch': 0.18}\n",
      "{'loss': 10.2382, 'learning_rate': 0.0005296422367133169, 'epoch': 0.21}\n",
      "{'loss': 10.0688, 'learning_rate': 0.000509916268865521, 'epoch': 0.24}\n",
      "{'loss': 9.9956, 'learning_rate': 0.0004901903010177253, 'epoch': 0.27}\n",
      "{'loss': 10.0305, 'learning_rate': 0.0004704643331699295, 'epoch': 0.3}\n",
      "{'loss': 9.9745, 'learning_rate': 0.00045073836532213366, 'epoch': 0.33}\n",
      "{'loss': 9.8802, 'learning_rate': 0.00043101239747433793, 'epoch': 0.36}\n",
      "{'loss': 9.9794, 'learning_rate': 0.00041128642962654215, 'epoch': 0.38}\n",
      "{'loss': 9.8796, 'learning_rate': 0.0003915604617787463, 'epoch': 0.41}\n",
      "{'loss': 9.7342, 'learning_rate': 0.0003718344939309506, 'epoch': 0.44}\n",
      "{'loss': 9.7167, 'learning_rate': 0.00035210852608315475, 'epoch': 0.47}\n",
      "{'loss': 9.7295, 'learning_rate': 0.00033238255823535897, 'epoch': 0.5}\n",
      "{'loss': 9.7277, 'learning_rate': 0.0003126565903875632, 'epoch': 0.53}\n",
      "{'loss': 9.6692, 'learning_rate': 0.00029293062253976746, 'epoch': 0.56}\n",
      "{'loss': 9.6907, 'learning_rate': 0.0002732046546919716, 'epoch': 0.59}\n",
      "{'loss': 9.7142, 'learning_rate': 0.00025347868684417584, 'epoch': 0.62}\n",
      "{'loss': 9.6817, 'learning_rate': 0.00023375271899638006, 'epoch': 0.65}\n",
      "{'loss': 9.3796, 'learning_rate': 0.00021402675114858425, 'epoch': 0.68}\n",
      "{'loss': 9.5749, 'learning_rate': 0.0001943007833007885, 'epoch': 0.71}\n",
      "{'loss': 9.5428, 'learning_rate': 0.00017457481545299271, 'epoch': 0.74}\n",
      "{'loss': 9.6506, 'learning_rate': 0.0001548488476051969, 'epoch': 0.77}\n",
      "{'loss': 9.668, 'learning_rate': 0.00013512287975740115, 'epoch': 0.8}\n",
      "{'loss': 9.574, 'learning_rate': 0.00011539691190960534, 'epoch': 0.83}\n",
      "{'loss': 9.5561, 'learning_rate': 9.567094406180957e-05, 'epoch': 0.86}\n",
      "{'loss': 9.5314, 'learning_rate': 7.594497621401378e-05, 'epoch': 0.89}\n",
      "{'loss': 9.6004, 'learning_rate': 5.621900836621799e-05, 'epoch': 0.92}\n",
      "{'loss': 9.5395, 'learning_rate': 3.6493040518422206e-05, 'epoch': 0.95}\n",
      "{'loss': 9.4442, 'learning_rate': 1.6767072670626417e-05, 'epoch': 0.98}\n",
      "{'train_runtime': 53.7141, 'train_samples_per_second': 0.019, 'train_steps_per_second': 12.585, 'train_loss': 10.03619669175007, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 20/676 [00:00<00:16, 40.24it/s]\n",
      "02/16/2023 03:09:39 - INFO - examples.t4rec_paper_experiments.t4r_paper_repro.exp_outputs -   ***** train results (time index): 2)*****\n",
      "02/16/2023 03:09:39 - INFO - examples.t4rec_paper_experiments.t4r_paper_repro.exp_outputs -     train_/loss = 9.205911636352539\n",
      "02/16/2023 03:09:39 - INFO - examples.t4rec_paper_experiments.t4r_paper_repro.exp_outputs -     train_/next-item/ndcg_at_10 = 0.03375788405537605\n",
      "02/16/2023 03:09:39 - INFO - examples.t4rec_paper_experiments.t4r_paper_repro.exp_outputs -     train_/next-item/ndcg_at_20 = 0.042607784271240234\n",
      "02/16/2023 03:09:39 - INFO - examples.t4rec_paper_experiments.t4r_paper_repro.exp_outputs -     train_/next-item/recall_at_10 = 0.06171875074505806\n",
      "02/16/2023 03:09:39 - INFO - examples.t4rec_paper_experiments.t4r_paper_repro.exp_outputs -     train_/next-item/recall_at_20 = 0.09648437798023224\n",
      "02/16/2023 03:09:39 - INFO - examples.t4rec_paper_experiments.t4r_paper_repro.exp_outputs -     train_runtime = 0.6408\n",
      "02/16/2023 03:09:39 - INFO - examples.t4rec_paper_experiments.t4r_paper_repro.exp_outputs -     train_samples_per_second = 3995.042\n",
      "02/16/2023 03:09:39 - INFO - examples.t4rec_paper_experiments.t4r_paper_repro.exp_outputs -     train_steps_per_second = 31.211\n",
      "02/16/2023 03:09:40 - INFO - transformers4rec.torch.trainer -   ***** Running Evaluation *****\n",
      "02/16/2023 03:09:40 - INFO - transformers4rec.torch.trainer -     Batch size = 128\n",
      "02/16/2023 03:09:40 - INFO - transformers4rec.torch.trainer -     Num sessions (examples) = 10624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Evaluation results for day 2 (train set):*****\n",
      "\n",
      "{'train_/next-item/ndcg_at_10': 0.03375788405537605, 'train_/next-item/ndcg_at_20': 0.042607784271240234, 'train_/next-item/recall_at_10': 0.06171875074505806, 'train_/next-item/recall_at_20': 0.09648437798023224, 'train_/loss': 9.205911636352539, 'train_runtime': 0.6408, 'train_samples_per_second': 3995.042, 'train_steps_per_second': 31.211}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [00:02<00:00, 38.82it/s]\n",
      "02/16/2023 03:09:42 - INFO - examples.t4rec_paper_experiments.t4r_paper_repro.exp_outputs -   ***** eval results (time index): 2)*****\n",
      "02/16/2023 03:09:42 - INFO - examples.t4rec_paper_experiments.t4r_paper_repro.exp_outputs -     eval_/loss = 9.29879093170166\n",
      "02/16/2023 03:09:42 - INFO - examples.t4rec_paper_experiments.t4r_paper_repro.exp_outputs -     eval_/next-item/ndcg_at_10 = 0.03531167283654213\n",
      "02/16/2023 03:09:42 - INFO - examples.t4rec_paper_experiments.t4r_paper_repro.exp_outputs -     eval_/next-item/ndcg_at_20 = 0.04438389092683792\n",
      "02/16/2023 03:09:42 - INFO - examples.t4rec_paper_experiments.t4r_paper_repro.exp_outputs -     eval_/next-item/recall_at_10 = 0.06984186172485352\n",
      "02/16/2023 03:09:42 - INFO - examples.t4rec_paper_experiments.t4r_paper_repro.exp_outputs -     eval_/next-item/recall_at_20 = 0.10598643869161606\n",
      "02/16/2023 03:09:42 - INFO - examples.t4rec_paper_experiments.t4r_paper_repro.exp_outputs -     eval_runtime = 2.2063\n",
      "02/16/2023 03:09:42 - INFO - examples.t4rec_paper_experiments.t4r_paper_repro.exp_outputs -     eval_samples_per_second = 4815.283\n",
      "02/16/2023 03:09:42 - INFO - examples.t4rec_paper_experiments.t4r_paper_repro.exp_outputs -     eval_steps_per_second = 37.619\n",
      "02/16/2023 03:09:42 - INFO - __main__ -   Computing and logging AOT (Average Over Time) metrics\n",
      "02/16/2023 03:09:42 - INFO - examples.t4rec_paper_experiments.t4r_paper_repro.exp_outputs -   ***** Eval results (avg over time) *****\n",
      "02/16/2023 03:09:42 - INFO - examples.t4rec_paper_experiments.t4r_paper_repro.exp_outputs -     eval_/loss_AOT = 9.29879093170166\n",
      "02/16/2023 03:09:42 - INFO - examples.t4rec_paper_experiments.t4r_paper_repro.exp_outputs -     eval_/next-item/ndcg_at_10_AOT = 0.03531167283654213\n",
      "02/16/2023 03:09:42 - INFO - examples.t4rec_paper_experiments.t4r_paper_repro.exp_outputs -     eval_/next-item/ndcg_at_20_AOT = 0.04438389092683792\n",
      "02/16/2023 03:09:42 - INFO - examples.t4rec_paper_experiments.t4r_paper_repro.exp_outputs -     eval_/next-item/recall_at_10_AOT = 0.06984186172485352\n",
      "02/16/2023 03:09:42 - INFO - examples.t4rec_paper_experiments.t4r_paper_repro.exp_outputs -     eval_/next-item/recall_at_20_AOT = 0.10598643869161606\n",
      "02/16/2023 03:09:42 - INFO - examples.t4rec_paper_experiments.t4r_paper_repro.exp_outputs -     eval_runtime_AOT = 2.2063\n",
      "02/16/2023 03:09:42 - INFO - examples.t4rec_paper_experiments.t4r_paper_repro.exp_outputs -     eval_samples_per_second_AOT = 4815.283\n",
      "02/16/2023 03:09:42 - INFO - examples.t4rec_paper_experiments.t4r_paper_repro.exp_outputs -     eval_steps_per_second_AOT = 37.619\n",
      "02/16/2023 03:09:42 - INFO - examples.t4rec_paper_experiments.t4r_paper_repro.exp_outputs -     train_/loss_AOT = 9.205911636352539\n",
      "02/16/2023 03:09:42 - INFO - examples.t4rec_paper_experiments.t4r_paper_repro.exp_outputs -     train_/next-item/ndcg_at_10_AOT = 0.03375788405537605\n",
      "02/16/2023 03:09:42 - INFO - examples.t4rec_paper_experiments.t4r_paper_repro.exp_outputs -     train_/next-item/ndcg_at_20_AOT = 0.042607784271240234\n",
      "02/16/2023 03:09:42 - INFO - examples.t4rec_paper_experiments.t4r_paper_repro.exp_outputs -     train_/next-item/recall_at_10_AOT = 0.06171875074505806\n",
      "02/16/2023 03:09:42 - INFO - examples.t4rec_paper_experiments.t4r_paper_repro.exp_outputs -     train_/next-item/recall_at_20_AOT = 0.09648437798023224\n",
      "02/16/2023 03:09:42 - INFO - examples.t4rec_paper_experiments.t4r_paper_repro.exp_outputs -     train_runtime_AOT = 0.6408\n",
      "02/16/2023 03:09:42 - INFO - examples.t4rec_paper_experiments.t4r_paper_repro.exp_outputs -     train_samples_per_second_AOT = 3995.042\n",
      "02/16/2023 03:09:42 - INFO - examples.t4rec_paper_experiments.t4r_paper_repro.exp_outputs -     train_steps_per_second_AOT = 31.211\n",
      "02/16/2023 03:09:42 - INFO - transformers4rec.torch.trainer -   ***** Running Prediction *****\n",
      "02/16/2023 03:09:42 - INFO - transformers4rec.torch.trainer -     Batch size = 128\n",
      "02/16/2023 03:09:42 - INFO - transformers4rec.torch.trainer -     Num sessions (examples) = 10752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Evaluation results for day 2 (eval set):*****\n",
      "\n",
      "{'eval_/next-item/ndcg_at_10': 0.03531167283654213, 'eval_/next-item/ndcg_at_20': 0.04438389092683792, 'eval_/next-item/recall_at_10': 0.06984186172485352, 'eval_/next-item/recall_at_20': 0.10598643869161606, 'eval_/loss': 9.29879093170166, 'eval_runtime': 2.2063, 'eval_samples_per_second': 4815.283, 'eval_steps_per_second': 37.619}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 83/84 [00:00<00:00, 85.70it/s]02/16/2023 03:09:43 - INFO - __main__ -   Recall@10 of manually masked test data = 0.06996426556328757\n",
      "100%|██████████| 84/84 [00:03<00:00, 22.67it/s]"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "FEATURE_SCHEMA_PATH=/workspace/examples/t4rec_paper_experiments/datasets_configs/ecom_rees46/rees46_schema.pbtxt\n",
    "DATA_PATH=/transformers4rec/examples/t4rec_paper_experiments/t4r_paper_repro/\n",
    "NUM_EPOCHS=1 # all the models in the papers were trained for 5 epochs\n",
    "\n",
    "# UNCOMMENT THE MODEL YOU'D LIKE TO TRAIN AND EXPORT\n",
    "\n",
    "### GPT-2 (CLM) - Item Id feature\n",
    "# python3 transf_exp_main_modified.py --output_dir ./tmp/ --overwrite_output_dir --do_train --do_eval --validate_every 10 --logging_steps 20 --save_steps 0 --data_path $DATA_PATH --features_schema_path $FEATURE_SCHEMA_PATH --fp16 --data_loader_engine merlin --start_time_window_index 1 --final_time_window_index 2 --time_window_folder_pad_digits 4 --model_type gpt2 --loss_type cross_entropy --per_device_eval_batch_size 128 --similarity_type concat_mlp --tf_out_activation tanh --inp_merge mlp --learning_rate_warmup_steps 0 --learning_rate_schedule linear_with_warmup --hidden_act gelu --num_train_epochs $NUM_EPOCHS --dataloader_drop_last --compute_metrics_each_n_steps 1 --session_seq_length_max 20 --eval_on_last_item_seq_only --mf_constrained_embeddings --layer_norm_featurewise --per_device_train_batch_size 128 --learning_rate 0.0008781937894379981 --dropout 0.2 --input_dropout 0.4 --weight_decay 1.4901138106122045e-05 --d_model 128 --item_embedding_dim 448 --n_layer 1 --n_head 1 --label_smoothing 0.9 --stochastic_shared_embeddings_replacement_prob 0.0 --item_id_embeddings_init_std 0.03 --other_embeddings_init_std 0.034999999999999996 --eval_on_test_set --seed 100 --report_to none\n",
    "\n",
    "### Transformer-XL (CLM) - Item Id feature\n",
    "# python3 transf_exp_main_modified.py --output_dir ./tmp/ --overwrite_output_dir --do_train --do_eval --validate_every 10 --logging_steps 20 --save_steps 0 --data_path $DATA_PATH --features_schema_path $FEATURE_SCHEMA_PATH --fp16 --data_loader_engine merlin --start_time_window_index 1 --final_time_window_index 2 --time_window_folder_pad_digits 4 --model_type transfoxl --loss_type cross_entropy --per_device_eval_batch_size 128 --similarity_type concat_mlp --tf_out_activation tanh --inp_merge mlp --learning_rate_warmup_steps 0 --learning_rate_schedule linear_with_warmup --hidden_act gelu --num_train_epochs $NUM_EPOCHS --dataloader_drop_last --compute_metrics_each_n_steps 1 --session_seq_length_max 20 --eval_on_last_item_seq_only --mf_constrained_embeddings --layer_norm_featurewise --per_device_train_batch_size 128 --learning_rate 0.001007765821083962 --dropout 0.1 --input_dropout 0.30000000000000004 --weight_decay 1.0673054163921092e-06 --d_model 448 --item_embedding_dim 320 --n_layer 1 --n_head 1 --label_smoothing 0.2 --stochastic_shared_embeddings_replacement_prob 0.02 --item_id_embeddings_init_std 0.15 --other_embeddings_init_std 0.01 --eval_on_test_set --seed 100 --report_to none\n",
    "\n",
    "### BERT (MLM) - Item Id feature\n",
    "# python3 transf_exp_main_modified.py --output_dir ./tmp/ --overwrite_output_dir --do_train --do_eval --validate_every 10 --logging_steps 20 --save_steps 0 --data_path $DATA_PATH --features_schema_path $FEATURE_SCHEMA_PATH --fp16 --data_loader_engine merlin --start_time_window_index 1 --final_time_window_index 2 --time_window_folder_pad_digits 4 --model_type albert --loss_type cross_entropy --per_device_eval_batch_size 128 --similarity_type concat_mlp --tf_out_activation tanh --inp_merge mlp --learning_rate_warmup_steps 0 --learning_rate_schedule linear_with_warmup --hidden_act gelu --num_train_epochs $NUM_EPOCHS --dataloader_drop_last --compute_metrics_each_n_steps 1 --session_seq_length_max 20 --eval_on_last_item_seq_only --mf_constrained_embeddings --layer_norm_featurewise --mlm --num_hidden_groups -1 --inner_group_num 1 --per_device_train_batch_size 128 --learning_rate 0.0004904752786458524 --dropout 0.0 --input_dropout 0.1 --weight_decay 9.565968888623912e-05 --d_model 320 --item_embedding_dim 320 --n_layer 2 --n_head 8 --label_smoothing 0.2 --stochastic_shared_embeddings_replacement_prob 0.06 --item_id_embeddings_init_std 0.11 --other_embeddings_init_std 0.025 --mlm_probability 0.6000000000000001 --eval_on_test_set --seed 100 --report_to none\n",
    "\n",
    "### XLNet (PLM) - Item Id feature\n",
    "# python3 transf_exp_main_modified.py --output_dir ./tmp/ --overwrite_output_dir --do_train --do_eval --validate_every 10 --logging_steps 20 --save_steps 0 --data_path $DATA_PATH --features_schema_path $FEATURE_SCHEMA_PATH --fp16 --data_loader_engine merlin --start_time_window_index 1 --final_time_window_index 2 --time_window_folder_pad_digits 4 --model_type xlnet --loss_type cross_entropy --per_device_eval_batch_size 128 --similarity_type concat_mlp --tf_out_activation tanh --inp_merge mlp --learning_rate_warmup_steps 0 --learning_rate_schedule linear_with_warmup --hidden_act gelu --num_train_epochs $NUM_EPOCHS --dataloader_drop_last --compute_metrics_each_n_steps 1 --session_seq_length_max 20 --eval_on_last_item_seq_only --mf_constrained_embeddings --layer_norm_featurewise --attn_type bi --plm --per_device_train_batch_size 128 --learning_rate 0.0003387925502203725 --dropout 0.0 --input_dropout 0.2 --weight_decay 2.1769664191492473e-05 --d_model 384 --item_embedding_dim 384 --n_layer 4 --n_head 16 --label_smoothing 0.7000000000000001 --stochastic_shared_embeddings_replacement_prob 0.02 --item_id_embeddings_init_std 0.13 --other_embeddings_init_std 0.005 --plm_probability 0.5 --plm_max_span_length 3 --eval_on_test_set --seed 100 --report_to none\n",
    "\n",
    "### XLNet (MLM) - Item Id feature\n",
    "python3 transf_exp_main_modified.py --output_dir ./tmp/ --overwrite_output_dir --do_train --do_eval --validate_every 10 --logging_steps 20 --save_steps 0 --data_path $DATA_PATH --features_schema_path $FEATURE_SCHEMA_PATH --fp16 --data_loader_engine merlin --start_time_window_index 1 --final_time_window_index 2 --time_window_folder_pad_digits 4 --model_type xlnet --loss_type cross_entropy --per_device_eval_batch_size 128 --similarity_type concat_mlp --tf_out_activation tanh --inp_merge mlp --learning_rate_warmup_steps 0 --learning_rate_schedule linear_with_warmup --hidden_act gelu --num_train_epochs $NUM_EPOCHS --dataloader_drop_last --compute_metrics_each_n_steps 1 --session_seq_length_max 20 --eval_on_last_item_seq_only --mf_constrained_embeddings --layer_norm_featurewise --attn_type bi --mlm --per_device_train_batch_size 128 --learning_rate 0.0006667377132554976 --dropout 0.0 --input_dropout 0.1 --weight_decay 3.910060265627374e-05 --d_model 192 --item_embedding_dim 448 --n_layer 3 --n_head 16 --label_smoothing 0.0 --stochastic_shared_embeddings_replacement_prob 0.1 --item_id_embeddings_init_std 0.11 --other_embeddings_init_std 0.02 --mlm_probability 0.30000000000000004 --eval_on_test_set --seed 100 --report_to none\n",
    "\n",
    "### XLNET (MLM) - CONCAT + SOFT ONE-HOT ENCODING - All features\n",
    "# python3 transf_exp_main_modified.py --output_dir ./tmp/ --overwrite_output_dir --do_train --do_eval --validate_every 10 --logging_steps 20 --save_steps 0 --data_path $DATA_PATH --features_schema_path $FEATURE_SCHEMA_PATH --fp16 --data_loader_engine merlin --start_time_window_index 1 --final_time_window_index 2 --time_window_folder_pad_digits 4 --model_type xlnet --loss_type cross_entropy --per_device_eval_batch_size 128 --similarity_type concat_mlp --tf_out_activation tanh --inp_merge mlp --learning_rate_warmup_steps 0 --learning_rate_schedule linear_with_warmup --hidden_act gelu --num_train_epochs $NUM_EPOCHS --dataloader_drop_last --compute_metrics_each_n_steps 1 --session_seq_length_max 20 --eval_on_last_item_seq_only --mf_constrained_embeddings --layer_norm_featurewise --attn_type bi --mlm --input_features_aggregation concat --per_device_train_batch_size 128 --learning_rate 0.00034029107417129616 --dropout 0.0 --input_dropout 0.1 --weight_decay 3.168336235732841e-05 --d_model 448 --item_embedding_dim 384 --n_layer 2 --n_head 8 --label_smoothing 0.6000000000000001 --stochastic_shared_embeddings_replacement_prob 0.0 --item_id_embeddings_init_std 0.06999999999999999 --other_embeddings_init_std 0.085 --mlm_probability 0.30000000000000004 --embedding_dim_from_cardinality_multiplier 1.0 --numeric_features_project_to_embedding_dim 20 --numeric_features_soft_one_hot_encoding_num_embeddings 5 --eval_on_test_set --seed 100 --use_side_information_features --report_to none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0af515e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -rf /workspace/models_for_benchmarking/t4r_pytorch /workspace/models_for_benchmarking/t4r_pytorch_nvt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c65f9a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /workspace/models_for_benchmarking/t4r_pytorch_pt/config.pbtxt\n"
     ]
    }
   ],
   "source": [
    "%%writefile /workspace/models_for_benchmarking/t4r_pytorch_pt/config.pbtxt\n",
    "\n",
    "name: \"t4r_pytorch_pt\"\n",
    "input {\n",
    "  name: \"sess_pid_seq__values\"\n",
    "  data_type: TYPE_INT64\n",
    "  dims: -1\n",
    "  dims: 1\n",
    "}\n",
    "input {\n",
    "  name: \"sess_pid_seq__nnzs\"\n",
    "  data_type: TYPE_INT64\n",
    "  dims: -1\n",
    "  dims: 1\n",
    "}\n",
    "output {\n",
    "  name: \"output\"\n",
    "  data_type: TYPE_FP32\n",
    "  dims: -1\n",
    "  dims: 20\n",
    "}\n",
    "backend: \"python\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9964a2cc",
   "metadata": {},
   "source": [
    "For running on the CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d61fe61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /workspace/models_for_benchmarking/t4r_pytorch_pt/config.pbtxt\n"
     ]
    }
   ],
   "source": [
    "%%writefile /workspace/models_for_benchmarking/t4r_pytorch_pt/config.pbtxt\n",
    "\n",
    "name: \"t4r_pytorch_pt\"\n",
    "instance_group [\n",
    "    {\n",
    "      count: 1\n",
    "      kind: KIND_CPU\n",
    "    }\n",
    "]\n",
    "input {\n",
    "  name: \"sess_pid_seq__values\"\n",
    "  data_type: TYPE_INT64\n",
    "  dims: -1\n",
    "  dims: 1\n",
    "}\n",
    "input {\n",
    "  name: \"sess_pid_seq__nnzs\"\n",
    "  data_type: TYPE_INT64\n",
    "  dims: -1\n",
    "  dims: 1\n",
    "}\n",
    "output {\n",
    "  name: \"output\"\n",
    "  data_type: TYPE_FP32\n",
    "  dims: -1\n",
    "  dims: 20\n",
    "}\n",
    "backend: \"python\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ba822c",
   "metadata": {},
   "source": [
    "You can control whether you would like to run on the GPU or the CPU by setting the environment variable `HAS_GPU` to either 0 or 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3a346b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /workspace/models_for_benchmarking/t4r_pytorch_pt/1/model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /workspace/models_for_benchmarking/t4r_pytorch_pt/1/model.py\n",
    "\n",
    "# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.\n",
    "#\n",
    "# Redistribution and use in source and binary forms, with or without\n",
    "# modification, are permitted provided that the following conditions\n",
    "# are met:\n",
    "#  * Redistributions of source code must retain the above copyright\n",
    "#    notice, this list of conditions and the following disclaimer.\n",
    "#  * Redistributions in binary form must reproduce the above copyright\n",
    "#    notice, this list of conditions and the following disclaimer in the\n",
    "#    documentation and/or other materials provided with the distribution.\n",
    "#  * Neither the name of NVIDIA CORPORATION nor the names of its\n",
    "#    contributors may be used to endorse or promote products derived\n",
    "#    from this software without specific prior written permission.\n",
    "#\n",
    "# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY\n",
    "# EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n",
    "# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR\n",
    "# PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR\n",
    "# CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,\n",
    "# EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,\n",
    "# PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR\n",
    "# PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY\n",
    "# OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n",
    "# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n",
    "# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
    "\n",
    "import json\n",
    "import logging\n",
    "import pathlib\n",
    "\n",
    "import cloudpickle\n",
    "import pickle\n",
    "import io\n",
    "import os\n",
    "import torch\n",
    "import triton_python_backend_utils as pb_utils\n",
    "\n",
    "from nvtabular.inference.triton import _convert_string2pytorch_dtype, _convert_tensor\n",
    "from merlin.core.dispatch import HAS_GPU\n",
    "\n",
    "LOG = logging.getLogger(\"nvtabular\")\n",
    "\n",
    "sparse_value_marker = \"__values\"\n",
    "sparse_nnzs_marker = \"__nnzs\"\n",
    "\n",
    "HAS_GPU = os.environ['HAS_GPU'] == '1'\n",
    "\n",
    "\n",
    "class CPU_Unpickler(pickle.Unpickler):\n",
    "    def find_class(self, module, name):\n",
    "        print(super().find_class(module, name))\n",
    "        if module == 'torch.storage' and name == '_load_from_bytes':\n",
    "            return lambda b: torch.load(io.BytesIO(b), map_location=torch.device('cpu'))\n",
    "        else:\n",
    "            return super().find_class(module, name)\n",
    "\n",
    "class TritonPythonModel:\n",
    "    \"\"\"Generic TritonPythonModel for nvtabular workflows\"\"\"\n",
    "\n",
    "    def initialize(self, args):\n",
    "        # Arg parsing\n",
    "        repository_path = pathlib.Path(args[\"model_repository\"])\n",
    "        model_version = str(args[\"model_version\"])\n",
    "\n",
    "        # Handle bug in Tritonserver 22.06\n",
    "        # model_repository argument became path to model.py\n",
    "        if str(repository_path).endswith(\".py\"):\n",
    "            repository_path = repository_path.parent.parent\n",
    "\n",
    "        model_path = repository_path / model_version / \"model.pkl\"\n",
    "\n",
    "        # Load the pickled PyTorch model\n",
    "        if HAS_GPU:\n",
    "            self.model = cloudpickle.load(\n",
    "                open(str(model_path), \"rb\")  # pylint: disable=consider-using-with\n",
    "            )\n",
    "            model_path = repository_path / model_version / \"model.pth\"\n",
    "            self.model.load_state_dict(torch.load(str(model_path)))\n",
    "        else:\n",
    "            self.model = CPU_Unpickler(open(str(model_path), \"rb\")).load()\n",
    "            model_path = repository_path / model_version / \"model.pth\"\n",
    "            self.model.load_state_dict(torch.load(str(model_path), map_location='cpu'))\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "        # Load model config file\n",
    "        self.model_config = json.loads(args[\"model_config\"])\n",
    "\n",
    "        # Load extra info needed for the Transformer4Rec (if exists)\n",
    "        model_info_path = repository_path / model_version / \"model_info.json\"\n",
    "        self.model_info = None\n",
    "        model_info_file = pathlib.Path(model_info_path)\n",
    "        if model_info_file.exists():\n",
    "            with open(str(model_info_path), encoding=\"utf-8\") as json_file:\n",
    "                self.model_info = json.load(json_file)\n",
    "\n",
    "        # Get the name of the dense and sparse inputs, and the outputs\n",
    "        self.inputs = {}\n",
    "        self.sparse_inputs = {}\n",
    "        self.outputs = {}\n",
    "        len_svm = len(sparse_value_marker)\n",
    "        len_snm = len(sparse_nnzs_marker)\n",
    "\n",
    "        for val in self.model_config[\"input\"]:\n",
    "            name = val[\"name\"]\n",
    "\n",
    "            # NVTabular adds this specific marker \"__values\" into the name of the sparse inputs\n",
    "            # The ones that has the marker \"__nnzs\" are for the sparse values\n",
    "            # Hence, dense and sparse inputs are identified based on these markers\n",
    "            if len(name) > len_svm:\n",
    "                if name[-len_svm:] == sparse_value_marker:\n",
    "                    self.sparse_inputs[\n",
    "                        name[0 : (len(name) - len_svm)]\n",
    "                    ] = _convert_string2pytorch_dtype(val[\"data_type\"])\n",
    "                elif name[-len_snm:] != sparse_nnzs_marker:\n",
    "                    self.inputs[name] = _convert_string2pytorch_dtype(val[\"data_type\"])\n",
    "            else:\n",
    "                if len(name) > len_snm:\n",
    "                    if name[-len_snm:] != sparse_nnzs_marker:\n",
    "                        self.inputs[name] = _convert_string2pytorch_dtype(val[\"data_type\"])\n",
    "                else:\n",
    "                    self.inputs[name] = _convert_string2pytorch_dtype(val[\"data_type\"])\n",
    "\n",
    "        for val in self.model_config[\"output\"]:\n",
    "            self.outputs[val[\"name\"]] = _convert_string2pytorch_dtype(val[\"data_type\"])\n",
    "\n",
    "    def execute(self, requests):\n",
    "        \"\"\"Predicts the input batches by running through a PyTorch predict function.\"\"\"\n",
    "\n",
    "        # To be able to execute the queries, the PyTorch model must accept a dict input\n",
    "        # and generates a dict output that has the output in the the \"predictions\"\n",
    "        # bucket. Otherwise, it'll throw an error.\n",
    "\n",
    "        with torch.no_grad():\n",
    "            responses = []\n",
    "            for request in requests:\n",
    "                # Convert the input data to dict to pass it into the PyTorch model\n",
    "                input_dict = {}\n",
    "                for name, dtype in self.inputs.items():\n",
    "                    # Convert to fixed dtypes if requested\n",
    "                    if self.model_info[\"use_fix_dtypes\"]:\n",
    "                        dtype = _convert_dtype(dtype)\n",
    "                    input_dict[name] = torch.tensor(\n",
    "                        _convert_tensor(pb_utils.get_input_tensor_by_name(request, name)),\n",
    "                        dtype=dtype,\n",
    "                    ).cuda()\n",
    "\n",
    "                # Sparse inputs have a special format\n",
    "                for name, dtype in self.sparse_inputs.items():\n",
    "\n",
    "                    # Get __values and __nnzs\n",
    "                    input_val = _convert_tensor(\n",
    "                        pb_utils.get_input_tensor_by_name(request, name + sparse_value_marker)\n",
    "                    )\n",
    "                    input_nnzs = _convert_tensor(\n",
    "                        pb_utils.get_input_tensor_by_name(request, name + sparse_nnzs_marker)\n",
    "                    )\n",
    "                    input_nnzs = torch.tensor(input_nnzs, dtype=torch.int64)\n",
    "                    input_values = torch.tensor(input_val, dtype=dtype)\n",
    "\n",
    "                    # Get the PyTorch sparse_coo_tensor\n",
    "                    sparse_to_dense = False\n",
    "                    seq_limit = 0\n",
    "                    if self.model_info is not None:\n",
    "                        if self.model_info[\"sparse_max\"].get(name) is not None:\n",
    "                            sparse_to_dense = True\n",
    "                            seq_limit = self.model_info[\"sparse_max\"][name]\n",
    "\n",
    "                    if seq_limit == 0:\n",
    "                        seq_limit = int(input_nnzs.max())\n",
    "\n",
    "                    input_dict[name] = _build_sparse_tensor(\n",
    "                        input_values, input_nnzs, seq_limit, sparse_to_dense\n",
    "                    )\n",
    "\n",
    "                # Call forward function to get the predictions\n",
    "                # Forward function should return a dict with the \"predictions\" bucket\n",
    "                pred = self.model(input_dict, training=False)\n",
    "                if pred is None:\n",
    "                    raise KeyError(\n",
    "                        \"output of the forward function should have a bucket named as predictions\"\n",
    "                    )\n",
    "\n",
    "\t\t\t\t#place holder for testing. \n",
    "                pred_numpy = (torch.topk(pred.detach(),20).indices).cpu().numpy()\n",
    "                # There is one output in the config file\n",
    "                # since the PyTorch models generate a tensor as an output\n",
    "                output_info = self.model_config[\"output\"][0]\n",
    "                output_tensor = pb_utils.Tensor(output_info[\"name\"], pred_numpy)\n",
    "                responses.append(pb_utils.InferenceResponse([output_tensor]))\n",
    "                \n",
    "                # pred_numpy = pred.cpu().detach().numpy()\n",
    "\n",
    "                # There is one output in the config file\n",
    "                # since the PyTorch models generate a tensor as an output\n",
    "                # output_info = self.model_config[\"output\"][0]\n",
    "                # output_tensor = pb_utils.Tensor(output_info[\"name\"], pred_numpy)\n",
    "                # responses.append(pb_utils.InferenceResponse([output_tensor]))\n",
    "\n",
    "        return responses\n",
    "\n",
    "\n",
    "def _get_indices(nnzs, device=\"cuda\"):\n",
    "    \"\"\"Calculate indices for the PyTorch sparse_coo_tensor\"\"\"\n",
    "    nnzs = nnzs[:, 0]\n",
    "    row_ids = torch.arange(len(nnzs)-1)\n",
    "    offsets = nnzs[1:]\n",
    "    offsets[1:] = offsets[1:] - offsets[:-1]\n",
    "    row_ids_repeated = torch.repeat_interleave(row_ids, offsets)\n",
    "    offsets_cols = nnzs[:-1]\n",
    "    offsets_cols = torch.repeat_interleave(offsets_cols.cumsum(0), offsets)\n",
    "    col_ids = torch.arange(len(row_ids_repeated)) - offsets_cols\n",
    "    indices = torch.cat([row_ids_repeated.unsqueeze(-1), col_ids.unsqueeze(-1)], axis=1)\n",
    "    return indices.T\n",
    "\n",
    "    offsets = torch.cat((torch.tensor([1]), nnzs), 0)\n",
    "    offsets = offsets.cumsum(0)\n",
    "    row_ids = torch.arange(len(offsets) - 1)\n",
    "    row_ids_repeated = torch.repeat_interleave(row_ids, nnzs)\n",
    "    row_offset_repeated = torch.repeat_interleave(offsets[:-1], nnzs)\n",
    "    col_ids = torch.arange(len(row_offset_repeated)) - row_offset_repeated + 1\n",
    "    indices = torch.cat([row_ids_repeated.unsqueeze(-1), col_ids.unsqueeze(-1)], axis=1)\n",
    "    return indices.T\n",
    "\n",
    "\n",
    "def _get_sparse_tensor(values, indices, num_rows, seq_limit, sparse_as_dense, device=\"cuda\"):\n",
    "    \"\"\"Creates the PyTorch sparse_coo_tensor\"\"\"\n",
    "    \n",
    "    if HAS_GPU:\n",
    "        device='cuda'\n",
    "    else:\n",
    "        device='cpu'\n",
    "    \n",
    "    sparse_tensor = torch.sparse_coo_tensor(\n",
    "        indices, values.squeeze(), torch.Size([num_rows-1, seq_limit]), device=device\n",
    "    )\n",
    "    if sparse_as_dense:\n",
    "        sparse_tensor = sparse_tensor.to_dense()\n",
    "    return sparse_tensor\n",
    "\n",
    "\n",
    "def _build_sparse_tensor(values, nnzs, seq_limit, sparse_as_dense, device=\"cuda\"):\n",
    "    \"\"\"Builds PyTorch sparse_coo_tensor by converting the __values and __nnzs inputs\"\"\"\n",
    "    indices = _get_indices(nnzs, device)\n",
    "    num_rows = len(nnzs)\n",
    "    return _get_sparse_tensor(values, indices, num_rows, seq_limit, sparse_as_dense, device)\n",
    "\n",
    "\n",
    "def _convert_dtype(dtype):\n",
    "    \"\"\"Transformer4Rec uses these fixed dtypes and this function converts the original dtype\n",
    "    to this fixed dtypes\"\"\"\n",
    "    if dtype in [torch.float64, torch.float32, torch.float16]:\n",
    "        return torch.float32\n",
    "    if dtype in [\n",
    "        torch.int64,\n",
    "        torch.int32,\n",
    "        torch.int16,\n",
    "        torch.int8,\n",
    "        torch.uint8,\n",
    "    ]:\n",
    "        return torch.long\n",
    "\n",
    "    raise ValueError(f\"Can't convert dtype {dtype})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
